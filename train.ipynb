{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "640e0dec",
   "metadata": {},
   "source": [
    "# 安装记录\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf67f5fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T15:18:53.084234Z",
     "start_time": "2022-07-09T15:18:53.067310Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12601/546636996.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInfoNCE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpositive_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#!pip install tb-nightly\n",
    "\n",
    "#LXMERT\n",
    "#!pip install boto3\n",
    "#!pip install info-nce-pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b137ac3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T15:19:17.491847Z",
     "start_time": "2022-07-09T15:19:17.479621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5422)\n"
     ]
    }
   ],
   "source": [
    "from info_nce import InfoNCE\n",
    "import torch\n",
    "loss = InfoNCE()\n",
    "batch_size, embedding_size = 32, 128\n",
    "query = torch.randn(batch_size, embedding_size)\n",
    "positive_key = torch.randn(batch_size, embedding_size)\n",
    "output = loss(query, positive_key)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "471a272b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T16:33:31.181091Z",
     "start_time": "2022-04-15T16:33:29.709211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "dump done!\n"
     ]
    }
   ],
   "source": [
    "%cd code\n",
    "!python ./deal_data.py --exp_name data_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdd47858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T08:36:26.959504Z",
     "start_time": "2022-03-08T08:36:24.637982Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1925/1462503502.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error, print_error_to)\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdownload_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1115\u001b[0m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m                 \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0;34m\"q) Quit\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m             )\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloader> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m         )\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52a9a332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T12:38:06.636462Z",
     "start_time": "2022-08-10T10:10:04.181983Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 08/10/22 18:10:06 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 08/10/22 18:10:06 - 0:00:00 - The experiment will be stored in dump/0810-knowledge_space/W2V\n",
      "                                     \n",
      "INFO - 08/10/22 18:10:06 - 0:00:00 - Running command: python main.py --gpu_id 6 --exp_name knowledge_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --save_model 1\n",
      "\n",
      "2022-08-10 18:10:07.163950: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-08-10 18:10:07.164019: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 128\n",
      "batch_size 128\n",
      "fusion_model:\n",
      "SAN(\n",
      "  (w_emb): WordEmbedding(\n",
      "    (emb): Embedding(15422, 300, padding_idx=15421)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (text): Seq2SeqRNN(\n",
      "    (rnn): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (attention): SanAttention(\n",
      "    (v_conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (q_lin): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (x_conv): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(5120, 8192, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(8192, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "Answer Model:\n",
      "MLP(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "train E000: 100% 21/21 [00:23<00:00,  1.10s/it]\n",
      "INFO - 08/10/22 18:10:48 - 0:00:42 - Train Epoch 0: LOSS= 5.46905, lr= 0.000500, acc1= 13.45,acc3= 24.43,acc10= 38.74\n",
      "train E001: 100% 21/21 [00:25<00:00,  1.20s/it]\n",
      "INFO - 08/10/22 18:11:14 - 0:01:07 - Train Epoch 1: LOSS= 2.42018, lr= 0.000750, acc1= 45.19,acc3= 62.72,acc10= 79.77\n",
      "eval E001: 100% 23/23 [00:25<00:00,  1.12s/it]\n",
      "INFO - 08/10/22 18:11:39 - 0:01:33 - #################################################################################################################\n",
      "INFO - 08/10/22 18:11:39 - 0:01:33 - Test Epoch 1: LOSS= 2.84795, acc1= 38.08, acc3= 58.24, acc10= 76.16\n",
      "INFO - 08/10/22 18:11:39 - 0:01:33 - #################################################################################################################\n",
      "train E002: 100% 21/21 [00:21<00:00,  1.03s/it]\n",
      "INFO - 08/10/22 18:12:01 - 0:01:55 - Train Epoch 2: LOSS= 1.49742, lr= 0.001000, acc1= 62.57,acc3= 80.97,acc10= 91.57\n",
      "eval E002: 100% 23/23 [00:19<00:00,  1.16it/s]\n",
      "INFO - 08/10/22 18:12:21 - 0:02:14 - #################################################################################################################\n",
      "INFO - 08/10/22 18:12:21 - 0:02:14 - Test Epoch 2: LOSS= 2.72619, acc1= 41.23, acc3= 59.94, acc10= 76.55\n",
      "INFO - 08/10/22 18:12:21 - 0:02:14 - #################################################################################################################\n",
      "train E003: 100% 21/21 [00:21<00:00,  1.03s/it]\n",
      "INFO - 08/10/22 18:12:42 - 0:02:36 - Train Epoch 3: LOSS= 1.08465, lr= 0.001250, acc1= 71.56,acc3= 88.01,acc10= 95.54\n",
      "eval E003: 100% 23/23 [00:20<00:00,  1.12it/s]\n",
      "INFO - 08/10/22 18:13:03 - 0:02:56 - #################################################################################################################\n",
      "INFO - 08/10/22 18:13:03 - 0:02:56 - Test Epoch 3: LOSS= 2.78568, acc1= 43.71, acc3= 63.05, acc10= 78.53\n",
      "INFO - 08/10/22 18:13:03 - 0:02:56 - #################################################################################################################\n",
      "train E004: 100% 21/21 [00:22<00:00,  1.06s/it]\n",
      "INFO - 08/10/22 18:13:25 - 0:03:19 - Train Epoch 4: LOSS= 0.88162, lr= 0.001500, acc1= 75.50,acc3= 91.53,acc10= 97.56\n",
      "eval E004: 100% 23/23 [00:21<00:00,  1.06it/s]\n",
      "INFO - 08/10/22 18:13:47 - 0:03:41 - #################################################################################################################\n",
      "INFO - 08/10/22 18:13:47 - 0:03:41 - Test Epoch 4: LOSS= 3.31390, acc1= 41.37, acc3= 60.72, acc10= 77.61\n",
      "INFO - 08/10/22 18:13:47 - 0:03:41 - #################################################################################################################\n",
      "train E005: 100% 21/21 [00:23<00:00,  1.10s/it]\n",
      "INFO - 08/10/22 18:14:10 - 0:04:04 - Train Epoch 5: LOSS= 0.80970, lr= 0.001750, acc1= 78.46,acc3= 92.66,acc10= 98.09\n",
      "eval E005: 100% 23/23 [00:24<00:00,  1.07s/it]\n",
      "INFO - 08/10/22 18:14:35 - 0:04:28 - #################################################################################################################\n",
      "INFO - 08/10/22 18:14:35 - 0:04:28 - Test Epoch 5: LOSS= 3.62645, acc1= 41.09, acc3= 59.97, acc10= 75.66\n",
      "INFO - 08/10/22 18:14:35 - 0:04:28 - #################################################################################################################\n",
      "train E006: 100% 21/21 [00:20<00:00,  1.03it/s]\n",
      "INFO - 08/10/22 18:14:55 - 0:04:49 - Train Epoch 6: LOSS= 0.95289, lr= 0.002000, acc1= 76.51,acc3= 90.86,acc10= 97.41\n",
      "eval E006: 100% 23/23 [00:22<00:00,  1.01it/s]\n",
      "INFO - 08/10/22 18:15:18 - 0:05:11 - #################################################################################################################\n",
      "INFO - 08/10/22 18:15:18 - 0:05:11 - Test Epoch 6: LOSS= 4.28457, acc1= 41.06, acc3= 57.17, acc10= 72.62\n",
      "INFO - 08/10/22 18:15:18 - 0:05:11 - #################################################################################################################\n",
      "train E007: 100% 21/21 [00:22<00:00,  1.05s/it]\n",
      "INFO - 08/10/22 18:15:40 - 0:05:34 - Train Epoch 7: LOSS= 1.01598, lr= 0.002000, acc1= 76.28,acc3= 90.30,acc10= 97.75\n",
      "eval E007: 100% 23/23 [00:23<00:00,  1.02s/it]\n",
      "INFO - 08/10/22 18:16:03 - 0:05:57 - #################################################################################################################\n",
      "INFO - 08/10/22 18:16:03 - 0:05:57 - Test Epoch 7: LOSS= 4.03831, acc1= 39.14, acc3= 56.82, acc10= 73.96\n",
      "INFO - 08/10/22 18:16:03 - 0:05:57 - #################################################################################################################\n",
      "train E008: 100% 21/21 [00:18<00:00,  1.13it/s]\n",
      "INFO - 08/10/22 18:16:22 - 0:06:16 - Train Epoch 8: LOSS= 0.78581, lr= 0.002000, acc1= 81.08,acc3= 93.52,acc10= 98.16\n",
      "eval E008: 100% 23/23 [00:19<00:00,  1.16it/s]\n",
      "INFO - 08/10/22 18:16:42 - 0:06:36 - #################################################################################################################\n",
      "INFO - 08/10/22 18:16:42 - 0:06:36 - Test Epoch 8: LOSS= 4.65056, acc1= 37.58, acc3= 56.75, acc10= 74.81\n",
      "INFO - 08/10/22 18:16:42 - 0:06:36 - #################################################################################################################\n",
      "train E009: 100% 21/21 [00:19<00:00,  1.09it/s]\n",
      "INFO - 08/10/22 18:17:01 - 0:06:55 - Train Epoch 9: LOSS= 0.65423, lr= 0.002000, acc1= 84.15,acc3= 95.13,acc10= 98.80\n",
      "eval E009: 100% 23/23 [00:21<00:00,  1.07it/s]\n",
      "INFO - 08/10/22 18:17:23 - 0:07:16 - #################################################################################################################\n",
      "INFO - 08/10/22 18:17:23 - 0:07:16 - Test Epoch 9: LOSS= 4.60677, acc1= 39.14, acc3= 56.85, acc10= 72.76\n",
      "INFO - 08/10/22 18:17:23 - 0:07:16 - #################################################################################################################\n",
      "train E010: 100% 21/21 [00:20<00:00,  1.01it/s]\n",
      "INFO - 08/10/22 18:17:44 - 0:07:37 - Train Epoch 10: LOSS= 0.58838, lr= 0.002000, acc1= 86.44,acc3= 96.25,acc10= 99.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E010: 100% 23/23 [00:19<00:00,  1.18it/s]\n",
      "INFO - 08/10/22 18:18:03 - 0:07:57 - #################################################################################################################\n",
      "INFO - 08/10/22 18:18:03 - 0:07:57 - Test Epoch 10: LOSS= 4.67159, acc1= 39.11, acc3= 57.00, acc10= 73.75\n",
      "INFO - 08/10/22 18:18:03 - 0:07:57 - #################################################################################################################\n",
      "train E011: 100% 21/21 [00:21<00:00,  1.02s/it]\n",
      "INFO - 08/10/22 18:18:25 - 0:08:18 - Train Epoch 11: LOSS= 0.59081, lr= 0.002000, acc1= 86.36,acc3= 96.14,acc10= 98.88\n",
      "eval E011: 100% 23/23 [00:22<00:00,  1.04it/s]\n",
      "INFO - 08/10/22 18:18:47 - 0:08:40 - #################################################################################################################\n",
      "INFO - 08/10/22 18:18:47 - 0:08:40 - Test Epoch 11: LOSS= 4.73832, acc1= 42.47, acc3= 58.66, acc10= 75.66\n",
      "INFO - 08/10/22 18:18:47 - 0:08:40 - #################################################################################################################\n",
      "train E012: 100% 21/21 [00:21<00:00,  1.01s/it]\n",
      "INFO - 08/10/22 18:19:08 - 0:09:02 - Train Epoch 12: LOSS= 0.51735, lr= 0.002000, acc1= 87.22,acc3= 96.97,acc10= 99.21\n",
      "eval E012: 100% 23/23 [00:21<00:00,  1.09it/s]\n",
      "INFO - 08/10/22 18:19:29 - 0:09:23 - #################################################################################################################\n",
      "INFO - 08/10/22 18:19:29 - 0:09:23 - Test Epoch 12: LOSS= 4.79160, acc1= 42.47, acc3= 59.02, acc10= 74.03\n",
      "INFO - 08/10/22 18:19:29 - 0:09:23 - #################################################################################################################\n",
      "train E013: 100% 21/21 [00:23<00:00,  1.13s/it]\n",
      "INFO - 08/10/22 18:19:53 - 0:09:47 - Train Epoch 13: LOSS= 0.56313, lr= 0.002000, acc1= 88.27,acc3= 96.67,acc10= 98.91\n",
      "eval E013: 100% 23/23 [00:22<00:00,  1.03it/s]\n",
      "INFO - 08/10/22 18:20:15 - 0:10:09 - #################################################################################################################\n",
      "INFO - 08/10/22 18:20:15 - 0:10:09 - Test Epoch 13: LOSS= 5.03733, acc1= 40.63, acc3= 57.81, acc10= 72.37\n",
      "INFO - 08/10/22 18:20:15 - 0:10:09 - #################################################################################################################\n",
      "train E014: 100% 21/21 [00:23<00:00,  1.11s/it]\n",
      "INFO - 08/10/22 18:20:39 - 0:10:32 - Train Epoch 14: LOSS= 0.35818, lr= 0.001400, acc1= 90.52,acc3= 98.16,acc10= 99.59\n",
      "eval E014: 100% 23/23 [00:20<00:00,  1.12it/s]\n",
      "INFO - 08/10/22 18:20:59 - 0:10:53 - #################################################################################################################\n",
      "INFO - 08/10/22 18:20:59 - 0:10:53 - Test Epoch 14: LOSS= 4.81191, acc1= 41.76, acc3= 59.83, acc10= 77.12\n",
      "INFO - 08/10/22 18:20:59 - 0:10:53 - #################################################################################################################\n",
      "train E015: 100% 21/21 [00:23<00:00,  1.14s/it]\n",
      "INFO - 08/10/22 18:21:23 - 0:11:17 - Train Epoch 15: LOSS= 0.23780, lr= 0.001400, acc1= 93.48,acc3= 99.33,acc10= 99.93\n",
      "eval E015: 100% 23/23 [00:22<00:00,  1.04it/s]\n",
      "INFO - 08/10/22 18:21:45 - 0:11:39 - #################################################################################################################\n",
      "INFO - 08/10/22 18:21:45 - 0:11:39 - Test Epoch 15: LOSS= 4.96933, acc1= 44.00, acc3= 60.82, acc10= 75.84\n",
      "INFO - 08/10/22 18:21:45 - 0:11:39 - #################################################################################################################\n",
      "train E016: 100% 21/21 [00:21<00:00,  1.02s/it]\n",
      "INFO - 08/10/22 18:22:07 - 0:12:00 - Train Epoch 16: LOSS= 0.20942, lr= 0.001400, acc1= 95.02,acc3= 99.06,acc10= 99.81\n",
      "eval E016: 100% 23/23 [00:22<00:00,  1.04it/s]\n",
      "INFO - 08/10/22 18:22:29 - 0:12:23 - #################################################################################################################\n",
      "INFO - 08/10/22 18:22:29 - 0:12:23 - Test Epoch 16: LOSS= 4.76558, acc1= 44.85, acc3= 62.59, acc10= 78.25\n",
      "INFO - 08/10/22 18:22:29 - 0:12:23 - #################################################################################################################\n",
      "train E017: 100% 21/21 [00:19<00:00,  1.07it/s]\n",
      "INFO - 08/10/22 18:22:49 - 0:12:42 - Train Epoch 17: LOSS= 0.14411, lr= 0.000980, acc1= 96.40,acc3= 99.59,acc10= 99.93\n",
      "eval E017: 100% 23/23 [00:22<00:00,  1.02it/s]\n",
      "INFO - 08/10/22 18:23:11 - 0:13:05 - #################################################################################################################\n",
      "INFO - 08/10/22 18:23:11 - 0:13:05 - Test Epoch 17: LOSS= 4.95806, acc1= 44.95, acc3= 63.23, acc10= 78.04\n",
      "INFO - 08/10/22 18:23:11 - 0:13:05 - #################################################################################################################\n",
      "train E018: 100% 21/21 [00:20<00:00,  1.01it/s]\n",
      "INFO - 08/10/22 18:23:32 - 0:13:26 - Train Epoch 18: LOSS= 0.12506, lr= 0.000980, acc1= 97.12,acc3= 99.70,acc10= 99.96\n",
      "eval E018: 100% 23/23 [00:19<00:00,  1.21it/s]\n",
      "INFO - 08/10/22 18:23:51 - 0:13:45 - #################################################################################################################\n",
      "INFO - 08/10/22 18:23:51 - 0:13:45 - Test Epoch 18: LOSS= 4.67570, acc1= 45.38, acc3= 63.41, acc10= 79.28\n",
      "INFO - 08/10/22 18:23:51 - 0:13:45 - #################################################################################################################\n",
      "train E019: 100% 21/21 [00:23<00:00,  1.13s/it]\n",
      "INFO - 08/10/22 18:24:15 - 0:14:08 - Train Epoch 19: LOSS= 0.09360, lr= 0.000980, acc1= 97.94,acc3= 99.78,acc10= 99.93\n",
      "eval E019: 100% 23/23 [00:22<00:00,  1.02it/s]\n",
      "INFO - 08/10/22 18:24:37 - 0:14:31 - #################################################################################################################\n",
      "INFO - 08/10/22 18:24:37 - 0:14:31 - Test Epoch 19: LOSS= 4.83684, acc1= 44.63, acc3= 64.08, acc10= 78.57\n",
      "INFO - 08/10/22 18:24:37 - 0:14:31 - #################################################################################################################\n",
      "train E020: 100% 21/21 [00:19<00:00,  1.06it/s]\n",
      "INFO - 08/10/22 18:24:57 - 0:14:51 - Train Epoch 20: LOSS= 0.07838, lr= 0.000686, acc1= 98.28,acc3= 99.85,acc10= 99.96\n",
      "eval E020: 100% 23/23 [00:23<00:00,  1.03s/it]\n",
      "INFO - 08/10/22 18:25:21 - 0:15:14 - #################################################################################################################\n",
      "INFO - 08/10/22 18:25:21 - 0:15:14 - Test Epoch 20: LOSS= 4.48041, acc1= 46.48, acc3= 65.32, acc10= 78.89\n",
      "INFO - 08/10/22 18:25:21 - 0:15:14 - #################################################################################################################\n",
      "train E021: 100% 21/21 [00:24<00:00,  1.17s/it]\n",
      "INFO - 08/10/22 18:25:45 - 0:15:39 - Train Epoch 21: LOSS= 0.06879, lr= 0.000686, acc1= 98.58,acc3= 99.93,acc10= 100.00\n",
      "eval E021: 100% 23/23 [00:20<00:00,  1.10it/s]\n",
      "INFO - 08/10/22 18:26:06 - 0:16:00 - #################################################################################################################\n",
      "INFO - 08/10/22 18:26:06 - 0:16:00 - Test Epoch 21: LOSS= 4.38519, acc1= 45.87, acc3= 64.82, acc10= 79.06\n",
      "INFO - 08/10/22 18:26:06 - 0:16:00 - #################################################################################################################\n",
      "train E022: 100% 21/21 [00:17<00:00,  1.22it/s]\n",
      "INFO - 08/10/22 18:26:23 - 0:16:17 - Train Epoch 22: LOSS= 0.04758, lr= 0.000686, acc1= 98.84,acc3= 99.81,acc10= 99.96\n",
      "eval E022: 100% 23/23 [00:20<00:00,  1.12it/s]\n",
      "INFO - 08/10/22 18:26:44 - 0:16:37 - #################################################################################################################\n",
      "INFO - 08/10/22 18:26:44 - 0:16:37 - Test Epoch 22: LOSS= 4.34762, acc1= 46.19, acc3= 65.53, acc10= 79.53\n",
      "INFO - 08/10/22 18:26:44 - 0:16:37 - #################################################################################################################\n",
      "train E023: 100% 21/21 [00:20<00:00,  1.01it/s]\n",
      "INFO - 08/10/22 18:27:05 - 0:16:58 - Train Epoch 23: LOSS= 0.04179, lr= 0.000480, acc1= 99.14,acc3= 99.89,acc10= 99.96\n",
      "eval E023: 100% 23/23 [00:24<00:00,  1.07s/it]\n",
      "INFO - 08/10/22 18:27:29 - 0:17:23 - #################################################################################################################\n",
      "INFO - 08/10/22 18:27:29 - 0:17:23 - Test Epoch 23: LOSS= 4.42033, acc1= 47.40, acc3= 65.78, acc10= 79.74\n",
      "INFO - 08/10/22 18:27:29 - 0:17:23 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E024: 100% 21/21 [00:24<00:00,  1.15s/it]\n",
      "INFO - 08/10/22 18:27:53 - 0:17:47 - Train Epoch 24: LOSS= 0.03512, lr= 0.000480, acc1= 99.06,acc3= 99.96,acc10= 100.00\n",
      "eval E024: 100% 23/23 [00:23<00:00,  1.03s/it]\n",
      "INFO - 08/10/22 18:28:17 - 0:18:11 - #################################################################################################################\n",
      "INFO - 08/10/22 18:28:17 - 0:18:11 - Test Epoch 24: LOSS= 4.31461, acc1= 46.51, acc3= 65.75, acc10= 79.88\n",
      "INFO - 08/10/22 18:28:17 - 0:18:11 - #################################################################################################################\n",
      "train E025: 100% 21/21 [00:21<00:00,  1.01s/it]\n",
      "INFO - 08/10/22 18:28:38 - 0:18:32 - Train Epoch 25: LOSS= 0.02996, lr= 0.000480, acc1= 99.29,acc3= 100.00,acc10= 100.00\n",
      "eval E025: 100% 23/23 [00:23<00:00,  1.02s/it]\n",
      "INFO - 08/10/22 18:29:02 - 0:18:55 - #################################################################################################################\n",
      "INFO - 08/10/22 18:29:02 - 0:18:55 - Test Epoch 25: LOSS= 4.29991, acc1= 46.94, acc3= 65.50, acc10= 79.99\n",
      "INFO - 08/10/22 18:29:02 - 0:18:55 - #################################################################################################################\n",
      "train E026: 100% 21/21 [00:21<00:00,  1.02s/it]\n",
      "INFO - 08/10/22 18:29:23 - 0:19:17 - Train Epoch 26: LOSS= 0.04022, lr= 0.000336, acc1= 99.06,acc3= 99.89,acc10= 99.96\n",
      "eval E026: 100% 23/23 [00:23<00:00,  1.03s/it]\n",
      "INFO - 08/10/22 18:29:47 - 0:19:40 - #################################################################################################################\n",
      "INFO - 08/10/22 18:29:47 - 0:19:40 - Test Epoch 26: LOSS= 4.33151, acc1= 47.01, acc3= 65.60, acc10= 79.95\n",
      "INFO - 08/10/22 18:29:47 - 0:19:40 - #################################################################################################################\n",
      "train E027: 100% 21/21 [00:23<00:00,  1.13s/it]\n",
      "INFO - 08/10/22 18:30:11 - 0:20:04 - Train Epoch 27: LOSS= 0.02968, lr= 0.000336, acc1= 99.18,acc3= 100.00,acc10= 100.00\n",
      "eval E027: 100% 23/23 [00:28<00:00,  1.25s/it]\n",
      "INFO - 08/10/22 18:30:39 - 0:20:33 - #################################################################################################################\n",
      "INFO - 08/10/22 18:30:39 - 0:20:33 - Test Epoch 27: LOSS= 4.40341, acc1= 47.47, acc3= 65.67, acc10= 79.81\n",
      "INFO - 08/10/22 18:30:39 - 0:20:33 - #################################################################################################################\n",
      "train E028: 100% 21/21 [00:19<00:00,  1.05it/s]\n",
      "INFO - 08/10/22 18:30:59 - 0:20:53 - Train Epoch 28: LOSS= 0.03711, lr= 0.000336, acc1= 98.99,acc3= 99.93,acc10= 100.00\n",
      "eval E028: 100% 23/23 [00:25<00:00,  1.09s/it]\n",
      "INFO - 08/10/22 18:31:25 - 0:21:18 - #################################################################################################################\n",
      "INFO - 08/10/22 18:31:25 - 0:21:18 - Test Epoch 28: LOSS= 4.42341, acc1= 46.97, acc3= 65.71, acc10= 79.77\n",
      "INFO - 08/10/22 18:31:25 - 0:21:18 - #################################################################################################################\n",
      "train E029: 100% 21/21 [00:21<00:00,  1.05s/it]\n",
      "INFO - 08/10/22 18:31:46 - 0:21:40 - Train Epoch 29: LOSS= 0.03448, lr= 0.000235, acc1= 99.03,acc3= 99.93,acc10= 100.00\n",
      "eval E029: 100% 23/23 [00:21<00:00,  1.06it/s]\n",
      "INFO - 08/10/22 18:32:08 - 0:22:02 - #################################################################################################################\n",
      "INFO - 08/10/22 18:32:08 - 0:22:02 - Test Epoch 29: LOSS= 4.32762, acc1= 47.57, acc3= 65.64, acc10= 79.70\n",
      "INFO - 08/10/22 18:32:08 - 0:22:02 - #################################################################################################################\n",
      "train E030: 100% 21/21 [00:20<00:00,  1.01it/s]\n",
      "INFO - 08/10/22 18:32:29 - 0:22:23 - Train Epoch 30: LOSS= 0.03033, lr= 0.000235, acc1= 99.10,acc3= 100.00,acc10= 100.00\n",
      "eval E030: 100% 23/23 [00:23<00:00,  1.04s/it]\n",
      "INFO - 08/10/22 18:32:53 - 0:22:46 - #################################################################################################################\n",
      "INFO - 08/10/22 18:32:53 - 0:22:46 - Test Epoch 30: LOSS= 4.27392, acc1= 47.33, acc3= 65.96, acc10= 79.70\n",
      "INFO - 08/10/22 18:32:53 - 0:22:46 - #################################################################################################################\n",
      "train E031: 100% 21/21 [00:22<00:00,  1.05s/it]\n",
      "INFO - 08/10/22 18:33:15 - 0:23:08 - Train Epoch 31: LOSS= 0.02671, lr= 0.000235, acc1= 99.29,acc3= 100.00,acc10= 100.00\n",
      "eval E031: 100% 23/23 [00:23<00:00,  1.02s/it]\n",
      "INFO - 08/10/22 18:33:38 - 0:23:32 - #################################################################################################################\n",
      "INFO - 08/10/22 18:33:38 - 0:23:32 - Test Epoch 31: LOSS= 4.47379, acc1= 47.57, acc3= 65.99, acc10= 80.09\n",
      "INFO - 08/10/22 18:33:38 - 0:23:32 - #################################################################################################################\n",
      "train E032: 100% 21/21 [00:25<00:00,  1.19s/it]\n",
      "INFO - 08/10/22 18:34:03 - 0:23:57 - Train Epoch 32: LOSS= 0.02316, lr= 0.000165, acc1= 99.36,acc3= 100.00,acc10= 100.00\n",
      "eval E032: 100% 23/23 [00:21<00:00,  1.08it/s]\n",
      "INFO - 08/10/22 18:34:25 - 0:24:18 - #################################################################################################################\n",
      "INFO - 08/10/22 18:34:25 - 0:24:18 - Test Epoch 32: LOSS= 4.26844, acc1= 47.61, acc3= 65.96, acc10= 79.99\n",
      "INFO - 08/10/22 18:34:25 - 0:24:18 - #################################################################################################################\n",
      "train E033: 100% 21/21 [00:22<00:00,  1.09s/it]\n",
      "INFO - 08/10/22 18:34:47 - 0:24:41 - Train Epoch 33: LOSS= 0.02192, lr= 0.000165, acc1= 99.36,acc3= 100.00,acc10= 100.00\n",
      "eval E033: 100% 23/23 [00:21<00:00,  1.05it/s]\n",
      "INFO - 08/10/22 18:35:09 - 0:25:03 - #################################################################################################################\n",
      "INFO - 08/10/22 18:35:09 - 0:25:03 - Test Epoch 33: LOSS= 4.35004, acc1= 47.36, acc3= 65.99, acc10= 80.06\n",
      "INFO - 08/10/22 18:35:09 - 0:25:03 - #################################################################################################################\n",
      "train E034: 100% 21/21 [00:20<00:00,  1.03it/s]\n",
      "INFO - 08/10/22 18:35:30 - 0:25:23 - Train Epoch 34: LOSS= 0.02676, lr= 0.000165, acc1= 99.29,acc3= 99.96,acc10= 100.00\n",
      "eval E034: 100% 23/23 [00:22<00:00,  1.03it/s]\n",
      "INFO - 08/10/22 18:35:52 - 0:25:46 - #################################################################################################################\n",
      "INFO - 08/10/22 18:35:52 - 0:25:46 - Test Epoch 34: LOSS= 4.25136, acc1= 47.22, acc3= 66.42, acc10= 79.95\n",
      "INFO - 08/10/22 18:35:52 - 0:25:46 - #################################################################################################################\n",
      "train E035: 100% 21/21 [00:19<00:00,  1.09it/s]\n",
      "INFO - 08/10/22 18:36:11 - 0:26:05 - Train Epoch 35: LOSS= 0.01761, lr= 0.000115, acc1= 99.36,acc3= 100.00,acc10= 100.00\n",
      "eval E035: 100% 23/23 [00:20<00:00,  1.10it/s]\n",
      "INFO - 08/10/22 18:36:32 - 0:26:26 - #################################################################################################################\n",
      "INFO - 08/10/22 18:36:32 - 0:26:26 - Test Epoch 35: LOSS= 4.21543, acc1= 47.40, acc3= 66.06, acc10= 79.88\n",
      "INFO - 08/10/22 18:36:32 - 0:26:26 - #################################################################################################################\n",
      "train E036: 100% 21/21 [00:21<00:00,  1.04s/it]\n",
      "INFO - 08/10/22 18:36:54 - 0:26:48 - Train Epoch 36: LOSS= 0.01880, lr= 0.000115, acc1= 99.29,acc3= 100.00,acc10= 100.00\n",
      "eval E036: 100% 23/23 [00:24<00:00,  1.08s/it]\n",
      "INFO - 08/10/22 18:37:19 - 0:27:13 - #################################################################################################################\n",
      "INFO - 08/10/22 18:37:19 - 0:27:13 - Test Epoch 36: LOSS= 4.26061, acc1= 47.72, acc3= 65.82, acc10= 79.81\n",
      "INFO - 08/10/22 18:37:19 - 0:27:13 - #################################################################################################################\n",
      "train E037: 100% 21/21 [00:19<00:00,  1.06it/s]\n",
      "INFO - 08/10/22 18:37:39 - 0:27:32 - Train Epoch 37: LOSS= 0.02261, lr= 0.000115, acc1= 99.29,acc3= 99.96,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E037: 100% 23/23 [00:21<00:00,  1.05it/s]\n",
      "INFO - 08/10/22 18:38:01 - 0:27:54 - #################################################################################################################\n",
      "INFO - 08/10/22 18:38:01 - 0:27:54 - Test Epoch 37: LOSS= 4.25849, acc1= 47.86, acc3= 65.85, acc10= 79.88\n",
      "INFO - 08/10/22 18:38:01 - 0:27:54 - #################################################################################################################\n",
      "train E038: 100% 21/21 [00:19<00:00,  1.07it/s]\n",
      "INFO - 08/10/22 18:38:20 - 0:28:14 - Train Epoch 38: LOSS= 0.02055, lr= 0.000081, acc1= 99.40,acc3= 99.96,acc10= 100.00\n",
      "eval E038: 100% 23/23 [00:22<00:00,  1.02it/s]\n",
      "INFO - 08/10/22 18:38:43 - 0:28:36 - #################################################################################################################\n",
      "INFO - 08/10/22 18:38:43 - 0:28:36 - Test Epoch 38: LOSS= 4.59976, acc1= 47.79, acc3= 65.89, acc10= 79.91\n",
      "INFO - 08/10/22 18:38:43 - 0:28:36 - #################################################################################################################\n",
      "train E039: 100% 21/21 [00:21<00:00,  1.01s/it]\n",
      "INFO - 08/10/22 18:39:04 - 0:28:58 - Train Epoch 39: LOSS= 0.02389, lr= 0.000081, acc1= 99.40,acc3= 100.00,acc10= 100.00\n",
      "eval E039: 100% 23/23 [00:23<00:00,  1.04s/it]\n",
      "INFO - 08/10/22 18:39:28 - 0:29:21 - #################################################################################################################\n",
      "INFO - 08/10/22 18:39:28 - 0:29:21 - Test Epoch 39: LOSS= 4.35832, acc1= 47.79, acc3= 65.89, acc10= 79.91\n",
      "INFO - 08/10/22 18:39:28 - 0:29:21 - #################################################################################################################\n",
      "train E040: 100% 21/21 [00:19<00:00,  1.07it/s]\n",
      "INFO - 08/10/22 18:39:48 - 0:29:41 - Train Epoch 40: LOSS= 0.01891, lr= 0.000081, acc1= 99.48,acc3= 99.96,acc10= 100.00\n",
      "eval E040: 100% 23/23 [00:21<00:00,  1.08it/s]\n",
      "INFO - 08/10/22 18:40:09 - 0:30:02 - #################################################################################################################\n",
      "INFO - 08/10/22 18:40:09 - 0:30:02 - Test Epoch 40: LOSS= 4.40231, acc1= 47.79, acc3= 65.92, acc10= 79.95\n",
      "INFO - 08/10/22 18:40:09 - 0:30:02 - #################################################################################################################\n",
      "train E041: 100% 21/21 [00:21<00:00,  1.03s/it]\n",
      "INFO - 08/10/22 18:40:30 - 0:30:24 - Train Epoch 41: LOSS= 0.01958, lr= 0.000056, acc1= 99.51,acc3= 100.00,acc10= 100.00\n",
      "eval E041: 100% 23/23 [00:21<00:00,  1.07it/s]\n",
      "INFO - 08/10/22 18:40:52 - 0:30:45 - #################################################################################################################\n",
      "INFO - 08/10/22 18:40:52 - 0:30:45 - Test Epoch 41: LOSS= 4.29780, acc1= 47.61, acc3= 65.92, acc10= 79.99\n",
      "INFO - 08/10/22 18:40:52 - 0:30:45 - #################################################################################################################\n",
      "train E042: 100% 21/21 [00:22<00:00,  1.09s/it]\n",
      "INFO - 08/10/22 18:41:15 - 0:31:08 - Train Epoch 42: LOSS= 0.02126, lr= 0.000056, acc1= 99.25,acc3= 100.00,acc10= 100.00\n",
      "eval E042: 100% 23/23 [00:28<00:00,  1.22s/it]\n",
      "INFO - 08/10/22 18:41:43 - 0:31:36 - #################################################################################################################\n",
      "INFO - 08/10/22 18:41:43 - 0:31:36 - Test Epoch 42: LOSS= 4.27008, acc1= 47.68, acc3= 66.03, acc10= 80.09\n",
      "INFO - 08/10/22 18:41:43 - 0:31:36 - #################################################################################################################\n",
      "train E043: 100% 21/21 [00:24<00:00,  1.15s/it]\n",
      "INFO - 08/10/22 18:42:07 - 0:32:01 - Train Epoch 43: LOSS= 0.01670, lr= 0.000056, acc1= 99.51,acc3= 100.00,acc10= 100.00\n",
      "eval E043: 100% 23/23 [00:25<00:00,  1.13s/it]\n",
      "INFO - 08/10/22 18:42:33 - 0:32:27 - #################################################################################################################\n",
      "INFO - 08/10/22 18:42:33 - 0:32:27 - Test Epoch 43: LOSS= 4.29608, acc1= 47.68, acc3= 66.17, acc10= 80.13\n",
      "INFO - 08/10/22 18:42:33 - 0:32:27 - #################################################################################################################\n",
      "train E044: 100% 21/21 [00:22<00:00,  1.06s/it]\n",
      "INFO - 08/10/22 18:42:55 - 0:32:49 - Train Epoch 44: LOSS= 0.01773, lr= 0.000040, acc1= 99.40,acc3= 100.00,acc10= 100.00\n",
      "eval E044: 100% 23/23 [00:25<00:00,  1.10s/it]\n",
      "INFO - 08/10/22 18:43:21 - 0:33:14 - #################################################################################################################\n",
      "INFO - 08/10/22 18:43:21 - 0:33:14 - Test Epoch 44: LOSS= 4.19742, acc1= 47.75, acc3= 66.10, acc10= 80.45\n",
      "INFO - 08/10/22 18:43:21 - 0:33:14 - #################################################################################################################\n",
      "train E045: 100% 21/21 [00:22<00:00,  1.08s/it]\n",
      "INFO - 08/10/22 18:43:43 - 0:33:37 - Train Epoch 45: LOSS= 0.01835, lr= 0.000040, acc1= 99.59,acc3= 99.96,acc10= 100.00\n",
      "eval E045: 100% 23/23 [00:23<00:00,  1.03s/it]\n",
      "INFO - 08/10/22 18:44:07 - 0:34:01 - #################################################################################################################\n",
      "INFO - 08/10/22 18:44:07 - 0:34:01 - Test Epoch 45: LOSS= 4.24170, acc1= 47.75, acc3= 66.14, acc10= 80.45\n",
      "INFO - 08/10/22 18:44:07 - 0:34:01 - #################################################################################################################\n",
      "train E046: 100% 21/21 [00:26<00:00,  1.28s/it]\n",
      "INFO - 08/10/22 18:44:34 - 0:34:27 - Train Epoch 46: LOSS= 0.01796, lr= 0.000040, acc1= 99.29,acc3= 100.00,acc10= 100.00\n",
      "eval E046: 100% 23/23 [00:26<00:00,  1.16s/it]\n",
      "INFO - 08/10/22 18:45:01 - 0:34:54 - #################################################################################################################\n",
      "INFO - 08/10/22 18:45:01 - 0:34:54 - Test Epoch 46: LOSS= 4.38046, acc1= 47.72, acc3= 66.06, acc10= 80.48\n",
      "INFO - 08/10/22 18:45:01 - 0:34:54 - #################################################################################################################\n",
      "train E047: 100% 21/21 [00:24<00:00,  1.19s/it]\n",
      "INFO - 08/10/22 18:45:26 - 0:35:19 - Train Epoch 47: LOSS= 0.01329, lr= 0.000040, acc1= 99.59,acc3= 100.00,acc10= 100.00\n",
      "eval E047: 100% 23/23 [00:27<00:00,  1.21s/it]\n",
      "INFO - 08/10/22 18:45:53 - 0:35:47 - #################################################################################################################\n",
      "INFO - 08/10/22 18:45:53 - 0:35:47 - Test Epoch 47: LOSS= 4.24709, acc1= 47.68, acc3= 66.06, acc10= 80.55\n",
      "INFO - 08/10/22 18:45:53 - 0:35:47 - #################################################################################################################\n",
      "train E048: 100% 21/21 [00:25<00:00,  1.20s/it]\n",
      "INFO - 08/10/22 18:46:18 - 0:36:12 - Train Epoch 48: LOSS= 0.01642, lr= 0.000040, acc1= 99.48,acc3= 100.00,acc10= 100.00\n",
      "eval E048: 100% 23/23 [00:22<00:00,  1.01it/s]\n",
      "INFO - 08/10/22 18:46:41 - 0:36:35 - #################################################################################################################\n",
      "INFO - 08/10/22 18:46:41 - 0:36:35 - Test Epoch 48: LOSS= 4.37929, acc1= 47.57, acc3= 66.10, acc10= 80.34\n",
      "INFO - 08/10/22 18:46:41 - 0:36:35 - #################################################################################################################\n",
      "train E049: 100% 21/21 [00:23<00:00,  1.10s/it]\n",
      "INFO - 08/10/22 18:47:04 - 0:36:58 - Train Epoch 49: LOSS= 0.02111, lr= 0.000040, acc1= 99.33,acc3= 100.00,acc10= 100.00\n",
      "eval E049: 100% 23/23 [00:27<00:00,  1.19s/it]\n",
      "INFO - 08/10/22 18:47:32 - 0:37:25 - #################################################################################################################\n",
      "INFO - 08/10/22 18:47:32 - 0:37:25 - Test Epoch 49: LOSS= 4.26477, acc1= 47.68, acc3= 65.96, acc10= 80.34\n",
      "INFO - 08/10/22 18:47:32 - 0:37:25 - #################################################################################################################\n",
      "train E050: 100% 21/21 [00:27<00:00,  1.31s/it]\n",
      "INFO - 08/10/22 18:47:59 - 0:37:53 - Train Epoch 50: LOSS= 0.01226, lr= 0.000040, acc1= 99.63,acc3= 100.00,acc10= 100.00\n",
      "eval E050: 100% 23/23 [00:23<00:00,  1.01s/it]\n",
      "INFO - 08/10/22 18:48:23 - 0:38:16 - #################################################################################################################\n",
      "INFO - 08/10/22 18:48:23 - 0:38:16 - Test Epoch 50: LOSS= 4.41772, acc1= 47.61, acc3= 66.03, acc10= 80.38\n",
      "INFO - 08/10/22 18:48:23 - 0:38:16 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E051: 100% 21/21 [00:22<00:00,  1.09s/it]\n",
      "INFO - 08/10/22 18:48:46 - 0:38:39 - Train Epoch 51: LOSS= 0.01730, lr= 0.000040, acc1= 99.51,acc3= 100.00,acc10= 100.00\n",
      "eval E051: 100% 23/23 [00:21<00:00,  1.08it/s]\n",
      "INFO - 08/10/22 18:49:07 - 0:39:00 - #################################################################################################################\n",
      "INFO - 08/10/22 18:49:07 - 0:39:00 - Test Epoch 51: LOSS= 4.43319, acc1= 47.68, acc3= 66.10, acc10= 80.34\n",
      "INFO - 08/10/22 18:49:07 - 0:39:00 - #################################################################################################################\n",
      "train E052: 100% 21/21 [00:23<00:00,  1.10s/it]\n",
      "INFO - 08/10/22 18:49:30 - 0:39:24 - Train Epoch 52: LOSS= 0.01095, lr= 0.000040, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E052: 100% 23/23 [00:23<00:00,  1.03s/it]\n",
      "INFO - 08/10/22 18:49:54 - 0:39:47 - #################################################################################################################\n",
      "INFO - 08/10/22 18:49:54 - 0:39:47 - Test Epoch 52: LOSS= 4.41187, acc1= 47.72, acc3= 66.10, acc10= 80.02\n",
      "INFO - 08/10/22 18:49:54 - 0:39:47 - #################################################################################################################\n",
      "train E053: 100% 21/21 [00:25<00:00,  1.22s/it]\n",
      "INFO - 08/10/22 18:50:19 - 0:40:13 - Train Epoch 53: LOSS= 0.01516, lr= 0.000040, acc1= 99.59,acc3= 100.00,acc10= 100.00\n",
      "eval E053: 100% 23/23 [00:22<00:00,  1.04it/s]\n",
      "INFO - 08/10/22 18:50:41 - 0:40:35 - #################################################################################################################\n",
      "INFO - 08/10/22 18:50:41 - 0:40:35 - Test Epoch 53: LOSS= 4.30059, acc1= 47.72, acc3= 65.96, acc10= 80.13\n",
      "INFO - 08/10/22 18:50:41 - 0:40:35 - #################################################################################################################\n",
      "train E054: 100% 21/21 [00:25<00:00,  1.20s/it]\n",
      "INFO - 08/10/22 18:51:07 - 0:41:00 - Train Epoch 54: LOSS= 0.01593, lr= 0.000040, acc1= 99.51,acc3= 100.00,acc10= 100.00\n",
      "eval E054: 100% 23/23 [00:24<00:00,  1.04s/it]\n",
      "INFO - 08/10/22 18:51:31 - 0:41:24 - #################################################################################################################\n",
      "INFO - 08/10/22 18:51:31 - 0:41:24 - Test Epoch 54: LOSS= 4.56703, acc1= 47.72, acc3= 66.10, acc10= 80.16\n",
      "INFO - 08/10/22 18:51:31 - 0:41:24 - #################################################################################################################\n",
      "train E055: 100% 21/21 [00:23<00:00,  1.10s/it]\n",
      "INFO - 08/10/22 18:51:54 - 0:41:47 - Train Epoch 55: LOSS= 0.02042, lr= 0.000040, acc1= 99.40,acc3= 100.00,acc10= 100.00\n",
      "eval E055: 100% 23/23 [00:24<00:00,  1.05s/it]\n",
      "INFO - 08/10/22 18:52:18 - 0:42:11 - #################################################################################################################\n",
      "INFO - 08/10/22 18:52:18 - 0:42:11 - Test Epoch 55: LOSS= 4.58689, acc1= 47.64, acc3= 66.17, acc10= 80.09\n",
      "INFO - 08/10/22 18:52:18 - 0:42:11 - #################################################################################################################\n",
      "train E056: 100% 21/21 [00:23<00:00,  1.11s/it]\n",
      "INFO - 08/10/22 18:52:41 - 0:42:35 - Train Epoch 56: LOSS= 0.01286, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E056: 100% 23/23 [00:22<00:00,  1.04it/s]\n",
      "INFO - 08/10/22 18:53:03 - 0:42:57 - #################################################################################################################\n",
      "INFO - 08/10/22 18:53:03 - 0:42:57 - Test Epoch 56: LOSS= 4.29510, acc1= 47.72, acc3= 66.10, acc10= 80.02\n",
      "INFO - 08/10/22 18:53:03 - 0:42:57 - #################################################################################################################\n",
      "train E057: 100% 21/21 [00:22<00:00,  1.08s/it]\n",
      "INFO - 08/10/22 18:53:26 - 0:43:20 - Train Epoch 57: LOSS= 0.01097, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E057: 100% 23/23 [00:26<00:00,  1.14s/it]\n",
      "INFO - 08/10/22 18:53:52 - 0:43:46 - #################################################################################################################\n",
      "INFO - 08/10/22 18:53:52 - 0:43:46 - Test Epoch 57: LOSS= 4.39462, acc1= 47.68, acc3= 66.03, acc10= 80.09\n",
      "INFO - 08/10/22 18:53:52 - 0:43:46 - #################################################################################################################\n",
      "train E058: 100% 21/21 [00:24<00:00,  1.18s/it]\n",
      "INFO - 08/10/22 18:54:17 - 0:44:10 - Train Epoch 58: LOSS= 0.01808, lr= 0.000040, acc1= 99.48,acc3= 100.00,acc10= 100.00\n",
      "eval E058: 100% 23/23 [00:23<00:00,  1.03s/it]\n",
      "INFO - 08/10/22 18:54:41 - 0:44:34 - #################################################################################################################\n",
      "INFO - 08/10/22 18:54:41 - 0:44:34 - Test Epoch 58: LOSS= 4.49786, acc1= 47.64, acc3= 66.03, acc10= 80.06\n",
      "INFO - 08/10/22 18:54:41 - 0:44:34 - #################################################################################################################\n",
      "train E059: 100% 21/21 [00:23<00:00,  1.10s/it]\n",
      "INFO - 08/10/22 18:55:04 - 0:44:57 - Train Epoch 59: LOSS= 0.01432, lr= 0.000040, acc1= 99.59,acc3= 100.00,acc10= 100.00\n",
      "eval E059: 100% 23/23 [00:25<00:00,  1.12s/it]\n",
      "INFO - 08/10/22 18:55:29 - 0:45:23 - #################################################################################################################\n",
      "INFO - 08/10/22 18:55:29 - 0:45:23 - Test Epoch 59: LOSS= 4.50591, acc1= 47.75, acc3= 65.92, acc10= 80.02\n",
      "INFO - 08/10/22 18:55:29 - 0:45:23 - #################################################################################################################\n",
      "train E060: 100% 21/21 [00:21<00:00,  1.00s/it]\n",
      "INFO - 08/10/22 18:55:51 - 0:45:44 - Train Epoch 60: LOSS= 0.01670, lr= 0.000040, acc1= 99.55,acc3= 99.96,acc10= 100.00\n",
      "eval E060: 100% 23/23 [00:23<00:00,  1.00s/it]\n",
      "INFO - 08/10/22 18:56:14 - 0:46:07 - #################################################################################################################\n",
      "INFO - 08/10/22 18:56:14 - 0:46:07 - Test Epoch 60: LOSS= 4.36390, acc1= 47.79, acc3= 65.92, acc10= 80.06\n",
      "INFO - 08/10/22 18:56:14 - 0:46:07 - #################################################################################################################\n",
      "train E061: 100% 21/21 [00:25<00:00,  1.23s/it]\n",
      "INFO - 08/10/22 18:56:39 - 0:46:33 - Train Epoch 61: LOSS= 0.02199, lr= 0.000040, acc1= 99.36,acc3= 99.96,acc10= 99.96\n",
      "eval E061: 100% 23/23 [00:18<00:00,  1.25it/s]\n",
      "INFO - 08/10/22 18:56:58 - 0:46:51 - #################################################################################################################\n",
      "INFO - 08/10/22 18:56:58 - 0:46:51 - Test Epoch 61: LOSS= 4.22556, acc1= 47.79, acc3= 65.85, acc10= 80.06\n",
      "INFO - 08/10/22 18:56:58 - 0:46:51 - #################################################################################################################\n",
      "train E062: 100% 21/21 [00:21<00:00,  1.03s/it]\n",
      "INFO - 08/10/22 18:57:20 - 0:47:13 - Train Epoch 62: LOSS= 0.01363, lr= 0.000040, acc1= 99.48,acc3= 100.00,acc10= 100.00\n",
      "eval E062: 100% 23/23 [00:26<00:00,  1.14s/it]\n",
      "INFO - 08/10/22 18:57:46 - 0:47:39 - #################################################################################################################\n",
      "INFO - 08/10/22 18:57:46 - 0:47:39 - Test Epoch 62: LOSS= 4.41617, acc1= 47.79, acc3= 65.89, acc10= 80.13\n",
      "INFO - 08/10/22 18:57:46 - 0:47:39 - #################################################################################################################\n",
      "train E063: 100% 21/21 [00:23<00:00,  1.13s/it]\n",
      "INFO - 08/10/22 18:58:09 - 0:48:03 - Train Epoch 63: LOSS= 0.01055, lr= 0.000040, acc1= 99.63,acc3= 100.00,acc10= 100.00\n",
      "eval E063: 100% 23/23 [00:23<00:00,  1.01s/it]\n",
      "INFO - 08/10/22 18:58:33 - 0:48:26 - #################################################################################################################\n",
      "INFO - 08/10/22 18:58:33 - 0:48:26 - Test Epoch 63: LOSS= 4.35164, acc1= 47.75, acc3= 65.92, acc10= 80.09\n",
      "INFO - 08/10/22 18:58:33 - 0:48:26 - #################################################################################################################\n",
      "train E064: 100% 21/21 [00:26<00:00,  1.27s/it]\n",
      "INFO - 08/10/22 18:58:59 - 0:48:53 - Train Epoch 64: LOSS= 0.01544, lr= 0.000040, acc1= 99.48,acc3= 100.00,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E064: 100% 23/23 [00:31<00:00,  1.37s/it]\n",
      "INFO - 08/10/22 18:59:31 - 0:49:24 - #################################################################################################################\n",
      "INFO - 08/10/22 18:59:31 - 0:49:24 - Test Epoch 64: LOSS= 4.23341, acc1= 47.89, acc3= 65.96, acc10= 80.16\n",
      "INFO - 08/10/22 18:59:31 - 0:49:24 - #################################################################################################################\n",
      "train E065: 100% 21/21 [00:28<00:00,  1.37s/it]\n",
      "INFO - 08/10/22 19:00:00 - 0:49:53 - Train Epoch 65: LOSS= 0.02039, lr= 0.000040, acc1= 99.40,acc3= 100.00,acc10= 100.00\n",
      "eval E065: 100% 23/23 [00:29<00:00,  1.29s/it]\n",
      "INFO - 08/10/22 19:00:29 - 0:50:23 - #################################################################################################################\n",
      "INFO - 08/10/22 19:00:29 - 0:50:23 - Test Epoch 65: LOSS= 4.22846, acc1= 48.00, acc3= 65.99, acc10= 80.02\n",
      "INFO - 08/10/22 19:00:29 - 0:50:23 - #################################################################################################################\n",
      "train E066: 100% 21/21 [00:29<00:00,  1.39s/it]\n",
      "INFO - 08/10/22 19:00:58 - 0:50:52 - Train Epoch 66: LOSS= 0.01759, lr= 0.000040, acc1= 99.40,acc3= 100.00,acc10= 100.00\n",
      "eval E066: 100% 23/23 [00:22<00:00,  1.02it/s]\n",
      "INFO - 08/10/22 19:01:21 - 0:51:15 - #################################################################################################################\n",
      "INFO - 08/10/22 19:01:21 - 0:51:15 - Test Epoch 66: LOSS= 4.49517, acc1= 47.93, acc3= 66.06, acc10= 80.09\n",
      "INFO - 08/10/22 19:01:21 - 0:51:15 - #################################################################################################################\n",
      "train E067: 100% 21/21 [00:23<00:00,  1.13s/it]\n",
      "INFO - 08/10/22 19:01:45 - 0:51:38 - Train Epoch 67: LOSS= 0.02239, lr= 0.000040, acc1= 99.44,acc3= 100.00,acc10= 100.00\n",
      "eval E067: 100% 23/23 [00:23<00:00,  1.01s/it]\n",
      "INFO - 08/10/22 19:02:08 - 0:52:02 - #################################################################################################################\n",
      "INFO - 08/10/22 19:02:08 - 0:52:02 - Test Epoch 67: LOSS= 4.28351, acc1= 48.03, acc3= 66.03, acc10= 80.02\n",
      "INFO - 08/10/22 19:02:08 - 0:52:02 - #################################################################################################################\n",
      "train E068: 100% 21/21 [00:23<00:00,  1.10s/it]\n",
      "INFO - 08/10/22 19:02:31 - 0:52:25 - Train Epoch 68: LOSS= 0.01668, lr= 0.000040, acc1= 99.48,acc3= 100.00,acc10= 100.00\n",
      "eval E068: 100% 23/23 [00:19<00:00,  1.16it/s]\n",
      "INFO - 08/10/22 19:02:51 - 0:52:45 - #################################################################################################################\n",
      "INFO - 08/10/22 19:02:51 - 0:52:45 - Test Epoch 68: LOSS= 4.30888, acc1= 48.00, acc3= 66.03, acc10= 79.99\n",
      "INFO - 08/10/22 19:02:51 - 0:52:45 - #################################################################################################################\n",
      "train E069: 100% 21/21 [00:24<00:00,  1.19s/it]\n",
      "INFO - 08/10/22 19:03:16 - 0:53:10 - Train Epoch 69: LOSS= 0.01215, lr= 0.000040, acc1= 99.63,acc3= 100.00,acc10= 100.00\n",
      "eval E069: 100% 23/23 [00:25<00:00,  1.11s/it]\n",
      "INFO - 08/10/22 19:03:42 - 0:53:35 - #################################################################################################################\n",
      "INFO - 08/10/22 19:03:42 - 0:53:35 - Test Epoch 69: LOSS= 4.36039, acc1= 47.96, acc3= 66.17, acc10= 79.99\n",
      "INFO - 08/10/22 19:03:42 - 0:53:35 - #################################################################################################################\n",
      "train E070: 100% 21/21 [00:24<00:00,  1.16s/it]\n",
      "INFO - 08/10/22 19:04:06 - 0:53:59 - Train Epoch 70: LOSS= 0.01766, lr= 0.000040, acc1= 99.48,acc3= 100.00,acc10= 100.00\n",
      "eval E070: 100% 23/23 [00:18<00:00,  1.22it/s]\n",
      "INFO - 08/10/22 19:04:25 - 0:54:18 - #################################################################################################################\n",
      "INFO - 08/10/22 19:04:25 - 0:54:18 - Test Epoch 70: LOSS= 4.32695, acc1= 47.89, acc3= 66.14, acc10= 79.99\n",
      "INFO - 08/10/22 19:04:25 - 0:54:18 - #################################################################################################################\n",
      "train E071: 100% 21/21 [00:22<00:00,  1.06s/it]\n",
      "INFO - 08/10/22 19:04:47 - 0:54:40 - Train Epoch 71: LOSS= 0.01241, lr= 0.000040, acc1= 99.55,acc3= 100.00,acc10= 100.00\n",
      "eval E071: 100% 23/23 [00:25<00:00,  1.12s/it]\n",
      "INFO - 08/10/22 19:05:13 - 0:55:06 - #################################################################################################################\n",
      "INFO - 08/10/22 19:05:13 - 0:55:06 - Test Epoch 71: LOSS= 4.32378, acc1= 48.03, acc3= 66.17, acc10= 79.99\n",
      "INFO - 08/10/22 19:05:13 - 0:55:06 - #################################################################################################################\n",
      "train E072: 100% 21/21 [00:21<00:00,  1.01s/it]\n",
      "INFO - 08/10/22 19:05:34 - 0:55:27 - Train Epoch 72: LOSS= 0.01600, lr= 0.000040, acc1= 99.48,acc3= 100.00,acc10= 100.00\n",
      "eval E072: 100% 23/23 [00:22<00:00,  1.03it/s]\n",
      "INFO - 08/10/22 19:05:56 - 0:55:50 - #################################################################################################################\n",
      "INFO - 08/10/22 19:05:56 - 0:55:50 - Test Epoch 72: LOSS= 4.41034, acc1= 48.03, acc3= 66.10, acc10= 80.06\n",
      "INFO - 08/10/22 19:05:56 - 0:55:50 - #################################################################################################################\n",
      "train E073: 100% 21/21 [00:18<00:00,  1.12it/s]\n",
      "INFO - 08/10/22 19:06:15 - 0:56:09 - Train Epoch 73: LOSS= 0.02133, lr= 0.000040, acc1= 99.40,acc3= 100.00,acc10= 100.00\n",
      "eval E073: 100% 23/23 [00:21<00:00,  1.06it/s]\n",
      "INFO - 08/10/22 19:06:37 - 0:56:30 - #################################################################################################################\n",
      "INFO - 08/10/22 19:06:37 - 0:56:30 - Test Epoch 73: LOSS= 4.30675, acc1= 48.03, acc3= 66.14, acc10= 80.06\n",
      "INFO - 08/10/22 19:06:37 - 0:56:30 - #################################################################################################################\n",
      "train E074: 100% 21/21 [00:23<00:00,  1.12s/it]\n",
      "INFO - 08/10/22 19:07:00 - 0:56:54 - Train Epoch 74: LOSS= 0.01483, lr= 0.000040, acc1= 99.55,acc3= 100.00,acc10= 100.00\n",
      "eval E074: 100% 23/23 [00:19<00:00,  1.17it/s]\n",
      "INFO - 08/10/22 19:07:20 - 0:57:13 - #################################################################################################################\n",
      "INFO - 08/10/22 19:07:20 - 0:57:13 - Test Epoch 74: LOSS= 4.58669, acc1= 47.93, acc3= 66.03, acc10= 80.13\n",
      "INFO - 08/10/22 19:07:20 - 0:57:13 - #################################################################################################################\n",
      "INFO - 08/10/22 19:07:22 - 0:57:15 - best performance =  47.75, 66.10, 80.45. best epoch = 44, correspond_loss= 4.1974\n",
      "INFO - 08/10/22 19:07:22 - 0:57:15 -  fusion_model_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_answer_SAN_3.pkl\n",
      "INFO - 08/10/22 19:07:22 - 0:57:15 -  answer_net_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_answer_MLP_3.pkl\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 08/10/22 19:07:28 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 08/10/22 19:07:28 - 0:00:00 - The experiment will be stored in dump/0810-semantic_space/W2V\n",
      "                                     \n",
      "INFO - 08/10/22 19:07:28 - 0:00:00 - Running command: python main.py --gpu_id 6 --exp_name semantic_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --save_model 1 --relation_map 1\n",
      "\n",
      "2022-08-10 19:07:28.685726: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-08-10 19:07:28.685799: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 128\n",
      "batch_size 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fusion_model:\n",
      "SAN(\n",
      "  (w_emb): WordEmbedding(\n",
      "    (emb): Embedding(15422, 300, padding_idx=15421)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (text): Seq2SeqRNN(\n",
      "    (rnn): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (attention): SanAttention(\n",
      "    (v_conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (q_lin): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (x_conv): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(5120, 8192, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(8192, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "Answer Model:\n",
      "MLP(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "train E000: 100% 21/21 [00:24<00:00,  1.18s/it]\n",
      "INFO - 08/10/22 19:08:15 - 0:00:47 - Train Epoch 0: LOSS= 4.88226, lr= 0.000500, acc1= 23.98,acc3= 46.35,acc10= 80.25\n",
      "train E001: 100% 21/21 [00:24<00:00,  1.14s/it]\n",
      "INFO - 08/10/22 19:08:39 - 0:01:11 - Train Epoch 1: LOSS= 1.67754, lr= 0.000750, acc1= 52.30,acc3= 75.83,acc10= 94.90\n",
      "eval E001: 100% 23/23 [00:26<00:00,  1.15s/it]\n",
      "INFO - 08/10/22 19:09:06 - 0:01:38 - #################################################################################################################\n",
      "INFO - 08/10/22 19:09:06 - 0:01:38 - Test Epoch 1: LOSS= 1.58679, acc1= 56.39, acc3= 77.29, acc10= 95.11\n",
      "INFO - 08/10/22 19:09:06 - 0:01:38 - #################################################################################################################\n",
      "train E002: 100% 21/21 [00:21<00:00,  1.04s/it]\n",
      "INFO - 08/10/22 19:09:28 - 0:02:00 - Train Epoch 2: LOSS= 1.22509, lr= 0.001000, acc1= 63.84,acc3= 84.83,acc10= 97.34\n",
      "eval E002: 100% 23/23 [00:27<00:00,  1.20s/it]\n",
      "INFO - 08/10/22 19:09:55 - 0:02:27 - #################################################################################################################\n",
      "INFO - 08/10/22 19:09:55 - 0:02:27 - Test Epoch 2: LOSS= 1.33803, acc1= 62.84, acc3= 82.64, acc10= 95.93\n",
      "INFO - 08/10/22 19:09:55 - 0:02:27 - #################################################################################################################\n",
      "train E003: 100% 21/21 [00:29<00:00,  1.38s/it]\n",
      "INFO - 08/10/22 19:10:24 - 0:02:56 - Train Epoch 3: LOSS= 0.99541, lr= 0.001250, acc1= 70.55,acc3= 89.47,acc10= 99.06\n",
      "eval E003: 100% 23/23 [00:25<00:00,  1.09s/it]\n",
      "INFO - 08/10/22 19:10:49 - 0:03:21 - #################################################################################################################\n",
      "INFO - 08/10/22 19:10:49 - 0:03:21 - Test Epoch 3: LOSS= 1.66377, acc1= 62.77, acc3= 78.18, acc10= 95.36\n",
      "INFO - 08/10/22 19:10:49 - 0:03:21 - #################################################################################################################\n",
      "train E004: 100% 21/21 [00:28<00:00,  1.34s/it]\n",
      "INFO - 08/10/22 19:11:18 - 0:03:50 - Train Epoch 4: LOSS= 0.91130, lr= 0.001500, acc1= 72.69,acc3= 91.31,acc10= 99.25\n",
      "eval E004: 100% 23/23 [00:30<00:00,  1.32s/it]\n",
      "INFO - 08/10/22 19:11:48 - 0:04:20 - #################################################################################################################\n",
      "INFO - 08/10/22 19:11:48 - 0:04:20 - Test Epoch 4: LOSS= 1.59897, acc1= 62.20, acc3= 83.21, acc10= 96.28\n",
      "INFO - 08/10/22 19:11:48 - 0:04:20 - #################################################################################################################\n",
      "train E005: 100% 21/21 [00:23<00:00,  1.10s/it]\n",
      "INFO - 08/10/22 19:12:11 - 0:04:43 - Train Epoch 5: LOSS= 0.80225, lr= 0.001750, acc1= 74.52,acc3= 93.18,acc10= 99.33\n",
      "eval E005: 100% 23/23 [00:35<00:00,  1.54s/it]\n",
      "INFO - 08/10/22 19:12:47 - 0:05:19 - #################################################################################################################\n",
      "INFO - 08/10/22 19:12:47 - 0:05:19 - Test Epoch 5: LOSS= 1.63544, acc1= 60.04, acc3= 84.98, acc10= 96.46\n",
      "INFO - 08/10/22 19:12:47 - 0:05:19 - #################################################################################################################\n",
      "train E006: 100% 21/21 [00:29<00:00,  1.41s/it]\n",
      "INFO - 08/10/22 19:13:16 - 0:05:48 - Train Epoch 6: LOSS= 0.75015, lr= 0.002000, acc1= 76.58,acc3= 93.78,acc10= 99.85\n",
      "eval E006: 100% 23/23 [00:29<00:00,  1.26s/it]\n",
      "INFO - 08/10/22 19:13:45 - 0:06:17 - #################################################################################################################\n",
      "INFO - 08/10/22 19:13:45 - 0:06:17 - Test Epoch 6: LOSS= 1.83288, acc1= 62.59, acc3= 81.01, acc10= 95.64\n",
      "INFO - 08/10/22 19:13:45 - 0:06:17 - #################################################################################################################\n",
      "train E007: 100% 21/21 [00:29<00:00,  1.41s/it]\n",
      "INFO - 08/10/22 19:14:15 - 0:06:47 - Train Epoch 7: LOSS= 0.71398, lr= 0.002000, acc1= 77.74,acc3= 95.35,acc10= 99.74\n",
      "eval E007: 100% 23/23 [00:25<00:00,  1.11s/it]\n",
      "INFO - 08/10/22 19:14:40 - 0:07:12 - #################################################################################################################\n",
      "INFO - 08/10/22 19:14:40 - 0:07:12 - Test Epoch 7: LOSS= 1.67981, acc1= 60.43, acc3= 81.76, acc10= 95.47\n",
      "INFO - 08/10/22 19:14:40 - 0:07:12 - #################################################################################################################\n",
      "train E008: 100% 21/21 [00:28<00:00,  1.34s/it]\n",
      "INFO - 08/10/22 19:15:08 - 0:07:41 - Train Epoch 8: LOSS= 0.53803, lr= 0.002000, acc1= 83.55,acc3= 97.12,acc10= 99.93\n",
      "eval E008: 100% 23/23 [00:29<00:00,  1.29s/it]\n",
      "INFO - 08/10/22 19:15:38 - 0:08:10 - #################################################################################################################\n",
      "INFO - 08/10/22 19:15:38 - 0:08:10 - Test Epoch 8: LOSS= 1.91882, acc1= 62.70, acc3= 81.19, acc10= 95.11\n",
      "INFO - 08/10/22 19:15:38 - 0:08:10 - #################################################################################################################\n",
      "train E009: 100% 21/21 [00:27<00:00,  1.30s/it]\n",
      "INFO - 08/10/22 19:16:06 - 0:08:38 - Train Epoch 9: LOSS= 0.44385, lr= 0.002000, acc1= 85.72,acc3= 97.75,acc10= 99.89\n",
      "eval E009: 100% 23/23 [00:34<00:00,  1.49s/it]\n",
      "INFO - 08/10/22 19:16:40 - 0:09:12 - #################################################################################################################\n",
      "INFO - 08/10/22 19:16:40 - 0:09:12 - Test Epoch 9: LOSS= 1.82271, acc1= 61.64, acc3= 84.63, acc10= 95.82\n",
      "INFO - 08/10/22 19:16:40 - 0:09:12 - #################################################################################################################\n",
      "train E010: 100% 21/21 [00:29<00:00,  1.40s/it]\n",
      "INFO - 08/10/22 19:17:09 - 0:09:41 - Train Epoch 10: LOSS= 0.37992, lr= 0.002000, acc1= 88.24,acc3= 98.50,acc10= 99.93\n",
      "eval E010: 100% 23/23 [00:31<00:00,  1.35s/it]\n",
      "INFO - 08/10/22 19:17:40 - 0:10:12 - #################################################################################################################\n",
      "INFO - 08/10/22 19:17:40 - 0:10:12 - Test Epoch 10: LOSS= 1.97489, acc1= 63.97, acc3= 83.88, acc10= 95.29\n",
      "INFO - 08/10/22 19:17:40 - 0:10:12 - #################################################################################################################\n",
      "train E011: 100% 21/21 [00:31<00:00,  1.49s/it]\n",
      "INFO - 08/10/22 19:18:12 - 0:10:44 - Train Epoch 11: LOSS= 0.35351, lr= 0.002000, acc1= 89.25,acc3= 98.95,acc10= 99.93\n",
      "eval E011: 100% 23/23 [00:27<00:00,  1.18s/it]\n",
      "INFO - 08/10/22 19:18:39 - 0:11:11 - #################################################################################################################\n",
      "INFO - 08/10/22 19:18:39 - 0:11:11 - Test Epoch 11: LOSS= 2.05605, acc1= 63.02, acc3= 82.25, acc10= 93.91\n",
      "INFO - 08/10/22 19:18:39 - 0:11:11 - #################################################################################################################\n",
      "train E012: 100% 21/21 [00:28<00:00,  1.34s/it]\n",
      "INFO - 08/10/22 19:19:07 - 0:11:39 - Train Epoch 12: LOSS= 0.36138, lr= 0.002000, acc1= 89.51,acc3= 98.84,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E012: 100% 23/23 [00:32<00:00,  1.42s/it]\n",
      "INFO - 08/10/22 19:19:40 - 0:12:12 - #################################################################################################################\n",
      "INFO - 08/10/22 19:19:40 - 0:12:12 - Test Epoch 12: LOSS= 2.20074, acc1= 63.87, acc3= 82.36, acc10= 94.58\n",
      "INFO - 08/10/22 19:19:40 - 0:12:12 - #################################################################################################################\n",
      "train E013: 100% 21/21 [00:30<00:00,  1.47s/it]\n",
      "INFO - 08/10/22 19:20:11 - 0:12:43 - Train Epoch 13: LOSS= 0.29608, lr= 0.002000, acc1= 91.27,acc3= 98.99,acc10= 99.89\n",
      "eval E013: 100% 23/23 [00:28<00:00,  1.26s/it]\n",
      "INFO - 08/10/22 19:20:39 - 0:13:12 - #################################################################################################################\n",
      "INFO - 08/10/22 19:20:39 - 0:13:12 - Test Epoch 13: LOSS= 2.22812, acc1= 64.08, acc3= 83.17, acc10= 95.25\n",
      "INFO - 08/10/22 19:20:39 - 0:13:12 - #################################################################################################################\n",
      "train E014: 100% 21/21 [00:27<00:00,  1.31s/it]\n",
      "INFO - 08/10/22 19:21:07 - 0:13:39 - Train Epoch 14: LOSS= 0.20578, lr= 0.001400, acc1= 93.48,acc3= 99.48,acc10= 99.96\n",
      "eval E014: 100% 23/23 [00:23<00:00,  1.01s/it]\n",
      "INFO - 08/10/22 19:21:30 - 0:14:02 - #################################################################################################################\n",
      "INFO - 08/10/22 19:21:30 - 0:14:02 - Test Epoch 14: LOSS= 2.30534, acc1= 65.36, acc3= 82.86, acc10= 94.97\n",
      "INFO - 08/10/22 19:21:30 - 0:14:02 - #################################################################################################################\n",
      "train E015: 100% 21/21 [00:25<00:00,  1.22s/it]\n",
      "INFO - 08/10/22 19:21:56 - 0:14:28 - Train Epoch 15: LOSS= 0.12385, lr= 0.001400, acc1= 95.77,acc3= 99.81,acc10= 100.00\n",
      "eval E015: 100% 23/23 [00:25<00:00,  1.12s/it]\n",
      "INFO - 08/10/22 19:22:21 - 0:14:54 - #################################################################################################################\n",
      "INFO - 08/10/22 19:22:21 - 0:14:54 - Test Epoch 15: LOSS= 2.38712, acc1= 64.79, acc3= 85.16, acc10= 95.32\n",
      "INFO - 08/10/22 19:22:21 - 0:14:54 - #################################################################################################################\n",
      "train E016: 100% 21/21 [00:22<00:00,  1.06s/it]\n",
      "INFO - 08/10/22 19:22:44 - 0:15:16 - Train Epoch 16: LOSS= 0.13875, lr= 0.001400, acc1= 96.10,acc3= 99.85,acc10= 100.00\n",
      "eval E016: 100% 23/23 [00:24<00:00,  1.05s/it]\n",
      "INFO - 08/10/22 19:23:08 - 0:15:40 - #################################################################################################################\n",
      "INFO - 08/10/22 19:23:08 - 0:15:40 - Test Epoch 16: LOSS= 2.30727, acc1= 65.53, acc3= 83.53, acc10= 95.39\n",
      "INFO - 08/10/22 19:23:08 - 0:15:40 - #################################################################################################################\n",
      "train E017: 100% 21/21 [00:24<00:00,  1.17s/it]\n",
      "INFO - 08/10/22 19:23:33 - 0:16:05 - Train Epoch 17: LOSS= 0.09101, lr= 0.000980, acc1= 97.15,acc3= 99.96,acc10= 100.00\n",
      "eval E017: 100% 23/23 [00:22<00:00,  1.02it/s]\n",
      "INFO - 08/10/22 19:23:55 - 0:16:27 - #################################################################################################################\n",
      "INFO - 08/10/22 19:23:55 - 0:16:27 - Test Epoch 17: LOSS= 2.39912, acc1= 65.89, acc3= 83.71, acc10= 95.18\n",
      "INFO - 08/10/22 19:23:55 - 0:16:27 - #################################################################################################################\n",
      "train E018: 100% 21/21 [00:22<00:00,  1.08s/it]\n",
      "INFO - 08/10/22 19:24:18 - 0:16:50 - Train Epoch 18: LOSS= 0.06630, lr= 0.000980, acc1= 97.98,acc3= 99.93,acc10= 100.00\n",
      "eval E018: 100% 23/23 [00:21<00:00,  1.05it/s]\n",
      "INFO - 08/10/22 19:24:40 - 0:17:12 - #################################################################################################################\n",
      "INFO - 08/10/22 19:24:40 - 0:17:12 - Test Epoch 18: LOSS= 2.19712, acc1= 66.38, acc3= 83.67, acc10= 94.83\n",
      "INFO - 08/10/22 19:24:40 - 0:17:12 - #################################################################################################################\n",
      "train E019: 100% 21/21 [00:21<00:00,  1.04s/it]\n",
      "INFO - 08/10/22 19:25:01 - 0:17:34 - Train Epoch 19: LOSS= 0.07166, lr= 0.000980, acc1= 97.90,acc3= 99.89,acc10= 100.00\n",
      "eval E019: 100% 23/23 [00:21<00:00,  1.05it/s]\n",
      "INFO - 08/10/22 19:25:23 - 0:17:55 - #################################################################################################################\n",
      "INFO - 08/10/22 19:25:23 - 0:17:55 - Test Epoch 19: LOSS= 2.26404, acc1= 66.14, acc3= 84.24, acc10= 94.90\n",
      "INFO - 08/10/22 19:25:23 - 0:17:55 - #################################################################################################################\n",
      "train E020: 100% 21/21 [00:21<00:00,  1.00s/it]\n",
      "INFO - 08/10/22 19:25:44 - 0:18:17 - Train Epoch 20: LOSS= 0.04308, lr= 0.000686, acc1= 98.61,acc3= 100.00,acc10= 100.00\n",
      "eval E020: 100% 23/23 [00:21<00:00,  1.05it/s]\n",
      "INFO - 08/10/22 19:26:06 - 0:18:38 - #################################################################################################################\n",
      "INFO - 08/10/22 19:26:06 - 0:18:38 - Test Epoch 20: LOSS= 2.38612, acc1= 66.28, acc3= 84.73, acc10= 94.65\n",
      "INFO - 08/10/22 19:26:06 - 0:18:38 - #################################################################################################################\n",
      "train E021: 100% 21/21 [00:23<00:00,  1.10s/it]\n",
      "INFO - 08/10/22 19:26:29 - 0:19:02 - Train Epoch 21: LOSS= 0.04233, lr= 0.000686, acc1= 98.65,acc3= 99.93,acc10= 100.00\n",
      "eval E021: 100% 23/23 [00:25<00:00,  1.10s/it]\n",
      "INFO - 08/10/22 19:26:55 - 0:19:27 - #################################################################################################################\n",
      "INFO - 08/10/22 19:26:55 - 0:19:27 - Test Epoch 21: LOSS= 2.51846, acc1= 66.91, acc3= 84.02, acc10= 94.83\n",
      "INFO - 08/10/22 19:26:55 - 0:19:27 - #################################################################################################################\n",
      "train E022: 100% 21/21 [00:21<00:00,  1.04s/it]\n",
      "INFO - 08/10/22 19:27:17 - 0:19:49 - Train Epoch 22: LOSS= 0.02954, lr= 0.000686, acc1= 98.99,acc3= 100.00,acc10= 100.00\n",
      "eval E022: 100% 23/23 [00:23<00:00,  1.01s/it]\n",
      "INFO - 08/10/22 19:27:40 - 0:20:12 - #################################################################################################################\n",
      "INFO - 08/10/22 19:27:40 - 0:20:12 - Test Epoch 22: LOSS= 2.28055, acc1= 66.24, acc3= 84.24, acc10= 95.61\n",
      "INFO - 08/10/22 19:27:40 - 0:20:12 - #################################################################################################################\n",
      "train E023: 100% 21/21 [00:21<00:00,  1.00s/it]\n",
      "INFO - 08/10/22 19:28:01 - 0:20:33 - Train Epoch 23: LOSS= 0.02607, lr= 0.000480, acc1= 99.14,acc3= 100.00,acc10= 100.00\n",
      "eval E023: 100% 23/23 [00:24<00:00,  1.08s/it]\n",
      "INFO - 08/10/22 19:28:26 - 0:20:58 - #################################################################################################################\n",
      "INFO - 08/10/22 19:28:26 - 0:20:58 - Test Epoch 23: LOSS= 2.28223, acc1= 66.91, acc3= 84.66, acc10= 95.61\n",
      "INFO - 08/10/22 19:28:26 - 0:20:58 - #################################################################################################################\n",
      "train E024: 100% 21/21 [00:21<00:00,  1.04s/it]\n",
      "INFO - 08/10/22 19:28:48 - 0:21:20 - Train Epoch 24: LOSS= 0.02240, lr= 0.000480, acc1= 99.14,acc3= 100.00,acc10= 100.00\n",
      "eval E024: 100% 23/23 [00:23<00:00,  1.04s/it]\n",
      "INFO - 08/10/22 19:29:12 - 0:21:44 - #################################################################################################################\n",
      "INFO - 08/10/22 19:29:12 - 0:21:44 - Test Epoch 24: LOSS= 2.33366, acc1= 66.95, acc3= 84.56, acc10= 95.47\n",
      "INFO - 08/10/22 19:29:12 - 0:21:44 - #################################################################################################################\n",
      "train E025: 100% 21/21 [00:22<00:00,  1.08s/it]\n",
      "INFO - 08/10/22 19:29:34 - 0:22:06 - Train Epoch 25: LOSS= 0.02049, lr= 0.000480, acc1= 99.29,acc3= 100.00,acc10= 100.00\n",
      "eval E025: 100% 23/23 [00:19<00:00,  1.17it/s]\n",
      "INFO - 08/10/22 19:29:54 - 0:22:26 - #################################################################################################################\n",
      "INFO - 08/10/22 19:29:54 - 0:22:26 - Test Epoch 25: LOSS= 2.38242, acc1= 66.99, acc3= 84.13, acc10= 95.47\n",
      "INFO - 08/10/22 19:29:54 - 0:22:26 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E026: 100% 21/21 [00:21<00:00,  1.04s/it]\n",
      "INFO - 08/10/22 19:30:16 - 0:22:48 - Train Epoch 26: LOSS= 0.02554, lr= 0.000336, acc1= 99.06,acc3= 100.00,acc10= 100.00\n",
      "eval E026: 100% 23/23 [00:21<00:00,  1.06it/s]\n",
      "INFO - 08/10/22 19:30:37 - 0:23:09 - #################################################################################################################\n",
      "INFO - 08/10/22 19:30:37 - 0:23:09 - Test Epoch 26: LOSS= 2.39427, acc1= 67.13, acc3= 84.52, acc10= 94.97\n",
      "INFO - 08/10/22 19:30:37 - 0:23:09 - #################################################################################################################\n",
      "train E027: 100% 21/21 [00:23<00:00,  1.11s/it]\n",
      "INFO - 08/10/22 19:31:01 - 0:23:33 - Train Epoch 27: LOSS= 0.01459, lr= 0.000336, acc1= 99.55,acc3= 100.00,acc10= 100.00\n",
      "eval E027: 100% 23/23 [00:22<00:00,  1.04it/s]\n",
      "INFO - 08/10/22 19:31:23 - 0:23:55 - #################################################################################################################\n",
      "INFO - 08/10/22 19:31:23 - 0:23:55 - Test Epoch 27: LOSS= 2.26480, acc1= 66.67, acc3= 84.70, acc10= 95.01\n",
      "INFO - 08/10/22 19:31:23 - 0:23:55 - #################################################################################################################\n",
      "train E028: 100% 21/21 [00:23<00:00,  1.14s/it]\n",
      "INFO - 08/10/22 19:31:47 - 0:24:19 - Train Epoch 28: LOSS= 0.02129, lr= 0.000336, acc1= 99.44,acc3= 100.00,acc10= 100.00\n",
      "eval E028: 100% 23/23 [00:23<00:00,  1.02s/it]\n",
      "INFO - 08/10/22 19:32:10 - 0:24:42 - #################################################################################################################\n",
      "INFO - 08/10/22 19:32:10 - 0:24:42 - Test Epoch 28: LOSS= 2.35200, acc1= 66.99, acc3= 84.31, acc10= 94.83\n",
      "INFO - 08/10/22 19:32:10 - 0:24:42 - #################################################################################################################\n",
      "train E029: 100% 21/21 [00:20<00:00,  1.03it/s]\n",
      "INFO - 08/10/22 19:32:31 - 0:25:03 - Train Epoch 29: LOSS= 0.01548, lr= 0.000235, acc1= 99.40,acc3= 100.00,acc10= 100.00\n",
      "eval E029: 100% 23/23 [00:23<00:00,  1.02s/it]\n",
      "INFO - 08/10/22 19:32:54 - 0:25:26 - #################################################################################################################\n",
      "INFO - 08/10/22 19:32:54 - 0:25:26 - Test Epoch 29: LOSS= 2.39031, acc1= 67.41, acc3= 84.48, acc10= 94.93\n",
      "INFO - 08/10/22 19:32:54 - 0:25:26 - #################################################################################################################\n",
      "train E030: 100% 21/21 [00:20<00:00,  1.04it/s]\n",
      "INFO - 08/10/22 19:33:14 - 0:25:46 - Train Epoch 30: LOSS= 0.01301, lr= 0.000235, acc1= 99.51,acc3= 100.00,acc10= 100.00\n",
      "eval E030: 100% 23/23 [00:21<00:00,  1.09it/s]\n",
      "INFO - 08/10/22 19:33:35 - 0:26:08 - #################################################################################################################\n",
      "INFO - 08/10/22 19:33:35 - 0:26:08 - Test Epoch 30: LOSS= 2.27893, acc1= 67.02, acc3= 84.87, acc10= 94.86\n",
      "INFO - 08/10/22 19:33:35 - 0:26:08 - #################################################################################################################\n",
      "train E031: 100% 21/21 [00:23<00:00,  1.11s/it]\n",
      "INFO - 08/10/22 19:33:59 - 0:26:31 - Train Epoch 31: LOSS= 0.01551, lr= 0.000235, acc1= 99.55,acc3= 100.00,acc10= 100.00\n",
      "eval E031: 100% 23/23 [00:23<00:00,  1.02s/it]\n",
      "INFO - 08/10/22 19:34:22 - 0:26:55 - #################################################################################################################\n",
      "INFO - 08/10/22 19:34:22 - 0:26:55 - Test Epoch 31: LOSS= 2.39681, acc1= 67.30, acc3= 84.91, acc10= 95.08\n",
      "INFO - 08/10/22 19:34:22 - 0:26:55 - #################################################################################################################\n",
      "train E032: 100% 21/21 [00:23<00:00,  1.10s/it]\n",
      "INFO - 08/10/22 19:34:45 - 0:27:18 - Train Epoch 32: LOSS= 0.00937, lr= 0.000165, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E032: 100% 23/23 [00:24<00:00,  1.05s/it]\n",
      "INFO - 08/10/22 19:35:10 - 0:27:42 - #################################################################################################################\n",
      "INFO - 08/10/22 19:35:10 - 0:27:42 - Test Epoch 32: LOSS= 2.53093, acc1= 67.52, acc3= 84.95, acc10= 95.01\n",
      "INFO - 08/10/22 19:35:10 - 0:27:42 - #################################################################################################################\n",
      "train E033: 100% 21/21 [00:20<00:00,  1.00it/s]\n",
      "INFO - 08/10/22 19:35:31 - 0:28:03 - Train Epoch 33: LOSS= 0.01409, lr= 0.000165, acc1= 99.63,acc3= 100.00,acc10= 100.00\n",
      "eval E033: 100% 23/23 [00:21<00:00,  1.08it/s]\n",
      "INFO - 08/10/22 19:35:52 - 0:28:24 - #################################################################################################################\n",
      "INFO - 08/10/22 19:35:52 - 0:28:24 - Test Epoch 33: LOSS= 2.51916, acc1= 67.30, acc3= 84.63, acc10= 94.97\n",
      "INFO - 08/10/22 19:35:52 - 0:28:24 - #################################################################################################################\n",
      "train E034: 100% 21/21 [00:18<00:00,  1.16it/s]\n",
      "INFO - 08/10/22 19:36:10 - 0:28:42 - Train Epoch 34: LOSS= 0.01215, lr= 0.000165, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E034: 100% 23/23 [00:14<00:00,  1.57it/s]\n",
      "INFO - 08/10/22 19:36:25 - 0:28:57 - #################################################################################################################\n",
      "INFO - 08/10/22 19:36:25 - 0:28:57 - Test Epoch 34: LOSS= 2.47495, acc1= 67.48, acc3= 84.48, acc10= 94.86\n",
      "INFO - 08/10/22 19:36:25 - 0:28:57 - #################################################################################################################\n",
      "train E035: 100% 21/21 [00:15<00:00,  1.35it/s]\n",
      "INFO - 08/10/22 19:36:40 - 0:29:12 - Train Epoch 35: LOSS= 0.01314, lr= 0.000115, acc1= 99.63,acc3= 100.00,acc10= 100.00\n",
      "eval E035: 100% 23/23 [00:14<00:00,  1.56it/s]\n",
      "INFO - 08/10/22 19:36:55 - 0:29:27 - #################################################################################################################\n",
      "INFO - 08/10/22 19:36:55 - 0:29:27 - Test Epoch 35: LOSS= 2.46780, acc1= 67.38, acc3= 84.56, acc10= 94.93\n",
      "INFO - 08/10/22 19:36:55 - 0:29:27 - #################################################################################################################\n",
      "train E036: 100% 21/21 [00:15<00:00,  1.35it/s]\n",
      "INFO - 08/10/22 19:37:11 - 0:29:43 - Train Epoch 36: LOSS= 0.01214, lr= 0.000115, acc1= 99.63,acc3= 100.00,acc10= 100.00\n",
      "eval E036: 100% 23/23 [00:15<00:00,  1.51it/s]\n",
      "INFO - 08/10/22 19:37:26 - 0:29:58 - #################################################################################################################\n",
      "INFO - 08/10/22 19:37:26 - 0:29:58 - Test Epoch 36: LOSS= 2.45659, acc1= 67.41, acc3= 84.59, acc10= 95.04\n",
      "INFO - 08/10/22 19:37:26 - 0:29:58 - #################################################################################################################\n",
      "train E037: 100% 21/21 [00:14<00:00,  1.43it/s]\n",
      "INFO - 08/10/22 19:37:40 - 0:30:13 - Train Epoch 37: LOSS= 0.01330, lr= 0.000115, acc1= 99.55,acc3= 100.00,acc10= 100.00\n",
      "eval E037: 100% 23/23 [00:15<00:00,  1.46it/s]\n",
      "INFO - 08/10/22 19:37:56 - 0:30:28 - #################################################################################################################\n",
      "INFO - 08/10/22 19:37:56 - 0:30:28 - Test Epoch 37: LOSS= 2.49100, acc1= 67.48, acc3= 84.63, acc10= 95.08\n",
      "INFO - 08/10/22 19:37:56 - 0:30:28 - #################################################################################################################\n",
      "train E038: 100% 21/21 [00:15<00:00,  1.32it/s]\n",
      "INFO - 08/10/22 19:38:12 - 0:30:44 - Train Epoch 38: LOSS= 0.00828, lr= 0.000081, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E038: 100% 23/23 [00:15<00:00,  1.49it/s]\n",
      "INFO - 08/10/22 19:38:28 - 0:31:00 - #################################################################################################################\n",
      "INFO - 08/10/22 19:38:28 - 0:31:00 - Test Epoch 38: LOSS= 2.38583, acc1= 67.30, acc3= 84.70, acc10= 95.04\n",
      "INFO - 08/10/22 19:38:28 - 0:31:00 - #################################################################################################################\n",
      "train E039: 100% 21/21 [00:15<00:00,  1.39it/s]\n",
      "INFO - 08/10/22 19:38:43 - 0:31:15 - Train Epoch 39: LOSS= 0.01337, lr= 0.000081, acc1= 99.59,acc3= 100.00,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E039: 100% 23/23 [00:14<00:00,  1.56it/s]\n",
      "INFO - 08/10/22 19:38:57 - 0:31:29 - #################################################################################################################\n",
      "INFO - 08/10/22 19:38:57 - 0:31:29 - Test Epoch 39: LOSS= 2.41518, acc1= 67.52, acc3= 84.70, acc10= 95.08\n",
      "INFO - 08/10/22 19:38:57 - 0:31:29 - #################################################################################################################\n",
      "train E040: 100% 21/21 [00:14<00:00,  1.45it/s]\n",
      "INFO - 08/10/22 19:39:12 - 0:31:44 - Train Epoch 40: LOSS= 0.01420, lr= 0.000081, acc1= 99.78,acc3= 99.96,acc10= 100.00\n",
      "eval E040: 100% 23/23 [00:14<00:00,  1.55it/s]\n",
      "INFO - 08/10/22 19:39:27 - 0:31:59 - #################################################################################################################\n",
      "INFO - 08/10/22 19:39:27 - 0:31:59 - Test Epoch 40: LOSS= 2.45091, acc1= 67.66, acc3= 84.70, acc10= 95.01\n",
      "INFO - 08/10/22 19:39:27 - 0:31:59 - #################################################################################################################\n",
      "train E041: 100% 21/21 [00:15<00:00,  1.40it/s]\n",
      "INFO - 08/10/22 19:39:42 - 0:32:14 - Train Epoch 41: LOSS= 0.01348, lr= 0.000056, acc1= 99.59,acc3= 100.00,acc10= 100.00\n",
      "eval E041: 100% 23/23 [00:15<00:00,  1.46it/s]\n",
      "INFO - 08/10/22 19:39:57 - 0:32:30 - #################################################################################################################\n",
      "INFO - 08/10/22 19:39:57 - 0:32:30 - Test Epoch 41: LOSS= 2.42781, acc1= 67.55, acc3= 84.73, acc10= 95.01\n",
      "INFO - 08/10/22 19:39:57 - 0:32:30 - #################################################################################################################\n",
      "train E042: 100% 21/21 [00:15<00:00,  1.39it/s]\n",
      "INFO - 08/10/22 19:40:13 - 0:32:45 - Train Epoch 42: LOSS= 0.01178, lr= 0.000056, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E042: 100% 23/23 [00:14<00:00,  1.59it/s]\n",
      "INFO - 08/10/22 19:40:27 - 0:32:59 - #################################################################################################################\n",
      "INFO - 08/10/22 19:40:27 - 0:32:59 - Test Epoch 42: LOSS= 2.47649, acc1= 67.62, acc3= 84.84, acc10= 95.01\n",
      "INFO - 08/10/22 19:40:27 - 0:32:59 - #################################################################################################################\n",
      "train E043: 100% 21/21 [00:15<00:00,  1.34it/s]\n",
      "INFO - 08/10/22 19:40:43 - 0:33:15 - Train Epoch 43: LOSS= 0.01350, lr= 0.000056, acc1= 99.48,acc3= 100.00,acc10= 100.00\n",
      "eval E043: 100% 23/23 [00:14<00:00,  1.53it/s]\n",
      "INFO - 08/10/22 19:40:58 - 0:33:30 - #################################################################################################################\n",
      "INFO - 08/10/22 19:40:58 - 0:33:30 - Test Epoch 43: LOSS= 2.46920, acc1= 67.59, acc3= 84.63, acc10= 95.01\n",
      "INFO - 08/10/22 19:40:58 - 0:33:30 - #################################################################################################################\n",
      "train E044: 100% 21/21 [00:15<00:00,  1.37it/s]\n",
      "INFO - 08/10/22 19:41:13 - 0:33:45 - Train Epoch 44: LOSS= 0.01206, lr= 0.000040, acc1= 99.63,acc3= 100.00,acc10= 100.00\n",
      "eval E044: 100% 23/23 [00:15<00:00,  1.50it/s]\n",
      "INFO - 08/10/22 19:41:28 - 0:34:00 - #################################################################################################################\n",
      "INFO - 08/10/22 19:41:28 - 0:34:00 - Test Epoch 44: LOSS= 2.50481, acc1= 67.52, acc3= 84.59, acc10= 94.97\n",
      "INFO - 08/10/22 19:41:28 - 0:34:00 - #################################################################################################################\n",
      "train E045: 100% 21/21 [00:14<00:00,  1.45it/s]\n",
      "INFO - 08/10/22 19:41:43 - 0:34:15 - Train Epoch 45: LOSS= 0.01204, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E045: 100% 23/23 [00:14<00:00,  1.59it/s]\n",
      "INFO - 08/10/22 19:41:57 - 0:34:29 - #################################################################################################################\n",
      "INFO - 08/10/22 19:41:57 - 0:34:29 - Test Epoch 45: LOSS= 2.39691, acc1= 67.41, acc3= 84.56, acc10= 95.04\n",
      "INFO - 08/10/22 19:41:57 - 0:34:29 - #################################################################################################################\n",
      "train E046: 100% 21/21 [00:13<00:00,  1.50it/s]\n",
      "INFO - 08/10/22 19:42:11 - 0:34:43 - Train Epoch 46: LOSS= 0.00521, lr= 0.000040, acc1= 99.85,acc3= 100.00,acc10= 100.00\n",
      "eval E046: 100% 23/23 [00:14<00:00,  1.64it/s]\n",
      "INFO - 08/10/22 19:42:25 - 0:34:57 - #################################################################################################################\n",
      "INFO - 08/10/22 19:42:25 - 0:34:57 - Test Epoch 46: LOSS= 2.46160, acc1= 67.52, acc3= 84.73, acc10= 95.04\n",
      "INFO - 08/10/22 19:42:25 - 0:34:57 - #################################################################################################################\n",
      "train E047: 100% 21/21 [00:14<00:00,  1.41it/s]\n",
      "INFO - 08/10/22 19:42:40 - 0:35:12 - Train Epoch 47: LOSS= 0.01397, lr= 0.000040, acc1= 99.55,acc3= 100.00,acc10= 100.00\n",
      "eval E047: 100% 23/23 [00:16<00:00,  1.41it/s]\n",
      "INFO - 08/10/22 19:42:56 - 0:35:29 - #################################################################################################################\n",
      "INFO - 08/10/22 19:42:56 - 0:35:29 - Test Epoch 47: LOSS= 2.43471, acc1= 67.62, acc3= 84.66, acc10= 95.04\n",
      "INFO - 08/10/22 19:42:56 - 0:35:29 - #################################################################################################################\n",
      "train E048: 100% 21/21 [00:14<00:00,  1.41it/s]\n",
      "INFO - 08/10/22 19:43:11 - 0:35:43 - Train Epoch 48: LOSS= 0.01272, lr= 0.000040, acc1= 99.59,acc3= 100.00,acc10= 100.00\n",
      "eval E048: 100% 23/23 [00:14<00:00,  1.55it/s]\n",
      "INFO - 08/10/22 19:43:26 - 0:35:58 - #################################################################################################################\n",
      "INFO - 08/10/22 19:43:26 - 0:35:58 - Test Epoch 48: LOSS= 2.46838, acc1= 67.48, acc3= 84.70, acc10= 95.08\n",
      "INFO - 08/10/22 19:43:26 - 0:35:58 - #################################################################################################################\n",
      "train E049: 100% 21/21 [00:16<00:00,  1.26it/s]\n",
      "INFO - 08/10/22 19:43:43 - 0:36:15 - Train Epoch 49: LOSS= 0.01221, lr= 0.000040, acc1= 99.63,acc3= 100.00,acc10= 100.00\n",
      "eval E049: 100% 23/23 [00:15<00:00,  1.49it/s]\n",
      "INFO - 08/10/22 19:43:58 - 0:36:30 - #################################################################################################################\n",
      "INFO - 08/10/22 19:43:58 - 0:36:30 - Test Epoch 49: LOSS= 2.36831, acc1= 67.41, acc3= 84.73, acc10= 95.11\n",
      "INFO - 08/10/22 19:43:58 - 0:36:30 - #################################################################################################################\n",
      "train E050: 100% 21/21 [00:15<00:00,  1.36it/s]\n",
      "INFO - 08/10/22 19:44:14 - 0:36:46 - Train Epoch 50: LOSS= 0.01334, lr= 0.000040, acc1= 99.66,acc3= 99.96,acc10= 100.00\n",
      "eval E050: 100% 23/23 [00:15<00:00,  1.51it/s]\n",
      "INFO - 08/10/22 19:44:29 - 0:37:01 - #################################################################################################################\n",
      "INFO - 08/10/22 19:44:29 - 0:37:01 - Test Epoch 50: LOSS= 2.41841, acc1= 67.45, acc3= 84.77, acc10= 95.15\n",
      "INFO - 08/10/22 19:44:29 - 0:37:01 - #################################################################################################################\n",
      "train E051: 100% 21/21 [00:14<00:00,  1.43it/s]\n",
      "INFO - 08/10/22 19:44:44 - 0:37:16 - Train Epoch 51: LOSS= 0.01302, lr= 0.000040, acc1= 99.48,acc3= 100.00,acc10= 100.00\n",
      "eval E051: 100% 23/23 [00:16<00:00,  1.39it/s]\n",
      "INFO - 08/10/22 19:45:00 - 0:37:32 - #################################################################################################################\n",
      "INFO - 08/10/22 19:45:00 - 0:37:32 - Test Epoch 51: LOSS= 2.48926, acc1= 67.52, acc3= 85.02, acc10= 95.15\n",
      "INFO - 08/10/22 19:45:00 - 0:37:32 - #################################################################################################################\n",
      "train E052: 100% 21/21 [00:15<00:00,  1.39it/s]\n",
      "INFO - 08/10/22 19:45:15 - 0:37:47 - Train Epoch 52: LOSS= 0.01020, lr= 0.000040, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E052: 100% 23/23 [00:14<00:00,  1.58it/s]\n",
      "INFO - 08/10/22 19:45:30 - 0:38:02 - #################################################################################################################\n",
      "INFO - 08/10/22 19:45:30 - 0:38:02 - Test Epoch 52: LOSS= 2.59940, acc1= 67.38, acc3= 84.77, acc10= 95.15\n",
      "INFO - 08/10/22 19:45:30 - 0:38:02 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E053: 100% 21/21 [00:15<00:00,  1.38it/s]\n",
      "INFO - 08/10/22 19:45:45 - 0:38:17 - Train Epoch 53: LOSS= 0.01165, lr= 0.000040, acc1= 99.63,acc3= 100.00,acc10= 100.00\n",
      "eval E053: 100% 23/23 [00:15<00:00,  1.44it/s]\n",
      "INFO - 08/10/22 19:46:01 - 0:38:33 - #################################################################################################################\n",
      "INFO - 08/10/22 19:46:01 - 0:38:33 - Test Epoch 53: LOSS= 2.42402, acc1= 67.48, acc3= 84.80, acc10= 95.11\n",
      "INFO - 08/10/22 19:46:01 - 0:38:33 - #################################################################################################################\n",
      "train E054: 100% 21/21 [00:14<00:00,  1.44it/s]\n",
      "INFO - 08/10/22 19:46:16 - 0:38:48 - Train Epoch 54: LOSS= 0.00886, lr= 0.000040, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E054: 100% 23/23 [00:14<00:00,  1.56it/s]\n",
      "INFO - 08/10/22 19:46:30 - 0:39:03 - #################################################################################################################\n",
      "INFO - 08/10/22 19:46:30 - 0:39:03 - Test Epoch 54: LOSS= 2.53926, acc1= 67.66, acc3= 84.80, acc10= 95.08\n",
      "INFO - 08/10/22 19:46:30 - 0:39:03 - #################################################################################################################\n",
      "train E055: 100% 21/21 [00:15<00:00,  1.37it/s]\n",
      "INFO - 08/10/22 19:46:46 - 0:39:18 - Train Epoch 55: LOSS= 0.01128, lr= 0.000040, acc1= 99.51,acc3= 100.00,acc10= 100.00\n",
      "eval E055: 100% 23/23 [00:15<00:00,  1.49it/s]\n",
      "INFO - 08/10/22 19:47:01 - 0:39:33 - #################################################################################################################\n",
      "INFO - 08/10/22 19:47:01 - 0:39:33 - Test Epoch 55: LOSS= 2.54983, acc1= 67.45, acc3= 84.63, acc10= 95.08\n",
      "INFO - 08/10/22 19:47:01 - 0:39:33 - #################################################################################################################\n",
      "train E056: 100% 21/21 [00:14<00:00,  1.43it/s]\n",
      "INFO - 08/10/22 19:47:16 - 0:39:48 - Train Epoch 56: LOSS= 0.00850, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E056: 100% 23/23 [00:14<00:00,  1.56it/s]\n",
      "INFO - 08/10/22 19:47:31 - 0:40:03 - #################################################################################################################\n",
      "INFO - 08/10/22 19:47:31 - 0:40:03 - Test Epoch 56: LOSS= 2.61429, acc1= 67.41, acc3= 84.66, acc10= 95.01\n",
      "INFO - 08/10/22 19:47:31 - 0:40:03 - #################################################################################################################\n",
      "train E057: 100% 21/21 [00:15<00:00,  1.38it/s]\n",
      "INFO - 08/10/22 19:47:46 - 0:40:18 - Train Epoch 57: LOSS= 0.01406, lr= 0.000040, acc1= 99.63,acc3= 100.00,acc10= 100.00\n",
      "eval E057: 100% 23/23 [00:15<00:00,  1.49it/s]\n",
      "INFO - 08/10/22 19:48:01 - 0:40:33 - #################################################################################################################\n",
      "INFO - 08/10/22 19:48:01 - 0:40:33 - Test Epoch 57: LOSS= 2.40186, acc1= 67.62, acc3= 84.66, acc10= 95.01\n",
      "INFO - 08/10/22 19:48:01 - 0:40:33 - #################################################################################################################\n",
      "train E058: 100% 21/21 [00:15<00:00,  1.36it/s]\n",
      "INFO - 08/10/22 19:48:17 - 0:40:49 - Train Epoch 58: LOSS= 0.01163, lr= 0.000040, acc1= 99.55,acc3= 100.00,acc10= 100.00\n",
      "eval E058: 100% 23/23 [00:14<00:00,  1.58it/s]\n",
      "INFO - 08/10/22 19:48:31 - 0:41:03 - #################################################################################################################\n",
      "INFO - 08/10/22 19:48:31 - 0:41:03 - Test Epoch 58: LOSS= 2.65151, acc1= 67.52, acc3= 84.77, acc10= 95.04\n",
      "INFO - 08/10/22 19:48:31 - 0:41:03 - #################################################################################################################\n",
      "train E059: 100% 21/21 [00:16<00:00,  1.27it/s]\n",
      "INFO - 08/10/22 19:48:48 - 0:41:20 - Train Epoch 59: LOSS= 0.00962, lr= 0.000040, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E059: 100% 23/23 [00:14<00:00,  1.56it/s]\n",
      "INFO - 08/10/22 19:49:02 - 0:41:34 - #################################################################################################################\n",
      "INFO - 08/10/22 19:49:02 - 0:41:34 - Test Epoch 59: LOSS= 2.36418, acc1= 67.41, acc3= 84.63, acc10= 95.22\n",
      "INFO - 08/10/22 19:49:02 - 0:41:34 - #################################################################################################################\n",
      "train E060: 100% 21/21 [00:14<00:00,  1.46it/s]\n",
      "INFO - 08/10/22 19:49:17 - 0:41:49 - Train Epoch 60: LOSS= 0.01092, lr= 0.000040, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E060: 100% 23/23 [00:16<00:00,  1.39it/s]\n",
      "INFO - 08/10/22 19:49:33 - 0:42:05 - #################################################################################################################\n",
      "INFO - 08/10/22 19:49:33 - 0:42:05 - Test Epoch 60: LOSS= 2.63963, acc1= 67.20, acc3= 84.56, acc10= 95.18\n",
      "INFO - 08/10/22 19:49:33 - 0:42:05 - #################################################################################################################\n",
      "train E061: 100% 21/21 [00:15<00:00,  1.40it/s]\n",
      "INFO - 08/10/22 19:49:48 - 0:42:20 - Train Epoch 61: LOSS= 0.00914, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E061: 100% 23/23 [00:15<00:00,  1.49it/s]\n",
      "INFO - 08/10/22 19:50:04 - 0:42:36 - #################################################################################################################\n",
      "INFO - 08/10/22 19:50:04 - 0:42:36 - Test Epoch 61: LOSS= 2.41765, acc1= 67.27, acc3= 84.70, acc10= 95.15\n",
      "INFO - 08/10/22 19:50:04 - 0:42:36 - #################################################################################################################\n",
      "train E062: 100% 21/21 [00:17<00:00,  1.23it/s]\n",
      "INFO - 08/10/22 19:50:21 - 0:42:53 - Train Epoch 62: LOSS= 0.01116, lr= 0.000040, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E062: 100% 23/23 [00:15<00:00,  1.46it/s]\n",
      "INFO - 08/10/22 19:50:37 - 0:43:09 - #################################################################################################################\n",
      "INFO - 08/10/22 19:50:37 - 0:43:09 - Test Epoch 62: LOSS= 2.51553, acc1= 67.20, acc3= 84.63, acc10= 95.25\n",
      "INFO - 08/10/22 19:50:37 - 0:43:09 - #################################################################################################################\n",
      "train E063: 100% 21/21 [00:14<00:00,  1.42it/s]\n",
      "INFO - 08/10/22 19:50:51 - 0:43:24 - Train Epoch 63: LOSS= 0.01004, lr= 0.000040, acc1= 99.81,acc3= 99.96,acc10= 100.00\n",
      "eval E063: 100% 23/23 [00:15<00:00,  1.49it/s]\n",
      "INFO - 08/10/22 19:51:07 - 0:43:39 - #################################################################################################################\n",
      "INFO - 08/10/22 19:51:07 - 0:43:39 - Test Epoch 63: LOSS= 2.53979, acc1= 67.13, acc3= 84.77, acc10= 95.25\n",
      "INFO - 08/10/22 19:51:07 - 0:43:39 - #################################################################################################################\n",
      "train E064: 100% 21/21 [00:15<00:00,  1.38it/s]\n",
      "INFO - 08/10/22 19:51:22 - 0:43:54 - Train Epoch 64: LOSS= 0.01312, lr= 0.000040, acc1= 99.59,acc3= 100.00,acc10= 100.00\n",
      "eval E064: 100% 23/23 [00:14<00:00,  1.57it/s]\n",
      "INFO - 08/10/22 19:51:37 - 0:44:09 - #################################################################################################################\n",
      "INFO - 08/10/22 19:51:37 - 0:44:09 - Test Epoch 64: LOSS= 2.39257, acc1= 67.23, acc3= 84.70, acc10= 95.25\n",
      "INFO - 08/10/22 19:51:37 - 0:44:09 - #################################################################################################################\n",
      "train E065: 100% 21/21 [00:15<00:00,  1.40it/s]\n",
      "INFO - 08/10/22 19:51:52 - 0:44:24 - Train Epoch 65: LOSS= 0.00728, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E065: 100% 23/23 [00:14<00:00,  1.61it/s]\n",
      "INFO - 08/10/22 19:52:06 - 0:44:38 - #################################################################################################################\n",
      "INFO - 08/10/22 19:52:06 - 0:44:38 - Test Epoch 65: LOSS= 2.39749, acc1= 67.38, acc3= 84.59, acc10= 95.22\n",
      "INFO - 08/10/22 19:52:06 - 0:44:38 - #################################################################################################################\n",
      "train E066: 100% 21/21 [00:14<00:00,  1.42it/s]\n",
      "INFO - 08/10/22 19:52:21 - 0:44:53 - Train Epoch 66: LOSS= 0.00913, lr= 0.000040, acc1= 99.78,acc3= 100.00,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E066: 100% 23/23 [00:15<00:00,  1.46it/s]\n",
      "INFO - 08/10/22 19:52:37 - 0:45:09 - #################################################################################################################\n",
      "INFO - 08/10/22 19:52:37 - 0:45:09 - Test Epoch 66: LOSS= 2.36791, acc1= 67.27, acc3= 84.52, acc10= 95.04\n",
      "INFO - 08/10/22 19:52:37 - 0:45:09 - #################################################################################################################\n",
      "train E067: 100% 21/21 [00:14<00:00,  1.43it/s]\n",
      "INFO - 08/10/22 19:52:51 - 0:45:23 - Train Epoch 67: LOSS= 0.01220, lr= 0.000040, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E067: 100% 23/23 [00:14<00:00,  1.54it/s]\n",
      "INFO - 08/10/22 19:53:06 - 0:45:38 - #################################################################################################################\n",
      "INFO - 08/10/22 19:53:06 - 0:45:38 - Test Epoch 67: LOSS= 2.47357, acc1= 67.45, acc3= 84.56, acc10= 95.04\n",
      "INFO - 08/10/22 19:53:06 - 0:45:38 - #################################################################################################################\n",
      "train E068: 100% 21/21 [00:15<00:00,  1.39it/s]\n",
      "INFO - 08/10/22 19:53:22 - 0:45:54 - Train Epoch 68: LOSS= 0.01169, lr= 0.000040, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E068: 100% 23/23 [00:16<00:00,  1.42it/s]\n",
      "INFO - 08/10/22 19:53:38 - 0:46:10 - #################################################################################################################\n",
      "INFO - 08/10/22 19:53:38 - 0:46:10 - Test Epoch 68: LOSS= 2.47339, acc1= 67.34, acc3= 84.56, acc10= 95.08\n",
      "INFO - 08/10/22 19:53:38 - 0:46:10 - #################################################################################################################\n",
      "train E069: 100% 21/21 [00:14<00:00,  1.43it/s]\n",
      "INFO - 08/10/22 19:53:52 - 0:46:25 - Train Epoch 69: LOSS= 0.01007, lr= 0.000040, acc1= 99.59,acc3= 100.00,acc10= 100.00\n",
      "eval E069: 100% 23/23 [00:14<00:00,  1.59it/s]\n",
      "INFO - 08/10/22 19:54:07 - 0:46:39 - #################################################################################################################\n",
      "INFO - 08/10/22 19:54:07 - 0:46:39 - Test Epoch 69: LOSS= 2.36011, acc1= 67.34, acc3= 84.56, acc10= 95.08\n",
      "INFO - 08/10/22 19:54:07 - 0:46:39 - #################################################################################################################\n",
      "train E070: 100% 21/21 [00:16<00:00,  1.29it/s]\n",
      "INFO - 08/10/22 19:54:23 - 0:46:55 - Train Epoch 70: LOSS= 0.00912, lr= 0.000040, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E070: 100% 23/23 [00:15<00:00,  1.52it/s]\n",
      "INFO - 08/10/22 19:54:38 - 0:47:10 - #################################################################################################################\n",
      "INFO - 08/10/22 19:54:38 - 0:47:10 - Test Epoch 70: LOSS= 2.40110, acc1= 67.30, acc3= 84.59, acc10= 95.04\n",
      "INFO - 08/10/22 19:54:38 - 0:47:10 - #################################################################################################################\n",
      "train E071: 100% 21/21 [00:14<00:00,  1.42it/s]\n",
      "INFO - 08/10/22 19:54:53 - 0:47:25 - Train Epoch 71: LOSS= 0.00725, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E071: 100% 23/23 [00:15<00:00,  1.53it/s]\n",
      "INFO - 08/10/22 19:55:08 - 0:47:40 - #################################################################################################################\n",
      "INFO - 08/10/22 19:55:08 - 0:47:40 - Test Epoch 71: LOSS= 2.61702, acc1= 67.48, acc3= 84.48, acc10= 95.04\n",
      "INFO - 08/10/22 19:55:08 - 0:47:40 - #################################################################################################################\n",
      "train E072: 100% 21/21 [00:14<00:00,  1.45it/s]\n",
      "INFO - 08/10/22 19:55:23 - 0:47:55 - Train Epoch 72: LOSS= 0.01155, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E072: 100% 23/23 [00:14<00:00,  1.54it/s]\n",
      "INFO - 08/10/22 19:55:38 - 0:48:10 - #################################################################################################################\n",
      "INFO - 08/10/22 19:55:38 - 0:48:10 - Test Epoch 72: LOSS= 2.51467, acc1= 67.27, acc3= 84.48, acc10= 95.04\n",
      "INFO - 08/10/22 19:55:38 - 0:48:10 - #################################################################################################################\n",
      "train E073: 100% 21/21 [00:15<00:00,  1.32it/s]\n",
      "INFO - 08/10/22 19:55:53 - 0:48:26 - Train Epoch 73: LOSS= 0.01113, lr= 0.000040, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E073: 100% 23/23 [00:15<00:00,  1.51it/s]\n",
      "INFO - 08/10/22 19:56:09 - 0:48:41 - #################################################################################################################\n",
      "INFO - 08/10/22 19:56:09 - 0:48:41 - Test Epoch 73: LOSS= 2.53771, acc1= 67.02, acc3= 84.38, acc10= 95.08\n",
      "INFO - 08/10/22 19:56:09 - 0:48:41 - #################################################################################################################\n",
      "train E074: 100% 21/21 [00:15<00:00,  1.34it/s]\n",
      "INFO - 08/10/22 19:56:24 - 0:48:56 - Train Epoch 74: LOSS= 0.01025, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E074: 100% 23/23 [00:15<00:00,  1.51it/s]\n",
      "INFO - 08/10/22 19:56:40 - 0:49:12 - #################################################################################################################\n",
      "INFO - 08/10/22 19:56:40 - 0:49:12 - Test Epoch 74: LOSS= 2.42234, acc1= 67.34, acc3= 84.63, acc10= 95.15\n",
      "INFO - 08/10/22 19:56:40 - 0:49:12 - #################################################################################################################\n",
      "train E075: 100% 21/21 [00:16<00:00,  1.27it/s]\n",
      "INFO - 08/10/22 19:56:56 - 0:49:28 - Train Epoch 75: LOSS= 0.00725, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E075: 100% 23/23 [00:16<00:00,  1.43it/s]\n",
      "INFO - 08/10/22 19:57:12 - 0:49:44 - #################################################################################################################\n",
      "INFO - 08/10/22 19:57:12 - 0:49:44 - Test Epoch 75: LOSS= 2.38145, acc1= 67.38, acc3= 84.41, acc10= 95.08\n",
      "INFO - 08/10/22 19:57:12 - 0:49:44 - #################################################################################################################\n",
      "train E076: 100% 21/21 [00:17<00:00,  1.22it/s]\n",
      "INFO - 08/10/22 19:57:29 - 0:50:02 - Train Epoch 76: LOSS= 0.01064, lr= 0.000040, acc1= 99.59,acc3= 100.00,acc10= 100.00\n",
      "eval E076: 100% 23/23 [00:12<00:00,  1.86it/s]\n",
      "INFO - 08/10/22 19:57:42 - 0:50:14 - #################################################################################################################\n",
      "INFO - 08/10/22 19:57:42 - 0:50:14 - Test Epoch 76: LOSS= 2.52688, acc1= 67.30, acc3= 84.56, acc10= 95.11\n",
      "INFO - 08/10/22 19:57:42 - 0:50:14 - #################################################################################################################\n",
      "train E077: 100% 21/21 [00:12<00:00,  1.63it/s]\n",
      "INFO - 08/10/22 19:57:55 - 0:50:27 - Train Epoch 77: LOSS= 0.00741, lr= 0.000040, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E077: 100% 23/23 [00:12<00:00,  1.90it/s]\n",
      "INFO - 08/10/22 19:58:07 - 0:50:39 - #################################################################################################################\n",
      "INFO - 08/10/22 19:58:07 - 0:50:39 - Test Epoch 77: LOSS= 2.37994, acc1= 67.45, acc3= 84.56, acc10= 95.15\n",
      "INFO - 08/10/22 19:58:07 - 0:50:39 - #################################################################################################################\n",
      "train E078: 100% 21/21 [00:11<00:00,  1.75it/s]\n",
      "INFO - 08/10/22 19:58:19 - 0:50:51 - Train Epoch 78: LOSS= 0.00741, lr= 0.000040, acc1= 99.81,acc3= 100.00,acc10= 100.00\n",
      "eval E078: 100% 23/23 [00:11<00:00,  1.94it/s]\n",
      "INFO - 08/10/22 19:58:31 - 0:51:03 - #################################################################################################################\n",
      "INFO - 08/10/22 19:58:31 - 0:51:03 - Test Epoch 78: LOSS= 2.36842, acc1= 67.59, acc3= 84.73, acc10= 95.11\n",
      "INFO - 08/10/22 19:58:31 - 0:51:03 - #################################################################################################################\n",
      "train E079: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 08/10/22 19:58:43 - 0:51:15 - Train Epoch 79: LOSS= 0.00758, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E079: 100% 23/23 [00:11<00:00,  1.94it/s]\n",
      "INFO - 08/10/22 19:58:54 - 0:51:26 - #################################################################################################################\n",
      "INFO - 08/10/22 19:58:54 - 0:51:26 - Test Epoch 79: LOSS= 2.43899, acc1= 67.52, acc3= 84.77, acc10= 95.01\n",
      "INFO - 08/10/22 19:58:54 - 0:51:26 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E080: 100% 21/21 [00:11<00:00,  1.78it/s]\n",
      "INFO - 08/10/22 19:59:06 - 0:51:38 - Train Epoch 80: LOSS= 0.00785, lr= 0.000040, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E080: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
      "INFO - 08/10/22 19:59:18 - 0:51:50 - #################################################################################################################\n",
      "INFO - 08/10/22 19:59:18 - 0:51:50 - Test Epoch 80: LOSS= 2.56945, acc1= 67.52, acc3= 84.73, acc10= 95.04\n",
      "INFO - 08/10/22 19:59:18 - 0:51:50 - #################################################################################################################\n",
      "train E081: 100% 21/21 [00:11<00:00,  1.79it/s]\n",
      "INFO - 08/10/22 19:59:30 - 0:52:02 - Train Epoch 81: LOSS= 0.00897, lr= 0.000040, acc1= 99.66,acc3= 99.96,acc10= 100.00\n",
      "eval E081: 100% 23/23 [00:12<00:00,  1.91it/s]\n",
      "INFO - 08/10/22 19:59:42 - 0:52:14 - #################################################################################################################\n",
      "INFO - 08/10/22 19:59:42 - 0:52:14 - Test Epoch 81: LOSS= 2.46605, acc1= 67.59, acc3= 84.70, acc10= 95.08\n",
      "INFO - 08/10/22 19:59:42 - 0:52:14 - #################################################################################################################\n",
      "INFO - 08/10/22 19:59:43 - 0:52:16 - best performance =  67.52, 85.02, 95.15. best epoch = 51, correspond_loss= 2.4893\n",
      "INFO - 08/10/22 19:59:43 - 0:52:16 -  fusion_model_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_relation_SAN_3.pkl\n",
      "INFO - 08/10/22 19:59:43 - 0:52:16 -  answer_net_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_relation_MLP_3.pkl\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 08/10/22 19:59:47 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 08/10/22 19:59:47 - 0:00:00 - The experiment will be stored in dump/0810-object_space/W2V\n",
      "                                     \n",
      "INFO - 08/10/22 19:59:47 - 0:00:00 - Running command: python main.py --gpu_id 6 --exp_name object_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --save_model 1 --fact_map 1\n",
      "\n",
      "2022-08-10 19:59:47.655827: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-08-10 19:59:47.655876: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 128\n",
      "batch_size 128\n",
      "fusion_model:\n",
      "SAN(\n",
      "  (w_emb): WordEmbedding(\n",
      "    (emb): Embedding(15422, 300, padding_idx=15421)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (text): Seq2SeqRNN(\n",
      "    (rnn): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (attention): SanAttention(\n",
      "    (v_conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (q_lin): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (x_conv): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(5120, 8192, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(8192, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "Answer Model:\n",
      "MLP(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "train E000: 100% 21/21 [00:10<00:00,  1.94it/s]\n",
      "INFO - 08/10/22 20:00:13 - 0:00:26 - Train Epoch 0: LOSS= 6.98915, lr= 0.000500, acc1= 18.21,acc3= 27.95,acc10= 33.16\n",
      "train E001: 100% 21/21 [00:10<00:00,  1.94it/s]\n",
      "INFO - 08/10/22 20:00:24 - 0:00:37 - Train Epoch 1: LOSS= 3.55189, lr= 0.000750, acc1= 65.08,acc3= 76.47,acc10= 81.72\n",
      "eval E001: 100% 23/23 [00:10<00:00,  2.21it/s]\n",
      "INFO - 08/10/22 20:00:34 - 0:00:47 - #################################################################################################################\n",
      "INFO - 08/10/22 20:00:34 - 0:00:47 - Test Epoch 1: LOSS= 3.55105, acc1= 66.17, acc3= 77.29, acc10= 81.37\n",
      "INFO - 08/10/22 20:00:34 - 0:00:47 - #################################################################################################################\n",
      "train E002: 100% 21/21 [00:10<00:00,  2.00it/s]\n",
      "INFO - 08/10/22 20:00:45 - 0:00:58 - Train Epoch 2: LOSS= 2.23257, lr= 0.001000, acc1= 82.47,acc3= 89.43,acc10= 92.24\n",
      "eval E002: 100% 23/23 [00:09<00:00,  2.30it/s]\n",
      "INFO - 08/10/22 20:00:55 - 0:01:08 - #################################################################################################################\n",
      "INFO - 08/10/22 20:00:55 - 0:01:08 - Test Epoch 2: LOSS= 3.39228, acc1= 69.61, acc3= 79.74, acc10= 83.03\n",
      "INFO - 08/10/22 20:00:55 - 0:01:08 - #################################################################################################################\n",
      "train E003: 100% 21/21 [00:11<00:00,  1.86it/s]\n",
      "INFO - 08/10/22 20:01:06 - 0:01:19 - Train Epoch 3: LOSS= 1.54817, lr= 0.001250, acc1= 90.56,acc3= 94.90,acc10= 96.33\n",
      "eval E003: 100% 23/23 [00:10<00:00,  2.09it/s]\n",
      "INFO - 08/10/22 20:01:17 - 0:01:30 - #################################################################################################################\n",
      "INFO - 08/10/22 20:01:17 - 0:01:30 - Test Epoch 3: LOSS= 3.45564, acc1= 70.88, acc3= 80.48, acc10= 83.21\n",
      "INFO - 08/10/22 20:01:17 - 0:01:30 - #################################################################################################################\n",
      "train E004: 100% 21/21 [00:12<00:00,  1.68it/s]\n",
      "INFO - 08/10/22 20:01:30 - 0:01:43 - Train Epoch 4: LOSS= 1.20122, lr= 0.001500, acc1= 94.04,acc3= 97.45,acc10= 98.61\n",
      "eval E004: 100% 23/23 [00:12<00:00,  1.83it/s]\n",
      "INFO - 08/10/22 20:01:42 - 0:01:55 - #################################################################################################################\n",
      "INFO - 08/10/22 20:01:42 - 0:01:55 - Test Epoch 4: LOSS= 3.71190, acc1= 71.27, acc3= 80.16, acc10= 83.35\n",
      "INFO - 08/10/22 20:01:42 - 0:01:55 - #################################################################################################################\n",
      "train E005: 100% 21/21 [00:13<00:00,  1.60it/s]\n",
      "INFO - 08/10/22 20:01:55 - 0:02:08 - Train Epoch 5: LOSS= 1.12376, lr= 0.001750, acc1= 95.69,acc3= 98.05,acc10= 98.76\n",
      "eval E005: 100% 23/23 [00:12<00:00,  1.78it/s]\n",
      "INFO - 08/10/22 20:02:08 - 0:02:21 - #################################################################################################################\n",
      "INFO - 08/10/22 20:02:08 - 0:02:21 - Test Epoch 5: LOSS= 4.06498, acc1= 70.78, acc3= 79.10, acc10= 82.75\n",
      "INFO - 08/10/22 20:02:08 - 0:02:21 - #################################################################################################################\n",
      "train E006: 100% 21/21 [00:13<00:00,  1.61it/s]\n",
      "INFO - 08/10/22 20:02:21 - 0:02:34 - Train Epoch 6: LOSS= 1.17934, lr= 0.002000, acc1= 95.43,acc3= 97.75,acc10= 98.50\n",
      "eval E006: 100% 23/23 [00:12<00:00,  1.84it/s]\n",
      "INFO - 08/10/22 20:02:34 - 0:02:47 - #################################################################################################################\n",
      "INFO - 08/10/22 20:02:34 - 0:02:47 - Test Epoch 6: LOSS= 4.52825, acc1= 69.39, acc3= 78.57, acc10= 81.93\n",
      "INFO - 08/10/22 20:02:34 - 0:02:47 - #################################################################################################################\n",
      "train E007: 100% 21/21 [00:12<00:00,  1.62it/s]\n",
      "INFO - 08/10/22 20:02:47 - 0:03:00 - Train Epoch 7: LOSS= 1.12103, lr= 0.002000, acc1= 95.77,acc3= 98.28,acc10= 98.80\n",
      "eval E007: 100% 23/23 [00:11<00:00,  1.93it/s]\n",
      "INFO - 08/10/22 20:02:59 - 0:03:12 - #################################################################################################################\n",
      "INFO - 08/10/22 20:02:59 - 0:03:12 - Test Epoch 7: LOSS= 4.64540, acc1= 69.32, acc3= 78.21, acc10= 81.33\n",
      "INFO - 08/10/22 20:02:59 - 0:03:12 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E008: 100% 21/21 [00:13<00:00,  1.59it/s]\n",
      "INFO - 08/10/22 20:03:12 - 0:03:25 - Train Epoch 8: LOSS= 1.09146, lr= 0.002000, acc1= 95.73,acc3= 98.20,acc10= 98.80\n",
      "eval E008: 100% 23/23 [00:11<00:00,  2.03it/s]\n",
      "INFO - 08/10/22 20:03:23 - 0:03:36 - #################################################################################################################\n",
      "INFO - 08/10/22 20:03:23 - 0:03:36 - Test Epoch 8: LOSS= 4.70882, acc1= 69.18, acc3= 77.33, acc10= 80.91\n",
      "INFO - 08/10/22 20:03:23 - 0:03:36 - #################################################################################################################\n",
      "train E009: 100% 21/21 [00:13<00:00,  1.61it/s]\n",
      "INFO - 08/10/22 20:03:36 - 0:03:49 - Train Epoch 9: LOSS= 0.87226, lr= 0.002000, acc1= 97.45,acc3= 99.06,acc10= 99.48\n",
      "eval E009: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
      "INFO - 08/10/22 20:03:48 - 0:04:01 - #################################################################################################################\n",
      "INFO - 08/10/22 20:03:48 - 0:04:01 - Test Epoch 9: LOSS= 5.12612, acc1= 70.60, acc3= 77.97, acc10= 80.98\n",
      "INFO - 08/10/22 20:03:48 - 0:04:01 - #################################################################################################################\n",
      "train E010: 100% 21/21 [00:14<00:00,  1.49it/s]\n",
      "INFO - 08/10/22 20:04:02 - 0:04:15 - Train Epoch 10: LOSS= 0.78597, lr= 0.002000, acc1= 98.28,acc3= 99.44,acc10= 99.59\n",
      "eval E010: 100% 23/23 [00:13<00:00,  1.73it/s]\n",
      "INFO - 08/10/22 20:04:15 - 0:04:28 - #################################################################################################################\n",
      "INFO - 08/10/22 20:04:15 - 0:04:28 - Test Epoch 10: LOSS= 5.03965, acc1= 69.64, acc3= 77.72, acc10= 81.12\n",
      "INFO - 08/10/22 20:04:15 - 0:04:28 - #################################################################################################################\n",
      "train E011: 100% 21/21 [00:13<00:00,  1.60it/s]\n",
      "INFO - 08/10/22 20:04:29 - 0:04:42 - Train Epoch 11: LOSS= 0.82391, lr= 0.002000, acc1= 97.53,acc3= 99.36,acc10= 99.63\n",
      "eval E011: 100% 23/23 [00:12<00:00,  1.88it/s]\n",
      "INFO - 08/10/22 20:04:41 - 0:04:54 - #################################################################################################################\n",
      "INFO - 08/10/22 20:04:41 - 0:04:54 - Test Epoch 11: LOSS= 5.28951, acc1= 70.32, acc3= 78.82, acc10= 81.86\n",
      "INFO - 08/10/22 20:04:41 - 0:04:54 - #################################################################################################################\n",
      "train E012: 100% 21/21 [00:13<00:00,  1.50it/s]\n",
      "INFO - 08/10/22 20:04:55 - 0:05:08 - Train Epoch 12: LOSS= 0.76499, lr= 0.002000, acc1= 97.98,acc3= 99.33,acc10= 99.59\n",
      "eval E012: 100% 23/23 [00:12<00:00,  1.79it/s]\n",
      "INFO - 08/10/22 20:05:08 - 0:05:21 - #################################################################################################################\n",
      "INFO - 08/10/22 20:05:08 - 0:05:21 - Test Epoch 12: LOSS= 5.28589, acc1= 70.32, acc3= 78.14, acc10= 81.90\n",
      "INFO - 08/10/22 20:05:08 - 0:05:21 - #################################################################################################################\n",
      "train E013: 100% 21/21 [00:13<00:00,  1.61it/s]\n",
      "INFO - 08/10/22 20:05:21 - 0:05:34 - Train Epoch 13: LOSS= 0.63885, lr= 0.002000, acc1= 98.09,acc3= 99.44,acc10= 99.59\n",
      "eval E013: 100% 23/23 [00:13<00:00,  1.71it/s]\n",
      "INFO - 08/10/22 20:05:34 - 0:05:47 - #################################################################################################################\n",
      "INFO - 08/10/22 20:05:34 - 0:05:47 - Test Epoch 13: LOSS= 5.18371, acc1= 71.70, acc3= 79.35, acc10= 82.11\n",
      "INFO - 08/10/22 20:05:34 - 0:05:47 - #################################################################################################################\n",
      "train E014: 100% 21/21 [00:12<00:00,  1.64it/s]\n",
      "INFO - 08/10/22 20:05:47 - 0:06:00 - Train Epoch 14: LOSS= 0.46396, lr= 0.001400, acc1= 99.10,acc3= 99.81,acc10= 99.93\n",
      "eval E014: 100% 23/23 [00:11<00:00,  1.98it/s]\n",
      "INFO - 08/10/22 20:05:59 - 0:06:12 - #################################################################################################################\n",
      "INFO - 08/10/22 20:05:59 - 0:06:12 - Test Epoch 14: LOSS= 4.98972, acc1= 72.37, acc3= 80.48, acc10= 83.46\n",
      "INFO - 08/10/22 20:05:59 - 0:06:12 - #################################################################################################################\n",
      "train E015: 100% 21/21 [00:12<00:00,  1.66it/s]\n",
      "INFO - 08/10/22 20:06:11 - 0:06:24 - Train Epoch 15: LOSS= 0.33284, lr= 0.001400, acc1= 99.25,acc3= 99.89,acc10= 100.00\n",
      "eval E015: 100% 23/23 [00:14<00:00,  1.61it/s]\n",
      "INFO - 08/10/22 20:06:26 - 0:06:39 - #################################################################################################################\n",
      "INFO - 08/10/22 20:06:26 - 0:06:39 - Test Epoch 15: LOSS= 5.26375, acc1= 72.05, acc3= 80.34, acc10= 83.35\n",
      "INFO - 08/10/22 20:06:26 - 0:06:39 - #################################################################################################################\n",
      "train E016: 100% 21/21 [00:14<00:00,  1.49it/s]\n",
      "INFO - 08/10/22 20:06:40 - 0:06:53 - Train Epoch 16: LOSS= 0.28667, lr= 0.001400, acc1= 99.33,acc3= 99.85,acc10= 99.89\n",
      "eval E016: 100% 23/23 [00:13<00:00,  1.72it/s]\n",
      "INFO - 08/10/22 20:06:53 - 0:07:06 - #################################################################################################################\n",
      "INFO - 08/10/22 20:06:53 - 0:07:06 - Test Epoch 16: LOSS= 5.27051, acc1= 74.00, acc3= 80.91, acc10= 83.95\n",
      "INFO - 08/10/22 20:06:53 - 0:07:06 - #################################################################################################################\n",
      "train E017: 100% 21/21 [00:13<00:00,  1.55it/s]\n",
      "INFO - 08/10/22 20:07:07 - 0:07:20 - Train Epoch 17: LOSS= 0.19757, lr= 0.000980, acc1= 99.40,acc3= 99.85,acc10= 99.96\n",
      "eval E017: 100% 23/23 [00:12<00:00,  1.86it/s]\n",
      "INFO - 08/10/22 20:07:19 - 0:07:32 - #################################################################################################################\n",
      "INFO - 08/10/22 20:07:19 - 0:07:32 - Test Epoch 17: LOSS= 5.10932, acc1= 73.26, acc3= 81.12, acc10= 83.92\n",
      "INFO - 08/10/22 20:07:19 - 0:07:32 - #################################################################################################################\n",
      "train E018: 100% 21/21 [00:14<00:00,  1.49it/s]\n",
      "INFO - 08/10/22 20:07:33 - 0:07:46 - Train Epoch 18: LOSS= 0.13818, lr= 0.000980, acc1= 99.59,acc3= 99.93,acc10= 100.00\n",
      "eval E018: 100% 23/23 [00:12<00:00,  1.81it/s]\n",
      "INFO - 08/10/22 20:07:46 - 0:07:59 - #################################################################################################################\n",
      "INFO - 08/10/22 20:07:46 - 0:07:59 - Test Epoch 18: LOSS= 5.21468, acc1= 73.79, acc3= 81.51, acc10= 84.52\n",
      "INFO - 08/10/22 20:07:46 - 0:07:59 - #################################################################################################################\n",
      "train E019: 100% 21/21 [00:13<00:00,  1.56it/s]\n",
      "INFO - 08/10/22 20:07:59 - 0:08:12 - Train Epoch 19: LOSS= 0.10844, lr= 0.000980, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E019: 100% 23/23 [00:12<00:00,  1.85it/s]\n",
      "INFO - 08/10/22 20:08:12 - 0:08:25 - #################################################################################################################\n",
      "INFO - 08/10/22 20:08:12 - 0:08:25 - Test Epoch 19: LOSS= 5.38058, acc1= 74.32, acc3= 82.08, acc10= 84.66\n",
      "INFO - 08/10/22 20:08:12 - 0:08:25 - #################################################################################################################\n",
      "train E020: 100% 21/21 [00:13<00:00,  1.52it/s]\n",
      "INFO - 08/10/22 20:08:25 - 0:08:38 - Train Epoch 20: LOSS= 0.11458, lr= 0.000686, acc1= 99.59,acc3= 99.96,acc10= 100.00\n",
      "eval E020: 100% 23/23 [00:11<00:00,  1.97it/s]\n",
      "INFO - 08/10/22 20:08:37 - 0:08:50 - #################################################################################################################\n",
      "INFO - 08/10/22 20:08:37 - 0:08:50 - Test Epoch 20: LOSS= 5.38961, acc1= 75.03, acc3= 81.90, acc10= 84.38\n",
      "INFO - 08/10/22 20:08:37 - 0:08:50 - #################################################################################################################\n",
      "train E021: 100% 21/21 [00:13<00:00,  1.53it/s]\n",
      "INFO - 08/10/22 20:08:51 - 0:09:04 - Train Epoch 21: LOSS= 0.10959, lr= 0.000686, acc1= 99.55,acc3= 100.00,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E021: 100% 23/23 [00:13<00:00,  1.72it/s]\n",
      "INFO - 08/10/22 20:09:04 - 0:09:17 - #################################################################################################################\n",
      "INFO - 08/10/22 20:09:04 - 0:09:17 - Test Epoch 21: LOSS= 5.20932, acc1= 74.21, acc3= 81.69, acc10= 84.27\n",
      "INFO - 08/10/22 20:09:04 - 0:09:17 - #################################################################################################################\n",
      "train E022: 100% 21/21 [00:13<00:00,  1.54it/s]\n",
      "INFO - 08/10/22 20:09:18 - 0:09:31 - Train Epoch 22: LOSS= 0.09697, lr= 0.000686, acc1= 99.63,acc3= 100.00,acc10= 100.00\n",
      "eval E022: 100% 23/23 [00:13<00:00,  1.69it/s]\n",
      "INFO - 08/10/22 20:09:31 - 0:09:45 - #################################################################################################################\n",
      "INFO - 08/10/22 20:09:31 - 0:09:45 - Test Epoch 22: LOSS= 4.86152, acc1= 74.60, acc3= 82.36, acc10= 84.70\n",
      "INFO - 08/10/22 20:09:31 - 0:09:45 - #################################################################################################################\n",
      "train E023: 100% 21/21 [00:13<00:00,  1.59it/s]\n",
      "INFO - 08/10/22 20:09:45 - 0:09:58 - Train Epoch 23: LOSS= 0.07236, lr= 0.000480, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E023: 100% 23/23 [00:13<00:00,  1.72it/s]\n",
      "INFO - 08/10/22 20:09:58 - 0:10:11 - #################################################################################################################\n",
      "INFO - 08/10/22 20:09:58 - 0:10:11 - Test Epoch 23: LOSS= 5.03030, acc1= 74.57, acc3= 82.39, acc10= 84.63\n",
      "INFO - 08/10/22 20:09:58 - 0:10:11 - #################################################################################################################\n",
      "train E024: 100% 21/21 [00:14<00:00,  1.48it/s]\n",
      "INFO - 08/10/22 20:10:12 - 0:10:25 - Train Epoch 24: LOSS= 0.05862, lr= 0.000480, acc1= 99.81,acc3= 100.00,acc10= 100.00\n",
      "eval E024: 100% 23/23 [00:13<00:00,  1.76it/s]\n",
      "INFO - 08/10/22 20:10:25 - 0:10:38 - #################################################################################################################\n",
      "INFO - 08/10/22 20:10:25 - 0:10:38 - Test Epoch 24: LOSS= 5.03467, acc1= 74.42, acc3= 81.97, acc10= 84.56\n",
      "INFO - 08/10/22 20:10:25 - 0:10:38 - #################################################################################################################\n",
      "train E025: 100% 21/21 [00:13<00:00,  1.56it/s]\n",
      "INFO - 08/10/22 20:10:39 - 0:10:52 - Train Epoch 25: LOSS= 0.06516, lr= 0.000480, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E025: 100% 23/23 [00:12<00:00,  1.77it/s]\n",
      "INFO - 08/10/22 20:10:52 - 0:11:05 - #################################################################################################################\n",
      "INFO - 08/10/22 20:10:52 - 0:11:05 - Test Epoch 25: LOSS= 4.87878, acc1= 74.39, acc3= 82.15, acc10= 84.41\n",
      "INFO - 08/10/22 20:10:52 - 0:11:05 - #################################################################################################################\n",
      "train E026: 100% 21/21 [00:13<00:00,  1.59it/s]\n",
      "INFO - 08/10/22 20:11:05 - 0:11:18 - Train Epoch 26: LOSS= 0.05636, lr= 0.000336, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E026: 100% 23/23 [00:11<00:00,  1.99it/s]\n",
      "INFO - 08/10/22 20:11:17 - 0:11:30 - #################################################################################################################\n",
      "INFO - 08/10/22 20:11:17 - 0:11:30 - Test Epoch 26: LOSS= 4.90808, acc1= 74.78, acc3= 82.22, acc10= 84.95\n",
      "INFO - 08/10/22 20:11:17 - 0:11:30 - #################################################################################################################\n",
      "train E027: 100% 21/21 [00:12<00:00,  1.64it/s]\n",
      "INFO - 08/10/22 20:11:29 - 0:11:42 - Train Epoch 27: LOSS= 0.04725, lr= 0.000336, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E027: 100% 23/23 [00:12<00:00,  1.83it/s]\n",
      "INFO - 08/10/22 20:11:42 - 0:11:55 - #################################################################################################################\n",
      "INFO - 08/10/22 20:11:42 - 0:11:55 - Test Epoch 27: LOSS= 5.08279, acc1= 75.17, acc3= 82.43, acc10= 84.98\n",
      "INFO - 08/10/22 20:11:42 - 0:11:55 - #################################################################################################################\n",
      "train E028: 100% 21/21 [00:14<00:00,  1.48it/s]\n",
      "INFO - 08/10/22 20:11:56 - 0:12:09 - Train Epoch 28: LOSS= 0.05641, lr= 0.000336, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E028: 100% 23/23 [00:12<00:00,  1.91it/s]\n",
      "INFO - 08/10/22 20:12:08 - 0:12:21 - #################################################################################################################\n",
      "INFO - 08/10/22 20:12:08 - 0:12:21 - Test Epoch 28: LOSS= 4.99903, acc1= 74.99, acc3= 82.32, acc10= 84.73\n",
      "INFO - 08/10/22 20:12:08 - 0:12:21 - #################################################################################################################\n",
      "train E029: 100% 21/21 [00:13<00:00,  1.58it/s]\n",
      "INFO - 08/10/22 20:12:22 - 0:12:35 - Train Epoch 29: LOSS= 0.05112, lr= 0.000235, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E029: 100% 23/23 [00:13<00:00,  1.77it/s]\n",
      "INFO - 08/10/22 20:12:35 - 0:12:48 - #################################################################################################################\n",
      "INFO - 08/10/22 20:12:35 - 0:12:48 - Test Epoch 29: LOSS= 5.19055, acc1= 74.74, acc3= 82.32, acc10= 84.70\n",
      "INFO - 08/10/22 20:12:35 - 0:12:48 - #################################################################################################################\n",
      "train E030: 100% 21/21 [00:14<00:00,  1.42it/s]\n",
      "INFO - 08/10/22 20:12:49 - 0:13:02 - Train Epoch 30: LOSS= 0.04294, lr= 0.000235, acc1= 99.81,acc3= 100.00,acc10= 100.00\n",
      "eval E030: 100% 23/23 [00:12<00:00,  1.82it/s]\n",
      "INFO - 08/10/22 20:13:02 - 0:13:15 - #################################################################################################################\n",
      "INFO - 08/10/22 20:13:02 - 0:13:15 - Test Epoch 30: LOSS= 4.94943, acc1= 75.06, acc3= 82.54, acc10= 84.66\n",
      "INFO - 08/10/22 20:13:02 - 0:13:15 - #################################################################################################################\n",
      "train E031: 100% 21/21 [00:11<00:00,  1.78it/s]\n",
      "INFO - 08/10/22 20:13:14 - 0:13:27 - Train Epoch 31: LOSS= 0.04417, lr= 0.000235, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E031: 100% 23/23 [00:11<00:00,  1.95it/s]\n",
      "INFO - 08/10/22 20:13:26 - 0:13:39 - #################################################################################################################\n",
      "INFO - 08/10/22 20:13:26 - 0:13:39 - Test Epoch 31: LOSS= 5.27601, acc1= 75.27, acc3= 82.54, acc10= 84.91\n",
      "INFO - 08/10/22 20:13:26 - 0:13:39 - #################################################################################################################\n",
      "train E032: 100% 21/21 [00:12<00:00,  1.64it/s]\n",
      "INFO - 08/10/22 20:13:38 - 0:13:51 - Train Epoch 32: LOSS= 0.04868, lr= 0.000165, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E032: 100% 23/23 [00:12<00:00,  1.88it/s]\n",
      "INFO - 08/10/22 20:13:51 - 0:14:04 - #################################################################################################################\n",
      "INFO - 08/10/22 20:13:51 - 0:14:04 - Test Epoch 32: LOSS= 5.07607, acc1= 75.03, acc3= 82.25, acc10= 84.80\n",
      "INFO - 08/10/22 20:13:51 - 0:14:04 - #################################################################################################################\n",
      "train E033: 100% 21/21 [00:12<00:00,  1.64it/s]\n",
      "INFO - 08/10/22 20:14:03 - 0:14:17 - Train Epoch 33: LOSS= 0.04830, lr= 0.000165, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E033: 100% 23/23 [00:12<00:00,  1.80it/s]\n",
      "INFO - 08/10/22 20:14:16 - 0:14:29 - #################################################################################################################\n",
      "INFO - 08/10/22 20:14:16 - 0:14:29 - Test Epoch 33: LOSS= 4.99361, acc1= 75.31, acc3= 82.57, acc10= 84.77\n",
      "INFO - 08/10/22 20:14:16 - 0:14:29 - #################################################################################################################\n",
      "train E034: 100% 21/21 [00:12<00:00,  1.68it/s]\n",
      "INFO - 08/10/22 20:14:29 - 0:14:42 - Train Epoch 34: LOSS= 0.04457, lr= 0.000165, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E034: 100% 23/23 [00:11<00:00,  1.92it/s]\n",
      "INFO - 08/10/22 20:14:41 - 0:14:54 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/10/22 20:14:41 - 0:14:54 - Test Epoch 34: LOSS= 5.16685, acc1= 75.38, acc3= 82.57, acc10= 84.87\n",
      "INFO - 08/10/22 20:14:41 - 0:14:54 - #################################################################################################################\n",
      "train E035: 100% 21/21 [00:13<00:00,  1.59it/s]\n",
      "INFO - 08/10/22 20:14:54 - 0:15:07 - Train Epoch 35: LOSS= 0.04388, lr= 0.000115, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E035: 100% 23/23 [00:12<00:00,  1.87it/s]\n",
      "INFO - 08/10/22 20:15:06 - 0:15:19 - #################################################################################################################\n",
      "INFO - 08/10/22 20:15:06 - 0:15:19 - Test Epoch 35: LOSS= 5.02651, acc1= 75.52, acc3= 82.50, acc10= 84.77\n",
      "INFO - 08/10/22 20:15:06 - 0:15:19 - #################################################################################################################\n",
      "train E036: 100% 21/21 [00:13<00:00,  1.60it/s]\n",
      "INFO - 08/10/22 20:15:19 - 0:15:32 - Train Epoch 36: LOSS= 0.03443, lr= 0.000115, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E036: 100% 23/23 [00:12<00:00,  1.91it/s]\n",
      "INFO - 08/10/22 20:15:31 - 0:15:44 - #################################################################################################################\n",
      "INFO - 08/10/22 20:15:31 - 0:15:44 - Test Epoch 36: LOSS= 5.19692, acc1= 75.77, acc3= 82.57, acc10= 84.66\n",
      "INFO - 08/10/22 20:15:31 - 0:15:44 - #################################################################################################################\n",
      "train E037: 100% 21/21 [00:12<00:00,  1.74it/s]\n",
      "INFO - 08/10/22 20:15:43 - 0:15:57 - Train Epoch 37: LOSS= 0.04423, lr= 0.000115, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E037: 100% 23/23 [00:11<00:00,  2.07it/s]\n",
      "INFO - 08/10/22 20:15:55 - 0:16:08 - #################################################################################################################\n",
      "INFO - 08/10/22 20:15:55 - 0:16:08 - Test Epoch 37: LOSS= 4.98061, acc1= 75.70, acc3= 82.54, acc10= 84.63\n",
      "INFO - 08/10/22 20:15:55 - 0:16:08 - #################################################################################################################\n",
      "train E038: 100% 21/21 [00:12<00:00,  1.63it/s]\n",
      "INFO - 08/10/22 20:16:08 - 0:16:21 - Train Epoch 38: LOSS= 0.04420, lr= 0.000081, acc1= 99.81,acc3= 100.00,acc10= 100.00\n",
      "eval E038: 100% 23/23 [00:11<00:00,  1.99it/s]\n",
      "INFO - 08/10/22 20:16:19 - 0:16:32 - #################################################################################################################\n",
      "INFO - 08/10/22 20:16:19 - 0:16:32 - Test Epoch 38: LOSS= 5.18668, acc1= 75.59, acc3= 82.57, acc10= 84.66\n",
      "INFO - 08/10/22 20:16:19 - 0:16:32 - #################################################################################################################\n",
      "train E039: 100% 21/21 [00:12<00:00,  1.66it/s]\n",
      "INFO - 08/10/22 20:16:32 - 0:16:45 - Train Epoch 39: LOSS= 0.04862, lr= 0.000081, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E039: 100% 23/23 [00:11<00:00,  2.02it/s]\n",
      "INFO - 08/10/22 20:16:43 - 0:16:56 - #################################################################################################################\n",
      "INFO - 08/10/22 20:16:43 - 0:16:56 - Test Epoch 39: LOSS= 5.26337, acc1= 75.56, acc3= 82.64, acc10= 84.70\n",
      "INFO - 08/10/22 20:16:43 - 0:16:56 - #################################################################################################################\n",
      "train E040: 100% 21/21 [00:12<00:00,  1.69it/s]\n",
      "INFO - 08/10/22 20:16:56 - 0:17:09 - Train Epoch 40: LOSS= 0.04062, lr= 0.000081, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E040: 100% 23/23 [00:11<00:00,  2.02it/s]\n",
      "INFO - 08/10/22 20:17:07 - 0:17:20 - #################################################################################################################\n",
      "INFO - 08/10/22 20:17:07 - 0:17:20 - Test Epoch 40: LOSS= 5.32085, acc1= 75.56, acc3= 82.57, acc10= 84.63\n",
      "INFO - 08/10/22 20:17:07 - 0:17:20 - #################################################################################################################\n",
      "train E041: 100% 21/21 [00:12<00:00,  1.72it/s]\n",
      "INFO - 08/10/22 20:17:19 - 0:17:32 - Train Epoch 41: LOSS= 0.03576, lr= 0.000056, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E041: 100% 23/23 [00:10<00:00,  2.19it/s]\n",
      "INFO - 08/10/22 20:17:30 - 0:17:43 - #################################################################################################################\n",
      "INFO - 08/10/22 20:17:30 - 0:17:43 - Test Epoch 41: LOSS= 4.97368, acc1= 75.63, acc3= 82.64, acc10= 84.63\n",
      "INFO - 08/10/22 20:17:30 - 0:17:43 - #################################################################################################################\n",
      "train E042: 100% 21/21 [00:11<00:00,  1.88it/s]\n",
      "INFO - 08/10/22 20:17:41 - 0:17:54 - Train Epoch 42: LOSS= 0.04179, lr= 0.000056, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E042: 100% 23/23 [00:10<00:00,  2.13it/s]\n",
      "INFO - 08/10/22 20:17:52 - 0:18:05 - #################################################################################################################\n",
      "INFO - 08/10/22 20:17:52 - 0:18:05 - Test Epoch 42: LOSS= 4.97445, acc1= 75.63, acc3= 82.61, acc10= 84.70\n",
      "INFO - 08/10/22 20:17:52 - 0:18:05 - #################################################################################################################\n",
      "train E043: 100% 21/21 [00:12<00:00,  1.68it/s]\n",
      "INFO - 08/10/22 20:18:04 - 0:18:17 - Train Epoch 43: LOSS= 0.04498, lr= 0.000056, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E043: 100% 23/23 [00:11<00:00,  2.03it/s]\n",
      "INFO - 08/10/22 20:18:15 - 0:18:28 - #################################################################################################################\n",
      "INFO - 08/10/22 20:18:15 - 0:18:28 - Test Epoch 43: LOSS= 5.19063, acc1= 75.52, acc3= 82.64, acc10= 84.73\n",
      "INFO - 08/10/22 20:18:15 - 0:18:28 - #################################################################################################################\n",
      "train E044: 100% 21/21 [00:12<00:00,  1.74it/s]\n",
      "INFO - 08/10/22 20:18:28 - 0:18:41 - Train Epoch 44: LOSS= 0.03806, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E044: 100% 23/23 [00:11<00:00,  2.09it/s]\n",
      "INFO - 08/10/22 20:18:39 - 0:18:52 - #################################################################################################################\n",
      "INFO - 08/10/22 20:18:39 - 0:18:52 - Test Epoch 44: LOSS= 4.93547, acc1= 75.42, acc3= 82.54, acc10= 84.77\n",
      "INFO - 08/10/22 20:18:39 - 0:18:52 - #################################################################################################################\n",
      "train E045: 100% 21/21 [00:12<00:00,  1.71it/s]\n",
      "INFO - 08/10/22 20:18:51 - 0:19:04 - Train Epoch 45: LOSS= 0.04377, lr= 0.000040, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E045: 100% 23/23 [00:11<00:00,  2.03it/s]\n",
      "INFO - 08/10/22 20:19:02 - 0:19:15 - #################################################################################################################\n",
      "INFO - 08/10/22 20:19:02 - 0:19:15 - Test Epoch 45: LOSS= 4.99245, acc1= 75.38, acc3= 82.61, acc10= 84.70\n",
      "INFO - 08/10/22 20:19:02 - 0:19:15 - #################################################################################################################\n",
      "train E046: 100% 21/21 [00:12<00:00,  1.71it/s]\n",
      "INFO - 08/10/22 20:19:14 - 0:19:28 - Train Epoch 46: LOSS= 0.04431, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E046: 100% 23/23 [00:11<00:00,  1.99it/s]\n",
      "INFO - 08/10/22 20:19:26 - 0:19:39 - #################################################################################################################\n",
      "INFO - 08/10/22 20:19:26 - 0:19:39 - Test Epoch 46: LOSS= 5.06168, acc1= 75.38, acc3= 82.54, acc10= 84.73\n",
      "INFO - 08/10/22 20:19:26 - 0:19:39 - #################################################################################################################\n",
      "train E047: 100% 21/21 [00:12<00:00,  1.72it/s]\n",
      "INFO - 08/10/22 20:19:38 - 0:19:51 - Train Epoch 47: LOSS= 0.03711, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E047: 100% 23/23 [00:11<00:00,  1.98it/s]\n",
      "INFO - 08/10/22 20:19:50 - 0:20:03 - #################################################################################################################\n",
      "INFO - 08/10/22 20:19:50 - 0:20:03 - Test Epoch 47: LOSS= 5.06552, acc1= 75.42, acc3= 82.54, acc10= 84.77\n",
      "INFO - 08/10/22 20:19:50 - 0:20:03 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E048: 100% 21/21 [00:12<00:00,  1.68it/s]\n",
      "INFO - 08/10/22 20:20:02 - 0:20:15 - Train Epoch 48: LOSS= 0.04286, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E048: 100% 23/23 [00:11<00:00,  2.04it/s]\n",
      "INFO - 08/10/22 20:20:14 - 0:20:27 - #################################################################################################################\n",
      "INFO - 08/10/22 20:20:14 - 0:20:27 - Test Epoch 48: LOSS= 5.30564, acc1= 75.52, acc3= 82.61, acc10= 84.80\n",
      "INFO - 08/10/22 20:20:14 - 0:20:27 - #################################################################################################################\n",
      "train E049: 100% 21/21 [00:12<00:00,  1.74it/s]\n",
      "INFO - 08/10/22 20:20:26 - 0:20:39 - Train Epoch 49: LOSS= 0.03496, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E049: 100% 23/23 [00:11<00:00,  2.05it/s]\n",
      "INFO - 08/10/22 20:20:37 - 0:20:50 - #################################################################################################################\n",
      "INFO - 08/10/22 20:20:37 - 0:20:50 - Test Epoch 49: LOSS= 4.99192, acc1= 75.56, acc3= 82.61, acc10= 84.77\n",
      "INFO - 08/10/22 20:20:37 - 0:20:50 - #################################################################################################################\n",
      "train E050: 100% 21/21 [00:11<00:00,  1.77it/s]\n",
      "INFO - 08/10/22 20:20:49 - 0:21:02 - Train Epoch 50: LOSS= 0.03497, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E050: 100% 23/23 [00:10<00:00,  2.14it/s]\n",
      "INFO - 08/10/22 20:21:00 - 0:21:13 - #################################################################################################################\n",
      "INFO - 08/10/22 20:21:00 - 0:21:13 - Test Epoch 50: LOSS= 5.28265, acc1= 75.49, acc3= 82.57, acc10= 84.70\n",
      "INFO - 08/10/22 20:21:00 - 0:21:13 - #################################################################################################################\n",
      "train E051: 100% 21/21 [00:12<00:00,  1.75it/s]\n",
      "INFO - 08/10/22 20:21:12 - 0:21:25 - Train Epoch 51: LOSS= 0.03327, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E051: 100% 23/23 [00:11<00:00,  2.08it/s]\n",
      "INFO - 08/10/22 20:21:23 - 0:21:36 - #################################################################################################################\n",
      "INFO - 08/10/22 20:21:23 - 0:21:36 - Test Epoch 51: LOSS= 5.02293, acc1= 75.52, acc3= 82.61, acc10= 84.73\n",
      "INFO - 08/10/22 20:21:23 - 0:21:36 - #################################################################################################################\n",
      "train E052: 100% 21/21 [00:12<00:00,  1.71it/s]\n",
      "INFO - 08/10/22 20:21:35 - 0:21:48 - Train Epoch 52: LOSS= 0.03093, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E052: 100% 23/23 [00:11<00:00,  2.07it/s]\n",
      "INFO - 08/10/22 20:21:46 - 0:21:59 - #################################################################################################################\n",
      "INFO - 08/10/22 20:21:46 - 0:21:59 - Test Epoch 52: LOSS= 5.20371, acc1= 75.45, acc3= 82.57, acc10= 84.84\n",
      "INFO - 08/10/22 20:21:46 - 0:21:59 - #################################################################################################################\n",
      "train E053: 100% 21/21 [00:10<00:00,  1.92it/s]\n",
      "INFO - 08/10/22 20:21:57 - 0:22:10 - Train Epoch 53: LOSS= 0.03929, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E053: 100% 23/23 [00:10<00:00,  2.21it/s]\n",
      "INFO - 08/10/22 20:22:07 - 0:22:21 - #################################################################################################################\n",
      "INFO - 08/10/22 20:22:07 - 0:22:21 - Test Epoch 53: LOSS= 5.11596, acc1= 75.49, acc3= 82.64, acc10= 84.80\n",
      "INFO - 08/10/22 20:22:07 - 0:22:21 - #################################################################################################################\n",
      "train E054: 100% 21/21 [00:11<00:00,  1.80it/s]\n",
      "INFO - 08/10/22 20:22:19 - 0:22:32 - Train Epoch 54: LOSS= 0.03738, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E054: 100% 23/23 [00:11<00:00,  2.05it/s]\n",
      "INFO - 08/10/22 20:22:30 - 0:22:43 - #################################################################################################################\n",
      "INFO - 08/10/22 20:22:30 - 0:22:43 - Test Epoch 54: LOSS= 5.04987, acc1= 75.52, acc3= 82.68, acc10= 84.80\n",
      "INFO - 08/10/22 20:22:30 - 0:22:43 - #################################################################################################################\n",
      "train E055: 100% 21/21 [00:12<00:00,  1.73it/s]\n",
      "INFO - 08/10/22 20:22:42 - 0:22:56 - Train Epoch 55: LOSS= 0.03573, lr= 0.000040, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E055: 100% 23/23 [00:11<00:00,  1.97it/s]\n",
      "INFO - 08/10/22 20:22:54 - 0:23:07 - #################################################################################################################\n",
      "INFO - 08/10/22 20:22:54 - 0:23:07 - Test Epoch 55: LOSS= 5.16857, acc1= 75.52, acc3= 82.82, acc10= 84.80\n",
      "INFO - 08/10/22 20:22:54 - 0:23:07 - #################################################################################################################\n",
      "train E056: 100% 21/21 [00:12<00:00,  1.72it/s]\n",
      "INFO - 08/10/22 20:23:06 - 0:23:19 - Train Epoch 56: LOSS= 0.03483, lr= 0.000040, acc1= 99.81,acc3= 100.00,acc10= 100.00\n",
      "eval E056: 100% 23/23 [00:11<00:00,  2.08it/s]\n",
      "INFO - 08/10/22 20:23:17 - 0:23:30 - #################################################################################################################\n",
      "INFO - 08/10/22 20:23:17 - 0:23:30 - Test Epoch 56: LOSS= 5.05438, acc1= 75.27, acc3= 82.75, acc10= 84.80\n",
      "INFO - 08/10/22 20:23:17 - 0:23:30 - #################################################################################################################\n",
      "train E057: 100% 21/21 [00:12<00:00,  1.72it/s]\n",
      "INFO - 08/10/22 20:23:30 - 0:23:43 - Train Epoch 57: LOSS= 0.03764, lr= 0.000040, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E057: 100% 23/23 [00:11<00:00,  2.03it/s]\n",
      "INFO - 08/10/22 20:23:41 - 0:23:54 - #################################################################################################################\n",
      "INFO - 08/10/22 20:23:41 - 0:23:54 - Test Epoch 57: LOSS= 5.05192, acc1= 75.52, acc3= 82.78, acc10= 84.73\n",
      "INFO - 08/10/22 20:23:41 - 0:23:54 - #################################################################################################################\n",
      "train E058: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 08/10/22 20:23:53 - 0:24:06 - Train Epoch 58: LOSS= 0.04418, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E058: 100% 23/23 [00:11<00:00,  2.05it/s]\n",
      "INFO - 08/10/22 20:24:04 - 0:24:17 - #################################################################################################################\n",
      "INFO - 08/10/22 20:24:04 - 0:24:17 - Test Epoch 58: LOSS= 5.50670, acc1= 75.59, acc3= 82.78, acc10= 84.77\n",
      "INFO - 08/10/22 20:24:04 - 0:24:17 - #################################################################################################################\n",
      "train E059: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 08/10/22 20:24:16 - 0:24:29 - Train Epoch 59: LOSS= 0.03798, lr= 0.000040, acc1= 99.81,acc3= 100.00,acc10= 100.00\n",
      "eval E059: 100% 23/23 [00:11<00:00,  2.05it/s]\n",
      "INFO - 08/10/22 20:24:27 - 0:24:40 - #################################################################################################################\n",
      "INFO - 08/10/22 20:24:27 - 0:24:40 - Test Epoch 59: LOSS= 5.24070, acc1= 75.42, acc3= 82.71, acc10= 84.73\n",
      "INFO - 08/10/22 20:24:27 - 0:24:40 - #################################################################################################################\n",
      "train E060: 100% 21/21 [00:12<00:00,  1.72it/s]\n",
      "INFO - 08/10/22 20:24:39 - 0:24:53 - Train Epoch 60: LOSS= 0.03695, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E060: 100% 23/23 [00:11<00:00,  2.05it/s]\n",
      "INFO - 08/10/22 20:24:51 - 0:25:04 - #################################################################################################################\n",
      "INFO - 08/10/22 20:24:51 - 0:25:04 - Test Epoch 60: LOSS= 5.14459, acc1= 75.59, acc3= 82.71, acc10= 84.73\n",
      "INFO - 08/10/22 20:24:51 - 0:25:04 - #################################################################################################################\n",
      "train E061: 100% 21/21 [00:12<00:00,  1.74it/s]\n",
      "INFO - 08/10/22 20:25:03 - 0:25:16 - Train Epoch 61: LOSS= 0.04373, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E061: 100% 23/23 [00:11<00:00,  2.03it/s]\n",
      "INFO - 08/10/22 20:25:14 - 0:25:27 - #################################################################################################################\n",
      "INFO - 08/10/22 20:25:14 - 0:25:27 - Test Epoch 61: LOSS= 4.96220, acc1= 75.70, acc3= 82.78, acc10= 84.73\n",
      "INFO - 08/10/22 20:25:14 - 0:25:27 - #################################################################################################################\n",
      "train E062: 100% 21/21 [00:12<00:00,  1.72it/s]\n",
      "INFO - 08/10/22 20:25:26 - 0:25:39 - Train Epoch 62: LOSS= 0.03288, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E062: 100% 23/23 [00:11<00:00,  2.04it/s]\n",
      "INFO - 08/10/22 20:25:38 - 0:25:51 - #################################################################################################################\n",
      "INFO - 08/10/22 20:25:38 - 0:25:51 - Test Epoch 62: LOSS= 5.00721, acc1= 75.63, acc3= 82.86, acc10= 84.73\n",
      "INFO - 08/10/22 20:25:38 - 0:25:51 - #################################################################################################################\n",
      "train E063: 100% 21/21 [00:12<00:00,  1.74it/s]\n",
      "INFO - 08/10/22 20:25:50 - 0:26:03 - Train Epoch 63: LOSS= 0.03761, lr= 0.000040, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E063: 100% 23/23 [00:11<00:00,  2.09it/s]\n",
      "INFO - 08/10/22 20:26:01 - 0:26:14 - #################################################################################################################\n",
      "INFO - 08/10/22 20:26:01 - 0:26:14 - Test Epoch 63: LOSS= 5.18387, acc1= 75.56, acc3= 82.82, acc10= 84.73\n",
      "INFO - 08/10/22 20:26:01 - 0:26:14 - #################################################################################################################\n",
      "train E064: 100% 21/21 [00:10<00:00,  1.93it/s]\n",
      "INFO - 08/10/22 20:26:12 - 0:26:25 - Train Epoch 64: LOSS= 0.03652, lr= 0.000040, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E064: 100% 23/23 [00:10<00:00,  2.25it/s]\n",
      "INFO - 08/10/22 20:26:22 - 0:26:35 - #################################################################################################################\n",
      "INFO - 08/10/22 20:26:22 - 0:26:35 - Test Epoch 64: LOSS= 5.13520, acc1= 75.63, acc3= 82.78, acc10= 84.73\n",
      "INFO - 08/10/22 20:26:22 - 0:26:35 - #################################################################################################################\n",
      "train E065: 100% 21/21 [00:11<00:00,  1.90it/s]\n",
      "INFO - 08/10/22 20:26:33 - 0:26:46 - Train Epoch 65: LOSS= 0.03742, lr= 0.000040, acc1= 99.63,acc3= 100.00,acc10= 100.00\n",
      "eval E065: 100% 23/23 [00:11<00:00,  2.03it/s]\n",
      "INFO - 08/10/22 20:26:44 - 0:26:57 - #################################################################################################################\n",
      "INFO - 08/10/22 20:26:44 - 0:26:57 - Test Epoch 65: LOSS= 4.94657, acc1= 75.81, acc3= 83.00, acc10= 85.02\n",
      "INFO - 08/10/22 20:26:44 - 0:26:57 - #################################################################################################################\n",
      "train E066: 100% 21/21 [00:12<00:00,  1.73it/s]\n",
      "INFO - 08/10/22 20:26:56 - 0:27:09 - Train Epoch 66: LOSS= 0.03634, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E066: 100% 23/23 [00:10<00:00,  2.12it/s]\n",
      "INFO - 08/10/22 20:27:07 - 0:27:20 - #################################################################################################################\n",
      "INFO - 08/10/22 20:27:07 - 0:27:20 - Test Epoch 66: LOSS= 5.07086, acc1= 75.88, acc3= 83.03, acc10= 84.98\n",
      "INFO - 08/10/22 20:27:07 - 0:27:20 - #################################################################################################################\n",
      "train E067: 100% 21/21 [00:12<00:00,  1.73it/s]\n",
      "INFO - 08/10/22 20:27:19 - 0:27:32 - Train Epoch 67: LOSS= 0.03663, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E067: 100% 23/23 [00:10<00:00,  2.12it/s]\n",
      "INFO - 08/10/22 20:27:30 - 0:27:43 - #################################################################################################################\n",
      "INFO - 08/10/22 20:27:30 - 0:27:43 - Test Epoch 67: LOSS= 4.97127, acc1= 75.77, acc3= 83.03, acc10= 85.02\n",
      "INFO - 08/10/22 20:27:30 - 0:27:43 - #################################################################################################################\n",
      "train E068: 100% 21/21 [00:11<00:00,  1.78it/s]\n",
      "INFO - 08/10/22 20:27:42 - 0:27:55 - Train Epoch 68: LOSS= 0.03772, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E068: 100% 23/23 [00:11<00:00,  2.08it/s]\n",
      "INFO - 08/10/22 20:27:53 - 0:28:06 - #################################################################################################################\n",
      "INFO - 08/10/22 20:27:53 - 0:28:06 - Test Epoch 68: LOSS= 5.03463, acc1= 75.59, acc3= 82.89, acc10= 84.87\n",
      "INFO - 08/10/22 20:27:53 - 0:28:06 - #################################################################################################################\n",
      "train E069: 100% 21/21 [00:11<00:00,  1.80it/s]\n",
      "INFO - 08/10/22 20:28:05 - 0:28:18 - Train Epoch 69: LOSS= 0.03137, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E069: 100% 23/23 [00:10<00:00,  2.13it/s]\n",
      "INFO - 08/10/22 20:28:15 - 0:28:28 - #################################################################################################################\n",
      "INFO - 08/10/22 20:28:15 - 0:28:28 - Test Epoch 69: LOSS= 5.11443, acc1= 75.66, acc3= 82.86, acc10= 84.98\n",
      "INFO - 08/10/22 20:28:15 - 0:28:28 - #################################################################################################################\n",
      "train E070: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 08/10/22 20:28:27 - 0:28:40 - Train Epoch 70: LOSS= 0.03539, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E070: 100% 23/23 [00:10<00:00,  2.15it/s]\n",
      "INFO - 08/10/22 20:28:38 - 0:28:51 - #################################################################################################################\n",
      "INFO - 08/10/22 20:28:38 - 0:28:51 - Test Epoch 70: LOSS= 4.94518, acc1= 75.70, acc3= 82.78, acc10= 84.95\n",
      "INFO - 08/10/22 20:28:38 - 0:28:51 - #################################################################################################################\n",
      "train E071: 100% 21/21 [00:11<00:00,  1.78it/s]\n",
      "INFO - 08/10/22 20:28:50 - 0:29:03 - Train Epoch 71: LOSS= 0.03277, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E071: 100% 23/23 [00:11<00:00,  2.04it/s]\n",
      "INFO - 08/10/22 20:29:01 - 0:29:14 - #################################################################################################################\n",
      "INFO - 08/10/22 20:29:01 - 0:29:14 - Test Epoch 71: LOSS= 5.08963, acc1= 75.66, acc3= 82.78, acc10= 85.02\n",
      "INFO - 08/10/22 20:29:01 - 0:29:14 - #################################################################################################################\n",
      "train E072: 100% 21/21 [00:11<00:00,  1.80it/s]\n",
      "INFO - 08/10/22 20:29:13 - 0:29:26 - Train Epoch 72: LOSS= 0.03635, lr= 0.000040, acc1= 99.63,acc3= 100.00,acc10= 100.00\n",
      "eval E072: 100% 23/23 [00:11<00:00,  2.09it/s]\n",
      "INFO - 08/10/22 20:29:24 - 0:29:37 - #################################################################################################################\n",
      "INFO - 08/10/22 20:29:24 - 0:29:37 - Test Epoch 72: LOSS= 5.06595, acc1= 75.66, acc3= 82.75, acc10= 84.98\n",
      "INFO - 08/10/22 20:29:24 - 0:29:37 - #################################################################################################################\n",
      "train E073: 100% 21/21 [00:11<00:00,  1.77it/s]\n",
      "INFO - 08/10/22 20:29:36 - 0:29:49 - Train Epoch 73: LOSS= 0.04002, lr= 0.000040, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E073: 100% 23/23 [00:11<00:00,  2.04it/s]\n",
      "INFO - 08/10/22 20:29:47 - 0:30:00 - #################################################################################################################\n",
      "INFO - 08/10/22 20:29:47 - 0:30:00 - Test Epoch 73: LOSS= 5.12086, acc1= 75.66, acc3= 82.68, acc10= 85.05\n",
      "INFO - 08/10/22 20:29:47 - 0:30:00 - #################################################################################################################\n",
      "train E074: 100% 21/21 [00:11<00:00,  1.78it/s]\n",
      "INFO - 08/10/22 20:29:59 - 0:30:12 - Train Epoch 74: LOSS= 0.03337, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E074: 100% 23/23 [00:11<00:00,  2.08it/s]\n",
      "INFO - 08/10/22 20:30:10 - 0:30:23 - #################################################################################################################\n",
      "INFO - 08/10/22 20:30:10 - 0:30:23 - Test Epoch 74: LOSS= 4.99670, acc1= 75.70, acc3= 82.75, acc10= 84.91\n",
      "INFO - 08/10/22 20:30:10 - 0:30:23 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E075: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 08/10/22 20:30:22 - 0:30:35 - Train Epoch 75: LOSS= 0.03579, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E075: 100% 23/23 [00:10<00:00,  2.23it/s]\n",
      "INFO - 08/10/22 20:30:32 - 0:30:45 - #################################################################################################################\n",
      "INFO - 08/10/22 20:30:32 - 0:30:45 - Test Epoch 75: LOSS= 5.13204, acc1= 75.66, acc3= 82.78, acc10= 84.84\n",
      "INFO - 08/10/22 20:30:32 - 0:30:45 - #################################################################################################################\n",
      "train E076: 100% 21/21 [00:10<00:00,  1.92it/s]\n",
      "INFO - 08/10/22 20:30:43 - 0:30:56 - Train Epoch 76: LOSS= 0.03582, lr= 0.000040, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E076: 100% 23/23 [00:10<00:00,  2.21it/s]\n",
      "INFO - 08/10/22 20:30:53 - 0:31:06 - #################################################################################################################\n",
      "INFO - 08/10/22 20:30:53 - 0:31:06 - Test Epoch 76: LOSS= 5.02487, acc1= 75.63, acc3= 82.78, acc10= 84.87\n",
      "INFO - 08/10/22 20:30:53 - 0:31:06 - #################################################################################################################\n",
      "train E077: 100% 21/21 [00:12<00:00,  1.72it/s]\n",
      "INFO - 08/10/22 20:31:06 - 0:31:19 - Train Epoch 77: LOSS= 0.03527, lr= 0.000040, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E077: 100% 23/23 [00:10<00:00,  2.10it/s]\n",
      "INFO - 08/10/22 20:31:17 - 0:31:30 - #################################################################################################################\n",
      "INFO - 08/10/22 20:31:17 - 0:31:30 - Test Epoch 77: LOSS= 5.11565, acc1= 75.59, acc3= 82.75, acc10= 84.87\n",
      "INFO - 08/10/22 20:31:17 - 0:31:30 - #################################################################################################################\n",
      "train E078: 100% 21/21 [00:11<00:00,  1.75it/s]\n",
      "INFO - 08/10/22 20:31:29 - 0:31:42 - Train Epoch 78: LOSS= 0.03531, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E078: 100% 23/23 [00:10<00:00,  2.10it/s]\n",
      "INFO - 08/10/22 20:31:40 - 0:31:53 - #################################################################################################################\n",
      "INFO - 08/10/22 20:31:40 - 0:31:53 - Test Epoch 78: LOSS= 5.00652, acc1= 75.59, acc3= 82.78, acc10= 85.02\n",
      "INFO - 08/10/22 20:31:40 - 0:31:53 - #################################################################################################################\n",
      "train E079: 100% 21/21 [00:11<00:00,  1.78it/s]\n",
      "INFO - 08/10/22 20:31:51 - 0:32:04 - Train Epoch 79: LOSS= 0.03935, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E079: 100% 23/23 [00:11<00:00,  2.07it/s]\n",
      "INFO - 08/10/22 20:32:02 - 0:32:16 - #################################################################################################################\n",
      "INFO - 08/10/22 20:32:02 - 0:32:16 - Test Epoch 79: LOSS= 4.98819, acc1= 75.66, acc3= 82.75, acc10= 85.02\n",
      "INFO - 08/10/22 20:32:02 - 0:32:16 - #################################################################################################################\n",
      "train E080: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 08/10/22 20:32:14 - 0:32:27 - Train Epoch 80: LOSS= 0.03408, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E080: 100% 23/23 [00:11<00:00,  2.08it/s]\n",
      "INFO - 08/10/22 20:32:25 - 0:32:39 - #################################################################################################################\n",
      "INFO - 08/10/22 20:32:25 - 0:32:39 - Test Epoch 80: LOSS= 5.10016, acc1= 75.59, acc3= 82.78, acc10= 85.02\n",
      "INFO - 08/10/22 20:32:25 - 0:32:39 - #################################################################################################################\n",
      "train E081: 100% 21/21 [00:11<00:00,  1.80it/s]\n",
      "INFO - 08/10/22 20:32:37 - 0:32:50 - Train Epoch 81: LOSS= 0.03504, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E081: 100% 23/23 [00:10<00:00,  2.09it/s]\n",
      "INFO - 08/10/22 20:32:48 - 0:33:01 - #################################################################################################################\n",
      "INFO - 08/10/22 20:32:48 - 0:33:01 - Test Epoch 81: LOSS= 5.01394, acc1= 75.52, acc3= 82.82, acc10= 84.98\n",
      "INFO - 08/10/22 20:32:48 - 0:33:01 - #################################################################################################################\n",
      "train E082: 100% 21/21 [00:11<00:00,  1.77it/s]\n",
      "INFO - 08/10/22 20:33:00 - 0:33:13 - Train Epoch 82: LOSS= 0.03334, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E082: 100% 23/23 [00:10<00:00,  2.12it/s]\n",
      "INFO - 08/10/22 20:33:11 - 0:33:24 - #################################################################################################################\n",
      "INFO - 08/10/22 20:33:11 - 0:33:24 - Test Epoch 82: LOSS= 5.58666, acc1= 75.70, acc3= 82.82, acc10= 84.98\n",
      "INFO - 08/10/22 20:33:11 - 0:33:24 - #################################################################################################################\n",
      "train E083: 100% 21/21 [00:11<00:00,  1.82it/s]\n",
      "INFO - 08/10/22 20:33:22 - 0:33:35 - Train Epoch 83: LOSS= 0.04056, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E083: 100% 23/23 [00:11<00:00,  2.08it/s]\n",
      "INFO - 08/10/22 20:33:34 - 0:33:47 - #################################################################################################################\n",
      "INFO - 08/10/22 20:33:34 - 0:33:47 - Test Epoch 83: LOSS= 5.14705, acc1= 75.66, acc3= 82.82, acc10= 84.98\n",
      "INFO - 08/10/22 20:33:34 - 0:33:47 - #################################################################################################################\n",
      "train E084: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 08/10/22 20:33:46 - 0:33:59 - Train Epoch 84: LOSS= 0.04389, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E084: 100% 23/23 [00:10<00:00,  2.12it/s]\n",
      "INFO - 08/10/22 20:33:56 - 0:34:09 - #################################################################################################################\n",
      "INFO - 08/10/22 20:33:56 - 0:34:09 - Test Epoch 84: LOSS= 5.21017, acc1= 75.59, acc3= 82.86, acc10= 85.05\n",
      "INFO - 08/10/22 20:33:56 - 0:34:09 - #################################################################################################################\n",
      "train E085: 100% 21/21 [00:11<00:00,  1.83it/s]\n",
      "INFO - 08/10/22 20:34:08 - 0:34:21 - Train Epoch 85: LOSS= 0.02813, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E085: 100% 23/23 [00:10<00:00,  2.14it/s]\n",
      "INFO - 08/10/22 20:34:19 - 0:34:32 - #################################################################################################################\n",
      "INFO - 08/10/22 20:34:19 - 0:34:32 - Test Epoch 85: LOSS= 4.90456, acc1= 75.63, acc3= 82.86, acc10= 85.19\n",
      "INFO - 08/10/22 20:34:19 - 0:34:32 - #################################################################################################################\n",
      "train E086: 100% 21/21 [00:11<00:00,  1.79it/s]\n",
      "INFO - 08/10/22 20:34:30 - 0:34:43 - Train Epoch 86: LOSS= 0.03817, lr= 0.000040, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E086: 100% 23/23 [00:10<00:00,  2.12it/s]\n",
      "INFO - 08/10/22 20:34:41 - 0:34:54 - #################################################################################################################\n",
      "INFO - 08/10/22 20:34:41 - 0:34:54 - Test Epoch 86: LOSS= 5.05011, acc1= 75.59, acc3= 82.89, acc10= 85.26\n",
      "INFO - 08/10/22 20:34:41 - 0:34:54 - #################################################################################################################\n",
      "train E087: 100% 21/21 [00:10<00:00,  1.91it/s]\n",
      "INFO - 08/10/22 20:34:52 - 0:35:05 - Train Epoch 87: LOSS= 0.03482, lr= 0.000040, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E087: 100% 23/23 [00:10<00:00,  2.18it/s]\n",
      "INFO - 08/10/22 20:35:03 - 0:35:16 - #################################################################################################################\n",
      "INFO - 08/10/22 20:35:03 - 0:35:16 - Test Epoch 87: LOSS= 4.96685, acc1= 75.63, acc3= 82.82, acc10= 85.09\n",
      "INFO - 08/10/22 20:35:03 - 0:35:16 - #################################################################################################################\n",
      "train E088: 100% 21/21 [00:11<00:00,  1.81it/s]\n",
      "INFO - 08/10/22 20:35:14 - 0:35:27 - Train Epoch 88: LOSS= 0.03588, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E088: 100% 23/23 [00:10<00:00,  2.12it/s]\n",
      "INFO - 08/10/22 20:35:25 - 0:35:38 - #################################################################################################################\n",
      "INFO - 08/10/22 20:35:25 - 0:35:38 - Test Epoch 88: LOSS= 5.01820, acc1= 75.63, acc3= 82.78, acc10= 85.19\n",
      "INFO - 08/10/22 20:35:25 - 0:35:38 - #################################################################################################################\n",
      "train E089: 100% 21/21 [00:11<00:00,  1.83it/s]\n",
      "INFO - 08/10/22 20:35:37 - 0:35:50 - Train Epoch 89: LOSS= 0.04159, lr= 0.000040, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E089: 100% 23/23 [00:10<00:00,  2.20it/s]\n",
      "INFO - 08/10/22 20:35:47 - 0:36:00 - #################################################################################################################\n",
      "INFO - 08/10/22 20:35:47 - 0:36:00 - Test Epoch 89: LOSS= 5.08961, acc1= 75.63, acc3= 82.86, acc10= 85.19\n",
      "INFO - 08/10/22 20:35:47 - 0:36:00 - #################################################################################################################\n",
      "train E090: 100% 21/21 [00:11<00:00,  1.75it/s]\n",
      "INFO - 08/10/22 20:35:59 - 0:36:12 - Train Epoch 90: LOSS= 0.03383, lr= 0.000040, acc1= 99.63,acc3= 100.00,acc10= 100.00\n",
      "eval E090: 100% 23/23 [00:10<00:00,  2.14it/s]\n",
      "INFO - 08/10/22 20:36:10 - 0:36:23 - #################################################################################################################\n",
      "INFO - 08/10/22 20:36:10 - 0:36:23 - Test Epoch 90: LOSS= 5.02484, acc1= 75.88, acc3= 82.89, acc10= 85.09\n",
      "INFO - 08/10/22 20:36:10 - 0:36:23 - #################################################################################################################\n",
      "train E091: 100% 21/21 [00:11<00:00,  1.80it/s]\n",
      "INFO - 08/10/22 20:36:21 - 0:36:35 - Train Epoch 91: LOSS= 0.03183, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E091: 100% 23/23 [00:10<00:00,  2.10it/s]\n",
      "INFO - 08/10/22 20:36:32 - 0:36:45 - #################################################################################################################\n",
      "INFO - 08/10/22 20:36:32 - 0:36:45 - Test Epoch 91: LOSS= 4.93750, acc1= 75.74, acc3= 82.86, acc10= 85.12\n",
      "INFO - 08/10/22 20:36:32 - 0:36:45 - #################################################################################################################\n",
      "train E092: 100% 21/21 [00:11<00:00,  1.82it/s]\n",
      "INFO - 08/10/22 20:36:44 - 0:36:57 - Train Epoch 92: LOSS= 0.03162, lr= 0.000040, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E092: 100% 23/23 [00:10<00:00,  2.13it/s]\n",
      "INFO - 08/10/22 20:36:55 - 0:37:08 - #################################################################################################################\n",
      "INFO - 08/10/22 20:36:55 - 0:37:08 - Test Epoch 92: LOSS= 4.93070, acc1= 75.70, acc3= 82.86, acc10= 85.16\n",
      "INFO - 08/10/22 20:36:55 - 0:37:08 - #################################################################################################################\n",
      "train E093: 100% 21/21 [00:11<00:00,  1.77it/s]\n",
      "INFO - 08/10/22 20:37:07 - 0:37:20 - Train Epoch 93: LOSS= 0.03176, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E093: 100% 23/23 [00:10<00:00,  2.11it/s]\n",
      "INFO - 08/10/22 20:37:18 - 0:37:31 - #################################################################################################################\n",
      "INFO - 08/10/22 20:37:18 - 0:37:31 - Test Epoch 93: LOSS= 5.05871, acc1= 75.74, acc3= 82.89, acc10= 85.16\n",
      "INFO - 08/10/22 20:37:18 - 0:37:31 - #################################################################################################################\n",
      "train E094: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 08/10/22 20:37:30 - 0:37:43 - Train Epoch 94: LOSS= 0.03176, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E094: 100% 23/23 [00:10<00:00,  2.11it/s]\n",
      "INFO - 08/10/22 20:37:40 - 0:37:53 - #################################################################################################################\n",
      "INFO - 08/10/22 20:37:40 - 0:37:53 - Test Epoch 94: LOSS= 5.16280, acc1= 75.74, acc3= 82.82, acc10= 85.02\n",
      "INFO - 08/10/22 20:37:40 - 0:37:53 - #################################################################################################################\n",
      "train E095: 100% 21/21 [00:11<00:00,  1.75it/s]\n",
      "INFO - 08/10/22 20:37:52 - 0:38:05 - Train Epoch 95: LOSS= 0.03685, lr= 0.000040, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E095: 100% 23/23 [00:10<00:00,  2.10it/s]\n",
      "INFO - 08/10/22 20:38:03 - 0:38:16 - #################################################################################################################\n",
      "INFO - 08/10/22 20:38:03 - 0:38:16 - Test Epoch 95: LOSS= 5.02066, acc1= 75.98, acc3= 82.82, acc10= 85.12\n",
      "INFO - 08/10/22 20:38:03 - 0:38:16 - #################################################################################################################\n",
      "INFO - 08/10/22 20:38:04 - 0:38:17 - best performance =  75.81, 83.00, 85.02. best epoch = 65, correspond_loss= 4.9466\n",
      "INFO - 08/10/22 20:38:04 - 0:38:17 -  fusion_model_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_fact_SAN_3.pkl\n",
      "INFO - 08/10/22 20:38:04 - 0:38:17 -  answer_net_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_fact_MLP_3.pkl\n"
     ]
    }
   ],
   "source": [
    "# General VQA:训练\n",
    "%cd code\n",
    "!bash ./run_FVQA_train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e2218",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T08:36:27.028705Z",
     "start_time": "2022-03-08T08:36:27.028671Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# General VQA:测试\n",
    "%cd code\n",
    "!bash run_FVQA.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7494e11",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-01-12T10:33:52.926Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "ZSL setting...\n",
      "INFO - 01/12/23 18:33:56 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 01/12/23 18:33:56 - 0:00:00 - The experiment will be stored in dump/0112-Zsl_knowledge_space/W2V\n",
      "                                     \n",
      "INFO - 01/12/23 18:33:56 - 0:00:00 - Running command: python main.py --gpu_id 8 --exp_name Zsl_knowledge_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --ZSL 1 --save_model 1\n",
      "\n",
      "2023-01-12 18:33:56.609659: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-12 18:33:56.609747: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 16\n",
      "batch_size 16\n",
      "fusion_model:\n",
      "SAN(\n",
      "  (w_emb): WordEmbedding(\n",
      "    (emb): Embedding(15422, 300, padding_idx=15421)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (text): Seq2SeqRNN(\n",
      "    (rnn): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (attention): SanAttention(\n",
      "    (v_conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (q_lin): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (x_conv): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(5120, 8192, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(8192, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "Answer Model:\n",
      "MLP(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "train E000:   0% 0/181 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 342, in <module>\n",
      "    runner.run()\n",
      "  File \"main.py\", line 139, in run\n",
      "    self.train(epoch)\n",
      "  File \"main.py\", line 189, in train\n",
      "    for visual_features, boxes, question_features, answers, idx, q_len in tq:\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tqdm/std.py\", line 1165, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 363, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 403, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/ws/code/ZS-F-VQA/code/data/fvqa.py\", line 92, in __getitem__\n",
      "    question, question_length = self.questions[item]  # 问题向量列表\n",
      "ValueError: too many values to unpack (expected 2)\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "ZSL setting...\n",
      "INFO - 01/12/23 18:34:24 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 01/12/23 18:34:24 - 0:00:00 - The experiment will be stored in dump/0112-Zsl_semantic_space/W2V\n",
      "                                     \n",
      "INFO - 01/12/23 18:34:24 - 0:00:00 - Running command: python main.py --gpu_id 8 --exp_name Zsl_semantic_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --ZSL 1 --save_model 1 --relation_map 1\n",
      "\n",
      "2023-01-12 18:34:24.636325: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-12 18:34:24.636393: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 16\n",
      "batch_size 16\n",
      "fusion_model:\n",
      "SAN(\n",
      "  (w_emb): WordEmbedding(\n",
      "    (emb): Embedding(15422, 300, padding_idx=15421)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (text): Seq2SeqRNN(\n",
      "    (rnn): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (attention): SanAttention(\n",
      "    (v_conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (q_lin): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (x_conv): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(5120, 8192, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(8192, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "Answer Model:\n",
      "MLP(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "train E000: 100% 181/181 [00:55<00:00,  3.29it/s]\n",
      "INFO - 01/12/23 18:35:40 - 0:01:16 - Train Epoch 0: LOSS= 2.44887, lr= 0.000500, acc1= 43.93,acc3= 66.86,acc10= 90.11\n",
      "train E001: 100% 181/181 [00:45<00:00,  4.02it/s]\n",
      "INFO - 01/12/23 18:36:25 - 0:02:01 - Train Epoch 1: LOSS= 1.61629, lr= 0.000750, acc1= 57.67,acc3= 79.49,acc10= 94.86\n",
      "eval E001:   7% 11/164 [00:02<00:30,  4.96it/s]"
     ]
    }
   ],
   "source": [
    "# ZSL/GZSL VQA:训练\n",
    "%cd code\n",
    "!bash run_ZSL_train.sh # > ./ZSL_GZSL_VQA_train.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a85f3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-01-13T06:40:20.332Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "ZSL setting...\n",
      "INFO - 01/13/23 14:40:23 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 01/13/23 14:40:23 - 0:00:00 - The experiment will be stored in dump/0113-Zsl_knowledge_space/W2V\n",
      "                                     \n",
      "INFO - 01/13/23 14:40:23 - 0:00:00 - Running command: python main.py --gpu_id 8 --exp_name Zsl_knowledge_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --ZSL 1 --save_model 1\n",
      "\n",
      "2023-01-13 14:40:23.616460: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-13 14:40:23.616539: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 16\n",
      "batch_size 16\n",
      "fusion_model:\n",
      "SAN(\n",
      "  (w_emb): WordEmbedding(\n",
      "    (emb): Embedding(15422, 300, padding_idx=15421)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (text): Seq2SeqRNN(\n",
      "    (rnn): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (attention): SanAttention(\n",
      "    (v_conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (q_lin): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (x_conv): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(5120, 8192, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(8192, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "Answer Model:\n",
      "MLP(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "train E000: 100% 181/181 [00:51<00:00,  3.54it/s]\n",
      "INFO - 01/13/23 14:41:37 - 0:01:14 - Train Epoch 0: LOSS= 3.32182, lr= 0.000500, acc1= 38.97,acc3= 55.20,acc10= 69.71\n",
      "train E001: 100% 181/181 [00:54<00:00,  3.34it/s]\n",
      "INFO - 01/13/23 14:42:31 - 0:02:08 - Train Epoch 1: LOSS= 1.95733, lr= 0.000750, acc1= 59.51,acc3= 76.96,acc10= 87.51\n",
      "eval E001: 100% 164/164 [00:41<00:00,  3.96it/s]\n",
      "INFO - 01/13/23 14:43:12 - 0:02:50 - #################################################################################################################\n",
      "INFO - 01/13/23 14:43:12 - 0:02:50 - Test Epoch 1: LOSS= 7.67929, acc1= 0.04, acc3= 3.03, acc10= 17.93\n",
      "INFO - 01/13/23 14:43:12 - 0:02:50 - Zsl Epoch 1: LOSS= 7.67929, acc1= 12.45, acc3= 26.67, acc10= 50.19\n",
      "INFO - 01/13/23 14:43:12 - 0:02:50 - #################################################################################################################\n",
      "train E002: 100% 181/181 [00:53<00:00,  3.40it/s]\n",
      "INFO - 01/13/23 14:44:06 - 0:03:43 - Train Epoch 2: LOSS= 1.91318, lr= 0.001000, acc1= 62.11,acc3= 79.32,acc10= 88.79\n",
      "eval E002: 100% 164/164 [00:44<00:00,  3.69it/s]\n",
      "INFO - 01/13/23 14:44:50 - 0:04:27 - #################################################################################################################\n",
      "INFO - 01/13/23 14:44:50 - 0:04:27 - Test Epoch 2: LOSS= 8.57831, acc1= 0.15, acc3= 3.56, acc10= 18.89\n",
      "INFO - 01/13/23 14:44:50 - 0:04:27 - Zsl Epoch 2: LOSS= 8.57831, acc1= 10.84, acc3= 25.13, acc10= 47.97\n",
      "INFO - 01/13/23 14:44:50 - 0:04:27 - #################################################################################################################\n",
      "train E003: 100% 181/181 [00:53<00:00,  3.40it/s]\n",
      "INFO - 01/13/23 14:45:43 - 0:05:20 - Train Epoch 3: LOSS= 2.09278, lr= 0.001250, acc1= 61.69,acc3= 78.87,acc10= 89.73\n",
      "eval E003: 100% 164/164 [00:43<00:00,  3.80it/s]\n",
      "INFO - 01/13/23 14:46:26 - 0:06:04 - #################################################################################################################\n",
      "INFO - 01/13/23 14:46:26 - 0:06:04 - Test Epoch 3: LOSS= 9.24455, acc1= 0.15, acc3= 4.75, acc10= 22.26\n",
      "INFO - 01/13/23 14:46:26 - 0:06:04 - Zsl Epoch 3: LOSS= 9.24455, acc1= 12.45, acc3= 25.63, acc10= 48.24\n",
      "INFO - 01/13/23 14:46:26 - 0:06:04 - #################################################################################################################\n",
      "train E004: 100% 181/181 [00:51<00:00,  3.54it/s]\n",
      "INFO - 01/13/23 14:47:18 - 0:06:55 - Train Epoch 4: LOSS= 1.91937, lr= 0.001500, acc1= 65.68,acc3= 80.99,acc10= 90.46\n",
      "eval E004: 100% 164/164 [00:42<00:00,  3.82it/s]\n",
      "INFO - 01/13/23 14:48:01 - 0:07:38 - #################################################################################################################\n",
      "INFO - 01/13/23 14:48:01 - 0:07:38 - Test Epoch 4: LOSS= 9.62842, acc1= 0.08, acc3= 1.72, acc10= 14.79\n",
      "INFO - 01/13/23 14:48:01 - 0:07:38 - Zsl Epoch 4: LOSS= 9.62842, acc1= 5.98, acc3= 16.17, acc10= 36.17\n",
      "INFO - 01/13/23 14:48:01 - 0:07:38 - #################################################################################################################\n",
      "train E005: 100% 181/181 [00:53<00:00,  3.40it/s]\n",
      "INFO - 01/13/23 14:48:54 - 0:08:31 - Train Epoch 5: LOSS= 2.17903, lr= 0.001750, acc1= 65.72,acc3= 80.33,acc10= 90.08\n",
      "eval E005: 100% 164/164 [00:42<00:00,  3.85it/s]\n",
      "INFO - 01/13/23 14:49:37 - 0:09:14 - #################################################################################################################\n",
      "INFO - 01/13/23 14:49:37 - 0:09:14 - Test Epoch 5: LOSS= 11.47609, acc1= 0.04, acc3= 4.37, acc10= 20.92\n",
      "INFO - 01/13/23 14:49:37 - 0:09:14 - Zsl Epoch 5: LOSS= 11.47609, acc1= 9.46, acc3= 21.15, acc10= 40.96\n",
      "INFO - 01/13/23 14:49:37 - 0:09:14 - #################################################################################################################\n",
      "train E006: 100% 181/181 [00:54<00:00,  3.34it/s]\n",
      "INFO - 01/13/23 14:50:31 - 0:10:08 - Train Epoch 6: LOSS= 2.56456, lr= 0.002000, acc1= 63.53,acc3= 78.31,acc10= 88.45\n",
      "eval E006: 100% 164/164 [00:43<00:00,  3.78it/s]\n",
      "INFO - 01/13/23 14:51:14 - 0:10:51 - #################################################################################################################\n",
      "INFO - 01/13/23 14:51:14 - 0:10:51 - Test Epoch 6: LOSS= 10.94919, acc1= 0.15, acc3= 2.30, acc10= 21.23\n",
      "INFO - 01/13/23 14:51:14 - 0:10:51 - Zsl Epoch 6: LOSS= 10.94919, acc1= 10.15, acc3= 21.99, acc10= 41.95\n",
      "INFO - 01/13/23 14:51:14 - 0:10:51 - #################################################################################################################\n",
      "train E007: 100% 181/181 [00:53<00:00,  3.41it/s]\n",
      "INFO - 01/13/23 14:52:07 - 0:11:44 - Train Epoch 7: LOSS= 1.94286, lr= 0.002000, acc1= 68.49,acc3= 83.17,acc10= 92.30\n",
      "eval E007: 100% 164/164 [00:42<00:00,  3.87it/s]\n",
      "INFO - 01/13/23 14:52:49 - 0:12:27 - #################################################################################################################\n",
      "INFO - 01/13/23 14:52:49 - 0:12:27 - Test Epoch 7: LOSS= 11.72174, acc1= 0.00, acc3= 4.44, acc10= 25.40\n",
      "INFO - 01/13/23 14:52:49 - 0:12:27 - Zsl Epoch 7: LOSS= 11.72174, acc1= 12.11, acc3= 27.70, acc10= 48.97\n",
      "INFO - 01/13/23 14:52:49 - 0:12:27 - #################################################################################################################\n",
      "train E008: 100% 181/181 [00:54<00:00,  3.33it/s]\n",
      "INFO - 01/13/23 14:53:44 - 0:13:21 - Train Epoch 8: LOSS= 1.73010, lr= 0.002000, acc1= 72.62,acc3= 85.88,acc10= 93.58\n",
      "eval E008: 100% 164/164 [00:42<00:00,  3.86it/s]\n",
      "INFO - 01/13/23 14:54:26 - 0:14:04 - #################################################################################################################\n",
      "INFO - 01/13/23 14:54:26 - 0:14:04 - Test Epoch 8: LOSS= 12.56069, acc1= 0.11, acc3= 4.56, acc10= 18.05\n",
      "INFO - 01/13/23 14:54:26 - 0:14:04 - Zsl Epoch 8: LOSS= 12.56069, acc1= 8.81, acc3= 19.43, acc10= 42.49\n",
      "INFO - 01/13/23 14:54:26 - 0:14:04 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E009: 100% 181/181 [00:53<00:00,  3.41it/s]\n",
      "INFO - 01/13/23 14:55:20 - 0:14:57 - Train Epoch 9: LOSS= 1.66821, lr= 0.002000, acc1= 74.60,acc3= 87.34,acc10= 94.34\n",
      "eval E009: 100% 164/164 [00:44<00:00,  3.69it/s]\n",
      "INFO - 01/13/23 14:56:04 - 0:15:41 - #################################################################################################################\n",
      "INFO - 01/13/23 14:56:04 - 0:15:41 - Test Epoch 9: LOSS= 11.79772, acc1= 0.19, acc3= 5.48, acc10= 27.13\n",
      "INFO - 01/13/23 14:56:04 - 0:15:41 - Zsl Epoch 9: LOSS= 11.79772, acc1= 11.53, acc3= 27.82, acc10= 51.19\n",
      "INFO - 01/13/23 14:56:04 - 0:15:41 - #################################################################################################################\n",
      "train E010: 100% 181/181 [00:53<00:00,  3.39it/s]\n",
      "INFO - 01/13/23 14:56:57 - 0:16:35 - Train Epoch 10: LOSS= 1.70272, lr= 0.002000, acc1= 75.88,acc3= 89.04,acc10= 94.52\n",
      "eval E010: 100% 164/164 [00:43<00:00,  3.73it/s]\n",
      "INFO - 01/13/23 14:57:41 - 0:17:18 - #################################################################################################################\n",
      "INFO - 01/13/23 14:57:41 - 0:17:18 - Test Epoch 10: LOSS= 14.53908, acc1= 0.08, acc3= 6.59, acc10= 24.06\n",
      "INFO - 01/13/23 14:57:41 - 0:17:18 - Zsl Epoch 10: LOSS= 14.53908, acc1= 11.11, acc3= 22.30, acc10= 40.84\n",
      "INFO - 01/13/23 14:57:41 - 0:17:18 - #################################################################################################################\n",
      "train E011: 100% 181/181 [00:54<00:00,  3.35it/s]\n",
      "INFO - 01/13/23 14:58:35 - 0:18:13 - Train Epoch 11: LOSS= 1.60130, lr= 0.002000, acc1= 77.65,acc3= 89.87,acc10= 95.80\n",
      "eval E011: 100% 164/164 [00:44<00:00,  3.72it/s]\n",
      "INFO - 01/13/23 14:59:20 - 0:18:57 - #################################################################################################################\n",
      "INFO - 01/13/23 14:59:20 - 0:18:57 - Test Epoch 11: LOSS= 15.67393, acc1= 0.08, acc3= 5.02, acc10= 23.18\n",
      "INFO - 01/13/23 14:59:20 - 0:18:57 - Zsl Epoch 11: LOSS= 15.67393, acc1= 10.96, acc3= 23.75, acc10= 45.59\n",
      "INFO - 01/13/23 14:59:20 - 0:18:57 - #################################################################################################################\n",
      "train E012: 100% 181/181 [00:53<00:00,  3.36it/s]\n",
      "INFO - 01/13/23 15:00:13 - 0:19:51 - Train Epoch 12: LOSS= 2.24038, lr= 0.002000, acc1= 76.20,acc3= 88.38,acc10= 94.69\n",
      "eval E012: 100% 164/164 [00:43<00:00,  3.79it/s]\n",
      "INFO - 01/13/23 15:00:57 - 0:20:34 - #################################################################################################################\n",
      "INFO - 01/13/23 15:00:57 - 0:20:34 - Test Epoch 12: LOSS= 16.24565, acc1= 0.31, acc3= 5.48, acc10= 24.14\n",
      "INFO - 01/13/23 15:00:57 - 0:20:34 - Zsl Epoch 12: LOSS= 16.24565, acc1= 9.89, acc3= 20.96, acc10= 42.84\n",
      "INFO - 01/13/23 15:00:57 - 0:20:34 - #################################################################################################################\n",
      "train E013: 100% 181/181 [00:52<00:00,  3.43it/s]\n",
      "INFO - 01/13/23 15:01:50 - 0:21:27 - Train Epoch 13: LOSS= 2.38647, lr= 0.002000, acc1= 74.71,acc3= 87.44,acc10= 94.31\n",
      "eval E013: 100% 164/164 [00:43<00:00,  3.80it/s]\n",
      "INFO - 01/13/23 15:02:33 - 0:22:10 - #################################################################################################################\n",
      "INFO - 01/13/23 15:02:33 - 0:22:10 - Test Epoch 13: LOSS= 19.86517, acc1= 0.15, acc3= 5.17, acc10= 26.67\n",
      "INFO - 01/13/23 15:02:33 - 0:22:10 - Zsl Epoch 13: LOSS= 19.86517, acc1= 12.84, acc3= 27.28, acc10= 48.77\n",
      "INFO - 01/13/23 15:02:33 - 0:22:10 - #################################################################################################################\n",
      "train E014: 100% 181/181 [00:54<00:00,  3.31it/s]\n",
      "INFO - 01/13/23 15:03:27 - 0:23:04 - Train Epoch 14: LOSS= 1.21492, lr= 0.001400, acc1= 84.66,acc3= 93.79,acc10= 97.74\n",
      "eval E014: 100% 164/164 [00:42<00:00,  3.83it/s]\n",
      "INFO - 01/13/23 15:04:10 - 0:23:47 - #################################################################################################################\n",
      "INFO - 01/13/23 15:04:10 - 0:23:47 - Test Epoch 14: LOSS= 14.16858, acc1= 0.11, acc3= 5.25, acc10= 27.70\n",
      "INFO - 01/13/23 15:04:10 - 0:23:47 - Zsl Epoch 14: LOSS= 14.16858, acc1= 11.92, acc3= 26.63, acc10= 49.77\n",
      "INFO - 01/13/23 15:04:10 - 0:23:47 - #################################################################################################################\n",
      "train E015: 100% 181/181 [00:54<00:00,  3.31it/s]\n",
      "INFO - 01/13/23 15:05:05 - 0:24:42 - Train Epoch 15: LOSS= 0.47903, lr= 0.001400, acc1= 91.26,acc3= 97.74,acc10= 99.55\n",
      "eval E015: 100% 164/164 [00:42<00:00,  3.89it/s]\n",
      "INFO - 01/13/23 15:05:47 - 0:25:24 - #################################################################################################################\n",
      "INFO - 01/13/23 15:05:47 - 0:25:24 - Test Epoch 15: LOSS= 15.18896, acc1= 0.11, acc3= 5.71, acc10= 29.23\n",
      "INFO - 01/13/23 15:05:47 - 0:25:24 - Zsl Epoch 15: LOSS= 15.18896, acc1= 12.22, acc3= 27.66, acc10= 52.64\n",
      "INFO - 01/13/23 15:05:47 - 0:25:24 - #################################################################################################################\n",
      "train E016: 100% 181/181 [00:51<00:00,  3.48it/s]\n",
      "INFO - 01/13/23 15:06:39 - 0:26:16 - Train Epoch 16: LOSS= 0.39154, lr= 0.001400, acc1= 92.96,acc3= 98.61,acc10= 99.69\n",
      "eval E016: 100% 164/164 [00:43<00:00,  3.79it/s]\n",
      "INFO - 01/13/23 15:07:22 - 0:26:59 - #################################################################################################################\n",
      "INFO - 01/13/23 15:07:22 - 0:26:59 - Test Epoch 16: LOSS= 15.14986, acc1= 0.23, acc3= 5.86, acc10= 28.62\n",
      "INFO - 01/13/23 15:07:22 - 0:26:59 - Zsl Epoch 16: LOSS= 15.14986, acc1= 13.95, acc3= 28.51, acc10= 50.88\n",
      "INFO - 01/13/23 15:07:22 - 0:26:59 - #################################################################################################################\n",
      "train E017: 100% 181/181 [00:53<00:00,  3.40it/s]\n",
      "INFO - 01/13/23 15:08:15 - 0:27:53 - Train Epoch 17: LOSS= 0.33503, lr= 0.000980, acc1= 93.86,acc3= 99.03,acc10= 99.83\n",
      "eval E017: 100% 164/164 [00:35<00:00,  4.57it/s]\n",
      "INFO - 01/13/23 15:08:51 - 0:28:28 - #################################################################################################################\n",
      "INFO - 01/13/23 15:08:51 - 0:28:28 - Test Epoch 17: LOSS= 16.10411, acc1= 0.15, acc3= 6.93, acc10= 30.31\n",
      "INFO - 01/13/23 15:08:51 - 0:28:28 - Zsl Epoch 17: LOSS= 16.10411, acc1= 13.10, acc3= 28.16, acc10= 50.84\n",
      "INFO - 01/13/23 15:08:51 - 0:28:28 - #################################################################################################################\n",
      "train E018: 100% 181/181 [00:40<00:00,  4.43it/s]\n",
      "INFO - 01/13/23 15:09:32 - 0:29:09 - Train Epoch 18: LOSS= 0.17175, lr= 0.000980, acc1= 95.91,acc3= 99.41,acc10= 99.97\n",
      "eval E018: 100% 164/164 [00:33<00:00,  4.94it/s]\n",
      "INFO - 01/13/23 15:10:06 - 0:29:43 - #################################################################################################################\n",
      "INFO - 01/13/23 15:10:06 - 0:29:43 - Test Epoch 18: LOSS= 16.05509, acc1= 0.23, acc3= 7.47, acc10= 29.46\n",
      "INFO - 01/13/23 15:10:06 - 0:29:43 - Zsl Epoch 18: LOSS= 16.05509, acc1= 13.37, acc3= 27.43, acc10= 51.65\n",
      "INFO - 01/13/23 15:10:06 - 0:29:43 - #################################################################################################################\n",
      "train E019: 100% 181/181 [00:39<00:00,  4.56it/s]\n",
      "INFO - 01/13/23 15:10:45 - 0:30:22 - Train Epoch 19: LOSS= 0.17519, lr= 0.000980, acc1= 95.98,acc3= 99.62,acc10= 99.90\n",
      "eval E019: 100% 164/164 [00:33<00:00,  4.94it/s]\n",
      "INFO - 01/13/23 15:11:18 - 0:30:56 - #################################################################################################################\n",
      "INFO - 01/13/23 15:11:18 - 0:30:56 - Test Epoch 19: LOSS= 15.67036, acc1= 0.11, acc3= 7.70, acc10= 30.08\n",
      "INFO - 01/13/23 15:11:18 - 0:30:56 - Zsl Epoch 19: LOSS= 15.67036, acc1= 13.49, acc3= 29.00, acc10= 51.23\n",
      "INFO - 01/13/23 15:11:18 - 0:30:56 - #################################################################################################################\n",
      "train E020: 100% 181/181 [00:40<00:00,  4.45it/s]\n",
      "INFO - 01/13/23 15:11:59 - 0:31:36 - Train Epoch 20: LOSS= 0.16718, lr= 0.000686, acc1= 96.46,acc3= 99.69,acc10= 99.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E020: 100% 164/164 [00:25<00:00,  6.39it/s]\n",
      "INFO - 01/13/23 15:12:25 - 0:32:02 - #################################################################################################################\n",
      "INFO - 01/13/23 15:12:25 - 0:32:02 - Test Epoch 20: LOSS= 15.20828, acc1= 0.08, acc3= 8.05, acc10= 33.56\n",
      "INFO - 01/13/23 15:12:25 - 0:32:02 - Zsl Epoch 20: LOSS= 15.20828, acc1= 15.10, acc3= 31.42, acc10= 55.17\n",
      "INFO - 01/13/23 15:12:25 - 0:32:02 - #################################################################################################################\n",
      "train E021: 100% 181/181 [00:40<00:00,  4.52it/s]\n",
      "INFO - 01/13/23 15:13:05 - 0:32:42 - Train Epoch 21: LOSS= 0.08367, lr= 0.000686, acc1= 97.74,acc3= 99.83,acc10= 99.97\n",
      "eval E021: 100% 164/164 [00:33<00:00,  4.85it/s]\n",
      "INFO - 01/13/23 15:13:39 - 0:33:16 - #################################################################################################################\n",
      "INFO - 01/13/23 15:13:39 - 0:33:16 - Test Epoch 21: LOSS= 15.71192, acc1= 0.11, acc3= 6.28, acc10= 31.92\n",
      "INFO - 01/13/23 15:13:39 - 0:33:16 - Zsl Epoch 21: LOSS= 15.71192, acc1= 15.29, acc3= 29.96, acc10= 53.07\n",
      "INFO - 01/13/23 15:13:39 - 0:33:16 - #################################################################################################################\n",
      "train E022: 100% 181/181 [00:38<00:00,  4.65it/s]\n",
      "INFO - 01/13/23 15:14:18 - 0:33:55 - Train Epoch 22: LOSS= 0.04696, lr= 0.000686, acc1= 98.61,acc3= 99.90,acc10= 100.00\n",
      "eval E022: 100% 164/164 [00:33<00:00,  4.91it/s]\n",
      "INFO - 01/13/23 15:14:51 - 0:34:28 - #################################################################################################################\n",
      "INFO - 01/13/23 15:14:51 - 0:34:28 - Test Epoch 22: LOSS= 15.48267, acc1= 0.19, acc3= 7.09, acc10= 32.91\n",
      "INFO - 01/13/23 15:14:51 - 0:34:28 - Zsl Epoch 22: LOSS= 15.48267, acc1= 16.05, acc3= 30.88, acc10= 54.67\n",
      "INFO - 01/13/23 15:14:51 - 0:34:28 - #################################################################################################################\n",
      "train E023: 100% 181/181 [00:40<00:00,  4.50it/s]\n",
      "INFO - 01/13/23 15:15:31 - 0:35:08 - Train Epoch 23: LOSS= 0.06791, lr= 0.000480, acc1= 98.16,acc3= 99.83,acc10= 99.97\n",
      "eval E023: 100% 164/164 [00:32<00:00,  5.09it/s]\n",
      "INFO - 01/13/23 15:16:03 - 0:35:41 - #################################################################################################################\n",
      "INFO - 01/13/23 15:16:03 - 0:35:41 - Test Epoch 23: LOSS= 15.57576, acc1= 0.04, acc3= 6.86, acc10= 32.41\n",
      "INFO - 01/13/23 15:16:03 - 0:35:41 - Zsl Epoch 23: LOSS= 15.57576, acc1= 15.29, acc3= 30.31, acc10= 54.90\n",
      "INFO - 01/13/23 15:16:03 - 0:35:41 - #################################################################################################################\n",
      "train E024: 100% 181/181 [00:40<00:00,  4.43it/s]\n",
      "INFO - 01/13/23 15:16:44 - 0:36:21 - Train Epoch 24: LOSS= 0.07518, lr= 0.000480, acc1= 98.40,acc3= 99.86,acc10= 99.97\n",
      "eval E024: 100% 164/164 [00:31<00:00,  5.17it/s]\n",
      "INFO - 01/13/23 15:17:16 - 0:36:53 - #################################################################################################################\n",
      "INFO - 01/13/23 15:17:16 - 0:36:53 - Test Epoch 24: LOSS= 15.68243, acc1= 0.00, acc3= 6.97, acc10= 32.61\n",
      "INFO - 01/13/23 15:17:16 - 0:36:53 - Zsl Epoch 24: LOSS= 15.68243, acc1= 16.09, acc3= 30.57, acc10= 54.10\n",
      "INFO - 01/13/23 15:17:16 - 0:36:53 - #################################################################################################################\n",
      "train E025: 100% 181/181 [00:40<00:00,  4.42it/s]\n",
      "INFO - 01/13/23 15:17:57 - 0:37:34 - Train Epoch 25: LOSS= 0.04734, lr= 0.000480, acc1= 98.72,acc3= 99.93,acc10= 99.97\n",
      "eval E025: 100% 164/164 [00:43<00:00,  3.80it/s]\n",
      "INFO - 01/13/23 15:18:40 - 0:38:17 - #################################################################################################################\n",
      "INFO - 01/13/23 15:18:40 - 0:38:17 - Test Epoch 25: LOSS= 16.07927, acc1= 0.08, acc3= 6.78, acc10= 30.54\n",
      "INFO - 01/13/23 15:18:40 - 0:38:17 - Zsl Epoch 25: LOSS= 16.07927, acc1= 15.90, acc3= 29.89, acc10= 52.34\n",
      "INFO - 01/13/23 15:18:40 - 0:38:17 - #################################################################################################################\n",
      "train E026: 100% 181/181 [00:52<00:00,  3.43it/s]\n",
      "INFO - 01/13/23 15:19:33 - 0:39:10 - Train Epoch 26: LOSS= 0.04580, lr= 0.000336, acc1= 98.58,acc3= 99.83,acc10= 99.97\n",
      "eval E026: 100% 164/164 [00:42<00:00,  3.85it/s]\n",
      "INFO - 01/13/23 15:20:16 - 0:39:53 - #################################################################################################################\n",
      "INFO - 01/13/23 15:20:16 - 0:39:53 - Test Epoch 26: LOSS= 15.89141, acc1= 0.11, acc3= 6.40, acc10= 32.45\n",
      "INFO - 01/13/23 15:20:16 - 0:39:53 - Zsl Epoch 26: LOSS= 15.89141, acc1= 16.09, acc3= 31.11, acc10= 54.14\n",
      "INFO - 01/13/23 15:20:16 - 0:39:53 - #################################################################################################################\n",
      "train E027: 100% 181/181 [00:53<00:00,  3.38it/s]\n",
      "INFO - 01/13/23 15:21:09 - 0:40:46 - Train Epoch 27: LOSS= 0.04181, lr= 0.000336, acc1= 99.13,acc3= 99.97,acc10= 100.00\n",
      "eval E027: 100% 164/164 [00:40<00:00,  4.02it/s]\n",
      "INFO - 01/13/23 15:21:50 - 0:41:27 - #################################################################################################################\n",
      "INFO - 01/13/23 15:21:50 - 0:41:27 - Test Epoch 27: LOSS= 15.42400, acc1= 0.11, acc3= 7.24, acc10= 32.95\n",
      "INFO - 01/13/23 15:21:50 - 0:41:27 - Zsl Epoch 27: LOSS= 15.42400, acc1= 16.86, acc3= 31.80, acc10= 55.44\n",
      "INFO - 01/13/23 15:21:50 - 0:41:27 - #################################################################################################################\n",
      "train E028: 100% 181/181 [00:53<00:00,  3.38it/s]\n",
      "INFO - 01/13/23 15:22:44 - 0:42:21 - Train Epoch 28: LOSS= 0.03520, lr= 0.000336, acc1= 99.13,acc3= 99.97,acc10= 99.97\n",
      "eval E028: 100% 164/164 [00:43<00:00,  3.81it/s]\n",
      "INFO - 01/13/23 15:23:27 - 0:43:04 - #################################################################################################################\n",
      "INFO - 01/13/23 15:23:27 - 0:43:04 - Test Epoch 28: LOSS= 15.55943, acc1= 0.19, acc3= 7.01, acc10= 33.18\n",
      "INFO - 01/13/23 15:23:27 - 0:43:04 - Zsl Epoch 28: LOSS= 15.55943, acc1= 16.74, acc3= 31.11, acc10= 54.67\n",
      "INFO - 01/13/23 15:23:27 - 0:43:04 - #################################################################################################################\n",
      "train E029: 100% 181/181 [00:54<00:00,  3.31it/s]\n",
      "INFO - 01/13/23 15:24:21 - 0:43:58 - Train Epoch 29: LOSS= 0.02774, lr= 0.000235, acc1= 99.10,acc3= 99.97,acc10= 100.00\n",
      "eval E029:  62% 102/164 [00:26<00:17,  3.54it/s]"
     ]
    }
   ],
   "source": [
    "!python main.py --gpu_id 8 --exp_name Zsl_knowledge_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --ZSL 1 --save_model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1380899f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T08:36:27.033410Z",
     "start_time": "2022-03-08T08:36:27.033376Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ZSL/GZSL VQA:测试\n",
    "%cd code\n",
    "!bash run_ZSL.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "802e2496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T15:31:18.787286Z",
     "start_time": "2022-08-13T15:29:39.206576Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 08/13/22 23:29:42 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 08/13/22 23:29:42 - 0:00:00 - The experiment will be stored in dump/0813-fusion_prediction_exp/rel15_fact3data_3score_10\n",
      "                                     \n",
      "INFO - 08/13/22 23:29:42 - 0:00:00 - Running command: python joint_test.py --gpu_id 4 --exp_name fusion_prediction_exp --ZSL 0 --fusion_model SAN --method_choice W2V --exp_id rel15_fact3data_3score_10 --batch_size 32 --data_choice 3 --top_rel 15 --top_fact 3 --soft_score 100 --mrr 1\n",
      "\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 32\n",
      "batch_size 32\n",
      "begin test! ...\n",
      "loading model  ...\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_answer_SAN_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_answer_MLP_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_relation_SAN_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_relation_MLP_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_fact_SAN_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_fact_MLP_3.pkl model done!\n",
      "use train data: 3\n",
      "batch_size 32\n",
      "use train data: 3\n",
      "batch_size 32\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]torch.Size([32, 2048, 14, 14]) torch.Size([32, 1, 1]) torch.Size([32, 30]) torch.Size([32])\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - test id = 1672, question = what does the object held in the woman's hand has as a part, img = COCO_val2014_000000006771.jpg\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - real suppord fact in dataset=['button', 'part of', 'cell phone'], real answer = button\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - normal model predict = ['shell', 'string', 'window', 'umbrella', 'keyboard', 'guitar', 'cloud', 'glass', 'canvas', 'drum']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict = ['shell', 'sofa', 'low', 'hammer', 'string', 'window', 'umbrella', 'keyboard', 'guitar', 'cloud']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict relation = ['has a', 'part of', 'large', 'has property', 'is a', 'animal family', 'small', 'social', 'at location', 'capable of', 'firm', 'independent', 'human', 'animal phylum', 'long']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict fact = ['nail nail', 'nail', 'soft cushion']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - suppord fact predict = ['nail nail-capable of', 'soft cushion-has a', 'nail-is a', 'nail-has property', 'nail-has a']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - correspond target = ['low', 'sofa', 'shell', 'hammer']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - test id = 1931, question = What property does the place in this image have?, img = COCO_val2014_000000015303.jpg\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - real suppord fact in dataset=['ocean', 'has property', 'very deep'], real answer = ocean\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - normal model predict = ['smooth', 'wave', 'pleasant', 'cold and wet', 'sweet and juicy', 'romantic', 'big', 'sandy', 'banana', 'beach']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict = ['wave', 'desert', 'whale', 'blue', 'water', 'coast', 'swim', 'shell', 'jellyfish', 'dolphin']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict relation = ['has property', 'has a', 'at location', 'firm', 'protected', 'stable', 'independent', 'solar', 'expensive', 'impassable', 'is a', 'created by', 'capable of', 'receives action', 'used for']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict fact = ['ocean', 'sea', 'sea water']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - suppord fact predict = ['sea-impassable', 'ocean-has a', 'ocean-at location', 'sea water-at location', 'ocean-used for', 'sea-at location', 'ocean-has property']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - correspond target = ['jellyfish', 'desert', 'blue', 'water', 'coast', 'wave', 'whale', 'shell', 'swim', 'dolphin']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - test id = 78, question = Which object in this image is coiled?, img = ILSVRC2012_test_00027806.JPEG\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - real suppord fact in dataset=['french horn', 'related to', 'coil'], real answer = french horn\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - normal model predict = ['french horn', 'trombone', 'dog', 'saxophone', 'trumpet', 'clarinet', 'hand', 'violin', 'shirt', 'flute']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict = ['hand', 'fence', 'cell phone', 'phone', 'racquet', 'french horn', 'trombone', 'dog', 'saxophone', 'trumpet']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict relation = ['is a', 'related to', 'has property', 'has a', 'used for', 'part of', 'belong to', 'specific', 'receives action', 'capable of', 'important', 'at location', 'common', 'good', 'animal order']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict fact = ['grasp appendage', 'wire', 'ring']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - suppord fact predict = ['ring-capable of', 'wire-related to', 'grasp appendage-related to']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - correspond target = ['fence', 'cell phone', 'racquet', 'hand', 'phone']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - test id = 2006, question = What is the place in this image used for?, img = COCO_val2014_000000011727.jpg\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - real suppord fact in dataset=['bathroom', 'used for', 'clean your tooth in'], real answer = clean your tooth in\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - normal model predict = ['pee', 'wash', 'swim', 'sleep', 'preventing from getting wet', 'laundromat', 'sleep away from home', 'toilet', 'cold and wet', 'sink']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict = ['pee', 'wash', 'cooking', 'prepare food', 'hotel room', 'breakfast', 'house', 'plunger', 'swim', 'sleep']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict relation = ['used for', 'belong to', 'capable of', 'related to', 'effective', 'good', 'receives action', 'part of', 'great', 'specific', 'easy', 'at location', 'popular', 'important', 'animal order']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict fact = ['kitchenette', 'shower', 'toilet']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - suppord fact predict = ['toilet-used for', 'kitchenette-used for', 'kitchenette-at location', 'shower-used for']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - correspond target = ['prepare food', 'house', 'hotel room', 'plunger', 'cooking', 'pee', 'wash', 'breakfast']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - test id = 2805, question = Who likes to play this game?, img = COCO_val2014_000000012543.jpg\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - real suppord fact in dataset=['kite', 'related to', 'child'], real answer = child\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - normal model predict = ['person', 'kite', 'racket', 'wii', 'tennis racket', 'frisbee', 'racquet', 'police', 'tennis ball', 'make person happy']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict = ['racket', 'wii', 'racquet', 'tennis ball', 'volleyball', 'baseball', 'computer', 'person', 'kite', 'tennis racket']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict relation = ['capable of', 'belong to', 'used for', 'related to', 'desires', 'at location', 'accurate', 'active', 'important', 'intelligent', 'reliable', 'easy', 'specific', 'loyal', 'is a']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict fact = ['ball games', 'video game', 'video game console']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - suppord fact predict = ['video game-belong to', 'video game console-belong to', 'video game-related to', 'ball games-belong to']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - correspond target = ['racquet', 'computer', 'wii', 'volleyball', 'racket', 'tennis ball', 'baseball']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - test id = 1958, question = which object in this image can we lie on, img = COCO_val2014_000000115870.jpg\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - real suppord fact in dataset=['sofa', 'used for', 'lie on it'], real answer = sofa\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - normal model predict = ['wall', 'person', 'computer', 'head', 'desk', 'donut', 'clock', 'position', 'couch', 'doughnut']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict = ['person', 'bed', 'horse', 'wall', 'computer', 'head', 'desk', 'donut', 'clock', 'position']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict relation = ['capable of', 'part of', 'has a', 'receives action', 'used for', 'at location', 'is a', 'related to', 'active', 'has property', 'fast', 'high', 'human', 'surface', 'desires']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict fact = ['lie', 'where you sleep', 'lie in bed']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - suppord fact predict = ['where you sleep-is a', 'lie in bed-capable of', 'lie-capable of']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - correspond target = ['person', 'horse', 'bed']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - test id = 1662, question = Where does the place in this image can be found in?, img = COCO_val2014_000000133042.jpg\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - real suppord fact in dataset=['baseball field', 'at location', 'shape of diamond'], real answer = baseball field\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - normal model predict = ['baseball', 'play baseball', 'baseball field', 'baseball bat', 'play baseball on it', 'play game of baseball', 'baseball glove', 'soccer ball', 'rugby ball', 'play basketball']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict = ['horse', 'chair', 'couch', 'sofa', 'baseball', 'play baseball', 'baseball field', 'baseball bat', 'play baseball on it', 'play game of baseball']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict relation = ['at location', 'used for', 'capable of', 'related to', 'specific', 'belong to', 'part of', 'has property', 'surface', 'important', 'convenient', 'human', 'active', 'animal family', 'has a']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict fact = ['countryside', 'sit in', 'armchair']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - suppord fact predict = ['sit in-used for', 'armchair-related to', 'countryside-at location']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - correspond target = ['couch', 'sofa', 'chair', 'horse']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - test id = 344, question = Normally you play this game with your?, img = COCO_val2014_000000100238.jpg\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - real suppord fact in dataset=['frisbee', 'used for', 'dog'], real answer = dog\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - normal model predict = ['airport', 'fair', 'screwdriver', 'road', 'person', 'golf ball', 'park', 'house', 'expensive', 'bathroom']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict = ['wii', 'computer', 'airport', 'fair', 'screwdriver', 'road', 'person', 'golf ball', 'park', 'house']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict relation = ['belong to', 'related to', 'used for', 'at location', 'capable of', 'is a', 'desires', 'specific', 'has property', 'important', 'has a', 'visible', 'part of', 'accurate', 'fast']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict fact = ['home video game consoles', 'video game', 'video game console']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - suppord fact predict = ['video game-belong to', 'video game console-belong to', 'video game-related to', 'home video game consoles-belong to']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - correspond target = ['wii', 'computer']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - test id = 1435, question = What in this image can be found in brush?, img = ILSVRC2012_test_00000165.JPEG\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - real suppord fact in dataset=['snake', 'at location', 'brush'], real answer = snake\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - normal model predict = ['snake', 'ant', 'tick', 'bird', 'lizard', 'armadillo', 'bee', 'tree', 'monkey', 'squirrel']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict = ['cat', 'handbag', 'tv', 'cup', 'snake', 'ant', 'tick', 'bird', 'lizard', 'armadillo']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict relation = ['at location', 'used for', 'related to', 'has a', 'part of', 'capable of', 'specific', 'is a', 'belong to', 'animal order', 'receives action', 'important', 'good', 'social', 'common']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict fact = ['apartment', \"woman's closet\", 'closet']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - suppord fact predict = [\"woman's closet-at location\", 'closet-at location', 'apartment-at location']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - correspond target = ['cat', 'tv', 'cup', 'handbag']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "  1%|▍                                           | 1/89 [00:00<01:10,  1.24it/s]INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - test id = 2425, question = Are the animals in the image smaller or bigger than normal horse?, img = COCO_val2014_000000100661.jpg\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - real suppord fact in dataset=['zebra', 'small', 'small'], real answer = small\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - normal model predict = ['zebra', 'horse', 'africa', 'animal', 'cow', 'toys', 'camel', 'cattle', 'herd sheep', 'antelope']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict = ['zebra', 'camel', 'elephant', 'horse', 'africa', 'animal', 'cow', 'toys', 'cattle', 'herd sheep']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict relation = ['small', 'large', 'big', 'tall', 'long', 'has a', 'animal family', 'independent', 'firm', 'compact', 'soft', 'is a', 'animal order', 'created by', 'animal kingdom']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict fact = ['horse', 'pony', 'follow horse']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - suppord fact predict = ['horse-small', 'horse-big', 'horse-tall']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - correspond target = ['zebra', 'camel', 'elephant']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - test id = 73, question = What might be the next step?, img = COCO_val2014_000000107831.jpg\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - real suppord fact in dataset=['knife', 'used for', 'pare apple'], real answer = pare apple\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - normal model predict = ['strawberry', 'cut', 'hair', 'scissors', 'clock', 'control', 'root', 'ice', 'drink', 'rich in vitamin c']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict = ['computer', 'water', 'wine', 'watch', 'couch', 'chair', 'sofa', 'strawberry', 'cut', 'hair']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict relation = ['belong to', 'related to', 'used for', 'capable of', 'at location', 'part of', 'is a', 'good', 'important', 'receives action', 'specific', 'has a', 'animal order', 'has property', 'easy']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict fact = ['monitor', 'it', 'bottle']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - suppord fact predict = ['it-is a', 'monitor-related to', 'monitor-used for', 'bottle-related to', 'it-used for', 'bottle-capable of', 'it-related to', 'it-belong to']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - correspond target = ['sofa', 'water', 'wine', 'computer', 'couch', 'watch', 'chair']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - test id = 1125, question = Which object in this image belongs to the category of kitchen items?, img = ILSVRC2012_test_00047461.JPEG\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - real suppord fact in dataset=['cup', 'belong to', 'kitchen'], real answer = cup\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - normal model predict = ['dishes', 'plate', 'cake', 'bird', 'basket', 'salad', 'dining table', 'sandwich', 'wedding', 'cook food']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict = ['cake', 'dining table', 'sandwich', 'cabinet', 'desk', 'bagel', 'monitor', 'cabinets', 'chair', 'dishes']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict relation = ['belong to', 'desires', 'animal phylum', 'animal kingdom', 'loyal', 'animal order', 'comfortable', 'protected', 'trustworthy', 'is a', 'animal class', 'animal family', 'at location', 'primitive', 'sensible']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict fact = ['assemble food', 'furniture', 'baked goods']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - suppord fact predict = ['furniture-belong to', 'furniture-is a', 'baked goods-belong to', 'assemble food-is a']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - correspond target = ['cake', 'bagel', 'desk', 'monitor', 'chair', 'cabinets', 'cabinet', 'sandwich', 'dining table']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - test id = 218, question = What object is related to bagage in this image?, img = COCO_val2014_000000137727.jpg\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - real suppord fact in dataset=['bagage', 'related to', 'luggage'], real answer = luggage\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - normal model predict = ['train', 'train station', 'railroad track', 'bus', 'taxi', 'truck', 'transport', 'station', 'track', 'ride']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict = ['bus', 'station', 'house', 'travel', 'chair', 'couch', 'sofa', 'train', 'train station', 'railroad track']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict relation = ['related to', 'is a', 'belong to', 'has property', 'has a', 'at location', 'used for', 'common', 'part of', 'easy', 'important', 'specific', 'convenient', 'good', 'animal order']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict fact = ['suburb', 'train', 'it']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - suppord fact predict = ['it-is a', 'train-at location', 'train-used for', 'suburb-at location', 'it-used for', 'it-related to', 'it-belong to', 'train-convenient']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - correspond target = ['sofa', 'bus', 'house', 'couch', 'chair', 'station', 'travel']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - test id = 404, question = What does the right large object contain?, img = ILSVRC2012_test_00032881.JPEG\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - real suppord fact in dataset=['bookshelf', 'has a', 'book'], real answer = book\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - normal model predict = ['glass', 'mirror', 'wall', 'sink', 'vase', 'cabinet', 'wine glass', 'cabinets', 'romantic', 'bookshelf']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict = ['desk', 'sand', 'glass', 'mirror', 'wall', 'sink', 'vase', 'cabinet', 'wine glass', 'cabinets']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict relation = ['has property', 'has a', 'used for', 'at location', 'part of', 'belong to', 'related to', 'is a', 'created by', 'capable of', 'receives action', 'animal order', 'specific', 'animal family', 'protected']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict fact = ['create glass', 'modify table table be furniture', 'office table']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - suppord fact predict = ['office table-related to', 'modify table table be furniture-is a', 'create glass-used for']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - correspond target = ['desk', 'sand']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - test id = 682, question = Which object in this image can be found in the ocean?, img = ILSVRC2012_test_00059915.JPEG\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - real suppord fact in dataset=['ship', 'at location', 'in ocean'], real answer = ship\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - normal model predict = ['boat', 'airplane', 'sail boat', 'raft', 'shore boat', 'snake', 'whale', 'store boat', 'fish', 'shell']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict = ['whale', 'shell', 'dolphin', 'large ship', 'seal', 'water', 'turtle', 'jellyfish', 'coast', 'swim']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict relation = ['at location', 'has a', 'capable of', 'surface', 'used for', 'related to', 'part of', 'specific', 'visible', 'human', 'frequent', 'social', 'animal order', 'active', 'primitive']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - our model predict fact = ['sea', 'ocean', 'sea water']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - suppord fact predict = ['ocean-has a', 'ocean-at location', 'sea water-at location', 'ocean-used for', 'sea-at location']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - correspond target = ['jellyfish', 'coast', 'whale', 'turtle', 'water', 'shell', 'swim', 'seal', 'large ship', 'dolphin']\n",
      "INFO - 08/13/22 23:30:15 - 0:00:33 - #################################################################################\n",
      "  2%|▉                                           | 2/89 [00:01<01:02,  1.40it/s]INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - test id = 2574, question = Which object in this image is an infant cat?, img = COCO_val2014_000000025138.jpg\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - real suppord fact in dataset=['kitten', 'is a', 'infant cat'], real answer = kitten\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - normal model predict = ['cat', 'kitten', 'dog', 'rabbit', 'otter', 'dog poop', 'teddy bear', 'monkey', 'animal', 'squirrel']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict = ['cat', 'dog', 'goldfish', 'ant', 'person', 'kitten', 'rabbit', 'otter', 'dog poop', 'teddy bear']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict relation = ['is a', 'has a', 'belong to', 'has property', 'animal class', 'cool', 'part of', 'good', 'clean', 'used for', 'capable of', 'independent', 'sweet', 'long', 'easy']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict fact = ['pet cat', 'pet', 'pet animal']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - suppord fact predict = ['pet-is a', 'pet animal-has a', 'pet-belong to', 'pet-used for']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - correspond target = ['cat', 'dog', 'ant', 'person', 'goldfish']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - test id = 2028, question = Which object in this image are dangerous?, img = ILSVRC2012_test_00048011.JPEG\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - real suppord fact in dataset=['axe', 'has property', 'dangerous'], real answer = axe\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - normal model predict = ['hammer', 'scissors', 'screwdriver', 'corkscrew', 'knife', 'wood', 'chain saw', 'ruler', 'metal', 'axe']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict = ['snake', 'clock', 'person', 'flute', 'crutch', 'hammer', 'scissors', 'screwdriver', 'corkscrew', 'knife']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict relation = ['related to', 'used for', 'is a', 'has property', 'capable of', 'has a', 'belong to', 'part of', 'at location', 'specific', 'receives action', 'important', 'dangerous', 'desires', 'common']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict fact = ['be dangerous', 'tick', 'feel pain both physically and emotionally']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - suppord fact predict = ['tick-related to', 'feel pain both physically and emotionally-capable of', 'be dangerous-capable of']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - correspond target = ['clock', 'person', 'crutch', 'flute', 'snake']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - test id = 82, question = What alcoholic beverage can be seen in this image?, img = ILSVRC2012_test_00005726.JPEG\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - real suppord fact in dataset=['beer', 'belong to', 'alcoholic beverage'], real answer = beer\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - normal model predict = ['guitar', 'music studio', 'drum', 'music', 'violin', 'cello', 'saxophone', 'piano', 'wedding', 'banjo']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict = ['fig', 'refrigerator', 'fruit', 'cup', 'vegetable', 'hot dog', 'banana', 'hotdog', 'pretzel', 'donut']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict relation = ['belong to', 'is a', 'related to', 'capable of', 'at location', 'has property', 'part of', 'has a', 'important', 'used for', 'created by', 'specific', 'common', 'desires', 'receives action']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict fact = ['food and drink', 'drink from', 'drink out of']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - suppord fact predict = ['drink from-used for', 'food and drink-belong to', 'drink out of-used for']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - correspond target = ['hotdog', 'fig', 'hot dog', 'refrigerator', 'banana', 'cup', 'pretzel', 'donut', 'vegetable', 'fruit']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - test id = 2212, question = What is the vegetable in the image?, img = ILSVRC2012_test_00043794.JPEG\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - real suppord fact in dataset=['bell pepper', 'is a', 'vegetable'], real answer = bell pepper\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - normal model predict = ['fruit', 'lemon', 'orange', 'pineapple', 'apple', 'vegetable', 'banana', 'strawberry', 'pare apple', 'cucumber']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict = ['fruit', 'lemon', 'orange', 'pineapple', 'apple', 'vegetable', 'banana', 'strawberry', 'pomegranate', 'fig']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict relation = ['belong to', 'is a', 'related to', 'has a', 'has property', 'used for', 'part of', 'at location', 'good', 'animal order', 'created by', 'animal class', 'common', 'important', 'receives action']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict fact = ['food', 'vegetable', 'fruit']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - suppord fact predict = ['fruit-belong to', 'fruit-related to', 'food-is a', 'fruit-is a', 'fruit-part of', 'food-belong to']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - correspond target = ['apple', 'strawberry', 'fig', 'pineapple', 'pomegranate', 'orange', 'banana', 'lemon', 'vegetable', 'fruit']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - test id = 155, question = Which object in this image is a bouyant?, img = COCO_val2014_000000104629.jpg\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - real suppord fact in dataset=['boat', 'is a', 'bouyant'], real answer = boat\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - normal model predict = ['boat', 'sail boat', 'shore boat', 'sea', 'surf board', 'store boat', 'ocean', 'whale', 'sand', 'beach']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict = ['whale', 'motorcycle', 'child', 'trombone', 'boat', 'sail boat', 'shore boat', 'sea', 'surf board', 'store boat']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict relation = ['is a', 'has property', 'has a', 'related to', 'belong to', 'visible', 'cool', 'light', 'convenient', 'part of', 'red', 'popular', 'compact', 'easy', 'green']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict fact = ['moby dick', 'subculture', 'tromboner']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - suppord fact predict = ['moby dick-related to', 'subculture-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - correspond target = ['trombone', 'whale', 'motorcycle', 'child']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - test id = 1304, question = Which food in this image is sometimes called 'mystery meat'?, img = COCO_val2014_000000007961.jpg\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - real suppord fact in dataset=['hot dog', 'is a', 'refer to as mystery meat'], real answer = hot dog\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - normal model predict = ['bagel', 'pizza', 'hamburger', 'hotdog', 'sandwich', 'salad', 'pretzel', 'lobster', 'burrito', 'banana']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict = ['pizza', 'knife', 'bagel', 'hamburger', 'hotdog', 'sandwich', 'salad', 'pretzel', 'lobster', 'burrito']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict relation = ['related to', 'belong to', 'is a', 'has property', 'has a', 'created by', 'used for', 'part of', 'specific', 'important', 'receives action', 'common', 'animal order', 'at location', 'capable of']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict fact = ['cut food', 'finger food', 'cut meat with']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - suppord fact predict = ['cut meat with-used for', 'cut food-capable of', 'finger food-is a']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - correspond target = ['pizza', 'knife']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - test id = 485, question = Which fruit in this image is crop originating from China, img = ILSVRC2012_test_00017039.JPEG\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - real suppord fact in dataset=['apple', 'belong to', 'crops originating from china'], real answer = apple\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - normal model predict = ['chair', 'banana', 'head', 'toothbrush', 'bowl', 'pineapple', 'spoon', 'hand', 'hair', 'carrot']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict = ['shirt', 'person', 'chair', 'banana', 'head', 'toothbrush', 'bowl', 'pineapple', 'spoon', 'hand']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict relation = ['is a', 'has a', 'part of', 'used for', 'related to', 'created by', 'has property', 'at location', 'belong to', 'receives action', 'popular', 'red', 'specific', 'small', 'common']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict fact = ['cover your chest', 'nose on their face', 'stand on their hind leg']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - suppord fact predict = ['cover your chest-used for', 'nose on their face-has a']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - correspond target = ['shirt', 'person']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - test id = 2449, question = Which object in this image can be found in a terrarium?, img = ILSVRC2012_test_00030135.JPEG\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - real suppord fact in dataset=['lizard', 'at location', 'terrarium'], real answer = lizard\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - normal model predict = ['zebra', 'lizard', 'snake', 'giraffe', 'frog', 'armadillo', 'dragonfly', 'turtle', 'africa', 'monkey']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict = ['zebra', 'giraffe', 'armadillo', 'monkey', 'antelope', 'zoo', 'camel', 'cat', 'elephant', 'jellyfish']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict relation = ['at location', 'belong to', 'related to', 'specific', 'used for', 'visible', 'capable of', 'human', 'has a', 'surface', 'animal order', 'active', 'part of', 'social', 'important']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict fact = ['animal', 'primate', 'monkey']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - suppord fact predict = ['animal-related to', 'monkey-at location', 'animal-belong to', 'primate-related to']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - correspond target = ['jellyfish', 'cat', 'armadillo', 'camel', 'antelope', 'zoo', 'zebra', 'elephant', 'giraffe', 'monkey']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - test id = 1812, question = Which object in the image is related to ping pong ball?, img = ILSVRC2012_test_00048422.JPEG\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - real suppord fact in dataset=['ping pong ball', 'related to', 'table tennis'], real answer = ping pong ball\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - normal model predict = ['tennis racket', 'tennis ball', 'racquet', 'ping pong ball', 'racket', 'tennis', 'soccer ball', 'golf ball', 'frisbee', 'ball']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict = ['tennis racket', 'tennis ball', 'racquet', 'racket', 'soccer ball', 'volleyball', 'rugby ball', 'baseball', 'ping pong ball', 'tennis']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict relation = ['related to', 'belong to', 'specific', 'important', 'common', 'part of', 'used for', 'animal order', 'social', 'prevalent', 'is a', 'has property', 'accurate', 'at location', 'capable of']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict fact = ['ball', 'ball games', 'ball bear']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - suppord fact predict = ['ball-related to', 'ball-belong to', 'ball games-belong to', 'ball-is a']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - correspond target = ['racket', 'rugby ball', 'volleyball', 'tennis racket', 'racquet', 'tennis ball', 'baseball', 'soccer ball']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - test id = 2694, question = Which object in this image is a long vehicle composed of many cars linked together?, img = COCO_val2014_000000116957.jpg\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - real suppord fact in dataset=['train', 'is a', 'longh vehicle compose of many car link together'], real answer = train\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - normal model predict = ['train', 'store boat', 'water', 'travel in car', 'child', 'bicycle', 'car', 'transport person', 'boy', 'street']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict = ['bus', 'horse', 'sofa', 'train', 'store boat', 'water', 'travel in car', 'child', 'bicycle', 'car']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict relation = ['is a', 'has a', 'belong to', 'related to', 'has property', 'part of', 'capable of', 'common', 'receives action', 'small', 'blind', 'animal phylum', 'important', 'long', 'animal kingdom']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict fact = ['large than person', 'large than chair', 'wheel and can transport many person at one time']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - suppord fact predict = ['wheel and can transport many person at one time-part of', 'large than person-has property', 'large than chair-is a']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - correspond target = ['bus', 'sofa', 'horse']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - test id = 2706, question = Which animal in this image like live mice, img = ILSVRC2012_test_00029408.JPEG\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - real suppord fact in dataset=['snake', 'desires', 'live mouse'], real answer = snake\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - normal model predict = ['snake', 'lizard', 'giraffe', 'frog', 'monkey', 'zebra', 'turtle', 'ray', 'armadillo', 'seal']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict = ['person', 'music studio', 'snake', 'lizard', 'giraffe', 'frog', 'monkey', 'zebra', 'turtle', 'ray']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict relation = ['is a', 'has a', 'at location', 'has property', 'capable of', 'belong to', 'used for', 'part of', 'desires', 'related to', 'receives action', 'independent', 'long', 'visible', 'important']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - our model predict fact = ['listen to sound', 'sound control room', 'listen to music with earphone']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - suppord fact predict = ['listen to music with earphone-capable of', 'sound control room-at location', 'listen to sound-capable of']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - correspond target = ['music studio', 'person']\n",
      "INFO - 08/13/22 23:30:16 - 0:00:34 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|█▍                                          | 3/89 [00:02<01:01,  1.40it/s]INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - test id = 1871, question = What thing can the object in this image do?, img = ILSVRC2012_test_00002300.JPEG\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - real suppord fact in dataset=['power drill', 'used for', 'drive screw'], real answer = drive screw\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - normal model predict = ['lipstick', 'nail', 'car', 'fruit', 'scissors', 'hair', 'peel', 'hair spray', 'bakery', 'drive screw']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict = ['mouse', 'toothbrush', 'tv', 'lipstick', 'nail', 'car', 'fruit', 'scissors', 'hair', 'peel']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict relation = ['used for', 'capable of', 'has property', 'at location', 'related to', 'has a', 'belong to', 'receives action', 'part of', 'created by', 'is a', 'specific', 'fast', 'common', 'animal order']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict fact = ['dental tool', 'advertise', 'leave click']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - suppord fact predict = ['advertise-used for', 'leave click-related to', 'dental tool-is a']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - correspond target = ['tv', 'mouse', 'toothbrush']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - test id = 549, question = Which object in this image is a kind of fuiniture?, img = COCO_val2014_000000150320.jpg\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - real suppord fact in dataset=['desk', 'is a', 'furniture'], real answer = desk\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - normal model predict = ['desk', 'computer', 'keyboard', 'laptop', 'pen', 'monitor', 'ram', 'chair', 'mouse', 'clock']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict = ['book', 'remote', 'camel', 'giraffe', 'desk', 'computer', 'keyboard', 'laptop', 'pen', 'monitor']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict relation = ['is a', 'related to', 'belong to', 'has a', 'has property', 'used for', 'at location', 'part of', 'specific', 'important', 'good', 'capable of', 'common', 'receives action', 'cool']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict fact = ['source of information', 'ruminant', 'Category:Human machine interaction']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - suppord fact predict = ['Category:Human machine interaction-belong to', 'ruminant-is a', 'source of information-is a']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - correspond target = ['remote', 'camel', 'giraffe', 'book']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - test id = 402, question = What thin in the image can block the sunlight from your eyes?, img = ILSVRC2012_test_00000957.JPEG\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - real suppord fact in dataset=['hat', 'capable of', 'go on hat rack'], real answer = hat\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - normal model predict = ['hair', 'head', 'lamp', 'lipstick', 'helmet', 'umbrella', 'mirror', 'hat', 'hair spray', 'sunglasses']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict = ['head', 'umbrella', 'tree', 'zebra', 'hair', 'lamp', 'lipstick', 'helmet', 'mirror', 'hat']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict relation = ['capable of', 'used for', 'fast', 'related to', 'specific', 'high', 'at location', 'effective', 'accurate', 'active', 'efficient', 'has a', 'part of', 'good', 'receives action']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict fact = ['eye', 'shade you from sun', 'shade person from sun']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - suppord fact predict = ['shade person from sun-capable of', 'eye-part of', 'eye-has a', 'shade you from sun-capable of']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - correspond target = ['zebra', 'umbrella', 'head', 'tree']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - test id = 2791, question = What can be found in this place?, img = COCO_val2014_000000154193.jpg\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - real suppord fact in dataset=['place to eat', 'at location', 'food'], real answer = food\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - normal model predict = ['pizza', 'food', 'restaurant', 'cheese', 'italian', 'cook food', 'big', 'hamburger', 'eat', 'lobster']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict = ['pizza', 'large container', 'kitchen', 'kitchen table', 'wine', 'food', 'restaurant', 'cheese', 'italian', 'cook food']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict relation = ['at location', 'belong to', 'has a', 'part of', 'used for', 'good', 'is a', 'animal order', 'has property', 'animal class', 'animal family', 'receives action', 'capable of', 'great', 'important']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict fact = ['restaurant kitchen', 'restaurant', 'restaurant terminology']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - suppord fact predict = ['restaurant terminology-belong to', 'restaurant kitchen-at location', 'restaurant-at location']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - correspond target = ['kitchen table', 'kitchen', 'wine', 'pizza', 'large container']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - test id = 535, question = What is the taste of the fruit in the image?, img = ILSVRC2012_test_00028372.JPEG\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - real suppord fact in dataset=['orange', 'is a', 'sweet and juicy'], real answer = sweet and juicy\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - normal model predict = ['orange', 'lemon', 'strawberry', 'green', 'fruit', 'vegetable', 'chocolate', 'cake', 'donut', 'pineapple']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict = ['orange', 'lemon', 'strawberry', 'fruit', 'pineapple', 'banana', 'rich in vitamin c', 'apple', 'pomegranate', 'peel']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict relation = ['is a', 'animal order', 'related to', 'animal class', 'animal family', 'animal kingdom', 'part of', 'has a', 'has property', 'common', 'belong to', 'animal phylum', 'at location', 'important', 'small']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict fact = ['fruit', 'apple', 'taste apple']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - suppord fact predict = ['fruit-belong to', 'apple-has a', 'fruit-related to', 'fruit-is a', 'apple-is a', 'fruit-part of']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - correspond target = ['apple', 'strawberry', 'pineapple', 'peel', 'pomegranate', 'orange', 'banana', 'lemon', 'rich in vitamin c', 'fruit']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - test id = 229, question = What is the flat disc in this image called?, img = COCO_val2014_000000025057.jpg\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - real suppord fact in dataset=['frisbee', 'is a', 'flat disc'], real answer = frisbee\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - normal model predict = ['grass', 'frisbee', 'soccer ball', 'play baseball on it', 'baseball field', 'rugby ball', 'play baseball', 'golf ball', 'tennis ball', 'play game of baseball']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict = ['rugby ball', 'airplane', 'grass', 'frisbee', 'soccer ball', 'play baseball on it', 'baseball field', 'play baseball', 'golf ball', 'tennis ball']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict relation = ['is a', 'related to', 'part of', 'has property', 'has a', 'capable of', 'animal family', 'at location', 'used for', 'animal order', 'important', 'animal class', 'good', 'common', 'animal kingdom']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict fact = ['circle airfield', 'flying disc', 'oval shape']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - suppord fact predict = ['circle airfield-capable of', 'oval shape-has property']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - correspond target = ['airplane', 'rugby ball']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - test id = 47, question = Which object in this image can sometimes be found in a horserace?, img = COCO_val2014_000000102672.jpg\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - real suppord fact in dataset=['horse', 'at location', 'horserace'], real answer = horse\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - normal model predict = ['horse', 'camel', 'elephant', 'cow', 'cattle', 'tree', 'car', 'boat', 'wooden', 'wood']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict = ['elephant', 'dog', 'giraffe', 'snake', 'zebra', 'tourist', 'monkey', 'animal', 'dolphin', 'city']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict relation = ['at location', 'belong to', 'used for', 'related to', 'visible', 'has a', 'capable of', 'specific', 'surface', 'active', 'part of', 'human', 'animal order', 'has property', 'small']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict fact = ['petshop', 'zoo', 'primate']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - suppord fact predict = ['zoo-at location', 'petshop-at location', 'primate-related to']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - correspond target = ['tourist', 'animal', 'dog', 'city', 'zebra', 'giraffe', 'elephant', 'dolphin', 'monkey', 'snake']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "  4%|█▉                                          | 4/89 [00:02<01:02,  1.35it/s]INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - test id = 1118, question = Which object in this image is related to tromboner?, img = ILSVRC2012_test_00000655.JPEG\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - real suppord fact in dataset=['tromboner', 'related to', 'trombone'], real answer = trombone\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - normal model predict = ['saxophone', 'flute', 'guitar', 'trombone', 'french horn', 'cello', 'clarinet', 'knife', 'metal', 'scissors']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict = ['guitar', 'scissors', 'person', 'saxophone', 'flute', 'trombone', 'french horn', 'cello', 'clarinet', 'knife']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict relation = ['related to', 'used for', 'specific', 'belong to', 'important', 'common', 'at location', 'animal order', 'is a', 'accurate', 'social', 'part of', 'prevalent', 'capable of', 'frequent']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict fact = ['luthier', 'rate', 'sew']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - suppord fact predict = ['sew-belong to', 'luthier-related to', 'rate-related to']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - correspond target = ['guitar', 'scissors', 'person']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - test id = 2764, question = What in this image desires to interact with people?, img = ILSVRC2012_test_00053584.JPEG\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - real suppord fact in dataset=['dog', 'desires', 'interract with person'], real answer = dog\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - normal model predict = ['dog', 'dog poop', 'hot dog', 'eat', 'horse', 'herd sheep', 'sheep', 'cat', 'kept as pets', 'food']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict = ['person', 'computer', 'dog', 'dog poop', 'hot dog', 'eat', 'horse', 'herd sheep', 'sheep', 'cat']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict relation = ['desires', 'has property', 'capable of', 'good', 'has a', 'used for', 'is a', 'at location', 'human', 'important', 'related to', 'belong to', 'trustworthy', 'independent', 'animal order']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict fact = ['help person', 'reason with another person', 'dine with other person']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - suppord fact predict = ['dine with other person-capable of', 'reason with another person-capable of', 'help person-capable of']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - correspond target = ['computer', 'person']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - test id = 702, question = Where does the vehicle in the middle of this image can be found in?, img = ILSVRC2012_test_00015539.JPEG\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - real suppord fact in dataset=['train', 'at location', 'station'], real answer = station\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - normal model predict = ['airport', 'mountainous area', 'hotel room', 'runway', 'land plane', 'tourist', 'flight', 'city', 'plane to land on', 'hot room']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict = ['airport', 'runway', 'travel', 'bathroom', 'airplane', 'luggage', 'toilet', 'fly', 'mountainous area', 'hotel room']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict relation = ['at location', 'has a', 'used for', 'is a', 'related to', 'has property', 'part of', 'specific', 'small', 'animal family', 'common', 'long', 'animal order', 'large', 'surface']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict fact = ['airplane', 'hotel', 'airport']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - suppord fact predict = ['airport-used for', 'airport-at location', 'airplane-used for', 'airport-has a', 'airplane-at location', 'hotel-at location']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - correspond target = ['toilet', 'fly', 'airplane', 'bathroom', 'runway', 'luggage', 'airport', 'travel']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - test id = 182, question = which object in this image can we find to be related to surf, img = COCO_val2014_000000004066.jpg\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - real suppord fact in dataset=['surfboard', 'related to', 'surf'], real answer = surfboard\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - normal model predict = ['surfboard', 'wave', 'person', 'surf board', 'raft', 'kite', 'cloud', 'water', 'skiiers', 'snowboard']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict = ['wave', 'whale', 'boat', 'blue', 'dolphin', 'jellyfish', 'swim', 'shell', 'seal', 'coast']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict relation = ['related to', 'belong to', 'specific', 'at location', 'important', 'used for', 'capable of', 'social', 'common', 'part of', 'desires', 'accurate', 'animal order', 'has property', 'visible']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict fact = ['ocean', 'sail', 'sea']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - suppord fact predict = ['sail-related to', 'ocean-at location', 'ocean-part of', 'ocean-used for', 'sea-at location', 'sail-used for', 'ocean-has property']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - correspond target = ['jellyfish', 'blue', 'coast', 'whale', 'wave', 'boat', 'shell', 'swim', 'seal', 'dolphin']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - test id = 2081, question = What is the place in this image used for?, img = COCO_val2014_000000107516.jpg\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - real suppord fact in dataset=['kitchen', 'used for', 'cook food'], real answer = cook food\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - normal model predict = ['cooking', 'sleep', 'sleep away from home', 'prepare food', 'cook food', 'living room', 'sit outside', 'your house', 'eat', 'kitchen']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict = ['sleep', 'sleep away from home', 'house', 'temporary residence', 'couch', 'human', 'furniture', 'wall', 'chair', 'person']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict relation = ['used for', 'at location', 'capable of', 'effective', 'related to', 'receives action', 'belong to', 'good', 'part of', 'specific', 'efficient', 'animal order', 'convenient', 'great', 'popular']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict fact = ['room', 'hotel room', 'dorm room']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - suppord fact predict = ['hotel room-used for', 'room-at location']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - correspond target = ['wall', 'sleep', 'house', 'furniture', 'couch', 'temporary residence', 'chair', 'person', 'sleep away from home', 'human']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - test id = 1150, question = What is the object on the right part of this image used for?, img = COCO_val2014_000000137573.jpg\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - real suppord fact in dataset=['umbrella', 'used for', 'protect person from sun and rain'], real answer = protect person from sun and rain\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - normal model predict = ['sleep away from home', 'entertain yourself on windy day', 'preventing from getting wet', 'protect person from sun and rain', 'sleep', 'space to run and play', 'travel', 'work', 'work for day without water', 'lay on']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict = ['sleep', 'travel', 'work', 'fly', 'bed', 'sleep away from home', 'entertain yourself on windy day', 'preventing from getting wet', 'protect person from sun and rain', 'space to run and play']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict relation = ['used for', 'related to', 'capable of', 'effective', 'belong to', 'good', 'specific', 'has property', 'receives action', 'animal order', 'expensive', 'high', 'efficient', 'part of', 'common']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict fact = ['office', 'bedroom', 'airplane']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - suppord fact predict = ['bedroom-used for', 'office-used for', 'bedroom-capable of', 'airplane-used for', 'bedroom-related to']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - correspond target = ['fly', 'sleep', 'work', 'travel', 'bed']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - test id = 461, question = Which object in this image is capable of eat most types of food?, img = COCO_val2014_000000008401.jpg\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - real suppord fact in dataset=['bear', 'capable of', 'eat most type of food'], real answer = bear\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - normal model predict = ['cat', 'animal', 'dog', 'mammal', 'otter', 'bear', 'elephant', 'monkey', 'rabbit', 'dog poop']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict = ['cat', 'person', 'fork', 'animal', 'dog', 'mammal', 'otter', 'bear', 'elephant', 'monkey']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict relation = ['capable of', 'intelligent', 'high', 'fast', 'stable', 'powerful', 'human', 'active', 'accurate', 'efficient', 'tall', 'primitive', 'has a', 'reliable', 'used for']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - our model predict fact = ['eat food', 'food', 'eat cat food']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - suppord fact predict = ['eat food-used for', 'eat cat food-capable of', 'eat food-capable of']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - correspond target = ['fork', 'cat', 'person']\n",
      "INFO - 08/13/22 23:30:17 - 0:00:35 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6%|██▍                                         | 5/89 [00:03<00:57,  1.45it/s]INFO - 08/13/22 23:30:18 - 0:00:36 - #################################################################################\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - test id = 1658, question = Which object in this image is a type of food?, img = COCO_val2014_000000131841.jpg\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - real suppord fact in dataset=['bread', 'is a', 'type of food'], real answer = bread\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - normal model predict = ['sandwich', 'bread', 'toast bread', 'fry bread', 'bagel', 'doughnut', 'donut', 'hamburger', 'cake', 'fork']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict = ['donut', 'hamburger', 'cake', 'fork', 'pretzel', 'salad', 'pizza', 'fruit', 'apple', 'vegetable']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict relation = ['is a', 'belong to', 'related to', 'has a', 'important', 'at location', 'used for', 'part of', 'capable of', 'good', 'has property', 'specific', 'cool', 'receives action', 'animal class']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict fact = ['food', 'eat food', 'stock food']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - suppord fact predict = ['food-related to', 'food-is a', 'eat food-related to', 'food-belong to', 'eat food-used for']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - correspond target = ['cake', 'apple', 'fruit', 'salad', 'pizza', 'pretzel', 'donut', 'vegetable', 'fork', 'hamburger']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - #################################################################################\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - #################################################################################\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - test id = 2647, question = What musical instrument is the shiny metallic object at the bottom of the image., img = ILSVRC2012_test_00015015.JPEG\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - real suppord fact in dataset=['drum', 'is a', 'music instrument'], real answer = drum\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - normal model predict = ['drum', 'orange', 'apple', 'shirt', 'sunglasses', 'bottle', 'water', 'monitor', 'guitar', 'hand']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict = ['guitar', 'violin', 'harp', 'drum', 'orange', 'apple', 'shirt', 'sunglasses', 'bottle', 'water']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict relation = ['has property', 'is a', 'part of', 'animal class', 'animal order', 'receives action', 'animal kingdom', 'at location', 'animal family', 'related to', 'has a', 'common', 'important', 'small', 'good']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict fact = ['knife', 'musical string instrument', 'string musical instrument']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - suppord fact predict = ['string musical instrument-is a', 'musical string instrument-is a']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - correspond target = ['guitar', 'violin', 'harp']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - #################################################################################\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - #################################################################################\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - test id = 1957, question = Which object in this image can be found in livingroom?, img = COCO_val2014_000000115870.jpg\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - real suppord fact in dataset=['sofa', 'at location', 'livingroom'], real answer = sofa\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - normal model predict = ['couch', 'sofa', 'dining table', 'pillows', 'furniture', 'donut', 'tv', 'bed', 'chair', 'toys']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict = ['pillows', 'furniture', 'tv', 'bed', 'cat', 'sleep', 'lamp', 'bookshelf', 'sleep away from home', 'temporary residence']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict relation = ['at location', 'belong to', 'part of', 'used for', 'has a', 'active', 'capable of', 'specific', 'animal order', 'social', 'animal family', 'visible', 'human', 'related to', 'frequent']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict fact = ['apartment', 'bedroom', 'hotel room']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - suppord fact predict = ['hotel room-used for', 'bedroom-used for', 'bedroom-at location', 'bedroom-capable of', 'bedroom-has a', 'bedroom-related to', 'apartment-at location']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - correspond target = ['cat', 'sleep', 'furniture', 'bookshelf', 'pillows', 'tv', 'lamp', 'temporary residence', 'sleep away from home', 'bed']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - #################################################################################\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - #################################################################################\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - test id = 1928, question = Which object in this image can we use for holding the mush, img = COCO_val2014_000000021435.jpg\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - real suppord fact in dataset=['bowl', 'used for', 'hold mush'], real answer = bowl\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - normal model predict = ['bowl', 'vase', 'basket', 'cup', 'dining table', 'spoon', 'shade table', 'sink', 'box', 'kitchen table']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict = ['cup', 'chair', 'sofa', 'couch', 'person', 'bowl', 'vase', 'basket', 'dining table', 'spoon']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict relation = ['used for', 'related to', 'capable of', 'belong to', 'specific', 'at location', 'easy', 'good', 'accurate', 'effective', 'has property', 'efficient', 'great', 'important', 'common']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict fact = ['hold his breath', 'it', 'hold coffee']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - suppord fact predict = ['hold coffee-capable of', 'hold his breath-capable of', 'hold coffee-used for', 'it-used for', 'it-related to', 'it-belong to']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - correspond target = ['sofa', 'cup', 'couch', 'chair', 'person']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - #################################################################################\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - #################################################################################\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - test id = 763, question = Which object in this image is capable of using tools?, img = ILSVRC2012_test_00027686.JPEG\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - real suppord fact in dataset=['monkey', 'capable of', 'use tool'], real answer = monkey\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - normal model predict = ['monkey', 'elephant', 'tick', 'human', 'animal', 'squirrel', 'zoo', 'rabbit', 'dog', 'lizard']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict = ['scissors', 'chain saw', 'person', 'monkey', 'elephant', 'tick', 'human', 'animal', 'squirrel', 'zoo']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict relation = ['capable of', 'stable', 'high', 'intelligent', 'used for', 'fast', 'reliable', 'efficient', 'powerful', 'tall', 'accurate', 'effective', 'easy', 'is a', 'belong to']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict fact = ['cutting tools', 'make tool', 'build']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - suppord fact predict = ['make tool-capable of', 'cutting tools-belong to']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - correspond target = ['scissors', 'chain saw', 'person']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - #################################################################################\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - #################################################################################\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - test id = 294, question = Which object in this image is a type of food?, img = COCO_val2014_000000131841.jpg\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - real suppord fact in dataset=['bread', 'is a', 'type of food'], real answer = bread\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - normal model predict = ['sandwich', 'bread', 'toast bread', 'fry bread', 'bagel', 'doughnut', 'donut', 'hamburger', 'cake', 'fork']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict = ['donut', 'hamburger', 'cake', 'fork', 'pretzel', 'salad', 'pizza', 'fruit', 'apple', 'vegetable']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict relation = ['is a', 'belong to', 'related to', 'has a', 'important', 'at location', 'used for', 'part of', 'capable of', 'good', 'has property', 'specific', 'cool', 'receives action', 'animal class']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict fact = ['food', 'eat food', 'stock food']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - suppord fact predict = ['food-related to', 'food-is a', 'eat food-related to', 'food-belong to', 'eat food-used for']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - correspond target = ['cake', 'apple', 'fruit', 'salad', 'pizza', 'pretzel', 'donut', 'vegetable', 'fork', 'hamburger']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - #################################################################################\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - #################################################################################\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - test id = 2580, question = Which object in this image is capable of farming carrots?, img = COCO_val2014_000000016382.jpg\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - real suppord fact in dataset=['person', 'capable of', 'farm carrot'], real answer = person\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - normal model predict = ['person', 'hotdog', 'hamburger', 'make person happy', 'pizza', 'sandwich', 'cat', 'burrito', 'any place where person live', 'apple']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict = ['carrot', 'broccoli', 'bell pepper', 'artichoke', 'person', 'hotdog', 'hamburger', 'make person happy', 'pizza', 'sandwich']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict relation = ['capable of', 'stable', 'efficient', 'high', 'intelligent', 'powerful', 'active', 'fast', 'reliable', 'effective', 'is a', 'accurate', 'tall', 'visible', 'transportable']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - our model predict fact = ['vegetable', 'root vegetable', 'cut vegetable']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - suppord fact predict = ['vegetable-is a']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - correspond target = ['bell pepper', 'broccoli', 'artichoke', 'carrot']\n",
      "INFO - 08/13/22 23:30:18 - 0:00:36 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7%|██▉                                         | 6/89 [00:04<00:58,  1.41it/s]INFO - 08/13/22 23:30:19 - 0:00:37 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - test id = 213, question = Which object in this image contains written knowledge?, img = COCO_val2014_000000008708.jpg\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - real suppord fact in dataset=['book', 'has a', 'write knowledge'], real answer = book\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - normal model predict = ['teddy bear', 'sheep', 'rabbit', 'bear', 'dog', 'baby bed', 'bed', 'skunk', 'animal', 'dog poop']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict = ['dog', 'cat', 'kitten', 'ant', 'goldfish', 'person', 'teddy bear', 'sheep', 'rabbit', 'bear']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict relation = ['desires', 'has a', 'belong to', 'has property', 'related to', 'is a', 'specific', 'social', 'used for', 'part of', 'long', 'independent', 'important', 'blind', 'animal order']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict fact = ['pet cat', 'pet', 'cat']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - suppord fact predict = ['pet-is a', 'pet-belong to', 'cat-independent', 'pet-used for', 'pet cat-desires', 'cat-long', 'cat-is a', 'pet-related to', 'cat-belong to']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - correspond target = ['cat', 'dog', 'ant', 'person', 'goldfish', 'kitten']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - test id = 2768, question = What colour is the stuff covering the car?, img = COCO_val2014_000000016931.jpg\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - real suppord fact in dataset=['snow', 'has a', 'white'], real answer = white\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - normal model predict = ['traffic light', 'light', 'car', 'road', 'vehicle', 'pavement', 'truck', 'driving', 'travel in car', 'snow']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict = ['light', 'driving', 'motorcycle', 'bicycle', 'bus', 'two', 'traffic light', 'car', 'road', 'vehicle']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict relation = ['related to', 'belong to', 'is a', 'at location', 'specific', 'animal order', 'receives action', 'animal family', 'has property', 'small', 'has a', 'light', 'used for', 'visible', 'animal kingdom']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict fact = ['car', 'motorcycle', 'automobile']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - suppord fact predict = ['car-light', 'car-visible', 'car-used for', 'automobile-small', 'motorcycle-has a', 'car-small']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - correspond target = ['driving', 'light', 'bus', 'two', 'motorcycle', 'bicycle']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - test id = 2140, question = Which object in this image is used for music, img = ILSVRC2012_test_00000881.JPEG\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - real suppord fact in dataset=['banjo', 'used for', 'music'], real answer = banjo\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - normal model predict = ['guitar', 'wall', 'bicycle', 'chain saw', 'wood', 'banjo', 'clock', 'skateboard', 'metal', 'unicycle']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict = ['scissors', 'cell phone', 'hair', 'guitar', 'wall', 'bicycle', 'chain saw', 'wood', 'banjo', 'clock']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict relation = ['used for', 'related to', 'belong to', 'specific', 'effective', 'accurate', 'easy', 'capable of', 'efficient', 'important', 'common', 'light', 'receives action', 'high', 'has property']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict fact = ['telecommunication', 'follicle', 'sew']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - suppord fact predict = ['follicle-related to', 'telecommunication-related to', 'sew-belong to']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - correspond target = ['hair', 'scissors', 'cell phone']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - test id = 2523, question = Which object in this image has gunports?, img = ILSVRC2012_test_00000149.JPEG\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - real suppord fact in dataset=['gunport', 'related to', 'ship'], real answer = ship\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - normal model predict = ['boat', 'sail boat', 'shore boat', 'bridge', 'store boat', 'cross river', 'river', 'train', 'ride', 'truck']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict = ['guitar', 'camel', 'accordion', 'boat', 'sail boat', 'shore boat', 'bridge', 'store boat', 'cross river', 'river']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict relation = ['related to', 'has a', 'part of', 'has property', 'specific', 'used for', 'social', 'is a', 'common', 'frequent', 'important', 'animal order', 'large', 'long', 'capable of']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict fact = ['bellow', 'hump', 'fretboard']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - suppord fact predict = ['hump-part of', 'fretboard-part of', 'hump-related to', 'bellow-related to']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - correspond target = ['guitar', 'accordion', 'camel']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - test id = 236, question = which object in this image is capable of purchasing an item with cash?, img = COCO_val2014_000000011567.jpg\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - real suppord fact in dataset=['person', 'capable of', 'purchase item use cash'], real answer = person\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - normal model predict = ['person', 'tennis ball', 'tennis racket', 'tennis', 'baseball glove', 'baseball', 'golf ball', 'baseball bat', 'baseball field', 'play tennis']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict = ['computer', 'wine', 'person', 'tennis ball', 'tennis racket', 'tennis', 'baseball glove', 'baseball', 'golf ball', 'baseball bat']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict relation = ['capable of', 'intelligent', 'powerful', 'used for', 'efficient', 'fast', 'stable', 'active', 'visible', 'accurate', 'high', 'reliable', 'effective', 'belong to', 'easy']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict fact = ['pay their salary by company', 'cost lot of money', 'sell']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - suppord fact predict = ['cost lot of money-capable of', 'sell-used for']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - correspond target = ['wine', 'computer']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - test id = 2708, question = What is the object the girl holding used to?, img = COCO_val2014_000000007088.jpg\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - real suppord fact in dataset=['umbrella', 'used for', 'protect person from sun and rain'], real answer = protect person from sun and rain\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - normal model predict = ['cut', 'lay on', 'life preserver', 'knife', 'protect person from sun and rain', 'car', 'fight fire', 'travel in car', 'tie', 'scissors']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict = ['hair', 'human', 'animal', 'banana', 'zoo', 'herd sheep', 'cut', 'lay on', 'life preserver', 'knife']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict relation = ['used for', 'related to', 'is a', 'capable of', 'belong to', 'has property', 'has a', 'at location', 'part of', 'animal order', 'receives action', 'good', 'specific', 'created by', 'important']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict fact = ['dog', \"monkey's hand\", 'monkey']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - suppord fact predict = ['dog-used for', 'dog-good', \"monkey's hand-at location\", 'dog-has a', 'dog-belong to', 'monkey-at location', 'monkey-related to']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - correspond target = ['animal', 'herd sheep', 'zoo', 'banana', 'hair', 'human']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - test id = 2023, question = Which object in this image are dangerous?, img = ILSVRC2012_test_00048011.JPEG\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - real suppord fact in dataset=['axe', 'has property', 'dangerous'], real answer = axe\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - normal model predict = ['hammer', 'scissors', 'screwdriver', 'corkscrew', 'knife', 'wood', 'chain saw', 'ruler', 'metal', 'axe']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict = ['snake', 'clock', 'person', 'flute', 'crutch', 'hammer', 'scissors', 'screwdriver', 'corkscrew', 'knife']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict relation = ['related to', 'used for', 'is a', 'has property', 'capable of', 'has a', 'belong to', 'part of', 'at location', 'specific', 'receives action', 'important', 'dangerous', 'desires', 'common']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict fact = ['be dangerous', 'tick', 'feel pain both physically and emotionally']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - suppord fact predict = ['tick-related to', 'feel pain both physically and emotionally-capable of', 'be dangerous-capable of']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - correspond target = ['clock', 'person', 'crutch', 'flute', 'snake']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - test id = 492, question = Which object in this image has a name that is also a colour?, img = ILSVRC2012_test_00037882.JPEG\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - real suppord fact in dataset=['orange', 'is a', 'color'], real answer = orange\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - normal model predict = ['banana', 'coffee', 'orange', 'apple', 'chocolate', 'lemon', 'strawberry', 'ball', 'fruit', 'palm tree']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict = ['coffee', 'camel', 'giraffe', 'sunglasses', 'banana', 'orange', 'apple', 'chocolate', 'lemon', 'strawberry']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict relation = ['is a', 'has a', 'related to', 'part of', 'used for', 'has property', 'at location', 'belong to', 'cool', 'specific', 'important', 'popular', 'light', 'good', 'common']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - our model predict fact = ['ruminant', 'stimulant', 'physician']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - suppord fact predict = ['ruminant-is a', 'physician-belong to', 'stimulant-belong to']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - correspond target = ['camel', 'giraffe', 'coffee', 'sunglasses']\r\n",
      "INFO - 08/13/22 23:30:19 - 0:00:37 - #################################################################################\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|███▍                                        | 7/89 [00:04<00:58,  1.40it/s]INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - test id = 1998, question = Which object in this image is a subclass of genus homo?, img = COCO_val2014_000000024931.jpg\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - real suppord fact in dataset=['person', 'is a', 'genus homo'], real answer = person\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - normal model predict = ['snake', 'bicycle', 'giraffe', 'mountain', 'zebra', 'horse', 'monkey', 'poisonous', 'lizard', 'hippopotamus']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict = ['monkey', 'fruit', 'bagel', 'snake', 'bicycle', 'giraffe', 'mountain', 'zebra', 'horse', 'poisonous']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict relation = ['is a', 'belong to', 'has a', 'animal phylum', 'receives action', 'tall', 'animal class', 'loud', 'sweet', 'cool', 'animal family', 'has property', 'at location', 'related to', 'big']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict fact = ['confection of jewish ethnic origin', 'fruit morphology', 'primate']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - suppord fact predict = ['primate-is a', 'primate-related to', 'confection of jewish ethnic origin-is a', 'fruit morphology-belong to']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - correspond target = ['monkey', 'bagel', 'fruit']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - test id = 380, question = what is the stuffed animal on the right?, img = COCO_val2014_000000145020.jpg\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - real suppord fact in dataset=['teddy bear', 'is a', 'stuff animal'], real answer = teddy bear\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - normal model predict = ['cut', 'eat', 'hair', 'scissors', 'grass', 'drink', 'car', 'cake', 'cheese', 'white']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict = ['hair', 'giraffidae', 'even toed ungulate', 'long necked', 'zoo', 'animal', 'extremely high blood pressure', 'herd sheep', 'africa', 'chordata']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict relation = ['is a', 'part of', 'related to', 'has a', 'at location', 'animal order', 'receives action', 'capable of', 'has property', 'belong to', 'animal family', 'used for', 'animal class', 'animal kingdom', 'animal phylum']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict fact = ['dog', 'giraffe', 'cow']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - suppord fact predict = ['dog-used for', 'giraffe-animal family', 'giraffe-animal order', 'giraffe-receives action', 'giraffe-animal phylum', 'giraffe-has a', 'dog-has a', 'dog-belong to', 'giraffe-has property', 'giraffe-at location']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - correspond target = ['chordata', 'giraffidae', 'extremely high blood pressure', 'animal', 'herd sheep', 'zoo', 'hair', 'even toed ungulate', 'long necked', 'africa']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - test id = 2280, question = What can be found in this place?, img = COCO_val2014_000000104837.jpg\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - real suppord fact in dataset=['mirror', 'at location', 'bathroom'], real answer = mirror\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - normal model predict = ['toilet', 'thing', 'use toilet', 'toilet seat', 'sound control room', 'toilet paper', 'wash machine', 'house', 'kitchen', 'door']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict = ['toilet', 'thing', 'use toilet', 'toilet seat', 'toilet paper', 'house', 'wash', 'sink', 'furniture', 'wall']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict relation = ['at location', 'used for', 'has a', 'part of', 'related to', 'specific', 'is a', 'good', 'belong to', 'capable of', 'animal order', 'great', 'frequent', 'social', 'receives action']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict fact = ['bathroom', 'room', 'hotel room']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - suppord fact predict = ['bathroom-at location', 'bathroom-has a', 'bathroom-part of', 'room-at location', 'bathroom-used for', 'room-has a']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - correspond target = ['wall', 'toilet', 'thing', 'use toilet', 'toilet paper', 'sink', 'house', 'furniture', 'toilet seat', 'wash']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - test id = 255, question = Which object in this image is faster than men?, img = COCO_val2014_000000020779.jpg\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - real suppord fact in dataset=['horse', 'is a', 'fast than men'], real answer = horse\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - normal model predict = ['horse', 'cow', 'dog', 'handbag', 'camel', 'buy and sell', 'cattle', 'hot dog', 'bicycle', 'cheap']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict = ['dog', 'horse', 'cow', 'handbag', 'camel', 'buy and sell', 'cattle', 'hot dog', 'bicycle', 'cheap']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict relation = ['fast', 'slow', 'easy', 'efficient', 'stable', 'low', 'long', 'comfortable', 'convenient', 'maneuverable', 'reliable', 'intelligent', 'high', 'effective', 'powerful']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict fact = ['woman', 'man', 'fast than men']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - suppord fact predict = ['man-fast']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - correspond target = ['dog']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - test id = 152, question = What types of music does this instrument used to play?, img = ILSVRC2012_test_00027848.JPEG\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - real suppord fact in dataset=['saxophone', 'related to', 'jazz blue'], real answer = jazz blue\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - normal model predict = ['saxophone', 'guitar', 'clarinet', 'trombone', 'flute', 'drum', 'play music', 'music', 'harmonica', 'piano']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict = ['saxophone', 'guitar', 'trombone', 'piano', 'cello', 'trumpet', 'french horn', 'clarinet', 'flute', 'drum']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict relation = ['used for', 'receives action', 'has property', 'is a', 'related to', 'belong to', 'at location', 'has a', 'capable of', 'part of', 'specific', 'desires', 'created by', 'important', 'animal order']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict fact = ['play music', 'bass string instrument use to play classical music', 'use to play jazz']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - suppord fact predict = ['play music-used for', 'bass string instrument use to play classical music-is a', 'use to play jazz-has property']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - correspond target = ['piano', 'french horn', 'cello', 'trumpet', 'guitar', 'trombone', 'saxophone']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - test id = 2106, question = Which object in this image is related to Roma?, img = ILSVRC2012_test_00056044.JPEG\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - real suppord fact in dataset=['rom', 'related to', 'tomato'], real answer = tomato\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - normal model predict = ['cucumber', 'strawberry', 'carrot', 'lemon', 'banana', 'fruit', 'pineapple', 'tomato', 'fig', 'lettuce']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict = ['ray', 'elephant', 'trombone', 'cucumber', 'strawberry', 'carrot', 'lemon', 'banana', 'fruit', 'pineapple']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict relation = ['related to', 'belong to', 'specific', 'important', 'used for', 'common', 'at location', 'has property', 'social', 'animal order', 'part of', 'prevalent', 'good', 'is a', 'accurate']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict fact = ['batoidea', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - suppord fact predict = ['batoidea-belong to', 'therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - correspond target = ['trombone', 'ray', 'elephant']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - test id = 721, question = Which place is more human than the place shown in this image, img = COCO_val2014_000000149444.jpg\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - real suppord fact in dataset=['bakery', 'human', 'most bakery'], real answer = bakery\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - normal model predict = ['fruit', 'donut', 'doughnut', 'bakery', 'cheese', 'pomegranate', 'strawberry', 'chocolate', 'bread', 'vegetable']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict = ['bread', 'cat', 'fruit', 'donut', 'doughnut', 'bakery', 'cheese', 'pomegranate', 'strawberry', 'chocolate']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict relation = ['important', 'at location', 'common', 'strenuous', 'prevalent', 'dangerous', 'used for', 'popular', 'good', 'easy', 'is a', 'belong to', 'specific', 'safe', 'related to']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict fact = ['this dog', \"catlover's home\", 'truth']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - suppord fact predict = [\"catlover's home-at location\", 'truth-important']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - correspond target = ['bread', 'cat']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - test id = 671, question = which object in this image  often occurs in the crossroad, img = COCO_val2014_000000128939.jpg\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - real suppord fact in dataset=['traffic light', 'at location', 'crossroad'], real answer = traffic light\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - normal model predict = ['car', 'travel in car', 'truck', 'train', 'eat', 'fruit', 'food', 'taxi', 'cat', 'drink']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict = ['car', 'person', 'computer', 'desk', 'travel in car', 'truck', 'train', 'eat', 'fruit', 'food']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict relation = ['belong to', 'used for', 'at location', 'has a', 'has property', 'capable of', 'related to', 'desires', 'is a', 'part of', 'specific', 'blind', 'receives action', 'animal order', 'important']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict fact = ['study archeology', 'study', 'seatbelt in them']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - suppord fact predict = ['seatbelt in them-has a', 'study archeology-capable of', 'study-used for']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - correspond target = ['person', 'car', 'computer', 'desk']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - test id = 17, question = What is the vehicle in the water?, img = COCO_val2014_000000101088.jpg\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - real suppord fact in dataset=['airplane', 'is a', 'vehicle'], real answer = airplane\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - normal model predict = ['water', 'cloud', 'sea', 'boat', 'shore boat', 'ocean', 'sand', 'lake', 'fish', 'beach']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict = ['cloud', 'lake', 'fish', 'jellyfish', 'river', 'whale', 'person', 'water', 'sea', 'boat']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict relation = ['used for', 'belong to', 'capable of', 'good', 'at location', 'receives action', 'has property', 'animal order', 'related to', 'fast', 'stable', 'has a', 'is a', 'animal class', 'light']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict fact = ['in water', 'water', 'swim in water']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - suppord fact predict = ['swim in water-capable of', 'water-belong to', 'in water-at location', 'water-at location', 'water-has a']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - correspond target = ['jellyfish', 'river', 'whale', 'lake', 'person', 'cloud', 'fish']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - test id = 1943, question = What is the class of the animal in this image?, img = COCO_val2014_000000149832.jpg\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - real suppord fact in dataset=['cattle', 'animal class', 'mammal'], real answer = mammal\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - normal model predict = ['cow', 'horse', 'dog', 'camel', 'sheep', 'herd sheep', 'animal', 'grass', 'human', 'cattle']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict = ['horse', 'animal', 'grass', 'giraffidae', 'even toed ungulate', 'zoo', 'africa', 'extremely high blood pressure', 'stripe', 'long necked']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict relation = ['animal family', 'animal class', 'has property', 'is a', 'animal order', 'animal kingdom', 'at location', 'animal phylum', 'used for', 'safe', 'has a', 'common', 'related to', 'part of', 'green']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - our model predict fact = ['zebra', 'sheep', 'giraffe']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - suppord fact predict = ['giraffe-animal family', 'sheep-animal order', 'giraffe-animal order', 'zebra-is a', 'giraffe-has a', 'zebra-has a', 'zebra-animal kingdom', 'giraffe-has property', 'sheep-related to', 'giraffe-at location', 'zebra-at location']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - correspond target = ['giraffidae', 'grass', 'extremely high blood pressure', 'animal', 'horse', 'stripe', 'zoo', 'even toed ungulate', 'long necked', 'africa']\n",
      "INFO - 08/13/22 23:30:19 - 0:00:38 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9%|███▉                                        | 8/89 [00:05<00:56,  1.43it/s]INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - test id = 263, question = What rain protection tool is used in the image?, img = COCO_val2014_000000007394.jpg\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - real suppord fact in dataset=['umbrella', 'is a', 'rain protection'], real answer = umbrella\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - normal model predict = ['surfboard', 'beach', 'grass', 'sand', 'kite', 'rain', 'surf board', 'park', 'palm tree', 'protect person from sun and rain']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict = ['surfboard', 'skateboard', 'snowboard', 'boat', 'ship', 'beach', 'grass', 'sand', 'kite', 'rain']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict relation = ['belong to', 'is a', 'has property', 'related to', 'has a', 'easy', 'important', 'safe', 'small', 'fast', 'stable', 'receives action', 'strong', 'visible', 'long']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict fact = ['water sports equipment', 'watercraft', 'boardsports']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - suppord fact predict = ['watercraft-related to', 'water sports equipment-belong to', 'watercraft-belong to', 'boardsports-belong to']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - correspond target = ['ship', 'boat', 'skateboard', 'surfboard', 'snowboard']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - test id = 2513, question = Which object in the image is often associated with Jazz music?, img = ILSVRC2012_test_00004214.JPEG\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - real suppord fact in dataset=['trumpet', 'belong to', 'jazz'], real answer = trumpet\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - normal model predict = ['trumpet', 'trombone', 'saxophone', 'clarinet', 'flute', 'french horn', 'accordion', 'harmonica', 'cello', 'violin']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict = ['trombone', 'saxophone', 'violin', 'trumpet', 'clarinet', 'flute', 'french horn', 'accordion', 'harmonica', 'cello']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict relation = ['has property', 'is a', 'has a', 'receives action', 'used for', 'at location', 'related to', 'protected', 'animal class', 'created by', 'common', 'part of', 'belong to', 'solar', 'popular']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict fact = ['use in jazz music', 'use in classical music', 'make music in jazz band']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - suppord fact predict = ['make music in jazz band-used for', 'use in jazz music-has property', 'use in classical music-has property']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - correspond target = ['trombone', 'violin', 'saxophone']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - test id = 714, question = what thing is less aggressive than wasp in this image?, img = ILSVRC2012_test_00000177.JPEG\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - real suppord fact in dataset=['bee', 'aggressive', 'wasp'], real answer = bee\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - normal model predict = ['goldfish', 'strawberry', 'human', 'animal', 'fruit', 'donut', 'chocolate', 'orange', 'cake', 'flowers']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict = ['apartment', 'goldfish', 'strawberry', 'human', 'animal', 'fruit', 'donut', 'chocolate', 'orange', 'cake']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict relation = ['good', 'safe', 'expensive', 'tough', 'fast', 'efficient', 'easy', 'comfortable', 'cheap', 'strong', 'reliable', 'stable', 'high', 'effective', 'popular']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict fact = ['this dog', 'drunk by person', 'dorm room']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - suppord fact predict = ['dorm room-cheap']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - correspond target = ['apartment']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - test id = 147, question = Which thing in this image is edible?, img = ILSVRC2012_test_00055836.JPEG\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - real suppord fact in dataset=['apple', 'has property', 'edible by human'], real answer = apple\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - normal model predict = ['refrigerator', 'microwave', 'tv', 'fridge', 'apple', 'kitchen utensil', 'ipod', 'wine', 'dishwasher', 'oven']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict = ['strawberry', 'fruit', 'pomegranate', 'vegetable', 'banana', 'broccoli', 'carrot', 'refrigerator', 'microwave', 'tv']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict relation = ['has property', 'used for', 'related to', 'belong to', 'is a', 'has a', 'at location', 'capable of', 'created by', 'specific', 'part of', 'common', 'receives action', 'cool', 'good']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict fact = ['edible plants', 'edible fruit', 'very nutritious']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - suppord fact predict = ['very nutritious-has property', 'edible plants-belong to', 'edible fruit-is a']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - correspond target = ['strawberry', 'pomegranate', 'banana', 'broccoli', 'carrot', 'vegetable', 'fruit']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - test id = 1057, question = Which object is the most related to crab, img = ILSVRC2012_test_00042670.JPEG\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - real suppord fact in dataset=['lobster', 'related to', 'crab'], real answer = lobster\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - normal model predict = ['lobster', 'snake', 'fish', 'turtle', 'bird', 'wine glass', 'frog', 'wine', 'vase', 'lizard']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict = ['elephant', 'ray', 'trombone', 'lobster', 'snake', 'fish', 'turtle', 'bird', 'wine glass', 'frog']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict relation = ['related to', 'used for', 'specific', 'belong to', 'important', 'is a', 'common', 'has property', 'at location', 'part of', 'has a', 'capable of', 'animal order', 'accurate', 'social']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict fact = ['batoidea', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - suppord fact predict = ['batoidea-belong to', 'therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - correspond target = ['trombone', 'ray', 'elephant']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - test id = 1632, question = What light sources are on the table?, img = COCO_val2014_000000104747.jpg\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - real suppord fact in dataset=['candles', 'belong to', 'light source'], real answer = candles\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - normal model predict = ['dining table', 'chair', 'kitchen table', 'wine glass', 'plate', 'glass', 'desk', 'sink', 'bowl', 'wine']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict = ['wine glass', 'plate', 'glass', 'kitchen', 'sunglasses', 'dining table', 'chair', 'kitchen table', 'desk', 'sink']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict relation = ['related to', 'has a', 'used for', 'belong to', 'capable of', 'is a', 'at location', 'part of', 'receives action', 'has property', 'animal order', 'specific', 'good', 'important', 'common']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict fact = ['dining table', 'serving and dining', 'glass']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - suppord fact predict = ['dining table-is a', 'serving and dining-belong to', 'glass-belong to', 'glass-related to']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - correspond target = ['kitchen', 'wine glass', 'plate', 'glass', 'sunglasses']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - test id = 1954, question = What shown here is related to botany?, img = COCO_val2014_000000149371.jpg\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - real suppord fact in dataset=['botany', 'related to', 'plant'], real answer = plant\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - normal model predict = ['tree', 'grass', 'wood', 'fire hydrant', 'cut', 'lay on', 'water', 'plant', 'sit down on', 'pavement']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict = ['butterfly', 'luggage', 'trombone', 'tree', 'grass', 'wood', 'fire hydrant', 'cut', 'lay on', 'water']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict relation = ['related to', 'belong to', 'specific', 'used for', 'important', 'at location', 'animal order', 'common', 'capable of', 'accurate', 'part of', 'is a', 'social', 'has property', 'good']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict fact = ['flutterby', 'bellhop', 'tromboner']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - suppord fact predict = ['flutterby-related to', 'bellhop-related to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - correspond target = ['luggage', 'trombone', 'butterfly']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - test id = 317, question = what is the skatboarder in this image doing?, img = COCO_val2014_000000008589.jpg\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - real suppord fact in dataset=['skateboard', 'related to', 'skateboard'], real answer = skateboard\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - normal model predict = ['car', 'skateboard', 'ski slope', 'bicycle', 'grass', 'mountain', 'ski', 'dumbbell', 'snowboard', 'dog']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict = ['dog', 'motorcycle', 'car', 'skateboard', 'ski slope', 'bicycle', 'grass', 'mountain', 'ski', 'dumbbell']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict relation = ['related to', 'is a', 'belong to', 'used for', 'capable of', 'has property', 'fast', 'has a', 'important', 'common', 'specific', 'easy', 'at location', 'animal order', 'good']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict fact = ['man', 'traffic', 'follow it master']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - suppord fact predict = ['man-fast', 'traffic-fast', 'follow it master-capable of']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - correspond target = ['motorcycle', 'dog']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - test id = 1850, question = which object in this image can we always buy in the supermarket, img = ILSVRC2012_test_00047632.JPEG\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - real suppord fact in dataset=['pineapple', 'at location', 'supermarket'], real answer = pineapple\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - normal model predict = ['fruit', 'pineapple', 'fig', 'banana', 'carrot', 'tomato', 'salad', 'strawberry', 'orange', 'vegetable']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict = ['person', 'beaker', 'toilet', 'fruit', 'pineapple', 'fig', 'banana', 'carrot', 'tomato', 'salad']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict relation = ['at location', 'belong to', 'related to', 'used for', 'capable of', 'specific', 'animal order', 'visible', 'desires', 'has a', 'important', 'is a', 'has property', 'blind', 'human']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict fact = ['deposit human waste', 'study archeology', 'laboratory']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - suppord fact predict = ['study archeology-capable of', 'deposit human waste-used for', 'laboratory-at location']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - correspond target = ['beaker', 'toilet', 'person']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - test id = 198, question = Which object in this image is grown in hawaii, img = ILSVRC2012_test_00059970.JPEG\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - real suppord fact in dataset=['pineapple', 'receives action', 'grow in hawaii'], real answer = pineapple\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - normal model predict = ['banana', 'lemon', 'strawberry', 'orange', 'fruit', 'chocolate', 'pineapple', 'green', 'cake', 'sweet and juicy']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict = ['banana', 'snake', 'lemon', 'strawberry', 'orange', 'fruit', 'chocolate', 'pineapple', 'green', 'cake']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict relation = ['has property', 'is a', 'part of', 'green', 'used for', 'at location', 'has a', 'receives action', 'good', 'popular', 'red', 'related to', 'important', 'created by', 'cool']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict fact = ['live in', 'rich in potassium', 'grow in knowledge']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - suppord fact predict = ['rich in potassium-has property', 'live in-used for']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - correspond target = ['banana', 'snake']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - test id = 191, question = Which object in this image is related to  cream?, img = COCO_val2014_000000003926.jpg\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - real suppord fact in dataset=['sheep', 'related to', 'woolly'], real answer = sheep\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - normal model predict = ['sheep', 'cheese', 'bread', 'mustard', 'chocolate', 'flour', 'teddy bear', 'herd sheep', 'bear', 'toast bread']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict = ['cheese', 'person', 'sheep', 'bread', 'mustard', 'chocolate', 'flour', 'teddy bear', 'herd sheep', 'bear']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict relation = ['related to', 'belong to', 'specific', 'important', 'used for', 'part of', 'at location', 'common', 'animal order', 'social', 'capable of', 'has property', 'accurate', 'prevalent', 'is a']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - our model predict fact = ['milk', 'taste ice cream', 'yogurt']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - suppord fact predict = ['milk-related to', 'yogurt-related to', 'taste ice cream-capable of']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - correspond target = ['cheese', 'person']\n",
      "INFO - 08/13/22 23:30:20 - 0:00:38 - #################################################################################\n",
      " 10%|████▍                                       | 9/89 [00:06<00:55,  1.44it/s]INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - test id = 2779, question = Which object in this image can soar?, img = COCO_val2014_000000114634.jpg\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - real suppord fact in dataset=['kite', 'related to', 'oar'], real answer = kite\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - normal model predict = ['kite', 'person', 'airplane', 'beach', 'plane', 'make person happy', 'butterfly', 'surf board', 'bird', 'clock']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict = ['hammer', 'mouth', 'axe', 'kite', 'person', 'airplane', 'beach', 'plane', 'make person happy', 'butterfly']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict relation = ['capable of', 'has a', 'part of', 'at location', 'is a', 'used for', 'related to', 'has property', 'visible', 'surface', 'active', 'belong to', 'long', 'stable', 'high']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict fact = ['laugh', 'feel joy', 'hurt person']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - suppord fact predict = ['hurt person-capable of', 'laugh-related to', 'hurt person-used for']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - correspond target = ['axe', 'mouth', 'hammer']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - test id = 658, question = Which object in this image is used to carry your things while travelling?, img = COCO_val2014_000000112022.jpg\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - real suppord fact in dataset=['luggage', 'used for', 'carry your thing while travel'], real answer = luggage\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - normal model predict = ['person', 'helmet', 'luggage', 'transport person', 'camera', 'backpack', 'microphone', 'make person happy', 'hat', 'car']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict = ['computer', 'dog', 'person', 'helmet', 'luggage', 'transport person', 'camera', 'backpack', 'microphone', 'make person happy']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict relation = ['used for', 'effective', 'efficient', 'easy', 'convenient', 'hot', 'popular', 'fast', 'expensive', 'flexible', 'accurate', 'capable of', 'transportable', 'warm', 'good']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict fact = ['make human life easy', 'help person', 'come to it master']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - suppord fact predict = ['make human life easy-used for', 'come to it master-capable of', 'help person-capable of']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - correspond target = ['computer', 'dog']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - test id = 425, question = Which object in this image might need a tuner?, img = ILSVRC2012_test_00022418.JPEG\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - real suppord fact in dataset=['tuner', 'related to', 'piano'], real answer = piano\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - normal model predict = ['person', 'cello', 'bus', 'violin', 'piano', 'transport person', 'canvas', 'boat', 'taxi', 'guitar']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict = ['violin', 'guitar', 'dog', 'person', 'cello', 'bus', 'piano', 'transport person', 'canvas', 'boat']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict relation = ['related to', 'capable of', 'has a', 'part of', 'specific', 'used for', 'important', 'is a', 'blind', 'frequent', 'desires', 'common', 'high', 'animal order', 'social']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict fact = ['violinist', 'luthier', 'follow it master']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - suppord fact predict = ['luthier-related to', 'violinist-related to', 'follow it master-capable of']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - correspond target = ['guitar', 'violin', 'dog']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - test id = 2054, question = Which sour yellow fruit is shown in this image?, img = ILSVRC2012_test_00002559.JPEG\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - real suppord fact in dataset=['lemon', 'is a', 'sour yellow fruit'], real answer = lemon\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - normal model predict = ['pineapple', 'bottle', 'banana', 'tomato', 'lipstick', 'salad', 'cake', 'wine', 'lemon', 'fruit']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict = ['banana', 'apple', 'strawberry', 'pineapple', 'bottle', 'tomato', 'lipstick', 'salad', 'cake', 'wine']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict relation = ['is a', 'related to', 'part of', 'has a', 'created by', 'small', 'has property', 'common', 'important', 'long', 'green', 'specific', 'sweet', 'acidic', 'popular']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict fact = ['sweet red fruit', 'red fruit', 'sweet yellow fruit']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - suppord fact predict = ['red fruit-related to', 'sweet red fruit-is a', 'sweet yellow fruit-is a']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - correspond target = ['banana', 'apple', 'strawberry']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - test id = 548, question = Which object in this image is related to a pointer?, img = COCO_val2014_000000150320.jpg\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - real suppord fact in dataset=['point', 'related to', 'mouse'], real answer = mouse\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - normal model predict = ['keyboard', 'mouse', 'desk', 'computer', 'hand', 'button', 'ram', 'metronome', 'pen', 'laptop']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict = ['keyboard', 'monitor', 'person', 'mouse', 'desk', 'computer', 'hand', 'button', 'ram', 'metronome']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict relation = ['related to', 'specific', 'used for', 'important', 'part of', 'belong to', 'common', 'social', 'is a', 'prevalent', 'accurate', 'capable of', 'animal order', 'has a', 'at location']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict fact = ['output', 'input data', 'number object']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - suppord fact predict = ['output-belong to', 'number object-capable of', 'output-related to', 'input data-used for']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - correspond target = ['keyboard', 'monitor', 'person']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - test id = 1702, question = Which object in this image is like a small plantain?, img = ILSVRC2012_test_00036186.JPEG\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - real suppord fact in dataset=['plantain', 'large', 'banana'], real answer = banana\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - normal model predict = ['banana', 'fruit', 'strawberry', 'basket', 'pineapple', 'potted plant', 'flower', 'flowers', 'chocolate', 'vegetable']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict = ['butterfly', 'sofa', 'kitchenette', 'banana', 'fruit', 'strawberry', 'basket', 'pineapple', 'potted plant', 'flower']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict relation = ['is a', 'related to', 'has property', 'has a', 'belong to', 'used for', 'part of', 'sweet', 'red', 'created by', 'at location', 'popular', 'important', 'common', 'good']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict fact = ['usually small', 'small than bird', 'large than chair']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - suppord fact predict = ['large than chair-is a', 'usually small-has property', 'small than bird-is a']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - correspond target = ['kitchenette', 'sofa', 'butterfly']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - test id = 1334, question = What does the object in the right of this image have as a part?, img = ILSVRC2012_test_00000138.JPEG\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - real suppord fact in dataset=['nail', 'has a', 'shell'], real answer = shell\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - normal model predict = ['shell', 'string', 'string attach', 'white', 'green', 'blue', 'cloud', 'small', 'peel', 'beach']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict = ['poisonous', 'banana', 'warm place', 'desert', 'no leg', 'racquet', 'zoo', 'fence', 'shell', 'string']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict relation = ['has a', 'part of', 'related to', 'at location', 'has property', 'capable of', 'social', 'is a', 'specific', 'animal family', 'receives action', 'created by', 'large', 'animal order', 'small']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict fact = ['snake', 'monkey', 'wire']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - suppord fact predict = ['snake-has property', 'snake-at location', 'wire-related to', 'monkey-at location', 'snake-has a', 'monkey-related to']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - correspond target = ['desert', 'fence', 'no leg', 'zoo', 'warm place', 'banana', 'racquet', 'poisonous']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - test id = 683, question = What kind of media is shown in this image ?, img = COCO_val2014_000000146487.jpg\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - real suppord fact in dataset=['tv', 'is a', 'medium'], real answer = tv\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - normal model predict = ['bedroom', 'couch', 'sofa', 'bed', 'monitor', 'furniture', 'pillows', 'bathroom', 'wall', 'apartment']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict = ['couch', 'furniture', 'wall', 'house', 'chair', 'lamp', 'park space', 'human', 'person', 'bedroom']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict relation = ['is a', 'belong to', 'related to', 'used for', 'has a', 'good', 'at location', 'part of', 'fast', 'animal order', 'capable of', 'important', 'easy', 'receives action', 'common']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict fact = ['room', 'dorm room', 'light room']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - suppord fact predict = ['room-at location', 'room-important', 'room-has a', 'light room-used for']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - correspond target = ['wall', 'house', 'furniture', 'couch', 'park space', 'lamp', 'chair', 'person', 'human']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - test id = 2532, question = What is the entertainment in the image?, img = COCO_val2014_000000145815.jpg\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - real suppord fact in dataset=['frisbee', 'belong to', 'entertainment'], real answer = frisbee\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - normal model predict = ['ski', 'ski slope', 'mountain', 'dog', 'snowboard', 'snow', 'desert', 'cat', 'snowmobile', 'carnivora']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict = ['dog', 'snow', 'cat', 'zoo', 'cow', 'sheep', 'whale', 'camel', 'tree', 'child']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict relation = ['belong to', 'is a', 'related to', 'has property', 'has a', 'part of', 'at location', 'animal class', 'animal order', 'important', 'animal family', 'animal kingdom', 'common', 'used for', 'specific']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict fact = ['mountain', 'mammal', 'marine mammal']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - suppord fact predict = ['mammal-has property', 'marine mammal-belong to', 'mountain-has a', 'mammal-animal class', 'mammal-at location', 'mammal-is a', 'mountain-at location', 'mammal-related to', 'marine mammal-is a', 'mammal-belong to']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - correspond target = ['snow', 'tree', 'cat', 'child', 'dog', 'whale', 'camel', 'zoo', 'sheep', 'cow']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - test id = 2510, question = Which animal in this image is slow?, img = ILSVRC2012_test_00001734.JPEG\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - real suppord fact in dataset=['nail', 'has property', 'low'], real answer = nail\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - normal model predict = ['turtle', 'lizard', 'frog', 'giraffe', 'ant', 'armadillo', 'zebra', 'butterfly', 'elephant', 'monkey']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict = ['turtle', 'dog', 'person', 'lizard', 'frog', 'giraffe', 'ant', 'armadillo', 'zebra', 'butterfly']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict relation = ['related to', 'has property', 'belong to', 'capable of', 'is a', 'part of', 'important', 'specific', 'has a', 'visible', 'protected', 'accurate', 'created by', 'receives action', 'social']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - our model predict fact = ['slow mover', 'move very fast or very slow', 'sleep long time']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - suppord fact predict = ['slow mover-is a', 'slow mover-related to', 'move very fast or very slow-capable of', 'sleep long time-capable of']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - correspond target = ['turtle', 'person', 'dog']\n",
      "INFO - 08/13/22 23:30:21 - 0:00:39 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11%|████▊                                      | 10/89 [00:07<01:01,  1.29it/s]INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - test id = 190, question = Which animal in this image is related to lambskin?, img = COCO_val2014_000000003926.jpg\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - real suppord fact in dataset=['lambkin', 'related to', 'sheep'], real answer = sheep\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - normal model predict = ['sheep', 'herd sheep', 'rabbit', 'cattle', 'mustard', 'otter', 'teddy bear', 'cow', 'ant', 'lettuce']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict = ['carrot', 'grass', 'banana', 'even toed ungulate', 'zoo', 'lamp', 'sheep', 'herd sheep', 'rabbit', 'cattle']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict relation = ['related to', 'belong to', 'specific', 'important', 'used for', 'common', 'part of', 'at location', 'social', 'animal order', 'is a', 'accurate', 'capable of', 'prevalent', 'has property']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict fact = ['monkey', 'sheep', 'rabbit']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - suppord fact predict = ['sheep-animal order', 'rabbit-related to', 'sheep-related to', 'monkey-at location', 'monkey-related to']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - correspond target = ['grass', 'zoo', 'banana', 'even toed ungulate', 'lamp', 'carrot']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - test id = 1995, question = What fruit can be seen in this image?, img = COCO_val2014_000000003817.jpg\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - real suppord fact in dataset=['banana', 'belong to', 'fruit'], real answer = banana\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - normal model predict = ['vegetable', 'fruit', 'pineapple', 'tomato', 'lemon', 'banana', 'flowers', 'broccoli', 'flower', 'strawberry']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict = ['tomato', 'orange', 'basket', 'vegetable', 'fruit', 'pineapple', 'lemon', 'banana', 'flowers', 'broccoli']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict relation = ['is a', 'belong to', 'has a', 'at location', 'related to', 'capable of', 'has property', 'small', 'created by', 'part of', 'used for', 'popular', 'visible', 'common', 'tall']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict fact = ['use to hold fruit', 'fruit but person call it vegetable', 'round citus fruit that be also colour']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - suppord fact predict = ['use to hold fruit-has property', 'fruit but person call it vegetable-is a', 'round citus fruit that be also colour-is a']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - correspond target = ['orange', 'basket', 'tomato']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - test id = 2656, question = which object in this image often moves slower than train, img = COCO_val2014_000000110330.jpg\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - real suppord fact in dataset=['train', 'fast', 'bus'], real answer = bus\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - normal model predict = ['bus', 'train', 'cheap', 'truck', 'taxi', 'train station', 'car', 'transport', 'stop sign', 'cat']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict = ['computer', 'cow', 'dog', 'bear', 'bus', 'train', 'cheap', 'truck', 'taxi', 'train station']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict relation = ['fast', 'slow', 'easy', 'long', 'low', 'big', 'good', 'frequent', 'fat', 'soft', 'high', 'blind', 'light', 'efficient', 'weak']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict fact = ['human', 'kill human', 'hurt']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - suppord fact predict = ['human-fast', 'human-big', 'human-good', 'human-long']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - correspond target = ['bear', 'cow', 'computer', 'dog']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - test id = 1458, question = which object in this picture can smell, img = ILSVRC2012_test_00051302.JPEG\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - real suppord fact in dataset=['person', 'capable of', 'smell'], real answer = person\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - normal model predict = ['guitar', 'person', 'dog', 'car', 'cat', 'cake', 'transport person', 'make person happy', 'hair', 'happy for bride and groom']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict = ['cat', 'mouse', 'guitar', 'person', 'dog', 'car', 'cake', 'transport person', 'make person happy', 'hair']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict relation = ['capable of', 'has a', 'has property', 'used for', 'is a', 'related to', 'desires', 'long', 'fast', 'belong to', 'visible', 'at location', 'high', 'blind', 'easy']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict fact = ['purr', 'meow', 'click fraud']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - suppord fact predict = ['purr-capable of', 'meow-capable of', 'click fraud-related to']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - correspond target = ['cat', 'mouse']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - test id = 1698, question = Which object in this image belongs to the class fragaria?, img = ILSVRC2012_test_00023364.JPEG\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - real suppord fact in dataset=['strawberry', 'belong to', 'fragaria'], real answer = strawberry\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - normal model predict = ['strawberry', 'pomegranate', 'fruit', 'fig', 'chocolate', 'cake', 'donut', 'doughnut', 'flowers', 'orange']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict = ['kite', 'person', 'horse', 'strawberry', 'pomegranate', 'fruit', 'fig', 'chocolate', 'cake', 'donut']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict relation = ['belong to', 'is a', 'desires', 'related to', 'loyal', 'animal kingdom', 'sensible', 'trustworthy', 'animal order', 'has a', 'at location', 'important', 'animal phylum', 'capable of', 'animal class']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict fact = ['study archeology', \"child's hand\", \"man's second best friend\"]\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - suppord fact predict = [\"child's hand-at location\", \"man's second best friend-is a\", 'study archeology-capable of']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - correspond target = ['kite', 'person', 'horse']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - test id = 145, question = Where can people find a dining table, img = ILSVRC2012_test_00001283.JPEG\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - real suppord fact in dataset=['dining table', 'is a', 'kitchen'], real answer = kitchen\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - normal model predict = ['chair', 'furniture', 'kitchen table', 'dining table', 'sofa', 'bedroom', 'bed', 'house', 'baby bed', 'kitchen']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict = ['chair', 'furniture', 'kitchen table', 'house', 'couch', 'kitchen utensil', 'oven', 'toilet paper', 'cup', 'restaurant']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict relation = ['at location', 'belong to', 'used for', 'related to', 'is a', 'has a', 'capable of', 'part of', 'specific', 'visible', 'has property', 'surface', 'animal order', 'desires', 'blind']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict fact = ['restaurant kitchen', 'kitchen', 'room']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - suppord fact predict = ['room-at location', 'kitchen-at location', 'restaurant kitchen-at location', 'kitchen-belong to']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - correspond target = ['kitchen table', 'kitchen utensil', 'oven', 'toilet paper', 'house', 'restaurant', 'furniture', 'cup', 'couch', 'chair']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - test id = 855, question = What is the place in this image used for?, img = COCO_val2014_000000011727.jpg\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - real suppord fact in dataset=['bathroom', 'used for', 'clean your tooth in'], real answer = clean your tooth in\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - normal model predict = ['pee', 'wash', 'swim', 'sleep', 'preventing from getting wet', 'laundromat', 'sleep away from home', 'toilet', 'cold and wet', 'sink']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict = ['pee', 'wash', 'cooking', 'prepare food', 'hotel room', 'breakfast', 'house', 'plunger', 'swim', 'sleep']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict relation = ['used for', 'belong to', 'capable of', 'related to', 'effective', 'good', 'receives action', 'part of', 'great', 'specific', 'easy', 'at location', 'popular', 'important', 'animal order']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict fact = ['kitchenette', 'shower', 'toilet']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - suppord fact predict = ['toilet-used for', 'kitchenette-used for', 'kitchenette-at location', 'shower-used for']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - correspond target = ['prepare food', 'house', 'hotel room', 'plunger', 'cooking', 'pee', 'wash', 'breakfast']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - test id = 2483, question = What kind of field do you need to play this game?, img = COCO_val2014_000000101985.jpg\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - real suppord fact in dataset=['soccer field', 'has a', 'grass'], real answer = grass\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - normal model predict = ['soccer ball', 'racquet', 'golf ball', 'baseball bat', 'tennis ball', 'baseball', 'volleyball', 'frisbee', 'rugby ball', 'ball']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict = ['racquet', 'tennis ball', 'baseball', 'volleyball', 'racket', 'person', 'kite', 'laptop', 'dog', 'soccer ball']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict relation = ['belong to', 'capable of', 'used for', 'related to', 'is a', 'desires', 'at location', 'has property', 'easy', 'important', 'part of', 'fast', 'specific', 'good', 'convenient']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict fact = ['ball games', 'play outside', 'play game']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - suppord fact predict = ['play game-capable of', 'play game-used for', 'play outside-capable of', 'play outside-has property', 'play game-desires', 'ball games-belong to']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - correspond target = ['racquet', 'dog', 'laptop', 'person', 'volleyball', 'racket', 'kite', 'tennis ball', 'baseball']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - test id = 1807, question = which object often parks on the street, img = COCO_val2014_000000107990.jpg\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - real suppord fact in dataset=['motorcycle', 'at location', 'street'], real answer = motorcycle\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - normal model predict = ['motorcycle', 'car', 'motorbike', 'bicycle', 'vehicle', 'truck', 'snowmobile', 'travel in car', 'helmet', 'taxi']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict = ['boat', 'horse', 'wall', 'motorcycle', 'car', 'motorbike', 'bicycle', 'vehicle', 'truck', 'snowmobile']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict relation = ['used for', 'has property', 'has a', 'is a', 'related to', 'at location', 'belong to', 'capable of', 'part of', 'blind', 'specific', 'common', 'surface', 'receives action', 'created by']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict fact = ['paint on them', 'on water', 'ride on']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - suppord fact predict = ['ride on-used for', 'on water-related to', 'on water-is a', 'paint on them-has a']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - correspond target = ['wall', 'boat', 'horse']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - test id = 1870, question = What the toy in the image is attached on?, img = COCO_val2014_000000104841.jpg\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - real suppord fact in dataset=['kite', 'related to', 'string attach'], real answer = string attach\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - normal model predict = ['throw', 'soccer ball', 'rugby ball', 'play baseball on it', 'grass', 'frisbee', 'ball', 'bench', 'tennis ball', 'golf ball']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict = ['camel', 'sofa', 'seal', 'throw', 'soccer ball', 'rugby ball', 'play baseball on it', 'grass', 'frisbee', 'ball']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict relation = ['is a', 'at location', 'related to', 'capable of', 'belong to', 'used for', 'part of', 'has a', 'animal family', 'receives action', 'has property', 'animal order', 'specific', 'good', 'important']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict fact = ['caravan', 'lie on', 'position itsself on rock']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - suppord fact predict = ['lie on-used for', 'position itsself on rock-capable of', 'caravan-related to']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - correspond target = ['seal', 'camel', 'sofa']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - test id = 52, question = Which kind of sport in this image comes from North America?, img = COCO_val2014_000000104417.jpg\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - real suppord fact in dataset=['baseball', 'is a', 'american sport'], real answer = baseball\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - normal model predict = ['baseball', 'baseball bat', 'play baseball', 'baseball glove', 'tennis racket', 'basketball', 'racket', 'chess board', 'baseball field', 'frisbee']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict = ['donut', 'giraffe', 'hot dog', 'baseball', 'baseball bat', 'play baseball', 'baseball glove', 'tennis racket', 'basketball', 'racket']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict relation = ['has property', 'is a', 'belong to', 'at location', 'protected', 'dangerous', 'safe', 'strenuous', 'popular', 'important', 'related to', 'impassable', 'part of', 'capable of', 'cool']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - our model predict fact = ['native to africa', 'north american culture', 'regions of africa']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - suppord fact predict = ['north american culture-belong to', 'regions of africa-belong to', 'native to africa-has property']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - correspond target = ['hot dog', 'giraffe', 'donut']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:40 - #################################################################################\n",
      " 12%|█████▎                                     | 11/89 [00:07<00:58,  1.32it/s]INFO - 08/13/22 23:30:22 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - test id = 1769, question = Which object in this image is like a hand-held piano, img = ILSVRC2012_test_00040602.JPEG\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - real suppord fact in dataset=['accordion', 'is a', 'hand hold piano'], real answer = accordion\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - normal model predict = ['accordion', 'bench', 'hand', 'tree', 'door', 'shirt', 'box', 'guitar', 'basket', 'person']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict = ['tree', 'bottle', 'vase', 'accordion', 'bench', 'hand', 'door', 'shirt', 'box', 'guitar']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict relation = ['related to', 'capable of', 'is a', 'has property', 'has a', 'used for', 'part of', 'at location', 'specific', 'high', 'important', 'low', 'good', 'common', 'visible']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict fact = ['shade car', 'use for hold flower', 'use to hold beverage']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - suppord fact predict = ['use to hold beverage-has property', 'use for hold flower-has property', 'shade car-capable of']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - correspond target = ['vase', 'bottle', 'tree']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - test id = 106, question = Which object in this image is capable of calculation?, img = COCO_val2014_000000006608.jpg\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - real suppord fact in dataset=['computer', 'used for', 'calculation'], real answer = computer\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - normal model predict = ['computer', 'desk', 'chair', 'home office', 'cat', 'lamp', 'bookshelf', 'clock', 'couch', 'ram']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict = ['dog', 'computer', 'desk', 'chair', 'home office', 'cat', 'lamp', 'bookshelf', 'clock', 'couch']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict relation = ['capable of', 'efficient', 'used for', 'intelligent', 'high', 'stable', 'fast', 'powerful', 'part of', 'active', 'effective', 'accurate', 'reliable', 'visible', 'human']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict fact = ['data process', 'reproduce', 'shred']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - suppord fact predict = ['reproduce-capable of']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - correspond target = ['dog']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - test id = 1236, question = Which object in this image is the most complicated, img = COCO_val2014_000000137573.jpg\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - real suppord fact in dataset=['computer', 'has property', 'complicate'], real answer = computer\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - normal model predict = ['butterfly', 'clock', 'umbrella', 'chair', 'chess board', 'bicycle', 'kite', 'beach', 'computer', 'protect person from sun and rain']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict = ['cat', 'baby bed', 'ruler', 'bed', 'sofa', 'butterfly', 'clock', 'umbrella', 'chair', 'chess board']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict relation = ['related to', 'has property', 'is a', 'belong to', 'has a', 'used for', 'important', 'part of', 'specific', 'common', 'at location', 'good', 'capable of', 'dangerous', 'receives action']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict fact = ['measurement', 'purr', 'sleep']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - suppord fact predict = ['sleep-used for', 'sleep-related to', 'sleep-belong to', 'purr-capable of', 'sleep-at location', 'measurement-related to']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - correspond target = ['cat', 'sofa', 'baby bed', 'ruler', 'bed']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - test id = 1130, question = Which kind of indoor sports are they playing?, img = ILSVRC2012_test_00002577.JPEG\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - real suppord fact in dataset=['table tennis', 'belong to', 'ping pong ball'], real answer = ping pong ball\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - normal model predict = ['volleyball', 'basketball', 'tennis ball', 'tennis', 'play basketball', 'soccer ball', 'baseball', 'tennis racket', 'play tennis', 'rugby ball']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict = ['volleyball', 'basketball', 'tennis ball', 'baseball', 'racket', 'racquet', 'tennis', 'play basketball', 'soccer ball', 'tennis racket']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict relation = ['belong to', 'is a', 'has property', 'receives action', 'has a', 'used for', 'related to', 'desires', 'part of', 'at location', 'created by', 'popular', 'important', 'common', 'animal class']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict fact = ['ball games', 'play outside', 'olympic games']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - suppord fact predict = ['olympic games-belong to', 'play outside-has property', 'ball games-belong to']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - correspond target = ['racquet', 'basketball', 'volleyball', 'racket', 'tennis ball', 'baseball']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - test id = 498, question = What is the animal famous for?, img = ILSVRC2012_test_00008993.JPEG\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - real suppord fact in dataset=['camel', 'capable of', 'work for day without water'], real answer = work for day without water\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - normal model predict = ['camel', 'desert', 'long necked', 'snake', 'elephant', 'travel', 'entertain yourself on windy day', 'fun', 'horse', 'lay on']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict = ['long necked', 'big', 'animal', 'even toed ungulate', 'zoo', 'africa', 'mammal', 'giraffidae', 'four', 'extremely high blood pressure']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict relation = ['has property', 'used for', 'is a', 'has a', 'capable of', 'animal class', 'animal family', 'at location', 'part of', 'receives action', 'animal order', 'good', 'related to', 'popular', 'belong to']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict fact = ['giraffe', 'fox', 'elephant']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - suppord fact predict = ['giraffe-animal family', 'elephant-related to', 'giraffe-animal order', 'giraffe-receives action', 'giraffe-has a', 'elephant-has property', 'fox-animal class', 'giraffe-has property', 'giraffe-at location', 'elephant-belong to']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - correspond target = ['giraffidae', 'extremely high blood pressure', 'animal', 'zoo', 'four', 'even toed ungulate', 'long necked', 'africa', 'mammal', 'big']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:22 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - test id = 1256, question = What tool the man is holding?, img = ILSVRC2012_test_00008415.JPEG\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - real suppord fact in dataset=['hammer', 'is a', 'tool'], real answer = hammer\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - normal model predict = ['grass', 'frisbee', 'throw', 'chain saw', 'snake', 'hand', 'baseball glove', 'corkscrew', 'fork', 'crutch']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict = ['fork', 'hair', 'animal', 'herd sheep', 'cut', 'human', 'pare apple', 'grass', 'frisbee', 'throw']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict relation = ['related to', 'belong to', 'is a', 'at location', 'used for', 'has property', 'animal order', 'animal class', 'specific', 'receives action', 'capable of', 'animal family', 'has a', 'important', 'good']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict fact = ['knife', 'dog', 'knife mate']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - suppord fact predict = ['dog-used for', 'dog-good', 'knife mate-related to', 'dog-has a', 'dog-belong to', 'knife-used for']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - correspond target = ['animal', 'herd sheep', 'hair', 'fork', 'pare apple', 'human', 'cut']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - test id = 865, question = Which animal in this image is the most related to big tail, img = COCO_val2014_000000015070.jpg\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - real suppord fact in dataset=['squirrel', 'related to', 'big tail'], real answer = squirrel\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - normal model predict = ['cat', 'dog', 'kitten', 'rabbit', 'squirrel', 'otter', 'dog poop', 'skunk', 'monkey', 'teddy bear']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict = ['dog', 'elephant', 'train', 'cat', 'kitten', 'rabbit', 'squirrel', 'otter', 'dog poop', 'skunk']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict relation = ['related to', 'specific', 'capable of', 'belong to', 'important', 'used for', 'has property', 'is a', 'part of', 'desires', 'has a', 'accurate', 'common', 'good', 'at location']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict fact = ['very big', 'big', 'big than cat']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - suppord fact predict = ['big-has property', 'big than cat-is a', 'very big-has property']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - correspond target = ['train', 'elephant', 'dog']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - test id = 912, question = Which object in this image is related to e mail?, img = COCO_val2014_000000025846.jpg\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - real suppord fact in dataset=['e mail', 'related to', 'computer'], real answer = computer\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - normal model predict = ['cell phone', 'keyboard', 'laptop', 'phone', 'ipod', 'computer', 'apple', 'mouse', 'printer', 'pare apple']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict = ['cell phone', 'keyboard', 'laptop', 'phone', 'ipod', 'computer', 'apple', 'mouse', 'printer', 'pare apple']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict relation = ['related to', 'specific', 'used for', 'belong to', 'important', 'common', 'part of', 'prevalent', 'social', 'is a', 'animal order', 'at location', 'accurate', 'has property', 'good']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - our model predict fact = ['type', 'call mobile phone', 'type letter']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - suppord fact predict = ['type-used for', 'type-related to', 'call mobile phone-is a', 'type letter-used for']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - correspond target = ['keyboard', 'cell phone']\n",
      "INFO - 08/13/22 23:30:22 - 0:00:41 - #################################################################################\n",
      " 13%|█████▊                                     | 12/89 [00:08<00:53,  1.44it/s]INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - test id = 528, question = Which object in this image can learn how to beg?, img = COCO_val2014_000000125405.jpg\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - real suppord fact in dataset=['dog', 'capable of', 'learn how to beg'], real answer = dog\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - normal model predict = ['dog', 'dog poop', 'person', 'cat', 'horse', 'sheep', 'herd sheep', 'animal', 'cow', 'make person happy']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict = ['person', 'dog', 'dog poop', 'cat', 'horse', 'sheep', 'herd sheep', 'animal', 'cow', 'make person happy']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict relation = ['capable of', 'related to', 'used for', 'specific', 'desires', 'at location', 'important', 'belong to', 'accurate', 'surface', 'visible', 'active', 'human', 'high', 'effective']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict fact = ['dare another to do something careless', 'lose his temper', 'trick others']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - suppord fact predict = ['dare another to do something careless-capable of', 'lose his temper-capable of', 'trick others-desires']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - correspond target = ['person']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - test id = 1180, question = Where are you likely to find a gift?, img = ILSVRC2012_test_00000015.JPEG\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - real suppord fact in dataset=['gift', 'at location', 'gift shop'], real answer = gift shop\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - normal model predict = ['wedding', 'africa', 'handbag', 'tourist', 'mountainous area', 'beach', 'your house', 'fair', 'house', 'city']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict = ['handbag', 'listen to music', 'cake', 'apple', 'wedding', 'africa', 'tourist', 'mountainous area', 'beach', 'your house']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict relation = ['at location', 'capable of', 'used for', 'related to', 'specific', 'visible', 'accurate', 'desires', 'surface', 'is a', 'primitive', 'cool', 'belong to', 'important', 'convenient']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict fact = ['birthday party', 'ipod', \"woman's closet\"]\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - suppord fact predict = ['birthday party-related to', 'ipod-belong to', 'birthday party-at location', \"woman's closet-at location\", 'ipod-used for']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - correspond target = ['cake', 'apple', 'listen to music', 'handbag']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - test id = 353, question = What thing does the place shown in this image have as a part?, img = COCO_val2014_000000126659.jpg\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - real suppord fact in dataset=['airport', 'has a', 'runway'], real answer = runway\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - normal model predict = ['airplane', 'cloud', 'airport', 'car', 'plane', 'land airplane', 'land plane', 'window', 'travel in car', 'flight']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict = ['motorcycle', 'string', 'helmet', 'entertain yourself on windy day', 'horse', 'string attach', 'fun', 'child', 'airplane', 'cloud']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict relation = ['part of', 'has a', 'related to', 'at location', 'small', 'large', 'is a', 'used for', 'animal family', 'capable of', 'social', 'common', 'has property', 'receives action', 'popular']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict fact = ['policeman', 'kite', 'biker']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - suppord fact predict = ['kite-used for', 'kite-related to', 'biker-related to', 'kite-part of', 'policeman-is a']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - correspond target = ['string attach', 'child', 'horse', 'fun', 'entertain yourself on windy day', 'motorcycle', 'helmet', 'string']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - test id = 727, question = Whether the fruit in the image has seed or not?, img = ILSVRC2012_test_00027435.JPEG\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - real suppord fact in dataset=['orange', 'has a', 'seed'], real answer = seed\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - normal model predict = ['orange', 'banana', 'lemon', 'strawberry', 'pineapple', 'peel', 'green', 'fruit', 'apple', 'pare apple']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict = ['orange', 'banana', 'lemon', 'strawberry', 'pineapple', 'apple', 'pomegranate', 'basket', 'peel', 'green']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict relation = ['has a', 'is a', 'has property', 'part of', 'related to', 'used for', 'receives action', 'created by', 'animal family', 'at location', 'red', 'green', 'popular', 'common', 'small']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict fact = ['fruit', 'yellow fruit', 'use to hold fruit']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - suppord fact predict = ['use to hold fruit-has property', 'fruit-related to', 'fruit-is a', 'fruit-part of', 'yellow fruit-is a']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - correspond target = ['apple', 'strawberry', 'pineapple', 'pomegranate', 'orange', 'banana', 'lemon', 'basket']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - test id = 25, question = Which European cuisine is shown in this image?, img = COCO_val2014_000000130438.jpg\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - real suppord fact in dataset=['sandwich', 'belong to', 'european cuisine'], real answer = sandwich\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - normal model predict = ['strawberry', 'hot dog', 'chocolate', 'hamburger', 'pizza', 'bagel', 'cheese', 'food', 'salad', 'fruit']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict = ['hot dog', 'pizza', 'bagel', 'strawberry', 'chocolate', 'hamburger', 'cheese', 'food', 'salad', 'fruit']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict relation = ['belong to', 'is a', 'created by', 'important', 'part of', 'related to', 'has property', 'sweet', 'popular', 'healthy', 'good', 'loyal', 'has a', 'easy', 'animal class']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict fact = ['popular breakfast food', 'street food', 'popular food']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - suppord fact predict = ['street food-belong to', 'popular food-is a', 'popular breakfast food-is a']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - correspond target = ['hot dog', 'bagel', 'pizza']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - test id = 2498, question = Train station is related to which object in this image?, img = COCO_val2014_000000026226.jpg\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - real suppord fact in dataset=['train station', 'related to', 'train'], real answer = train\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - normal model predict = ['train', 'taxi', 'train station', 'house', 'airport', 'railroad track', 'bicycle', 'car', 'bus', 'airplane']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict = ['bus', 'station', 'driving', 'motorcycle', 'travel', 'person', 'train', 'taxi', 'train station', 'house']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict relation = ['belong to', 'related to', 'is a', 'at location', 'has property', 'has a', 'important', 'used for', 'common', 'specific', 'capable of', 'part of', 'visible', 'small', 'easy']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict fact = ['car', 'board train', 'train']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - suppord fact predict = ['train-at location', 'car-visible', 'car-used for', 'board train-capable of', 'train-used for', 'car-small']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - correspond target = ['driving', 'bus', 'motorcycle', 'station', 'person', 'travel']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - test id = 1705, question = which object in this image is able to use a pencil for drawing, img = ILSVRC2012_test_00052945.JPEG\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - real suppord fact in dataset=['person', 'capable of', 'draw with pencil'], real answer = person\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - normal model predict = ['computer', 'remote', 'person', 'desk', 'toothbrush', 'screwdriver', 'pencil box', 'pen', 'corkscrew', 'sofa']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict = ['pen', 'camera', 'rubber eraser', 'computer', 'remote', 'person', 'desk', 'toothbrush', 'screwdriver', 'pencil box']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict relation = ['capable of', 'used for', 'is a', 'easy', 'fast', 'accurate', 'efficient', 'desires', 'good', 'convenient', 'related to', 'effective', 'reliable', 'powerful', 'important']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict fact = ['erase pencil', 'tool for take picture', 'write or draw tool']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - suppord fact predict = ['write or draw tool-is a', 'erase pencil-used for', 'tool for take picture-is a']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - correspond target = ['pen', 'rubber eraser', 'camera']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - test id = 1332, question = What object in this image is like a slug?, img = ILSVRC2012_test_00000138.JPEG\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - real suppord fact in dataset=['gastropod', 'related to', 'nail'], real answer = nail\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - normal model predict = ['baseball bat', 'ray', 'baseball', 'cow', 'ant', 'snake', 'sand', 'jellyfish', 'poisonous', 'grass']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict = ['snake', 'baseball bat', 'ray', 'baseball', 'cow', 'ant', 'sand', 'jellyfish', 'poisonous', 'grass']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict relation = ['is a', 'related to', 'belong to', 'has property', 'has a', 'capable of', 'cool', 'at location', 'part of', 'visible', 'important', 'specific', 'created by', 'independent', 'desires']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict fact = ['poisonous', 'poison', 'snake pit']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - suppord fact predict = ['snake pit-related to', 'poison-related to', 'poisonous-has property']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - correspond target = ['snake']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - test id = 2711, question = What thing in this image like live mice, img = ILSVRC2012_test_00029408.JPEG\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - real suppord fact in dataset=['snake', 'desires', 'live mouse'], real answer = snake\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - normal model predict = ['snake', 'lizard', 'frog', 'giraffe', 'desert', 'clock', 'armadillo', 'turtle', 'monkey', 'zebra']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict = ['person', 'snake', 'lizard', 'frog', 'giraffe', 'desert', 'clock', 'armadillo', 'turtle', 'monkey']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict relation = ['at location', 'used for', 'is a', 'has a', 'capable of', 'has property', 'receives action', 'belong to', 'part of', 'related to', 'good', 'convenient', 'desires', 'fast', 'great']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict fact = ['hear noise', 'hear voice', 'listen to sound']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - suppord fact predict = ['hear noise-capable of', 'hear voice-capable of', 'listen to sound-capable of']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - correspond target = ['person']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - test id = 2632, question = Which object in this image is used for rest?, img = ILSVRC2012_test_00002135.JPEG\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - real suppord fact in dataset=['sofa', 'used for', 'sleep upon'], real answer = sofa\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - normal model predict = ['couch', 'sofa', 'bed', 'chair', 'pillows', 'baby bed', 'bedroom', 'sleep', 'blanket', 'bathtub']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict = ['bed', 'luggage', 'cat', 'couch', 'sofa', 'chair', 'pillows', 'baby bed', 'bedroom', 'sleep']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict relation = ['used for', 'related to', 'specific', 'belong to', 'part of', 'important', 'receives action', 'common', 'effective', 'is a', 'capable of', 'easy', 'accurate', 'popular', 'good']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict fact = ['carry clothe on vacation', 'carry clothe on trip', 'nap']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - suppord fact predict = ['carry clothe on trip-used for', 'nap-used for', 'carry clothe on vacation-used for', 'nap-capable of']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - correspond target = ['luggage', 'cat', 'bed']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - test id = 1343, question = What is made with mild in this image?, img = COCO_val2014_000000024144.jpg\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - real suppord fact in dataset=['cheese', 'created by', 'milk'], real answer = cheese\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - normal model predict = ['cheese', 'fork', 'pizza', 'flour', 'bread', 'large container', 'artichoke', 'zucchini', 'tomato', 'knife']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict = ['strawberry', 'cake', 'donut', 'cheese', 'fork', 'pizza', 'flour', 'bread', 'large container', 'artichoke']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict relation = ['belong to', 'has property', 'protected', 'is a', 'at location', 'safe', 'important', 'independent', 'animal class', 'good', 'part of', 'related to', 'trustworthy', 'loyal', 'created by']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - our model predict fact = ['sweet red fruit', 'sweet breads', 'sweet bread']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - suppord fact predict = ['sweet red fruit-is a', 'sweet bread-related to', 'sweet breads-belong to']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - correspond target = ['cake', 'strawberry', 'donut']\r\n",
      "INFO - 08/13/22 23:30:23 - 0:00:41 - #################################################################################\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15%|██████▎                                    | 13/89 [00:08<00:47,  1.58it/s]INFO - 08/13/22 23:30:23 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - test id = 643, question = What object is falling from sky?, img = COCO_val2014_000000020972.jpg\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - real suppord fact in dataset=['snow', 'has property', 'fall from sku'], real answer = snow\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - normal model predict = ['otter', 'mammal', 'sheep', 'teddy bear', 'bear', 'herd sheep', 'whale', 'rabbit', 'ant', 'poisonous']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict = ['umbrella', 'otter', 'mammal', 'sheep', 'teddy bear', 'bear', 'herd sheep', 'whale', 'rabbit', 'ant']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict relation = ['is a', 'related to', 'capable of', 'has property', 'belong to', 'good', 'has a', 'important', 'animal order', 'used for', 'easy', 'accurate', 'specific', 'desires', 'fast']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict fact = ['fly in sky', 'shade you from sun', 'prtoect you from sun']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - suppord fact predict = ['prtoect you from sun-capable of', 'shade you from sun-capable of']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - correspond target = ['umbrella']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - test id = 872, question = Which object in this image is a part of a typical livingroom?, img = COCO_val2014_000000003145.jpg\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - real suppord fact in dataset=['typical livingroom', 'has a', 'sofa'], real answer = sofa\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - normal model predict = ['sofa', 'couch', 'bed', 'tv', 'bedroom', 'furniture', 'chair', 'monitor', 'pillows', 'lamp']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict = ['guitar', 'harp', 'flute', 'trumpet', 'sofa', 'couch', 'bed', 'tv', 'bedroom', 'furniture']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict relation = ['is a', 'belong to', 'has a', 'related to', 'has property', 'cool', 'part of', 'used for', 'easy', 'convenient', 'warm', 'sweet', 'at location', 'animal class', 'blind']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict fact = ['instrument of music', 'very common musical instrument', 'musician']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - suppord fact predict = ['very common musical instrument-is a', 'musician-related to', 'instrument of music-is a']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - correspond target = ['guitar', 'trumpet', 'flute', 'harp']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - test id = 1514, question = What is a TV used for, img = ILSVRC2012_test_00027726.JPEG\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - real suppord fact in dataset=['tv', 'used for', 'watch'], real answer = watch\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - normal model predict = ['sleep', 'bedroom', 'swimming', 'bathroom', 'swim', 'clock', 'living room', 'wall', 'sleep away from home', 'life preserver']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict = ['bathroom', 'use twice day', 'lay on', 'toothbrush', 'pillows', 'teddy bear', 'sleep', 'bedroom', 'swimming', 'swim']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict relation = ['related to', 'belong to', 'used for', 'at location', 'specific', 'part of', 'capable of', 'important', 'good', 'receives action', 'is a', 'animal order', 'great', 'accurate', 'has a']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict fact = ['bed', 'toothbrush', 'dental tool']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - suppord fact predict = ['bed-at location', 'dental tool-is a', 'bed-belong to', 'toothbrush-at location', 'bed-used for', 'toothbrush-receives action']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - correspond target = ['bathroom', 'lay on', 'pillows', 'toothbrush', 'teddy bear', 'use twice day']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - test id = 290, question = Which animal is capable of storing nuts for the winter, img = COCO_val2014_000000015070.jpg\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - real suppord fact in dataset=['squirrel', 'capable of', 'store nut for winter'], real answer = squirrel\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - normal model predict = ['cat', 'dog', 'monkey', 'kitten', 'rabbit', 'squirrel', 'dog poop', 'animal', 'elephant', 'skunk']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict = ['monkey', 'giraffe', 'person', 'herd sheep', 'cat', 'dog', 'kitten', 'rabbit', 'squirrel', 'dog poop']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict relation = ['capable of', 'intelligent', 'fast', 'efficient', 'powerful', 'high', 'stable', 'slow', 'used for', 'accurate', 'active', 'reliable', 'effective', 'tall', 'energetic']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict fact = ['fee themselves', 'groom each other', 'dog']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - suppord fact predict = ['dog-used for', 'groom each other-capable of', 'dog-tall', 'fee themselves-capable of']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - correspond target = ['giraffe', 'monkey', 'herd sheep', 'person']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - test id = 1849, question = Which object in this image has a prickle?, img = ILSVRC2012_test_00047632.JPEG\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - real suppord fact in dataset=['pineapple', 'is a', 'prickley'], real answer = pineapple\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - normal model predict = ['banana', 'fruit', 'pineapple', 'strawberry', 'zucchini', 'orange', 'fig', 'potted plant', 'tomato', 'lemon']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict = ['tree', 'bicycle', 'microwave', 'banana', 'fruit', 'pineapple', 'strawberry', 'zucchini', 'orange', 'fig']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict relation = ['related to', 'has a', 'is a', 'part of', 'specific', 'social', 'common', 'used for', 'animal order', 'important', 'has property', 'animal family', 'large', 'light', 'at location']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict fact = ['branch', 'magnetron', 'chain']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - suppord fact predict = ['branch-related to', 'chain-has a', 'magnetron-related to']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - correspond target = ['tree', 'microwave', 'bicycle']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - test id = 2430, question = What can be found in this place?, img = ILSVRC2012_test_00027726.JPEG\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - real suppord fact in dataset=['cushion', 'at location', 'room'], real answer = room\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - normal model predict = ['wall', 'bedroom', 'use toilet', 'bathroom', 'house', 'toilet', 'furniture', 'baby bed', 'sound control room', 'bookshelf']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict = ['wall', 'use toilet', 'house', 'toilet', 'furniture', 'sleep', 'toilet seat', 'thing', 'toilet paper', 'wash']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict relation = ['at location', 'part of', 'related to', 'used for', 'belong to', 'specific', 'has a', 'animal order', 'receives action', 'social', 'important', 'surface', 'animal family', 'great', 'frequent']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict fact = ['hotel room', 'bathroom', 'room']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - suppord fact predict = ['hotel room-used for', 'bathroom-at location', 'bathroom-part of', 'room-at location', 'bathroom-used for', 'room-has a']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - correspond target = ['wall', 'toilet', 'thing', 'sleep', 'toilet paper', 'use toilet', 'house', 'furniture', 'toilet seat', 'wash']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - test id = 318, question = which thing does the place shown in this image have as a part?, img = ILSVRC2012_test_00002037.JPEG\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - real suppord fact in dataset=['ocean', 'has a', 'water'], real answer = water\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - normal model predict = ['water', 'boat', 'beach', 'blue', 'travel across water', 'ocean', 'sea', 'river', 'cloud', 'umbrella']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict = ['blue', 'cloud', 'life preserver', 'kite', 'water', 'boat', 'beach', 'travel across water', 'ocean', 'sea']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict relation = ['has a', 'part of', 'related to', 'large', 'small', 'has property', 'light', 'is a', 'animal family', 'firm', 'specific', 'social', 'common', 'frequent', 'long']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict fact = ['sky', 'sea', 'boat']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - suppord fact predict = ['boat-has a', 'sky-part of', 'sky-related to', 'sky-has property']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - correspond target = ['kite', 'life preserver', 'blue', 'cloud']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - test id = 857, question = Where is this place?, img = COCO_val2014_000000002388.jpg\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - real suppord fact in dataset=['bathroom', 'used for', 'wash up in'], real answer = bathroom\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - normal model predict = ['bathroom', 'toilet', 'toilet seat', 'pee', 'bathtub', 'bed', 'use toilet', 'bedroom', 'kitchen', 'sink']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict = ['toilet', 'toilet seat', 'pee', 'use toilet', 'sink', 'toilet paper', 'wash', 'mirror', 'wash your hand', 'plunger']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict relation = ['at location', 'used for', 'is a', 'related to', 'has property', 'belong to', 'part of', 'has a', 'capable of', 'important', 'specific', 'good', 'desires', 'common', 'receives action']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - our model predict fact = ['bathroom', 'toilet', 'shower']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - suppord fact predict = ['bathroom-at location', 'bathroom-has a', 'bathroom-part of', 'toilet-used for', 'bathroom-used for', 'shower-used for']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - correspond target = ['pee', 'toilet', 'use toilet', 'toilet paper', 'sink', 'wash your hand', 'plunger', 'toilet seat', 'mirror', 'wash']\n",
      "INFO - 08/13/22 23:30:23 - 0:00:42 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|██████▊                                    | 14/89 [00:09<00:46,  1.60it/s]INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - test id = 2336, question = Which object in this image is more maneuverable than a bicycle?, img = ILSVRC2012_test_00035105.JPEG\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - real suppord fact in dataset=['unicycle', 'maneuverable', 'bicycle'], real answer = unicycle\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - normal model predict = ['car', 'train', 'bus', 'driving', 'truck', 'taxi', 'bicycle', 'stop sign', 'vehicle', 'airplane']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict = ['car', 'bus', 'motorbike', 'train', 'driving', 'truck', 'taxi', 'bicycle', 'stop sign', 'vehicle']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict relation = ['important', 'cheap', 'prevalent', 'expensive', 'convenient', 'strenuous', 'good', 'dangerous', 'easy', 'efficient', 'blind', 'frequent', 'stressful', 'reliable', 'slow']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict fact = ['bicycle', 'bike', 'scooter']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - suppord fact predict = ['bicycle-expensive', 'bike-important', 'bike-slow']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - correspond target = ['bus', 'car', 'motorbike']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - test id = 478, question = What can be seen in this image?, img = COCO_val2014_000000144062.jpg\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - real suppord fact in dataset=['toilet', 'part of', 'bathroom'], real answer = toilet\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - normal model predict = ['flowers', 'hair spray', 'hair', 'handbag', 'flower', 'lipstick', 'potted plant', 'tourist', 'expensive', 'vegetable']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict = ['handbag', 'canvas', 'flowers', 'hair spray', 'hair', 'flower', 'lipstick', 'potted plant', 'tourist', 'expensive']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict relation = ['at location', 'used for', 'is a', 'has a', 'related to', 'capable of', 'good', 'specific', 'great', 'part of', 'belong to', 'animal order', 'easy', 'important', 'cool']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict fact = ['happyness', \"woman's closet\", 'art gallery']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - suppord fact predict = [\"woman's closet-at location\", 'art gallery-at location']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - correspond target = ['canvas', 'handbag']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - test id = 2157, question = What percussion instrument is in this image?, img = ILSVRC2012_test_00001366.JPEG\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - real suppord fact in dataset=['maraca', 'related to', 'percussion'], real answer = maraca\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - normal model predict = ['butterfly', 'surfboard', 'goldfish', 'baseball bat', 'tick', 'hammer', 'racket', 'axe', 'ping pong ball', 'nail']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict = ['drum', 'harp', 'banjo', 'harmonica', 'guitar', 'accordion', 'violin', 'trombone', 'saxophone', 'french horn']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict relation = ['belong to', 'is a', 'related to', 'has property', 'used for', 'safe', 'good', 'important', 'at location', 'easy', 'receives action', 'specific', 'animal class', 'has a', 'fast']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict fact = ['musical string instrument', 'string musical instrument', 'musical instrument']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - suppord fact predict = ['musical string instrument-is a', 'musical instrument-belong to', 'musical instrument-related to', 'string musical instrument-is a', 'musical instrument-is a']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - correspond target = ['harmonica', 'harp', 'accordion', 'french horn', 'drum', 'banjo', 'violin', 'guitar', 'trombone', 'saxophone']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - test id = 2179, question = what object in this image is used for surfing, img = COCO_val2014_000000111644.jpg\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - real suppord fact in dataset=['surfboard', 'used for', 'surfing'], real answer = surfboard\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - normal model predict = ['surfboard', 'kite', 'raft', 'surf board', 'snowboard', 'skateboard', 'boat', 'sand', 'swimming', 'sail boat']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict = ['sand', 'couch', 'drum', 'surfboard', 'kite', 'raft', 'surf board', 'snowboard', 'skateboard', 'boat']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict relation = ['related to', 'used for', 'belong to', 'specific', 'efficient', 'important', 'effective', 'easy', 'light', 'capable of', 'has property', 'receives action', 'accurate', 'good', 'high']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict fact = ['sandbar', 'laze', 'drumbeating']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - suppord fact predict = ['sandbar-related to', 'drumbeating-related to', 'laze-used for']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - correspond target = ['drum', 'couch', 'sand']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - test id = 564, question = Which object in this image belongs to the category Bovinae?, img = COCO_val2014_000000105367.jpg\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - real suppord fact in dataset=['cow', 'belong to', 'bovinae'], real answer = cow\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - normal model predict = ['cow', 'child', 'horse', 'grass', 'flowers', 'sheep', 'toddler', 'camel', 'car', 'toys']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict = ['child', 'zebra', 'motorcycle', 'monkey', 'cow', 'horse', 'grass', 'flowers', 'sheep', 'toddler']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict relation = ['belong to', 'desires', 'is a', 'loyal', 'animal kingdom', 'animal phylum', 'trustworthy', 'comfortable', 'capable of', 'sensible', 'animal order', 'small', 'protected', 'visible', 'human']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict fact = ['primate', 'subculture', 'eukaryote']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - suppord fact predict = ['primate-is a', 'subculture-belong to', 'eukaryote-belong to']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - correspond target = ['zebra', 'motorcycle', 'monkey', 'child']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - test id = 2710, question = Tell me the name of the limbless creature?, img = ILSVRC2012_test_00029408.JPEG\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - real suppord fact in dataset=['snake', 'desires', 'live mouse'], real answer = snake\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - normal model predict = ['snake', 'dragonfly', 'wii', 'frog', 'lizard', 'guitar', 'banjo', 'butterfly', 'harmonica', 'corkscrew']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict = ['poisonous', 'desert', 'child', 'no leg', 'bear', 'person', 'warm place', 'snake', 'dragonfly', 'wii']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict relation = ['is a', 'related to', 'belong to', 'part of', 'receives action', 'animal order', 'has a', 'at location', 'capable of', 'animal class', 'animal family', 'animal kingdom', 'has property', 'animal phylum', 'independent']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict fact = ['snake', 'kill human', 'human']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - suppord fact predict = ['snake-has property', 'human-belong to', 'snake-at location', 'kill human-capable of', 'human-related to', 'snake-has a']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - correspond target = ['desert', 'child', 'no leg', 'warm place', 'person', 'bear', 'poisonous']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - test id = 1333, question = Which object in this image is related to escargot?, img = ILSVRC2012_test_00000138.JPEG\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - real suppord fact in dataset=['escargot', 'related to', 'nail'], real answer = nail\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - normal model predict = ['scissors', 'knife', 'corkscrew', 'wood', 'poisonous', 'axe', 'grass', 'ant', 'snake', 'root']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict = ['ray', 'elephant', 'trombone', 'scissors', 'knife', 'corkscrew', 'wood', 'poisonous', 'axe', 'grass']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict relation = ['related to', 'specific', 'belong to', 'important', 'at location', 'used for', 'social', 'common', 'prevalent', 'animal order', 'accurate', 'capable of', 'part of', 'has property', 'desires']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict fact = ['batoidea', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - suppord fact predict = ['batoidea-belong to', 'therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - correspond target = ['trombone', 'ray', 'elephant']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - test id = 2268, question = what object in this image has roots?, img = COCO_val2014_000000018888.jpg\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - real suppord fact in dataset=['tree', 'has a', 'root'], real answer = tree\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - normal model predict = ['tree', 'grass', 'green', 'plant', 'palm tree', 'skunk', 'forest road', 'flowers', 'potted plant', 'orange']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict = ['cattle', 'banjo', 'harp', 'guitar', 'kite', 'tennis racket', 'tree', 'grass', 'green', 'plant']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict relation = ['has a', 'related to', 'part of', 'specific', 'has property', 'social', 'animal order', 'used for', 'belong to', 'is a', 'at location', 'animal family', 'receives action', 'capable of', 'firm']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict fact = ['hoove', 'string instrumetnt', 'string']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - suppord fact predict = ['string-related to', 'string-part of', 'string-has a', 'hoove-related to', 'string instrumetnt-is a']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - correspond target = ['cattle', 'harp', 'banjo', 'tennis racket', 'guitar', 'kite']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - test id = 1976, question = Which object in this image is alive?, img = COCO_val2014_000000106235.jpg\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - real suppord fact in dataset=['potted plant', 'belong to', 'life'], real answer = potted plant\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - normal model predict = ['couch', 'sofa', 'bed', 'bedroom', 'furniture', 'tv', 'pillows', 'chair', 'cat', 'baby bed']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict = ['cat', 'house', 'person', 'couch', 'sofa', 'bed', 'bedroom', 'furniture', 'tv', 'pillows']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict relation = ['is a', 'belong to', 'related to', 'has property', 'part of', 'has a', 'important', 'receives action', 'capable of', 'trustworthy', 'desires', 'loyal', 'used for', 'common', 'easy']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict fact = ['live room', 'alive', 'live entity']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - suppord fact predict = ['live entity-is a', 'alive-has property', 'live room-related to']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - correspond target = ['house', 'cat', 'person']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - test id = 97, question = What is the dog lying on in the image?, img = ILSVRC2012_test_00011808.JPEG\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - real suppord fact in dataset=['sofa', 'used for', 'lie on'], real answer = sofa\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - normal model predict = ['dog', 'donut', 'cat', 'human', 'hair', 'doughnut', 'mouse', 'hot dog', 'dog poop', 'kitten']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict = ['dog', 'cat', 'human', 'animal', 'goldfish', 'herd sheep', 'ant', 'donut', 'hair', 'doughnut']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict relation = ['related to', 'animal order', 'good', 'is a', 'used for', 'important', 'at location', 'part of', 'animal class', 'capable of', 'specific', 'great', 'human', 'belong to', 'fast']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - our model predict fact = ['dog', 'pet', 'pet cat']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - suppord fact predict = ['dog-used for', 'pet-is a', 'dog-good', 'pet-belong to', 'pet-used for', 'dog-belong to', 'pet-related to']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - correspond target = ['cat', 'animal', 'dog', 'ant', 'herd sheep', 'goldfish', 'human']\n",
      "INFO - 08/13/22 23:30:24 - 0:00:42 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17%|███████▏                                   | 15/89 [00:10<00:46,  1.59it/s]INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 965, question = what does the cat sit on?, img = ILSVRC2012_test_00010630.JPEG\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['desk', 'belong to', 'living arrangements'], real answer = desk\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['sofa', 'couch', 'chair', 'desk', 'bed', 'bench', 'pillows', 'toilet seat', 'cat', 'grass']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['cat', 'kitten', 'mouse', 'hair', 'animal', 'dog', 'human', 'herd sheep', 'any place where person live', 'person']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['at location', 'is a', 'has property', 'capable of', 'has a', 'used for', 'related to', 'belong to', 'good', 'animal order', 'receives action', 'part of', 'desires', 'independent', 'animal family']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['dog', 'pet cat', 'cat']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['dog-used for', 'dog-good', 'dog-independent', 'cat-independent', 'cat-at location', 'dog-has a', 'pet cat-desires', 'dog-belong to', 'cat-capable of', 'cat-is a', 'cat-belong to']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['cat', 'animal', 'dog', 'herd sheep', 'hair', 'mouse', 'human', 'person', 'kitten', 'any place where person live']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 39, question = which fruit in this image has less natural sugar than sweet potato?, img = COCO_val2014_000000016161.jpg\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['sweet potato', 'natural', 'banana'], real answer = banana\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['apple', 'banana', 'chocolate', 'cake', 'lemon', 'orange', 'pineapple', 'pare apple', 'sandwich', 'coffee']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['cake', 'carrot', 'apple', 'banana', 'chocolate', 'lemon', 'orange', 'pineapple', 'pare apple', 'sandwich']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['related to', 'has a', 'has property', 'is a', 'green', 'light', 'red', 'created by', 'popular', 'small', 'social', 'acid', 'common', 'solar', 'dark']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['orange vegetable', 'sweet bread', 'taste salt']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['orange vegetable-related to', 'sweet bread-related to', 'orange vegetable-is a']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['cake', 'carrot']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 1469, question = which object in this image can ring, img = COCO_val2014_000000013639.jpg\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['cell phone', 'capable of', 'ring'], real answer = cell phone\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['person', 'make person happy', 'romantic', 'thing', 'clock', 'cake', 'guitar', 'hair', 'computer', 'any place where person live']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['person', 'cat', 'dog', 'make person happy', 'romantic', 'thing', 'clock', 'cake', 'guitar', 'hair']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['capable of', 'used for', 'has a', 'has property', 'is a', 'related to', 'belong to', 'part of', 'high', 'long', 'at location', 'desires', 'good', 'great', 'important']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['purr', 'make joke', 'woof woof']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['purr-capable of', 'woof woof-related to', 'make joke-capable of']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['cat', 'person', 'dog']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 1464, question =  Which object in this image constists out of frozen liquid?, img = ILSVRC2012_test_00003052.JPEG\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['ice', 'has property', 'freeze liquid'], real answer = ice\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['banana', 'cup', 'bread', 'spoon', 'chocolate', 'lemon', 'drink', 'toast bread', 'orange', 'doughnut']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['cup', 'bottle', 'glass', 'water', 'stove', 'banana', 'bread', 'spoon', 'chocolate', 'lemon']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['capable of', 'has property', 'belong to', 'at location', 'is a', 'has a', 'used for', 'related to', 'visible', 'desires', 'good', 'accurate', 'surface', 'blind', 'receives action']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['boil liquid like water', 'liquid', 'hold liquid']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['liquid-has property', 'boil liquid like water-used for', 'hold liquid-capable of', 'liquid-has a']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['bottle', 'water', 'glass', 'cup', 'stove']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 873, question = Waht object in this image is used for cooling?, img = COCO_val2014_000000003145.jpg\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['electric fan', 'used for', 'cool'], real answer = electric fan\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['bed', 'couch', 'sofa', 'lamp', 'blanket', 'pillows', 'refrigerator', 'sleep', 'baby bed', 'tv']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['refrigerator', 'umbrella', 'bed', 'couch', 'sofa', 'lamp', 'blanket', 'pillows', 'sleep', 'baby bed']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['used for', 'related to', 'belong to', 'capable of', 'specific', 'easy', 'efficient', 'effective', 'good', 'convenient', 'important', 'part of', 'receives action', 'great', 'accurate']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['chill', 'stay dry', 'stay dry in rain']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['chill-related to', 'stay dry-used for', 'stay dry in rain-used for']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['refrigerator', 'umbrella']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 2392, question = Which object in this image belong to the category 'water transport'?, img = COCO_val2014_000000023489.jpg\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['boat', 'belong to', 'ship transport'], real answer = boat\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['boat', 'shore boat', 'sail boat', 'grass', 'horse', 'water', 'sand', 'whale', 'store boat', 'river']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['traffic light', 'bicycle', 'cart', 'airplane', 'motorcycle', 'golfcart', 'bus', 'boat', 'shore boat', 'sail boat']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['belong to', 'related to', 'desires', 'animal phylum', 'animal order', 'animal kingdom', 'loyal', 'trustworthy', 'is a', 'specific', 'important', 'sensible', 'visible', 'animal family', 'animal class']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['transport safety', 'road transport', 'transport']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['transport safety-belong to', 'transport-belong to', 'road transport-belong to', 'transport-related to']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['traffic light', 'airplane', 'bus', 'golfcart', 'motorcycle', 'bicycle', 'cart']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 345, question = What is the stuffed animal in the middle?, img = COCO_val2014_000000134688.jpg\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['teddy bear', 'is a', 'stuff animal'], real answer = teddy bear\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['fork', 'eat', 'cheese', 'food', 'cake', 'doughnut', 'carrot', 'thing', 'bread', 'prepare food']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['carrot', 'green', 'hair', 'human', 'animal', 'wild', 'herd sheep', 'fork', 'eat', 'cheese']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['related to', 'has property', 'is a', 'at location', 'receives action', 'used for', 'belong to', 'animal order', 'has a', 'specific', 'animal class', 'part of', 'animal family', 'important', 'good']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['dog', 'rabbit', 'frog']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['dog-used for', 'dog-good', 'rabbit-related to', 'dog-has a', 'dog-belong to', 'frog-at location', 'frog-has property']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['animal', 'wild', 'herd sheep', 'green', 'hair', 'carrot', 'human']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 2036, question = What can you find in the place shown in this image, img = COCO_val2014_000000145020.jpg\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['amusement park', 'has a', 'ride'], real answer = ride\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['furniture', 'eat', 'expensive', 'road', 'food', 'car', 'prepare food', 'restaurant', 'ride', 'fair']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['house', 'dog', 'cat', 'tv', 'furniture', 'eat', 'expensive', 'road', 'food', 'car']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['at location', 'part of', 'used for', 'has a', 'capable of', 'belong to', 'is a', 'animal order', 'receives action', 'related to', 'specific', 'animal family', 'important', 'animal class', 'created by']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['apartment', 'petshop', 'suburb']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['petshop-at location', 'apartment-at location', 'suburb-at location']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['cat', 'house', 'tv', 'dog']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 437, question = What can be less expensive than the place shown on the left?, img = COCO_val2014_000000139969.jpg\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['restaurant', 'expensive', 'cafe'], real answer = cafe\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['cafe', 'restaurant', 'taxi', 'drink', 'road', 'eat', 'car', 'coffee', 'food', 'bus']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['car', 'bus', 'station', 'cheap', 'travel', 'flight', 'person', 'cafe', 'restaurant', 'taxi']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['used for', 'cheap', 'capable of', 'at location', 'common', 'fast', 'animal order', 'low', 'expensive', 'good', 'effective', 'high', 'frequent', 'efficient', 'popular']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['head north', 'train', 'board train']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['head north-capable of', 'train-at location', 'train-frequent', 'train-used for', 'board train-capable of', 'train-fast', 'train-cheap', 'train-efficient']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['bus', 'cheap', 'person', 'car', 'station', 'travel', 'flight']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 2279, question = Which object in this image comes down in a thunderstorm?, img = COCO_val2014_000000007394.jpg\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['thunderstorm', 'related to', 'rain'], real answer = rain\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['umbrella', 'kite', 'sand', 'beach', 'rain', 'person', 'protect person from sun and rain', 'car', 'boat', 'lamp']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['umbrella', 'kite', 'sand', 'beach', 'rain', 'person', 'protect person from sun and rain', 'car', 'boat', 'lamp']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['is a', 'has a', 'used for', 'visible', 'belong to', 'capable of', 'related to', 'small', 'fast', 'has property', 'light', 'slow', 'stable', 'easy', 'big']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['good in rain', 'use when it rain', 'in sky']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['use when it rain-is a', 'good in rain-has property']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['umbrella']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      " 18%|███████▋                                   | 16/89 [00:10<00:43,  1.67it/s]INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 745, question = which object in this image is less sweet than strawberry?, img = COCO_val2014_000000103490.jpg\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['strawberry', 'sweet', 'banana'], real answer = banana\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['apple', 'banana', 'chocolate', 'orange', 'fruit', 'white', 'coffee', 'cake', 'pare apple', 'strawberry']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['orange', 'cake', 'apple', 'banana', 'chocolate', 'fruit', 'white', 'coffee', 'pare apple', 'strawberry']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['has property', 'green', 'low', 'efficient', 'high', 'safe', 'prevalent', 'expensive', 'light', 'stable', 'reliable', 'good', 'popular', 'effective', 'strong']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['candy apple', 'sweet', 'sweet taste']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['sweet-has property']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['cake', 'orange']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 1300, question = Who has the longest lives in the image?, img = ILSVRC2012_test_00034257.JPEG\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['turtle', 'has a', 'long life'], real answer = turtle\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['desert', 'mountainous area', 'human', 'police', 'africa', 'tourist', 'turtle', 'coast', 'beach', 'city']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['low', 'shell', 'zebra', 'desert', 'mountainous area', 'human', 'police', 'africa', 'tourist', 'turtle']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['belong to', 'stable', 'has a', 'impassable', 'is a', 'strong', 'long', 'has property', 'capable of', 'loyal', 'important', 'tough', 'independent', 'good', 'weak']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['otter', 'turtle', 'mammal families']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['turtle-has a', 'turtle-has property', 'mammal families-belong to']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['zebra', 'low', 'shell']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 1629, question = Whether this meal is normally cheaper or more expensive than steak?, img = ILSVRC2012_test_00040777.JPEG\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['hamburger', 'cheap', 'cheap'], real answer = cheap\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['low', 'big', 'unhealthy', 'cheap', 'hot dog', 'expensive', 'fair', 'hot room', 'cold and wet', 'white']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['hot dog', 'fork', 'stove', 'low', 'big', 'unhealthy', 'cheap', 'expensive', 'fair', 'hot room']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['expensive', 'cheap', 'efficient', 'comfortable', 'popular', 'convenient', 'used for', 'crowded', 'green', 'tough', 'good', 'safe', 'clean', 'compact', 'easy']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['steak', 'eat steak', 'grill steak']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['steak-expensive', 'eat steak-used for', 'grill steak-used for']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['hot dog', 'fork', 'stove']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 1213, question = What thing does the animal in this image have as a part?, img = COCO_val2014_000000010822.jpg\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['zebra', 'has a', 'stripe'], real answer = stripe\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['zebra', 'stripe', 'blue', 'long necked', 'cloud', 'bikini', 'giraffe', 'jazz blue', 'camel', 'ocean']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['long necked', 'africa', 'animal', 'giraffidae', 'tree', 'skunk', 'even toed ungulate', 'dog', 'zoo', 'squirrel']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['has a', 'part of', 'is a', 'related to', 'animal family', 'animal order', 'large', 'receives action', 'small', 'has property', 'capable of', 'social', 'used for', 'animal kingdom', 'at location']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['giraffe', 'wolf', 'forest']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['giraffe-animal family', 'giraffe-animal order', 'giraffe-receives action', 'wolf-related to', 'forest-part of', 'forest-at location', 'giraffe-has property', 'giraffe-at location']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['giraffidae', 'tree', 'animal', 'dog', 'zoo', 'squirrel', 'skunk', 'even toed ungulate', 'long necked', 'africa']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 1882, question = What item of eyewear is in this image?, img = ILSVRC2012_test_00045346.JPEG\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['sunglasses', 'belong to', 'eyewear'], real answer = sunglasses\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['sunglasses', 'motorcycle', 'shirt', 'helmet', 'baseball bat', 'baseball glove', 'bicycle', 'hair', 'glove', 'hair spray']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['shirt', 'skateboard', 'surfboard', 'snowboard', 'guitar', 'saxophone', 'violin', 'cello', 'flute', 'harp']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['belong to', 'is a', 'related to', 'has property', 'has a', 'at location', 'used for', 'important', 'desires', 'part of', 'easy', 'specific', 'good', 'capable of', 'common']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['boardsports', 'instrument', 'form of clothe']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['instrument-is a', 'instrument-related to', 'form of clothe-is a', 'boardsports-belong to']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['harp', 'skateboard', 'cello', 'violin', 'surfboard', 'guitar', 'shirt', 'flute', 'snowboard', 'saxophone']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 863, question = which object in this image can be used for moving luggage, img = COCO_val2014_000000108408.jpg\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['suitcase', 'related to', 'luggage'], real answer = suitcase\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['suitcase', 'luggage', 'cart', 'basket', 'car', 'truck', 'backpack', 'door', 'bottle', 'punching bag']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['luggage', 'car', 'bus', 'airplane', 'motorcycle', 'bicycle', 'mouse', 'road', 'suitcase', 'cart']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['used for', 'related to', 'capable of', 'belong to', 'specific', 'effective', 'efficient', 'easy', 'good', 'has property', 'accurate', 'common', 'fast', 'high', 'important']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['travel', 'leave click', 'travel on road']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['travel-used for', 'travel on road-capable of', 'travel-related to', 'leave click-related to']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['airplane', 'bus', 'motorcycle', 'bicycle', 'mouse', 'car', 'luggage', 'road']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 2002, question = What is the place in this image used for?, img = COCO_val2014_000000011727.jpg\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['bathroom', 'used for', 'clean your tooth in'], real answer = clean your tooth in\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['pee', 'wash', 'swim', 'sleep', 'preventing from getting wet', 'laundromat', 'sleep away from home', 'toilet', 'cold and wet', 'sink']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['pee', 'wash', 'cooking', 'prepare food', 'hotel room', 'breakfast', 'house', 'plunger', 'swim', 'sleep']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['used for', 'belong to', 'capable of', 'related to', 'effective', 'good', 'receives action', 'part of', 'great', 'specific', 'easy', 'at location', 'popular', 'important', 'animal order']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['kitchenette', 'shower', 'toilet']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['toilet-used for', 'kitchenette-used for', 'kitchenette-at location', 'shower-used for']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['prepare food', 'house', 'hotel room', 'plunger', 'cooking', 'pee', 'wash', 'breakfast']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 2332, question = What objects in this image are inspirational, img = ILSVRC2012_test_00035105.JPEG\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['forest road', 'has property', 'inspirational'], real answer = forest road\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['stop sign', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car', 'bus', 'person']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['stop sign', 'horse', 'tv', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['capable of', 'is a', 'has property', 'receives action', 'has a', 'used for', 'related to', 'part of', 'desires', 'at location', 'belong to', 'created by', 'specific', 'good', 'animal order']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['traffic sign', 'clop', 'advertise']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['advertise-used for', 'traffic sign-belong to', 'clop-related to']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['stop sign', 'tv', 'horse']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - test id = 681, question = Which object in this image is related to ballast?, img = ILSVRC2012_test_00059915.JPEG\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - real suppord fact in dataset=['ballast', 'related to', 'ship'], real answer = ship\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - normal model predict = ['boat', 'sail boat', 'shore boat', 'raft', 'whale', 'surfboard', 'knife', 'axe', 'dolphin', 'corkscrew']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict = ['whale', 'cell phone', 'trombone', 'boat', 'sail boat', 'shore boat', 'raft', 'surfboard', 'knife', 'axe']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict relation = ['related to', 'specific', 'belong to', 'used for', 'important', 'common', 'social', 'part of', 'prevalent', 'animal order', 'frequent', 'accurate', 'has a', 'at location', 'light']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - our model predict fact = ['moby dick', 'm', 'tromboner']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - suppord fact predict = ['moby dick-related to', 'm-related to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - correspond target = ['trombone', 'whale', 'cell phone']\n",
      "INFO - 08/13/22 23:30:25 - 0:00:43 - #################################################################################\n",
      " 19%|████████▏                                  | 17/89 [00:11<00:40,  1.76it/s]INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - test id = 1809, question = which object in this image can die from infection?, img = ILSVRC2012_test_00048422.JPEG\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - real suppord fact in dataset=['person', 'capable of', 'die from infection'], real answer = person\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - normal model predict = ['tennis ball', 'person', 'camera', 'cell phone', 'make person happy', 'stop sign', 'tennis racket', 'tennis', 'golf ball', 'phone']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict = ['power drill', 'umbrella', 'helmet', 'tennis ball', 'person', 'camera', 'cell phone', 'make person happy', 'stop sign', 'tennis racket']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict relation = ['capable of', 'used for', 'is a', 'has property', 'desires', 'at location', 'receives action', 'fast', 'related to', 'accurate', 'easy', 'good', 'important', 'high', 'part of']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict fact = ['shield yourself from rain if you must be outside', 'roughly spherical hard shell that you can wear around your head to protect it from injury', 'cause injury when not use carefully']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - suppord fact predict = ['roughly spherical hard shell that you can wear around your head to protect it from injury-is a', 'shield yourself from rain if you must be outside-used for', 'cause injury when not use carefully-capable of']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - correspond target = ['power drill', 'umbrella', 'helmet']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - test id = 301, question = Which object in this image is related to boomerang?, img = COCO_val2014_000000134459.jpg\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - real suppord fact in dataset=['frisbee', 'related to', 'boomerang'], real answer = frisbee\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - normal model predict = ['grass', 'frisbee', 'horse', 'sheep', 'soccer ball', 'cow', 'crutch', 'baseball field', 'dog poop', 'rugby ball']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict = ['grass', 'flowers', 'plant', 'zebra', 'turtle', 'frisbee', 'horse', 'sheep', 'soccer ball', 'cow']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict relation = ['related to', 'belong to', 'specific', 'important', 'used for', 'capable of', 'common', 'at location', 'accurate', 'part of', 'animal order', 'social', 'desires', 'surface', 'prevalent']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict fact = ['botany', 'herpetology', 'zonkey']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - suppord fact predict = ['zonkey-related to', 'herpetology-belong to', 'botany-belong to', 'botany-related to']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - correspond target = ['grass', 'plant', 'turtle', 'flowers', 'zebra']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - test id = 747, question = Which object in this image is capable of running faster than most humans?, img = COCO_val2014_000000109403.jpg\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - real suppord fact in dataset=['horse', 'capable of', 'run fast than most human'], real answer = horse\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - normal model predict = ['elephant', 'horse', 'dog', 'cow', 'person', 'monkey', 'animal', 'bird', 'giraffe', 'dog poop']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict = ['elephant', 'dog', 'bear', 'computer', 'horse', 'cow', 'person', 'monkey', 'animal', 'bird']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict relation = ['capable of', 'fast', 'slow', 'stable', 'intelligent', 'powerful', 'efficient', 'high', 'effective', 'accurate', 'long', 'tall', 'reliable', 'easy', 'energetic']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict fact = ['human', 'human being', 'kill human']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - suppord fact predict = ['human-fast', 'kill human-capable of', 'human-long', 'human-accurate', 'human-intelligent']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - correspond target = ['bear', 'elephant', 'computer', 'dog']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - test id = 2615, question = Which liquid in the mug on the bottom of the image contains caffeine, img = COCO_val2014_000000024112.jpg\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - real suppord fact in dataset=['coffee', 'has a', 'caffeine'], real answer = coffee\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - normal model predict = ['wine', 'wine glass', 'bottle', 'laboratory', 'drink', 'fruit', 'glass', 'pomegranate', 'beer', 'prepare food']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict = ['wine glass', 'sunglasses', 'tree', 'baseball bat', 'sofa', 'wine', 'bottle', 'laboratory', 'drink', 'fruit']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict relation = ['part of', 'has a', 'related to', 'is a', 'has property', 'small', 'large', 'social', 'important', 'common', 'specific', 'animal family', 'belong to', 'created by', 'animal kingdom']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict fact = ['glass', 'wood', 'piece of furniture']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - suppord fact predict = ['wood-related to', 'glass-belong to', 'piece of furniture-is a', 'glass-related to']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - correspond target = ['tree', 'sofa', 'wine glass', 'baseball bat', 'sunglasses']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - test id = 1302, question = Which species that can be found in this image can hide in its shell, img = ILSVRC2012_test_00034257.JPEG\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - real suppord fact in dataset=['turtle', 'capable of', 'hide in it shell'], real answer = turtle\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - normal model predict = ['turtle', 'frog', 'elephant', 'giraffe', 'lizard', 'monkey', 'armadillo', 'snake', 'mushroom', 'squirrel']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict = ['giraffe', 'whale', 'ship', 'turtle', 'frog', 'elephant', 'lizard', 'monkey', 'armadillo', 'snake']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict relation = ['capable of', 'has a', 'at location', 'stable', 'belong to', 'has property', 'is a', 'visible', 'impassable', 'desires', 'long', 'active', 'human', 'surface', 'blind']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict fact = ['mammals by continent', 'marine mammal', 'in ocean']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - suppord fact predict = ['marine mammal-belong to', 'mammals by continent-belong to', 'in ocean-at location', 'marine mammal-is a']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - correspond target = ['whale', 'giraffe', 'ship']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - test id = 1331, question = What object in this image is slimy?, img = ILSVRC2012_test_00000138.JPEG\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - real suppord fact in dataset=['lime', 'related to', 'nail'], real answer = nail\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - normal model predict = ['snake', 'poisonous', 'baseball bat', 'ray', 'jellyfish', 'baseball', 'green', 'shell', 'lizard', 'fish']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict = ['snake', 'orange', 'poisonous', 'baseball bat', 'ray', 'jellyfish', 'baseball', 'green', 'shell', 'lizard']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict relation = ['has property', 'related to', 'is a', 'belong to', 'has a', 'protected', 'receives action', 'specific', 'created by', 'desires', 'at location', 'part of', 'capable of', 'important', 'visible']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict fact = ['slimy', 'poisonous', 'rind']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - suppord fact predict = ['poisonous-has property', 'rind-part of', 'slimy-has property']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - correspond target = ['snake', 'orange']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - test id = 2712, question = Which object has fangs in its mouth, img = ILSVRC2012_test_00029408.JPEG\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - real suppord fact in dataset=['snake', 'used for', 'live in'], real answer = snake\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - normal model predict = ['snake', 'lizard', 'frog', 'monkey', 'armadillo', 'giraffe', 'turtle', 'tree', 'car', 'banjo']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict = ['turtle', 'person', 'banana', 'snake', 'lizard', 'frog', 'monkey', 'armadillo', 'giraffe', 'tree']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict relation = ['has a', 'has property', 'at location', 'is a', 'part of', 'belong to', 'used for', 'capable of', 'receives action', 'related to', 'blind', 'surface', 'animal family', 'social', 'long']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict fact = ['hide in it shell', 'grow in knowledge', \"monkey's hand\"]\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - suppord fact predict = [\"monkey's hand-at location\", 'hide in it shell-capable of', 'grow in knowledge-capable of']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - correspond target = ['banana', 'turtle', 'person']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - test id = 2742, question = Which object in this image is a pest?, img = ILSVRC2012_test_00000196.JPEG\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - real suppord fact in dataset=['ant', 'is a', 'pet'], real answer = ant\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - normal model predict = ['trumpet', 'clock', 'camel', 'french horn', 'car', 'coffee', 'lizard', 'dragonfly', 'butterfly', 'horse']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict = ['camel', 'monkey', 'zebra', 'giraffe', 'trumpet', 'clock', 'french horn', 'car', 'coffee', 'lizard']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict relation = ['is a', 'related to', 'belong to', 'has property', 'part of', 'used for', 'has a', 'cool', 'important', 'capable of', 'visible', 'specific', 'easy', 'accurate', 'good']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict fact = ['eukaryote', 'ruminant', 'primate']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - suppord fact predict = ['primate-is a', 'ruminant-is a', 'eukaryote-belong to', 'primate-related to']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - correspond target = ['zebra', 'monkey', 'camel', 'giraffe']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - test id = 1221, question = What thing does the animal in this image have as a part?, img = COCO_val2014_000000010822.jpg\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - real suppord fact in dataset=['zebra', 'has a', 'stripe'], real answer = stripe\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - normal model predict = ['zebra', 'stripe', 'blue', 'long necked', 'cloud', 'bikini', 'giraffe', 'jazz blue', 'camel', 'ocean']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict = ['long necked', 'africa', 'animal', 'giraffidae', 'tree', 'skunk', 'even toed ungulate', 'dog', 'zoo', 'squirrel']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict relation = ['has a', 'part of', 'is a', 'related to', 'animal family', 'animal order', 'large', 'receives action', 'small', 'has property', 'capable of', 'social', 'used for', 'animal kingdom', 'at location']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict fact = ['giraffe', 'wolf', 'forest']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - suppord fact predict = ['giraffe-animal family', 'giraffe-animal order', 'giraffe-receives action', 'wolf-related to', 'forest-part of', 'forest-at location', 'giraffe-has property', 'giraffe-at location']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - correspond target = ['giraffidae', 'tree', 'animal', 'dog', 'zoo', 'squirrel', 'skunk', 'even toed ungulate', 'long necked', 'africa']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - test id = 2123, question = What do you need to make the instrument in the image work?, img = ILSVRC2012_test_00022927.JPEG\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - real suppord fact in dataset=['drum', 'related to', 'tick'], real answer = tick\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - normal model predict = ['car', 'travel in car', 'grass', 'vehicle', 'police', 'motorbike', 'ski slope', 'park', 'cheap', 'driving']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict = ['your house', 'printer', 'monitor', 'computer', 'window', 'work', 'tall build', 'pen', 'desk', 'keyboard']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict relation = ['used for', 'capable of', 'related to', 'at location', 'receives action', 'has property', 'belong to', 'animal order', 'has a', 'created by', 'specific', 'fast', 'high', 'surface', 'desires']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict fact = ['home office', 'office', 'help person']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - suppord fact predict = ['home office-at location', 'office-used for', 'office-has a', 'office-at location', 'help person-capable of']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - correspond target = ['pen', 'desk', 'your house', 'tall build', 'monitor', 'computer', 'window', 'keyboard', 'printer', 'work']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - test id = 134, question = which object in this image can be as a means of road transportation?, img = COCO_val2014_000000015827.jpg\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - real suppord fact in dataset=['motorcycle', 'belong to', 'road transport'], real answer = motorcycle\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - normal model predict = ['motorcycle', 'motorbike', 'truck', 'bicycle', 'vehicle', 'snowmobile', 'car', 'golfcart', 'airplane', 'spaceship']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict = ['bicycle', 'airplane', 'bus', 'boat', 'train', 'motorcycle', 'motorbike', 'truck', 'vehicle', 'snowmobile']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict relation = ['belong to', 'is a', 'related to', 'has property', 'used for', 'capable of', 'at location', 'visible', 'common', 'dangerous', 'has a', 'specific', 'important', 'accurate', 'protected']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict fact = ['mean of transportation', 'non pollute form of transport', 'form of transportation']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - suppord fact predict = ['form of transportation-is a', 'non pollute form of transport-is a', 'mean of transportation-is a']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - correspond target = ['airplane', 'bus', 'boat', 'train', 'bicycle']\r\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|████████▋                                  | 18/89 [00:11<00:38,  1.85it/s]INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - test id = 297, question = Which object in this image is a type of food?, img = COCO_val2014_000000131841.jpg\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - real suppord fact in dataset=['bread', 'is a', 'type of food'], real answer = bread\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - normal model predict = ['sandwich', 'bread', 'toast bread', 'fry bread', 'bagel', 'doughnut', 'donut', 'hamburger', 'cake', 'fork']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict = ['donut', 'hamburger', 'cake', 'fork', 'pretzel', 'salad', 'pizza', 'fruit', 'apple', 'vegetable']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict relation = ['is a', 'belong to', 'related to', 'has a', 'important', 'at location', 'used for', 'part of', 'capable of', 'good', 'has property', 'specific', 'cool', 'receives action', 'animal class']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict fact = ['food', 'eat food', 'stock food']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - suppord fact predict = ['food-related to', 'food-is a', 'eat food-related to', 'food-belong to', 'eat food-used for']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - correspond target = ['cake', 'apple', 'fruit', 'salad', 'pizza', 'pretzel', 'donut', 'vegetable', 'fork', 'hamburger']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - test id = 1486, question = What does elephant belong to, img = COCO_val2014_000000118401.jpg\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - real suppord fact in dataset=['elephant', 'belong to', 'animal'], real answer = animal\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - normal model predict = ['elephant', 'cow', 'giraffe', 'antelope', 'bird', 'camel', 'herd sheep', 'hippopotamus', 'sheep', 'animal']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict = ['desert', 'zoo', 'poisonous', 'warm place', 'chordata', 'no leg', 'banana', 'carnivora', 'elephant', 'cow']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict relation = ['related to', 'belong to', 'is a', 'has a', 'at location', 'capable of', 'has property', 'animal order', 'animal family', 'specific', 'receives action', 'used for', 'big', 'animal phylum', 'part of']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - our model predict fact = ['monkey', 'snake', 'fox']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - suppord fact predict = ['snake-has property', 'fox-animal order', 'fox-animal phylum', 'snake-at location', 'monkey-at location', 'snake-has a', 'monkey-related to']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - correspond target = ['chordata', 'carnivora', 'desert', 'no leg', 'zoo', 'warm place', 'banana', 'poisonous']\n",
      "INFO - 08/13/22 23:30:26 - 0:00:44 - #################################################################################\n",
      " 21%|█████████▏                                 | 19/89 [00:12<00:38,  1.82it/s]INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - test id = 1388, question = what do the person stand on?, img = COCO_val2014_000000015559.jpg\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - real suppord fact in dataset=['snow', 'has property', 'white and cold'], real answer = snow\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - normal model predict = ['ski slope', 'bench', 'throw', 'snow', 'skiiers', 'ski', 'sit outside', 'sand', 'grass', 'mountainous area']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict = ['ski slope', 'throw', 'kite', 'hammer', 'axe', 'elephant', 'bench', 'snow', 'skiiers', 'ski']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict relation = ['at location', 'capable of', 'related to', 'used for', 'belong to', 'has a', 'good', 'has property', 'specific', 'is a', 'animal order', 'receives action', 'fast', 'stable', 'accurate']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict fact = ['skiiers', 'person', 'hurt person']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - suppord fact predict = ['skiiers-at location', 'hurt person-capable of', 'person-has property', 'person-capable of', 'hurt person-used for']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - correspond target = ['axe', 'ski slope', 'throw', 'elephant', 'kite', 'hammer']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - test id = 2540, question = What does this place have?, img = COCO_val2014_000000134112.jpg\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - real suppord fact in dataset=['bedroom', 'has a', 'bed'], real answer = bed\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - normal model predict = ['hair', 'cut', 'laboratory', 'peel', 'clean your tooth in', 'scissors', 'hair spray', 'computer', 'work', 'cold and wet']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict = ['hair', 'computer', 'work', 'mouse', 'window', 'animal', 'human', 'desk', 'monitor', 'pen']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict relation = ['has a', 'at location', 'has property', 'used for', 'related to', 'belong to', 'is a', 'desires', 'receives action', 'part of', 'capable of', 'animal order', 'good', 'specific', 'common']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict fact = ['office', 'dog', 'cat']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - suppord fact predict = ['office-used for', 'dog-good', 'office-has a', 'dog-has a', 'office-at location', 'dog-belong to', 'cat-capable of']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - correspond target = ['pen', 'animal', 'desk', 'monitor', 'computer', 'window', 'hair', 'work', 'mouse', 'human']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - test id = 2333, question = What objects in this image are inspirational, img = ILSVRC2012_test_00035105.JPEG\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - real suppord fact in dataset=['forest road', 'has property', 'inspirational'], real answer = forest road\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - normal model predict = ['stop sign', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car', 'bus', 'person']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict = ['stop sign', 'horse', 'tv', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict relation = ['capable of', 'is a', 'has property', 'receives action', 'has a', 'used for', 'related to', 'part of', 'desires', 'at location', 'belong to', 'created by', 'specific', 'good', 'animal order']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict fact = ['traffic sign', 'clop', 'advertise']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - suppord fact predict = ['advertise-used for', 'traffic sign-belong to', 'clop-related to']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - correspond target = ['stop sign', 'tv', 'horse']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - test id = 827, question = What objects in this image are inspirational, img = ILSVRC2012_test_00035105.JPEG\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - real suppord fact in dataset=['forest road', 'has property', 'inspirational'], real answer = forest road\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - normal model predict = ['stop sign', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car', 'bus', 'person']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict = ['stop sign', 'horse', 'tv', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict relation = ['capable of', 'is a', 'has property', 'receives action', 'has a', 'used for', 'related to', 'part of', 'desires', 'at location', 'belong to', 'created by', 'specific', 'good', 'animal order']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict fact = ['traffic sign', 'clop', 'advertise']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - suppord fact predict = ['advertise-used for', 'traffic sign-belong to', 'clop-related to']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - correspond target = ['stop sign', 'tv', 'horse']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - test id = 420, question = Which object in this image is related to blade?, img = ILSVRC2012_test_00037716.JPEG\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - real suppord fact in dataset=['blade', 'related to', 'grass'], real answer = grass\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - normal model predict = ['elephant', 'horse', 'cattle', 'bear', 'cow', 'fence', 'sheep', 'hippopotamus', 'dog', 'scissors']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict = ['elephant', 'horse', 'dog', 'lizard', 'zebra', 'cat', 'kite', 'sofa', 'cattle', 'bear']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict relation = ['related to', 'specific', 'important', 'belong to', 'part of', 'animal order', 'common', 'social', 'has a', 'used for', 'capable of', 'is a', 'frequent', 'accurate', 'prevalent']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict fact = ['tail', 'leg', 'tusk']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - suppord fact predict = ['leg-part of', 'tusk-has a', 'tail-part of', 'tusk-related to', 'leg-has a', 'tail-has a']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - correspond target = ['cat', 'sofa', 'horse', 'dog', 'zebra', 'elephant', 'lizard', 'kite']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - test id = 2630, question = What is the disc-shaped food item in this image?, img = COCO_val2014_000000014353.jpg\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - real suppord fact in dataset=['pizza', 'is a', 'disc shape food item'], real answer = pizza\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - normal model predict = ['pizza', 'cake', 'cheese', 'italian', 'donut', 'lobster', 'oven', 'bakery', 'restaurant', 'chocolate']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict = ['cheese', 'italian', 'oven', 'bread', 'toast bread', 'kitchen', 'mushroom', 'fork', 'unhealthy', 'ye']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict relation = ['is a', 'belong to', 'related to', 'has property', 'part of', 'used for', 'has a', 'at location', 'common', 'animal order', 'good', 'fast', 'animal class', 'important', 'cheap']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict fact = ['toaster', 'kitchen utensil', 'pizza']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - suppord fact predict = ['toaster-related to', 'pizza-has a', 'toaster-used for', 'pizza-related to', 'kitchen utensil-is a', 'pizza-has property', 'pizza-at location', 'toaster-at location', 'pizza-belong to']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - correspond target = ['mushroom', 'kitchen', 'oven', 'bread', 'unhealthy', 'ye', 'toast bread', 'italian', 'fork', 'cheese']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - test id = 1608, question = which object in this image belongs to the category 'drinkware'?, img = COCO_val2014_000000003595.jpg\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - real suppord fact in dataset=['wine glass', 'belong to', 'drinkware'], real answer = wine glass\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - normal model predict = ['wine', 'bottle', 'wine glass', 'drink', 'beer', 'glass', 'fruit', 'cell phone', 'food', 'pomegranate']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict = ['crutch', 'clock', 'neck brace', 'flute', 'rugby ball', 'wine', 'bottle', 'wine glass', 'drink', 'beer']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict relation = ['belong to', 'desires', 'related to', 'loyal', 'animal kingdom', 'animal phylum', 'trustworthy', 'is a', 'animal order', 'comfortable', 'sensible', 'important', 'visible', 'protected', 'animal family']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict fact = ['bladder', 'tick', 'orthopedics']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - suppord fact predict = ['orthopedics-belong to', 'bladder-related to', 'tick-related to']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - correspond target = ['rugby ball', 'clock', 'crutch', 'neck brace', 'flute']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - test id = 2657, question = What is the cylindrical object shown in this image ?, img = ILSVRC2012_test_00019516.JPEG\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - real suppord fact in dataset=['drum', 'related to', 'cylindrical'], real answer = drum\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - normal model predict = ['surfboard', 'drum', 'laboratory', 'wall', 'monitor', 'fish', 'cheese', 'whale', 'balance beam', 'apartment']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict = ['laboratory', 'cheese', 'house', 'fork', 'plate', 'knife in drawer', 'light', 'restaurant', 'toilet paper', 'cup']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict relation = ['part of', 'is a', 'related to', 'has property', 'belong to', 'capable of', 'animal order', 'at location', 'important', 'animal class', 'has a', 'receives action', 'animal family', 'good', 'specific']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict fact = ['kitchen utensil', 'beaker', 'kitchen']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - suppord fact predict = ['kitchen-at location', 'kitchen utensil-is a', 'kitchen-part of', 'beaker-at location', 'kitchen-belong to']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - correspond target = ['light', 'toilet paper', 'knife in drawer', 'house', 'plate', 'laboratory', 'restaurant', 'cup', 'fork', 'cheese']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - test id = 2629, question = Which object in this image is used for play?, img = ILSVRC2012_test_00002135.JPEG\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - real suppord fact in dataset=['sofa', 'used for', 'watch tv'], real answer = sofa\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - normal model predict = ['couch', 'sofa', 'bed', 'pillows', 'bedroom', 'baby bed', 'sleep', 'chair', 'blanket', 'tv']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict = ['piano', 'tennis ball', 'toy', 'cello', 'guitar', 'saxophone', 'harp', 'play baseball', 'racquet', 'frisbee']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict relation = ['used for', 'related to', 'specific', 'belong to', 'effective', 'efficient', 'important', 'popular', 'easy', 'common', 'part of', 'capable of', 'convenient', 'good', 'has property']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict fact = ['play', 'play tune', 'play music']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - suppord fact predict = ['play-belong to', 'play-related to', 'play-used for', 'play music-used for', 'play tune-used for']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - correspond target = ['piano', 'harp', 'toy', 'tennis ball', 'frisbee', 'cello', 'guitar', 'racquet', 'play baseball', 'saxophone']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - test id = 824, question = What objects in this image are inspirational, img = ILSVRC2012_test_00035105.JPEG\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - real suppord fact in dataset=['forest road', 'has property', 'inspirational'], real answer = forest road\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - normal model predict = ['stop sign', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car', 'bus', 'person']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict = ['stop sign', 'horse', 'tv', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict relation = ['capable of', 'is a', 'has property', 'receives action', 'has a', 'used for', 'related to', 'part of', 'desires', 'at location', 'belong to', 'created by', 'specific', 'good', 'animal order']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict fact = ['traffic sign', 'clop', 'advertise']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - suppord fact predict = ['advertise-used for', 'traffic sign-belong to', 'clop-related to']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - correspond target = ['stop sign', 'tv', 'horse']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - test id = 1821, question = Which object in the image is related to Normandy pippins?, img = COCO_val2014_000000007913.jpg\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - real suppord fact in dataset=['normandy pippin', 'related to', 'apple'], real answer = apple\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - normal model predict = ['pomegranate', 'fig', 'fruit', 'lemon', 'strawberry', 'pineapple', 'apple', 'cucumber', 'pare apple', 'walnut']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict = ['elephant', 'ray', 'trombone', 'pomegranate', 'fig', 'fruit', 'lemon', 'strawberry', 'pineapple', 'apple']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict relation = ['related to', 'specific', 'belong to', 'used for', 'important', 'common', 'part of', 'social', 'animal order', 'prevalent', 'is a', 'at location', 'frequent', 'acid', 'accurate']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict fact = ['batoidea', 'therapsida', 'tromboner']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - suppord fact predict = ['batoidea-belong to', 'therapsida-belong to', 'tromboner-related to']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - correspond target = ['trombone', 'ray', 'elephant']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - test id = 335, question = what is the name of the animal in this image?, img = COCO_val2014_000000002315.jpg\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - real suppord fact in dataset=['elephant', 'is a', 'animal'], real answer = elephant\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - normal model predict = ['whale', 'animal', 'mammal', 'dolphin', 'fish', 'blue', 'water', 'human', 'cow', 'orange']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict = ['giraffidae', 'green', 'even toed ungulate', 'shell', 'africa', 'zoo', 'chordata', 'wild', 'low', 'extremely high blood pressure']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict relation = ['is a', 'related to', 'animal order', 'animal family', 'animal class', 'animal kingdom', 'belong to', 'animal phylum', 'has a', 'has property', 'specific', 'important', 'common', 'part of', 'at location']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - our model predict fact = ['giraffe', 'turtle', 'frog']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - suppord fact predict = ['giraffe-animal family', 'giraffe-animal order', 'turtle-has a', 'giraffe-has a', 'turtle-has property', 'giraffe-animal phylum', 'frog-at location', 'giraffe-at location', 'frog-has property']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - correspond target = ['chordata', 'giraffidae', 'extremely high blood pressure', 'wild', 'shell', 'zoo', 'low', 'green', 'even toed ungulate', 'africa']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:45 - #################################################################################\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████▋                                 | 20/89 [00:12<00:40,  1.71it/s]INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - test id = 1224, question = Which object in this image belongs to the category of Megafauna?, img = ILSVRC2012_test_00002904.JPEG\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - real suppord fact in dataset=['hippopotamus', 'belong to', 'megafauna'], real answer = hippopotamus\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - normal model predict = ['cow', 'elephant', 'grass', 'dog', 'chain saw', 'screwdriver', 'hammer', 'monkey', 'frog', 'dog poop']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict = ['elephant', 'skateboard', 'trombone', 'cow', 'grass', 'dog', 'chain saw', 'screwdriver', 'hammer', 'monkey']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict relation = ['belong to', 'desires', 'loyal', 'animal kingdom', 'animal phylum', 'trustworthy', 'animal order', 'comfortable', 'protected', 'sensible', 'related to', 'is a', 'visible', 'primitive', 'human']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict fact = ['boardsport', 'therapsida', 'tromboner']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - suppord fact predict = ['tromboner-related to', 'therapsida-belong to', 'boardsport-belong to']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - correspond target = ['trombone', 'elephant', 'skateboard']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - test id = 2029, question = Which object in this image are dangerous?, img = ILSVRC2012_test_00048011.JPEG\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - real suppord fact in dataset=['axe', 'has property', 'dangerous'], real answer = axe\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - normal model predict = ['hammer', 'scissors', 'screwdriver', 'corkscrew', 'knife', 'wood', 'chain saw', 'ruler', 'metal', 'axe']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict = ['snake', 'clock', 'person', 'flute', 'crutch', 'hammer', 'scissors', 'screwdriver', 'corkscrew', 'knife']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict relation = ['related to', 'used for', 'is a', 'has property', 'capable of', 'has a', 'belong to', 'part of', 'at location', 'specific', 'receives action', 'important', 'dangerous', 'desires', 'common']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict fact = ['be dangerous', 'tick', 'feel pain both physically and emotionally']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - suppord fact predict = ['tick-related to', 'feel pain both physically and emotionally-capable of', 'be dangerous-capable of']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - correspond target = ['clock', 'person', 'crutch', 'flute', 'snake']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - test id = 2686, question = Which object in this image has a drink, img = COCO_val2014_000000016030.jpg\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - real suppord fact in dataset=['cup', 'has a', 'drink'], real answer = cup\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - normal model predict = ['wine glass', 'wine', 'glass', 'coffee', 'drink', 'beer', 'white', 'jazz blue', 'pizza', 'chocolate']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict = ['keyboard', 'camel', 'piano', 'trombone', 'wine glass', 'wine', 'glass', 'coffee', 'drink', 'beer']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict relation = ['part of', 'has a', 'related to', 'is a', 'used for', 'specific', 'capable of', 'social', 'large', 'important', 'frequent', 'common', 'great', 'small', 'light']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict fact = ['slider', 'hump', 'key']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - suppord fact predict = ['hump-related to', 'key-has a', 'key-related to', 'key-part of', 'hump-part of', 'slider-related to']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - correspond target = ['keyboard', 'piano', 'camel', 'trombone']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - test id = 1478, question = What kind of machine the man choose to travel?, img = COCO_val2014_000000136833.jpg\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - real suppord fact in dataset=['motorcycle', 'used for', 'travel'], real answer = motorcycle\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - normal model predict = ['airplane', 'luggage', 'car', 'handbag', 'snowmobile', 'vehicle', 'surfboard', 'motorcycle', 'land airplane', 'store boat']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict = ['airplane', 'spaceship', 'person', 'fly', 'travel', 'airport', 'luggage', 'car', 'handbag', 'snowmobile']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict relation = ['capable of', 'is a', 'at location', 'used for', 'belong to', 'related to', 'animal order', 'safe', 'has property', 'receives action', 'animal family', 'has a', 'animal class', 'specific', 'part of']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict fact = ['flight', 'airplane', 'carry suitcase when they travel']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - suppord fact predict = ['flight-belong to', 'flight-capable of', 'airplane-used for', 'carry suitcase when they travel-capable of', 'airplane-safe', 'airplane-at location']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - correspond target = ['airplane', 'fly', 'person', 'travel', 'airport', 'spaceship']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - test id = 1557, question = Which animal in this image has no feet, img = ILSVRC2012_test_00029408.JPEG\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - real suppord fact in dataset=['snake', 'has a', 'no foot'], real answer = snake\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - normal model predict = ['snake', 'lizard', 'frog', 'giraffe', 'ray', 'armadillo', 'zebra', 'monkey', 'turtle', 'butterfly']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict = ['computer', 'person', 'snake', 'lizard', 'frog', 'giraffe', 'ray', 'armadillo', 'zebra', 'monkey']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict relation = ['has a', 'related to', 'part of', 'has property', 'used for', 'is a', 'capable of', 'large', 'receives action', 'long', 'social', 'big', 'firm', 'specific', 'frequent']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict fact = ['cost lot of money', 'pay on bill', 'fee themselves']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - suppord fact predict = ['cost lot of money-capable of', 'pay on bill-capable of', 'fee themselves-capable of']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - correspond target = ['computer', 'person']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - test id = 1141, question = Which object in this image has cups?, img = ILSVRC2012_test_00018779.JPEG\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - real suppord fact in dataset=['cup', 'related to', 'brassiere'], real answer = brassiere\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - normal model predict = ['person', 'make person happy', 'cake', 'thing', 'fork', 'any place where person live', 'romantic', 'hand', 'happy for bride and groom', 'hair']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict = ['glass', 'cup', 'pencil box', 'bottle', 'vase', 'handbag', 'beaker', 'suitcase', 'person', 'make person happy']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict relation = ['has a', 'part of', 'has property', 'capable of', 'is a', 'related to', 'belong to', 'used for', 'great', 'long', 'good', 'large', 'strong', 'at location', 'social']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict fact = ['hold juice', 'container', 'hold liquid']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - suppord fact predict = ['hold juice-used for', 'container-is a', 'hold liquid-capable of', 'container-belong to']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - correspond target = ['beaker', 'handbag', 'bottle', 'suitcase', 'pencil box', 'glass', 'cup', 'vase']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - test id = 989, question = which object in this image belong to the category of 'flight'?, img = COCO_val2014_000000100404.jpg\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - real suppord fact in dataset=['airplane', 'belong to', 'flight'], real answer = airplane\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - normal model predict = ['kite', 'coast', 'jellyfish', 'grass', 'sea', 'whale', 'sand', 'horse', 'ocean', 'protect person from sun and rain']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict = ['whale', 'surfboard', 'kite', 'coast', 'jellyfish', 'grass', 'sea', 'sand', 'horse', 'ocean']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict relation = ['belong to', 'desires', 'related to', 'loyal', 'trustworthy', 'animal kingdom', 'animal phylum', 'animal order', 'specific', 'important', 'protected', 'is a', 'sensible', 'capable of', 'human']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict fact = ['marine mammal', 'ocean', 'water sports']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - suppord fact predict = ['marine mammal-is a', 'marine mammal-belong to', 'water sports-belong to']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - correspond target = ['whale', 'surfboard']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - test id = 1219, question = What thing does the animal in this image have as a part?, img = COCO_val2014_000000010822.jpg\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - real suppord fact in dataset=['zebra', 'has a', 'stripe'], real answer = stripe\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - normal model predict = ['zebra', 'stripe', 'blue', 'long necked', 'cloud', 'bikini', 'giraffe', 'jazz blue', 'camel', 'ocean']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict = ['long necked', 'africa', 'animal', 'giraffidae', 'tree', 'skunk', 'even toed ungulate', 'dog', 'zoo', 'squirrel']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict relation = ['has a', 'part of', 'is a', 'related to', 'animal family', 'animal order', 'large', 'receives action', 'small', 'has property', 'capable of', 'social', 'used for', 'animal kingdom', 'at location']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict fact = ['giraffe', 'wolf', 'forest']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - suppord fact predict = ['giraffe-animal family', 'giraffe-animal order', 'giraffe-receives action', 'wolf-related to', 'forest-part of', 'forest-at location', 'giraffe-has property', 'giraffe-at location']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - correspond target = ['giraffidae', 'tree', 'animal', 'dog', 'zoo', 'squirrel', 'skunk', 'even toed ungulate', 'long necked', 'africa']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - test id = 1783, question = What do you call the Kitchenware on which the food is served? , img = COCO_val2014_000000111024.jpg\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - real suppord fact in dataset=['plate', 'belong to', 'kitchenware'], real answer = plate\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - normal model predict = ['bread', 'toast bread', 'fry bread', 'cheese', 'cook food', 'flour', 'salad', 'pizza', 'doughnut', 'oven']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict = ['bread', 'cheese', 'oven', 'bagel', 'mushroom', 'fridge', 'unhealthy', 'hamburger', 'italian', 'hot dog']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict relation = ['belong to', 'at location', 'has property', 'related to', 'receives action', 'used for', 'animal order', 'created by', 'has a', 'is a', 'protected', 'good', 'animal class', 'animal family', 'specific']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict fact = ['pizza', 'sandwich', 'bread']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - suppord fact predict = ['pizza-has a', 'sandwich-belong to', 'pizza-related to', 'bread-belong to', 'pizza-at location', 'pizza-has property', 'sandwich-used for', 'sandwich-at location', 'pizza-belong to']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - correspond target = ['bagel', 'cheese', 'mushroom', 'oven', 'hot dog', 'bread', 'fridge', 'unhealthy', 'italian', 'hamburger']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - test id = 41, question = Do you need small balls or big balls for this game?, img = ILSVRC2012_test_00042019.JPEG\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - real suppord fact in dataset=['table tennis', 'receives action', 'small'], real answer = small\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - normal model predict = ['racquet', 'wii', 'tennis racket', 'tennis', 'tennis ball', 'racket', 'volleyball', 'basketball', 'baseball', 'baseball bat']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict = ['racquet', 'tennis racket', 'tennis ball', 'racket', 'volleyball', 'basketball', 'baseball', 'soccer ball', 'rugby ball', 'wii']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict relation = ['used for', 'at location', 'belong to', 'has property', 'created by', 'related to', 'fast', 'expensive', 'receives action', 'is a', 'easy', 'animal order', 'has a', 'convenient', 'specific']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict fact = ['ball games', 'ball', 'olympic games']\r\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - suppord fact predict = ['ball-related to', 'olympic games-belong to', 'ball-is a', 'ball-belong to', 'ball games-belong to']\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:27 - 0:00:46 - correspond target = ['racquet', 'basketball', 'rugby ball', 'tennis racket', 'volleyball', 'racket', 'tennis ball', 'baseball', 'soccer ball']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - test id = 1802, question = What can ring in this image?, img = COCO_val2014_000000112997.jpg\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - real suppord fact in dataset=['cell phone', 'capable of', 'ring'], real answer = cell phone\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - normal model predict = ['vend stand', 'cell phone', 'bottle', 'hair spray', 'hammer', 'phone', 'printer', 'coffee', 'wash machine', 'hair']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict = ['mouse', 'keyboard', 'vend stand', 'cell phone', 'bottle', 'hair spray', 'hammer', 'phone', 'printer', 'coffee']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict relation = ['used for', 'related to', 'has property', 'at location', 'is a', 'capable of', 'belong to', 'has a', 'specific', 'common', 'good', 'important', 'part of', 'fast', 'expensive']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict fact = ['enter text', 'leave click', 'click']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - suppord fact predict = ['click-used for', 'leave click-related to', 'enter text-used for']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - correspond target = ['keyboard', 'mouse']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - test id = 2809, question = What can the object in this image do, img = ILSVRC2012_test_00057349.JPEG\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - real suppord fact in dataset=['can opener', 'capable of', 'open can'], real answer = open can\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - normal model predict = ['hammer', 'scissors', 'hand', 'knife', 'horizontal bar', 'vend stand', 'apple', 'corkscrew', 'cut', 'drink']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict = ['use twice day', 'toothbrush', 'bathroom', 'dog', 'ant', 'goldfish', 'cat', 'hammer', 'scissors', 'hand']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict relation = ['used for', 'has property', 'at location', 'related to', 'belong to', 'specific', 'capable of', 'good', 'is a', 'animal order', 'part of', 'has a', 'created by', 'receives action', 'common']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - our model predict fact = ['dental tool', 'pet', 'toothbrush']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - suppord fact predict = ['pet-is a', 'pet-belong to', 'dental tool-is a', 'pet-used for', 'toothbrush-at location', 'toothbrush-receives action', 'pet-related to']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - correspond target = ['cat', 'dog', 'ant', 'bathroom', 'goldfish', 'toothbrush', 'use twice day']\n",
      "INFO - 08/13/22 23:30:27 - 0:00:46 - #################################################################################\n",
      " 24%|██████████▏                                | 21/89 [00:13<00:41,  1.65it/s]INFO - 08/13/22 23:30:28 - 0:00:46 - #################################################################################\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - test id = 101, question = What is the dog lying on in the image?, img = ILSVRC2012_test_00011808.JPEG\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - real suppord fact in dataset=['sofa', 'used for', 'lie on'], real answer = sofa\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - normal model predict = ['dog', 'donut', 'cat', 'human', 'hair', 'doughnut', 'mouse', 'hot dog', 'dog poop', 'kitten']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - our model predict = ['dog', 'cat', 'human', 'animal', 'goldfish', 'herd sheep', 'ant', 'donut', 'hair', 'doughnut']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - our model predict relation = ['related to', 'animal order', 'good', 'is a', 'used for', 'important', 'at location', 'part of', 'animal class', 'capable of', 'specific', 'great', 'human', 'belong to', 'fast']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - our model predict fact = ['dog', 'pet', 'pet cat']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - suppord fact predict = ['dog-used for', 'pet-is a', 'dog-good', 'pet-belong to', 'pet-used for', 'dog-belong to', 'pet-related to']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - correspond target = ['cat', 'animal', 'dog', 'ant', 'herd sheep', 'goldfish', 'human']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - #################################################################################\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - #################################################################################\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - test id = 320, question = what can you find in this image?, img = ILSVRC2012_test_00002037.JPEG\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - real suppord fact in dataset=['ocean', 'at location', 'new york'], real answer = ocean\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - normal model predict = ['boat', 'wave', 'water', 'sand', 'shore boat', 'store boat', 'sail boat', 'desert', 'lot of sand', 'surfboard']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - our model predict = ['wave', 'water', 'sand', 'whale', 'large ship', 'coast', 'blue', 'dolphin', 'swim', 'turtle']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - our model predict relation = ['has property', 'at location', 'has a', 'related to', 'belong to', 'used for', 'is a', 'capable of', 'protected', 'specific', 'surface', 'light', 'visible', 'part of', 'stable']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - our model predict fact = ['ocean', 'sea', 'ocean beach']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - suppord fact predict = ['ocean-has a', 'ocean-at location', 'ocean-part of', 'ocean beach-used for', 'ocean-used for', 'sea-at location', 'ocean-has property']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - correspond target = ['blue', 'coast', 'turtle', 'wave', 'whale', 'water', 'swim', 'large ship', 'dolphin', 'sand']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - #################################################################################\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - #################################################################################\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - test id = 795, question = Where the animal is laying on?, img = ILSVRC2012_test_00003730.JPEG\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - real suppord fact in dataset=['whale', 'at location', 'beach'], real answer = beach\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - normal model predict = ['shore boat', 'river', 'sand', 'beach', 'sea', 'coast', 'sandy', 'mountainous area', 'boat', 'sail boat']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - our model predict = ['sofa', 'seal', 'person', 'shore boat', 'river', 'sand', 'beach', 'sea', 'coast', 'sandy']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - our model predict relation = ['is a', 'related to', 'belong to', 'has property', 'at location', 'used for', 'has a', 'capable of', 'light', 'receives action', 'specific', 'part of', 'good', 'cool', 'important']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - our model predict fact = ['lie on', 'stand on foot', 'position itsself on rock']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - suppord fact predict = ['lie on-used for', 'position itsself on rock-capable of', 'stand on foot-capable of']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - correspond target = ['seal', 'sofa', 'person']\n",
      "INFO - 08/13/22 23:30:28 - 0:00:46 - #################################################################################\n",
      " 25%|██████████▋                                | 22/89 [00:14<00:42,  1.58it/s]INFO - 08/13/22 23:30:29 - 0:00:47 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - test id = 722, question = Which object in this image is a kind of American Cuisine ?, img = COCO_val2014_000000149444.jpg\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - real suppord fact in dataset=['donut', 'belong to', 'cuisine of the americas'], real answer = donut\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - normal model predict = ['donut', 'pizza', 'doughnut', 'sandwich', 'bakery', 'chocolate', 'hotdog', 'bread', 'burrito', 'bagel']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict = ['pizza', 'sandwich', 'hot dog', 'donut', 'doughnut', 'bakery', 'chocolate', 'hotdog', 'bread', 'burrito']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict relation = ['belong to', 'is a', 'related to', 'has property', 'has a', 'at location', 'animal class', 'animal phylum', 'important', 'dangerous', 'visible', 'trustworthy', 'common', 'sensible', 'specific']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict fact = ['irish cuisine', 'european cuisine', 'traditional american food']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - suppord fact predict = ['irish cuisine-belong to', 'traditional american food-is a', 'european cuisine-belong to']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - correspond target = ['hot dog', 'pizza', 'sandwich']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - test id = 511, question = What is the healthier food in the image ?, img = COCO_val2014_000000121826.jpg\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - real suppord fact in dataset=['fesh vegtables', 'part of', 'salad'], real answer = fesh vegtables\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - normal model predict = ['vegetable', 'cheese', 'fruit', 'meat', 'food', 'salad', 'strawberry', 'vegetarian', 'green', 'prepare food']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict = ['vegetable', 'fruit', 'salad', 'orange', 'lettuce', 'pizza', 'hot dog', 'fork', 'fig', 'hamburger']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict relation = ['belong to', 'related to', 'is a', 'easy', 'animal order', 'important', 'used for', 'animal class', 'common', 'created by', 'popular', 'fast', 'specific', 'good', 'animal kingdom']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict fact = ['food', 'eat food', 'snack food']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - suppord fact predict = ['eat food-related to', 'eat food-used for', 'food-is a', 'food-belong to']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - correspond target = ['fig', 'hamburger', 'hot dog', 'salad', 'orange', 'lettuce', 'pizza', 'vegetable', 'fork', 'fruit']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - test id = 2373, question = Which animal in this image can be found in jungle, img = COCO_val2014_000000015070.jpg\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - real suppord fact in dataset=['squirrel', 'at location', 'jungle'], real answer = squirrel\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - normal model predict = ['cat', 'dog', 'kitten', 'rabbit', 'monkey', 'dog poop', 'squirrel', 'otter', 'skunk', 'ray']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict = ['cat', 'dog', 'goldfish', 'person', 'kitten', 'rabbit', 'monkey', 'dog poop', 'squirrel', 'otter']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict relation = ['at location', 'capable of', 'has a', 'used for', 'belong to', 'specific', 'human', 'related to', 'good', 'visible', 'active', 'great', 'has property', 'accurate', 'desires']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict fact = ['pet', 'pet cat', 'kitten']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - suppord fact predict = ['pet-belong to', 'pet-used for', 'pet cat-desires', 'pet-related to', 'kitten-has a']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - correspond target = ['cat', 'person', 'goldfish', 'dog']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - test id = 2606, question = What can be found in this place?, img = ILSVRC2012_test_00019930.JPEG\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - real suppord fact in dataset=['dancer', 'at location', 'ballroom'], real answer = dancer\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - normal model predict = ['sound control room', 'street', 'thing', 'modern device', 'cafe', 'restaurant', 'horizontal bar', 'space to run and play', 'lot of sand', 'music studio']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict = ['sound control room', 'furniture', 'wall', 'house', 'sleep away from home', 'person', 'human', 'chair', 'sleep', 'couch']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict relation = ['at location', 'used for', 'has a', 'part of', 'related to', 'has property', 'belong to', 'specific', 'animal order', 'capable of', 'is a', 'receives action', 'animal family', 'social', 'surface']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict fact = ['music studio', 'room', 'hotel room']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - suppord fact predict = ['hotel room-used for', 'room-at location', 'music studio-at location', 'room-has a']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - correspond target = ['wall', 'sleep', 'house', 'furniture', 'couch', 'chair', 'person', 'sleep away from home', 'human', 'sound control room']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - test id = 862, question = What object in the image is a subclass of box?, img = COCO_val2014_000000108408.jpg\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - real suppord fact in dataset=['suitcase', 'is a', 'box'], real answer = suitcase\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - normal model predict = ['luggage', 'suitcase', 'car', 'truck', 'vend stand', 'bicycle', 'bottle', 'cart', 'travel in car', 'railroad track']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict = ['gift shop', 'dog', 'shirt', 'luggage', 'suitcase', 'car', 'truck', 'vend stand', 'bicycle', 'bottle']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict relation = ['is a', 'belong to', 'related to', 'used for', 'has a', 'has property', 'good', 'at location', 'capable of', 'part of', 'easy', 'important', 'specific', 'cool', 'great']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict fact = ['form of clothe', 'name', 'gift']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - suppord fact predict = ['form of clothe-is a', 'gift-at location', 'name-has a']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - correspond target = ['shirt', 'gift shop', 'dog']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - test id = 2777, question = Which object in this image is a kind of Automotive technologies?, img = ILSVRC2012_test_00004836.JPEG\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - real suppord fact in dataset=['snowmobile', 'belong to', 'automotive technologies'], real answer = snowmobile\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - normal model predict = ['snowboard', 'ski', 'snowmobile', 'ski slope', 'snow', 'skiiers', 'skiier', 'mountain', 'bicycle', 'skateboard']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict = ['snowboard', 'car', 'motorcycle', 'surfboard', 'ski', 'snowmobile', 'ski slope', 'snow', 'skiiers', 'skiier']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict relation = ['is a', 'belong to', 'has a', 'related to', 'at location', 'part of', 'receives action', 'cool', 'has property', 'animal class', 'visible', 'animal phylum', 'sweet', 'specific', 'loud']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict fact = ['sport equipment', 'automobile', 'motor vehicle']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - suppord fact predict = ['sport equipment-is a', 'motor vehicle-is a']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - correspond target = ['motorcycle', 'surfboard', 'car', 'snowboard']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - test id = 879, question = Which object in this image is related to distantness?, img = ILSVRC2012_test_00008552.JPEG\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - real suppord fact in dataset=['distantness', 'related to', 'remote'], real answer = remote\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - normal model predict = ['cell phone', 'keyboard', 'phone', 'hand', 'metronome', 'ruler', 'scissors', 'button', 'control', 'guitar']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict = ['cell phone', 'elephant', 'trombone', 'keyboard', 'phone', 'hand', 'metronome', 'ruler', 'scissors', 'button']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict relation = ['related to', 'specific', 'belong to', 'important', 'used for', 'common', 'at location', 'part of', 'animal order', 'social', 'prevalent', 'accurate', 'has property', 'capable of', 'visible']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - our model predict fact = ['m', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - suppord fact predict = ['m-related to', 'therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - correspond target = ['trombone', 'elephant', 'cell phone']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:47 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26%|███████████                                | 23/89 [00:15<00:44,  1.50it/s]INFO - 08/13/22 23:30:29 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - test id = 913, question = Where does the object at the bottom of the image can be found in?, img = COCO_val2014_000000026501.jpg\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - real suppord fact in dataset=['bus', 'at location', 'street'], real answer = street\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - normal model predict = ['mountainous area', 'hotel room', 'airport', 'city', 'tourist', 'beach', 'park', 'park space', 'zoo', 'travel']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - our model predict = ['airport', 'zoo', 'travel', 'africa', 'extremely high blood pressure', 'fly', 'giraffidae', 'long necked', 'mountainous area', 'hotel room']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - our model predict relation = ['at location', 'has a', 'is a', 'capable of', 'part of', 'used for', 'has property', 'animal family', 'long', 'small', 'human', 'convenient', 'compact', 'common', 'surface']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - our model predict fact = ['monkey', 'giraffe', 'airplane']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - suppord fact predict = ['giraffe-animal family', 'giraffe-has a', 'airplane-used for', 'airplane-at location', 'giraffe-has property', 'giraffe-at location', 'monkey-at location']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - correspond target = ['giraffidae', 'extremely high blood pressure', 'fly', 'zoo', 'long necked', 'africa', 'airport', 'travel']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - test id = 396, question = What property does the scenario in this image have?, img = ILSVRC2012_test_00000082.JPEG\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - real suppord fact in dataset=['wedding', 'has property', 'costly'], real answer = wedding\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - normal model predict = ['romantic', 'pleasant', 'smooth', 'hair', 'sweet and juicy', 'cold and wet', 'beach', 'clean your tooth in', 'warm place', 'short']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - our model predict = ['romantic', 'smooth', 'cold and wet', 'happy for bride and groom', 'expensive', 'cake', 'cold', 'fun', 'costly', 'white']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - our model predict relation = ['has property', 'has a', 'belong to', 'part of', 'at location', 'used for', 'protected', 'created by', 'receives action', 'is a', 'related to', 'firm', 'animal family', 'expensive', 'capable of']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - our model predict fact = ['wedding', 'office', 'snow']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - suppord fact predict = ['snow-belong to', 'wedding-has property', 'snow-has property', 'wedding-related to', 'snow-has a']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - correspond target = ['cake', 'smooth', 'fun', 'expensive', 'cold and wet', 'cold', 'happy for bride and groom', 'white', 'costly', 'romantic']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - test id = 917, question = Which object in this image belongs to the category Gymnastics?, img = ILSVRC2012_test_00008843.JPEG\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - real suppord fact in dataset=['balance beam', 'belong to', 'gymnastics'], real answer = balance beam\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - normal model predict = ['basketball', 'volleyball', 'child', 'skateboard', 'toddler', 'play basketball', 'snowboard', 'tennis', 'sleep', 'ski']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - our model predict = ['baby bed', 'dining table', 'monitor', 'bed', 'sofa', 'chair', 'cabinets', 'desk', 'cabinet', 'basketball']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - our model predict relation = ['belong to', 'desires', 'is a', 'loyal', 'animal kingdom', 'animal phylum', 'comfortable', 'trustworthy', 'sensible', 'animal order', 'small', 'related to', 'capable of', 'loud', 'visible']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - our model predict fact = ['furniture', 'sleep', 'africa']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - suppord fact predict = ['sleep-related to', 'furniture-is a', 'furniture-related to', 'sleep-belong to', 'furniture-belong to']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - correspond target = ['sofa', 'baby bed', 'desk', 'bed', 'monitor', 'chair', 'cabinets', 'cabinet', 'dining table']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - test id = 2486, question = which object in this image is regarded as a pet in most family ?, img = COCO_val2014_000000131131.jpg\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - real suppord fact in dataset=['cat', 'at location', 'many people home'], real answer = cat\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - normal model predict = ['cat', 'kitten', 'dog', 'dog poop', 'otter', 'animal', 'kept as pets', 'rabbit', 'skunk', 'tv']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - our model predict = ['dog', 'goldfish', 'cat', 'kitten', 'dog poop', 'otter', 'animal', 'kept as pets', 'rabbit', 'skunk']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - our model predict relation = ['is a', 'capable of', 'has property', 'belong to', 'sensible', 'safe', 'visible', 'loyal', 'intelligent', 'has a', 'desires', 'trustworthy', 'animal class', 'independent', 'at location']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - our model predict fact = ['popular family pet', 'popular pet', 'great pet']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - suppord fact predict = ['popular family pet-is a', 'popular pet-is a', 'great pet-is a']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - correspond target = ['goldfish', 'dog']\n",
      "INFO - 08/13/22 23:30:29 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - test id = 22, question = What is white in this image?, img = COCO_val2014_000000109889.jpg\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - real suppord fact in dataset=['snow', 'has property', 'usually white'], real answer = snow\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - normal model predict = ['ski', 'ski slope', 'mountain', 'snow', 'skiier', 'skiiers', 'snowboard', 'snowmobile', 'kite', 'flowers']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict = ['banana', 'baseball', 'ski', 'ski slope', 'mountain', 'snow', 'skiier', 'skiiers', 'snowboard', 'snowmobile']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict relation = ['related to', 'belong to', 'is a', 'has property', 'has a', 'at location', 'specific', 'capable of', 'receives action', 'stable', 'used for', 'part of', 'desires', 'important', 'animal order']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict fact = ['outdoor sport', 'green or yellow in color', 'yellow with small brown spot when ripe']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - suppord fact predict = ['green or yellow in color-has property', 'outdoor sport-is a', 'yellow with small brown spot when ripe-has property']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - correspond target = ['banana', 'baseball']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - test id = 2382, question = Which object in this image can be tucked in?, img = COCO_val2014_000000100428.jpg\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - real suppord fact in dataset=['tuck in', 'related to', 'shirt'], real answer = shirt\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - normal model predict = ['chair', 'person', 'sofa', 'toilet seat', 'head', 'hotel room', 'tennis ball', 'bench', 'tennis racket', 'desk']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict = ['chair', 'sofa', 'person', 'toilet seat', 'head', 'hotel room', 'tennis ball', 'bench', 'tennis racket', 'desk']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict relation = ['at location', 'has property', 'capable of', 'used for', 'is a', 'has a', 'belong to', 'part of', 'desires', 'related to', 'receives action', 'visible', 'specific', 'surface', 'active']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict fact = ['comfortable to sit in', 'sit in', 'comfortable place to sit']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - suppord fact predict = ['sit in-used for', 'sit in-is a', 'comfortable to sit in-has property', 'comfortable place to sit-is a']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - correspond target = ['sofa', 'chair']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - test id = 2175, question = What object in this image is bigger than an ant?, img = COCO_val2014_000000101959.jpg\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - real suppord fact in dataset=['elephant', 'is a', 'big than ant'], real answer = elephant\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - normal model predict = ['elephant', 'cow', 'hippopotamus', 'horse', 'cattle', 'camel', 'herd sheep', 'whale', 'sheep', 'big']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict = ['cow', 'giraffe', 'elephant', 'hippopotamus', 'horse', 'cattle', 'camel', 'herd sheep', 'whale', 'sheep']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict relation = ['big', 'tall', 'good', 'large', 'long', 'small', 'important', 'great', 'comfortable', 'expensive', 'crowded', 'tough', 'easy', 'strong', 'cheap']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict fact = ['ant', 'wasp', 'insect']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - suppord fact predict = ['ant-tall', 'ant-big']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - correspond target = ['giraffe', 'cow']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27%|███████████▌                               | 24/89 [00:15<00:42,  1.52it/s]INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - test id = 684, question = What kind of media is shown in this image ?, img = COCO_val2014_000000146487.jpg\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - real suppord fact in dataset=['tv', 'is a', 'medium'], real answer = tv\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - normal model predict = ['bedroom', 'couch', 'sofa', 'bed', 'monitor', 'furniture', 'pillows', 'bathroom', 'wall', 'apartment']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict = ['couch', 'furniture', 'wall', 'house', 'chair', 'lamp', 'park space', 'human', 'person', 'bedroom']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict relation = ['is a', 'belong to', 'related to', 'used for', 'has a', 'good', 'at location', 'part of', 'fast', 'animal order', 'capable of', 'important', 'easy', 'receives action', 'common']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict fact = ['room', 'dorm room', 'light room']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - suppord fact predict = ['room-at location', 'room-important', 'room-has a', 'light room-used for']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - correspond target = ['wall', 'house', 'furniture', 'couch', 'park space', 'lamp', 'chair', 'person', 'human']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - test id = 644, question = Which thing in this image is used in an hourglass?, img = COCO_val2014_000000124599.jpg\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - real suppord fact in dataset=['sand', 'used for', 'hourglass'], real answer = sand\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - normal model predict = ['boat', 'sand', 'shore boat', 'umbrella', 'sail boat', 'lot of sand', 'chair', 'kite', 'beach', 'lake']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict = ['cell phone', 'boat', 'sand', 'shore boat', 'umbrella', 'sail boat', 'lot of sand', 'chair', 'kite', 'beach']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict relation = ['used for', 'related to', 'has property', 'belong to', 'is a', 'has a', 'important', 'specific', 'popular', 'capable of', 'common', 'receives action', 'easy', 'effective', 'part of']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict fact = ['roam', \"catlover's home\", 'suburb']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - suppord fact predict = ['roam-related to']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - correspond target = ['cell phone']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - test id = 1014, question = Which object in this image is capable of training a dog?, img = COCO_val2014_000000148392.jpg\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - real suppord fact in dataset=['person', 'capable of', 'train dog'], real answer = person\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - normal model predict = ['elephant', 'monkey', 'snake', 'giraffe', 'bear', 'dog', 'squirrel', 'lizard', 'bird', 'cat']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict = ['giraffe', 'dog', 'car', 'cow', 'herd sheep', 'camel', 'elephant', 'monkey', 'snake', 'bear']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict relation = ['capable of', 'intelligent', 'stable', 'fast', 'powerful', 'used for', 'tall', 'high', 'accurate', 'efficient', 'active', 'visible', 'is a', 'transportable', 'reliable']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict fact = ['dog', 'horse', 'animal human keep as pet']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - suppord fact predict = ['dog-used for', 'animal human keep as pet-is a', 'dog-tall', 'horse-fast', 'horse-tall']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - correspond target = ['dog', 'camel', 'herd sheep', 'giraffe', 'car', 'cow']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - test id = 2093, question = What object in this image is used for storing things?, img = COCO_val2014_000000000536.jpg\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - real suppord fact in dataset=['handbag', 'used for', 'store thing'], real answer = handbag\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - normal model predict = ['person', 'beam', 'wall', 'sink', 'corkscrew', 'mirror', 'camera', 'microphone', 'balance beam', 'umbrella']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict = ['person', 'beam', 'wall', 'sink', 'corkscrew', 'mirror', 'camera', 'microphone', 'balance beam', 'umbrella']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict relation = ['used for', 'related to', 'belong to', 'specific', 'receives action', 'capable of', 'effective', 'efficient', 'accurate', 'important', 'easy', 'animal order', 'common', 'expensive', 'desires']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict fact = ['something', 'forget thing', 'be sell thing']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - suppord fact predict = ['be sell thing-capable of', 'forget thing-capable of']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - correspond target = ['person']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - test id = 2143, question = Which object in this image is a type of headpiece?, img = COCO_val2014_000000116061.jpg\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - real suppord fact in dataset=['headpiece', 'related to', 'helmet'], real answer = helmet\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - normal model predict = ['motorcycle', 'bicycle', 'motorbike', 'car', 'truck', 'snowmobile', 'vehicle', 'driving', 'racing', 'road']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict = ['motorcycle', 'car', 'truck', 'snowmobile', 'unicycle', 'bus', 'airplane', 'skateboard', 'cart', 'boat']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict relation = ['is a', 'belong to', 'related to', 'has a', 'has property', 'used for', 'part of', 'at location', 'receives action', 'capable of', 'important', 'animal class', 'blind', 'specific', 'desires']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict fact = ['passenger', 'truck', 'vehicle']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - suppord fact predict = ['vehicle-belong to', 'vehicle-is a', 'truck-related to', 'passenger-related to', 'vehicle-related to']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - correspond target = ['airplane', 'bus', 'snowmobile', 'boat', 'truck', 'skateboard', 'motorcycle', 'unicycle', 'car', 'cart']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - test id = 1355, question = which liquid in this image is denser than alcohol?, img = ILSVRC2012_test_00049970.JPEG\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - real suppord fact in dataset=['alcohol', 'dense', 'water'], real answer = water\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - normal model predict = ['giraffe', 'snake', 'wine', 'water', 'seal', 'camel', 'lizard', 'life preserver', 'hippopotamus', 'rich in vitamin c']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict = ['wine', 'giraffe', 'snake', 'water', 'seal', 'camel', 'lizard', 'life preserver', 'hippopotamus', 'rich in vitamin c']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict relation = ['light', 'low', 'good', 'long', 'has a', 'high', 'stable', 'big', 'clean', 'strong', 'heavy', 'acid', 'easy', 'acidic', 'fast']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict fact = ['alcohol', 'alcohol in it', 'alcoholic drink']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - suppord fact predict = ['alcohol in it-has a', 'alcohol-has a']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - correspond target = ['wine']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - test id = 555, question = which object in this image could run faster than pedestrian, img = COCO_val2014_000000028526.jpg\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - real suppord fact in dataset=['train', 'fast', 'pedestrian'], real answer = train\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - normal model predict = ['train', 'bus', 'train station', 'taxi', 'railroad track', 'cheap', 'airport', 'ship', 'car', 'truck']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict = ['bus', 'car', 'travel', 'computer', 'dog', 'bear', 'train', 'train station', 'taxi', 'railroad track']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict relation = ['fast', 'long', 'slow', 'low', 'easy', 'used for', 'frequent', 'high', 'light', 'efficient', 'large', 'good', 'stable', 'soft', 'has a']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict fact = ['train', 'human', 'kill human']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - suppord fact predict = ['train-frequent', 'train-used for', 'train-fast', 'human-fast', 'train-efficient', 'train-slow', 'human-long', 'human-good']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - correspond target = ['dog', 'bus', 'computer', 'car', 'bear', 'travel']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - test id = 2021, question = Which object in this image are dangerous?, img = ILSVRC2012_test_00048011.JPEG\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - real suppord fact in dataset=['axe', 'has property', 'dangerous'], real answer = axe\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - normal model predict = ['hammer', 'scissors', 'screwdriver', 'corkscrew', 'knife', 'wood', 'chain saw', 'ruler', 'metal', 'axe']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict = ['snake', 'clock', 'person', 'flute', 'crutch', 'hammer', 'scissors', 'screwdriver', 'corkscrew', 'knife']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict relation = ['related to', 'used for', 'is a', 'has property', 'capable of', 'has a', 'belong to', 'part of', 'at location', 'specific', 'receives action', 'important', 'dangerous', 'desires', 'common']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - our model predict fact = ['be dangerous', 'tick', 'feel pain both physically and emotionally']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - suppord fact predict = ['tick-related to', 'feel pain both physically and emotionally-capable of', 'be dangerous-capable of']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - correspond target = ['clock', 'person', 'crutch', 'flute', 'snake']\n",
      "INFO - 08/13/22 23:30:30 - 0:00:48 - #################################################################################\n",
      " 28%|████████████                               | 25/89 [00:16<00:43,  1.48it/s]INFO - 08/13/22 23:30:31 - 0:00:49 - #################################################################################\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - test id = 2704, question = Which food in this image is baked?, img = COCO_val2014_000000022690.jpg\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - real suppord fact in dataset=['bread', 'related to', 'bake'], real answer = bread\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - normal model predict = ['pizza', 'sandwich', 'hamburger', 'bread', 'bagel', 'cake', 'chocolate', 'hotdog', 'toast bread', 'cheese']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - our model predict = ['pizza', 'sandwich', 'bagel', 'hamburger', 'bread', 'cake', 'chocolate', 'hotdog', 'toast bread', 'cheese']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - our model predict relation = ['has property', 'related to', 'part of', 'belong to', 'created by', 'is a', 'important', 'independent', 'sweet', 'firm', 'green', 'loyal', 'capable of', 'healthy', 'protected']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - our model predict fact = ['bake bread', 'bread', 'dough tomato sauce and mozzarella cheese']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - suppord fact predict = ['dough tomato sauce and mozzarella cheese-created by', 'bread-belong to', 'bread-part of']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - correspond target = ['bagel', 'sandwich', 'pizza']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - #################################################################################\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - #################################################################################\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - test id = 2244, question = Which object in this image is high?, img = COCO_val2014_000000027658.jpg\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - real suppord fact in dataset=['mountain', 'has property', 'high'], real answer = mountain\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - normal model predict = ['horse', 'grass', 'dog', 'fire hydrant', 'car', 'road', 'cow', 'stop sign', 'person', 'dog poop']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - our model predict = ['horse', 'cat', 'nail', 'ruler', 'grass', 'dog', 'fire hydrant', 'car', 'road', 'cow']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - our model predict relation = ['has property', 'capable of', 'belong to', 'is a', 'related to', 'has a', 'protected', 'used for', 'at location', 'desires', 'safe', 'important', 'part of', 'high', 'dependable']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - our model predict fact = ['low', 'jump very high', 'measure distance']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - suppord fact predict = ['low-has property', 'jump very high-capable of', 'low-related to', 'measure distance-capable of']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - correspond target = ['ruler', 'cat', 'horse', 'nail']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - #################################################################################\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - #################################################################################\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - test id = 2472, question = which object in this image is dangerous for human, img = COCO_val2014_000000006437.jpg\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - real suppord fact in dataset=['bear', 'capable of', 'kill human'], real answer = bear\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - normal model predict = ['rabbit', 'teddy bear', 'sheep', 'dog', 'bear', 'animal', 'dog poop', 'mammal', 'herd sheep', 'monkey']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - our model predict = ['dog', 'ant', 'cat', 'turtle', 'goldfish', 'person', 'rabbit', 'teddy bear', 'sheep', 'bear']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - our model predict relation = ['has property', 'used for', 'related to', 'belong to', 'is a', 'desires', 'important', 'capable of', 'dangerous', 'specific', 'accurate', 'easy', 'safe', 'good', 'at location']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - our model predict fact = ['pet', 'pet cat', 'be pet']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - suppord fact predict = ['pet-is a', 'pet-belong to', 'be pet-desires', 'pet-used for', 'pet cat-desires', 'be pet-capable of', 'pet-related to']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - correspond target = ['cat', 'dog', 'ant', 'turtle', 'person', 'goldfish']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - #################################################################################\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - #################################################################################\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - test id = 1465, question = what can we see from the image, img = ILSVRC2012_test_00022357.JPEG\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - real suppord fact in dataset=['fruit', 'belong to', 'agriculture'], real answer = fruit\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - normal model predict = ['orange', 'banana', 'fruit', 'strawberry', 'lemon', 'fig', 'apple', 'peel', 'pare apple', 'green']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - our model predict = ['bread', 'hair', 'hammer', 'human', 'axe', 'animal', 'herd sheep', 'orange', 'banana', 'fruit']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - our model predict relation = ['at location', 'used for', 'belong to', 'related to', 'capable of', 'is a', 'part of', 'good', 'has a', 'has property', 'receives action', 'specific', 'important', 'great', 'animal order']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - our model predict fact = ['truth', 'dog', 'hurt person']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - suppord fact predict = ['dog-used for', 'dog-good', 'hurt person-capable of', 'dog-has a', 'dog-belong to', 'hurt person-used for', 'truth-important']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - correspond target = ['axe', 'animal', 'bread', 'herd sheep', 'hair', 'human', 'hammer']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - #################################################################################\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - #################################################################################\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - test id = 2131, question = Which object in this image is used for inputing?, img = ILSVRC2012_test_00029694.JPEG\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - real suppord fact in dataset=['keyboard', 'used for', 'input data'], real answer = keyboard\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - normal model predict = ['computer', 'mouse', 'cat', 'cell phone', 'couch', 'laptop', 'keyboard', 'desk', 'phone', 'kitten']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - our model predict = ['computer', 'cell phone', 'mouse', 'cat', 'couch', 'laptop', 'keyboard', 'desk', 'phone', 'kitten']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - our model predict relation = ['used for', 'related to', 'specific', 'belong to', 'important', 'effective', 'common', 'good', 'accurate', 'efficient', 'popular', 'easy', 'part of', 'receives action', 'great']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - our model predict fact = ['cyberdating', 'telecommunication', 'type on']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - suppord fact predict = ['telecommunication-related to', 'cyberdating-related to']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - correspond target = ['cell phone', 'computer']\n",
      "INFO - 08/13/22 23:30:31 - 0:00:49 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29%|████████████▌                              | 26/89 [00:17<00:47,  1.34it/s]INFO - 08/13/22 23:30:32 - 0:00:50 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - test id = 1456, question = which object in this image are fun to learn to play, img = ILSVRC2012_test_00051302.JPEG\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - real suppord fact in dataset=['guitar', 'has property', 'fun to learn to play'], real answer = guitar\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - normal model predict = ['person', 'guitar', 'dog', 'transport person', 'make person happy', 'microphone', 'cat', 'cake', 'happy for bride and groom', 'hotdog']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict = ['dog', 'bus', 'person', 'guitar', 'transport person', 'make person happy', 'microphone', 'cat', 'cake', 'happy for bride and groom']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict relation = ['capable of', 'has property', 'desires', 'used for', 'related to', 'belong to', 'visible', 'is a', 'specific', 'dangerous', 'important', 'easy', 'long', 'convenient', 'accurate']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict fact = ['go to school', 'come to it master', 'follow it master']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - suppord fact predict = ['come to it master-capable of', 'go to school-used for', 'follow it master-capable of']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - correspond target = ['bus', 'dog']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - test id = 2115, question = What is the object in the middle right of this image used for?, img = ILSVRC2012_test_00001600.JPEG\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - real suppord fact in dataset=['saxophone', 'used for', 'music'], real answer = music\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - normal model predict = ['travel', 'play music', 'listen to music', 'prepare food', 'space to run and play', 'any place where person live', 'sleep away from home', 'travel in car', 'play', 'entertain yourself on windy day']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict = ['listen to music', 'mouse', 'dog', 'travel', 'play music', 'prepare food', 'space to run and play', 'any place where person live', 'sleep away from home', 'travel in car']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict relation = ['used for', 'capable of', 'effective', 'efficient', 'safe', 'expensive', 'has property', 'good', 'reliable', 'dependable', 'convenient', 'easy', 'high', 'great', 'related to']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict fact = ['ipod', 'cat', 'fox']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - suppord fact predict = ['cat-dependable', 'ipod-used for', 'cat-capable of']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - correspond target = ['listen to music', 'mouse', 'dog']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - test id = 527, question = What property does the place in this image have?, img = COCO_val2014_000000004069.jpg\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - real suppord fact in dataset=['forest road', 'has property', 'inspirational'], real answer = forest road\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - normal model predict = ['smooth', 'pleasant', 'mountain', 'forest road', 'road', 'travel in car', 'sandy', 'rich in vitamin c', 'mountainous area', 'cold and wet']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict = ['smooth', 'cold and wet', 'slippery', 'white', 'cold', 'ski', 'toaster', 'snowboard', 'pleasant', 'mountain']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict relation = ['has property', 'has a', 'at location', 'created by', 'is a', 'used for', 'animal family', 'protected', 'belong to', 'firm', 'animal class', 'animal order', 'related to', 'animal kingdom', 'part of']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict fact = ['brown bread', 'snow', 'turn brown']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - suppord fact predict = ['snow-belong to', 'snow-used for', 'snow-has property', 'brown bread-related to', 'snow-has a']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - correspond target = ['smooth', 'slippery', 'ski', 'toaster', 'cold and wet', 'cold', 'white', 'snowboard']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - test id = 2100, question = What is the yellow object in this image?, img = ILSVRC2012_test_00038877.JPEG\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - real suppord fact in dataset=['lemon', 'has property', 'yellow'], real answer = lemon\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - normal model predict = ['fig', 'plant', 'ant', 'potted plant', 'bird', 'tomato', 'banana', 'walnut', 'fruit', 'tick']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict = ['banana', 'strawberry', 'apple', 'fig', 'plant', 'ant', 'potted plant', 'bird', 'tomato', 'walnut']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict relation = ['has property', 'belong to', 'is a', 'related to', 'has a', 'animal order', 'part of', 'at location', 'animal class', 'animal family', 'capable of', 'common', 'animal kingdom', 'protected', 'important']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict fact = ['yellow fruit', 'round fruit', 'small red fruit']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - suppord fact predict = ['round fruit-related to', 'small red fruit-is a', 'yellow fruit-is a']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - correspond target = ['banana', 'apple', 'strawberry']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - test id = 1428, question = What is the place in this image used for?, img = COCO_val2014_000000006608.jpg\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - real suppord fact in dataset=['home office', 'capable of', 'mean office in home'], real answer = home office\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - normal model predict = ['sleep away from home', 'work', 'sleep', 'space to run and play', 'home office', 'play music', 'living room', 'listen to music', 'sit down on', 'work for day without water']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict = ['work', 'your house', 'computer', 'couch', 'monitor', 'human', 'park space', 'desk', 'house', 'furniture']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict relation = ['used for', 'capable of', 'related to', 'receives action', 'part of', 'specific', 'effective', 'belong to', 'at location', 'good', 'great', 'efficient', 'high', 'animal order', 'important']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict fact = ['office', 'home office', 'room']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - suppord fact predict = ['home office-at location', 'office-used for', 'room-important', 'office-at location', 'room-at location']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - correspond target = ['desk', 'your house', 'house', 'monitor', 'computer', 'furniture', 'couch', 'park space', 'work', 'human']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - test id = 1643, question = Why the candle is used hear?, img = ILSVRC2012_test_00025208.JPEG\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - real suppord fact in dataset=['candle', 'used for', 'light'], real answer = light\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - normal model predict = ['cake', 'light', 'spoon', 'banana', 'shell', 'glass', 'ice', 'fork', 'sink', 'chocolate']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict = ['person', 'sheep', 'cake', 'light', 'spoon', 'banana', 'shell', 'glass', 'ice', 'fork']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict relation = ['used for', 'related to', 'receives action', 'belong to', 'has property', 'specific', 'at location', 'is a', 'important', 'has a', 'part of', 'good', 'capable of', 'animal order', 'common']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - our model predict fact = ['hear voice', 'hear', 'hear noise']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - suppord fact predict = ['hear-used for', 'hear noise-capable of', 'hear voice-capable of']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - correspond target = ['sheep', 'person']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:50 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|█████████████                              | 27/89 [00:17<00:45,  1.37it/s]INFO - 08/13/22 23:30:32 - 0:00:51 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - test id = 2439, question = Which object in this image is part of a lower jaw?, img = ILSVRC2012_test_00008234.JPEG\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - real suppord fact in dataset=['low jaw', 'related to', 'mouth'], real answer = mouth\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - normal model predict = ['hand', 'screwdriver', 'flute', 'harmonica', 'person', 'mouth', 'drink', 'corkscrew', 'crutch', 'scissors']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - our model predict = ['nail', 'horse', 'cat', 'hand', 'screwdriver', 'flute', 'harmonica', 'person', 'mouth', 'drink']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - our model predict relation = ['is a', 'has a', 'related to', 'part of', 'has property', 'belong to', 'at location', 'used for', 'important', 'good', 'cool', 'common', 'light', 'easy', 'low']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - our model predict fact = ['low brances of tree', 'low', 'beast of burden']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - suppord fact predict = ['low-has property', 'low-related to', 'beast of burden-is a', 'low brances of tree-at location']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - correspond target = ['cat', 'horse', 'nail']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - test id = 1844, question = Which object in this image is strung?, img = COCO_val2014_000000133090.jpg\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - real suppord fact in dataset=['tennis racket', 'related to', 'string'], real answer = tennis racket\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - normal model predict = ['tennis racket', 'frisbee', 'tennis ball', 'tennis', 'soccer ball', 'rugby ball', 'play tennis', 'baseball', 'golf ball', 'volleyball']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - our model predict = ['frisbee', 'tennis ball', 'soccer ball', 'baseball', 'baseball bat', 'basketball', 'orange', 'apple', 'tennis racket', 'tennis']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - our model predict relation = ['has property', 'is a', 'desires', 'has a', 'related to', 'belong to', 'dangerous', 'receives action', 'protected', 'used for', 'strenuous', 'popular', 'firm', 'important', 'impassable']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - our model predict fact = ['round object', 'round', 'long round taper object']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - suppord fact predict = ['round object-is a', 'round-is a', 'round-has property', 'long round taper object-is a', 'round-related to']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - correspond target = ['apple', 'basketball', 'orange', 'frisbee', 'baseball bat', 'soccer ball', 'tennis ball', 'baseball']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - test id = 2000, question = What is the place in this image used for?, img = COCO_val2014_000000011727.jpg\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - real suppord fact in dataset=['bathroom', 'used for', 'clean your tooth in'], real answer = clean your tooth in\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - normal model predict = ['pee', 'wash', 'swim', 'sleep', 'preventing from getting wet', 'laundromat', 'sleep away from home', 'toilet', 'cold and wet', 'sink']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - our model predict = ['pee', 'wash', 'cooking', 'prepare food', 'hotel room', 'breakfast', 'house', 'plunger', 'swim', 'sleep']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - our model predict relation = ['used for', 'belong to', 'capable of', 'related to', 'effective', 'good', 'receives action', 'part of', 'great', 'specific', 'easy', 'at location', 'popular', 'important', 'animal order']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - our model predict fact = ['kitchenette', 'shower', 'toilet']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - suppord fact predict = ['toilet-used for', 'kitchenette-used for', 'kitchenette-at location', 'shower-used for']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - correspond target = ['prepare food', 'house', 'hotel room', 'plunger', 'cooking', 'pee', 'wash', 'breakfast']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - #################################################################################\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - test id = 473, question = What is the reptile in this image?, img = ILSVRC2012_test_00034257.JPEG\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - real suppord fact in dataset=['turtle', 'is a', 'reptile'], real answer = turtle\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - normal model predict = ['turtle', 'elephant', 'armadillo', 'lizard', 'whale', 'frog', 'desert', 'otter', 'mammal', 'dolphin']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - our model predict = ['elephant', 'whale', 'lobster', 'seal', 'hippopotamus', 'giraffe', 'zebra', 'dog', 'cat', 'camel']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - our model predict relation = ['is a', 'belong to', 'related to', 'has property', 'has a', 'important', 'stable', 'dangerous', 'strong', 'safe', 'animal class', 'animal family', 'animal order', 'easy', 'independent']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - our model predict fact = ['mammal', 'marine mammal', 'crustacean']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - suppord fact predict = ['crustacean-related to', 'mammal-has property', 'marine mammal-belong to', 'mammal-is a', 'mammal-animal class', 'marine mammal-is a', 'mammal-belong to']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - correspond target = ['cat', 'dog', 'whale', 'camel', 'zebra', 'seal', 'lobster', 'elephant', 'giraffe', 'hippopotamus']\n",
      "INFO - 08/13/22 23:30:32 - 0:00:51 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - test id = 1935, question = What is the colour of the toilet seat?, img = COCO_val2014_000000005412.jpg\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - real suppord fact in dataset=['toilet seat', 'has property', 'white'], real answer = white\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - normal model predict = ['sofa', 'couch', 'bench', 'sink', 'toilet seat', 'chair', 'bed', 'bathroom', 'bathtub', 'dining table']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - our model predict = ['sofa', 'couch', 'bench', 'toilet', 'pee', 'plunger', 'sink', 'toilet seat', 'chair', 'bed']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - our model predict relation = ['is a', 'used for', 'related to', 'light', 'belong to', 'animal order', 'part of', 'at location', 'animal class', 'has a', 'specific', 'animal family', 'good', 'cool', 'important']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - our model predict fact = ['toilet seat', 'seat', 'toilet']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - suppord fact predict = ['seat-related to', 'toilet-used for', 'seat-is a', 'seat-belong to']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - correspond target = ['sofa', 'bench', 'toilet', 'plunger', 'couch', 'pee']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - test id = 1434, question = Which animal in this image can be found in louisiana?, img = ILSVRC2012_test_00000165.JPEG\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - real suppord fact in dataset=['snake', 'at location', 'louisiana'], real answer = snake\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - normal model predict = ['snake', 'lizard', 'frog', 'bird', 'monkey', 'giraffe', 'butterfly', 'turtle', 'ant', 'armadillo']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - our model predict = ['dog', 'zoo', 'dog poop', 'banana', 'person', 'space to run and play', 'frisbee', 'vend stand', 'snake', 'lizard']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - our model predict relation = ['at location', 'used for', 'has a', 'capable of', 'part of', 'related to', 'belong to', 'is a', 'specific', 'human', 'receives action', 'small', 'animal order', 'active', 'surface']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - our model predict fact = ['park', 'village', 'monkey']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - suppord fact predict = ['park-at location', 'park-used for', 'village-at location', 'monkey-at location', 'monkey-related to']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - correspond target = ['dog poop', 'dog', 'zoo', 'frisbee', 'banana', 'space to run and play', 'vend stand', 'person']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - test id = 117, question = What is lightening the room and place in this image?, img = ILSVRC2012_test_00002967.JPEG\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - real suppord fact in dataset=['lamp', 'used for', 'lighten room and place'], real answer = lamp\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - normal model predict = ['computer', 'laptop', 'home office', 'mouse', 'cell phone', 'your house', 'printer', 'apple', 'laboratory', 'monitor']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - our model predict = ['computer', 'home office', 'your house', 'printer', 'desk', 'laptop', 'mouse', 'cell phone', 'apple', 'laboratory']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - our model predict relation = ['used for', 'has property', 'related to', 'is a', 'at location', 'good', 'part of', 'common', 'expensive', 'has a', 'important', 'belong to', 'capable of', 'specific', 'easy']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - our model predict fact = ['mean office in home', 'in office', 'home office']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - suppord fact predict = ['home office-at location', 'mean office in home-capable of', 'in office-at location']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - correspond target = ['desk', 'your house', 'computer', 'home office', 'printer']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - test id = 954, question = What the umbrella in the image is used for?, img = COCO_val2014_000000121506.jpg\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - real suppord fact in dataset=['umbrella', 'capable of', 'shade table'], real answer = shade table\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - normal model predict = ['entertain yourself on windy day', 'sleep away from home', 'preventing from getting wet', 'sit down on', 'travel across water', 'sleep', 'lot of sand', 'space to run and play', 'protect person from sun and rain', 'lay on']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - our model predict = ['travel', 'cold and wet', 'ski', 'cold', 'slippery', 'transport', 'smooth', 'snowboard', 'entertain yourself on windy day', 'sleep away from home']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - our model predict relation = ['used for', 'capable of', 'related to', 'is a', 'effective', 'good', 'receives action', 'efficient', 'easy', 'animal order', 'belong to', 'safe', 'popular', 'specific', 'has property']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - our model predict fact = ['snow', 'road', 'driveway']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - suppord fact predict = ['snow-belong to', 'snow-used for', 'road-used for', 'snow-has property']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - correspond target = ['smooth', 'slippery', 'ski', 'transport', 'cold and wet', 'cold', 'travel', 'snowboard']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:33 - 0:00:51 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - test id = 1794, question = Where does the object in the image can be found in?, img = ILSVRC2012_test_00002176.JPEG\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - real suppord fact in dataset=['bookshelf', 'at location', 'furniture store'], real answer = furniture store\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - normal model predict = ['hotel room', 'hot room', 'room', 'house', 'home office', 'your house', 'mountainous area', 'airport', 'living room', 'bedroom']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - our model predict = ['desk', 'pen', 'tv', 'listen to music', 'keyboard', 'work', 'window', 'monitor', 'cat', 'tall build']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - our model predict relation = ['at location', 'used for', 'has a', 'part of', 'capable of', 'has property', 'receives action', 'belong to', 'surface', 'expensive', 'is a', 'great', 'active', 'visible', 'good']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - our model predict fact = ['office', 'ipod', 'apartment']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - suppord fact predict = ['office-used for', 'office-has a', 'office-at location', 'apartment-at location', 'ipod-used for']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - correspond target = ['pen', 'cat', 'desk', 'tall build', 'monitor', 'window', 'keyboard', 'tv', 'work', 'listen to music']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:51 - #################################################################################\n",
      " 31%|█████████████▌                             | 28/89 [00:18<00:43,  1.39it/s]INFO - 08/13/22 23:30:33 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - test id = 2085, question = Which place is more crowded than the place shown in this image, img = ILSVRC2012_test_00015539.JPEG\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - real suppord fact in dataset=['train station', 'crowded', 'airport'], real answer = train station\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - normal model predict = ['house', 'flight', 'car', 'airplane', 'plane', 'airport', 'land airplane', 'train', 'land plane', 'spaceship']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict = ['airport', 'train', 'travel', 'fly', 'pavement', 'house', 'flight', 'car', 'airplane', 'plane']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict relation = ['common', 'important', 'at location', 'frequent', 'prevalent', 'low', 'blind', 'popular', 'used for', 'cheap', 'specific', 'acid', 'convenient', 'visible', 'long']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict fact = ['city', 'airplane', 'luggage trolley']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - suppord fact predict = ['city-at location', 'airplane-at location', 'luggage trolley-at location', 'airplane-used for']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - correspond target = ['fly', 'pavement', 'train', 'travel', 'airport']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - test id = 2238, question = Which object is more playful? sea lion? or the animal in the image?, img = ILSVRC2012_test_00018998.JPEG\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - real suppord fact in dataset=['otter', 'playful', 'sea lion'], real answer = otter\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - normal model predict = ['whale', 'sea', 'jellyfish', 'dolphin', 'turtle', 'water', 'fish', 'ocean', 'beach', 'goldfish']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict = ['ray', 'desert', 'shell', 'low', 'whale', 'sea', 'jellyfish', 'dolphin', 'turtle', 'water']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict relation = ['has property', 'impassable', 'has a', 'light', 'protected', 'small', 'strong', 'visible', 'long', 'solar', 'dense', 'large', 'firm', 'tall', 'animal kingdom']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict fact = ['shark', 'turtle', 'sea']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - suppord fact predict = ['sea-impassable', 'turtle-has a', 'turtle-has property', 'shark-long']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - correspond target = ['low', 'desert', 'ray', 'shell']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - test id = 460, question = What can this place in the image be used for?, img = COCO_val2014_000000024195.jpg\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - real suppord fact in dataset=['road', 'used for', 'transport'], real answer = transport\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - normal model predict = ['bus', 'travel', 'travel in car', 'travel across water', 'laundromat', 'sleep away from home', 'transport', 'prepare food', 'space to run and play', 'taxi']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict = ['bus', 'travel', 'plane to land on', 'work', 'station', 'land plane', 'airport', 'car', 'plane', 'land airplane']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict relation = ['used for', 'capable of', 'at location', 'related to', 'receives action', 'belong to', 'has property', 'effective', 'animal order', 'specific', 'high', 'efficient', 'part of', 'good', 'convenient']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict fact = ['office', 'train', 'runway']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - suppord fact predict = ['train-at location', 'office-used for', 'train-used for', 'runway-at location', 'train-efficient', 'runway-used for', 'train-convenient']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - correspond target = ['bus', 'land airplane', 'plane', 'work', 'plane to land on', 'station', 'car', 'travel', 'airport', 'land plane']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - test id = 1445, question = Tell me the name of the domestic animal in this image, img = COCO_val2014_000000019032.jpg\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - real suppord fact in dataset=['horse', 'is a', 'domestic animal'], real answer = horse\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - normal model predict = ['horse', 'violin', 'train', 'elephant', 'cow', 'ride', 'scissors', 'piano', 'cello', 'cart']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict = ['wii', 'dog', 'chordata', 'mammal', 'carnivora', 'horse', 'violin', 'train', 'elephant', 'cow']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict relation = ['is a', 'belong to', 'animal class', 'animal family', 'has a', 'animal order', 'animal kingdom', 'part of', 'related to', 'important', 'safe', 'has property', 'receives action', 'capable of', 'animal phylum']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict fact = ['fox', 'wolf', 'game system']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - suppord fact predict = ['game system-is a', 'fox-animal phylum', 'wolf-related to', 'fox-animal class', 'fox-animal order']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - correspond target = ['chordata', 'dog', 'wii', 'mammal', 'carnivora']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - test id = 434, question = which sport equipment in this image is softer than basketball?, img = ILSVRC2012_test_00008641.JPEG\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - real suppord fact in dataset=['volleyball', 'soft', 'basketball'], real answer = volleyball\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - normal model predict = ['volleyball', 'tennis racket', 'tennis', 'racket', 'tennis ball', 'soccer ball', 'baseball', 'swimming', 'baseball glove', 'child']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict = ['baseball', 'volleyball', 'tennis racket', 'tennis', 'racket', 'tennis ball', 'soccer ball', 'swimming', 'baseball glove', 'child']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict relation = ['popular', 'prevalent', 'easy', 'important', 'healthy', 'comfortable', 'convenient', 'effective', 'acid', 'long', 'fast', 'strict', 'warm', 'good', 'efficient']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict fact = ['soccer', 'basketball', 'volleyball']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - suppord fact predict = ['soccer-popular']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - correspond target = ['baseball']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - test id = 319, question = Which link is less accurate than the action shown in this image, img = ILSVRC2012_test_00002037.JPEG\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - real suppord fact in dataset=['driving', 'accurate', 'drunk driving'], real answer = driving\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - normal model predict = ['boat', 'sail boat', 'fish', 'eat', 'goldfish', 'drink', 'ship', 'jumping', 'work for day without water', 'fun']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict = ['desert', 'boat', 'sail boat', 'fish', 'eat', 'goldfish', 'drink', 'ship', 'jumping', 'work for day without water']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict relation = ['important', 'impassable', 'light', 'dangerous', 'tough', 'safe', 'strenuous', 'dense', 'prevalent', 'vulnerable', 'stable', 'popular', 'maneuverable', 'strong', 'natural']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict fact = ['ocean', 'sea', 'underwater']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - suppord fact predict = ['sea-impassable']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - correspond target = ['desert']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - test id = 2535, question = Which object in this image is the most related to pickle, img = ILSVRC2012_test_00048262.JPEG\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - real suppord fact in dataset=['cucumber', 'related to', 'pickle'], real answer = cucumber\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - normal model predict = ['cucumber', 'carrot', 'strawberry', 'fruit', 'lemon', 'fig', 'tomato', 'root', 'pineapple', 'mushroom']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict = ['banana', 'nail', 'zoo', 'trombone', 'cucumber', 'carrot', 'strawberry', 'fruit', 'lemon', 'fig']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict relation = ['related to', 'used for', 'specific', 'belong to', 'important', 'common', 'has property', 'at location', 'is a', 'good', 'part of', 'prevalent', 'animal order', 'social', 'accurate']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - our model predict fact = ['monkey', 'low', 'tromboner']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - suppord fact predict = ['tromboner-related to', 'low-has property', 'monkey-at location', 'low-related to', 'monkey-related to']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - correspond target = ['banana', 'trombone', 'zoo', 'nail']\n",
      "INFO - 08/13/22 23:30:33 - 0:00:52 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33%|██████████████                             | 29/89 [00:19<00:44,  1.35it/s]INFO - 08/13/22 23:30:34 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - test id = 2726, question = What object in this image belongs to the category Pollination?, img = ILSVRC2012_test_00036186.JPEG\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - real suppord fact in dataset=['fruit', 'belong to', 'pollination'], real answer = fruit\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - normal model predict = ['fruit', 'vegetable', 'flowers', 'child', 'potted plant', 'flower', 'pomegranate', 'basket', 'seed', 'toys']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - our model predict = ['elephant', 'trombone', 'fruit', 'vegetable', 'flowers', 'child', 'potted plant', 'flower', 'pomegranate', 'basket']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - our model predict relation = ['belong to', 'desires', 'animal kingdom', 'animal phylum', 'related to', 'animal order', 'is a', 'loyal', 'animal family', 'trustworthy', 'animal class', 'important', 'sensible', 'protected', 'comfortable']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - our model predict fact = ['petshop', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - suppord fact predict = ['therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - correspond target = ['trombone', 'elephant']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - test id = 951, question = What is the white frozen thing in the image? , img = COCO_val2014_000000102159.jpg\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - real suppord fact in dataset=['snow', 'related to', 'white freeze'], real answer = snow\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - normal model predict = ['cow', 'grass', 'wall', 'car', 'green', 'beach', 'horse', 'orange', 'cheese', 'white']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - our model predict = ['grass', 'elephant', 'even toed ungulate', 'lamp', 'cow', 'wall', 'car', 'green', 'beach', 'horse']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - our model predict relation = ['related to', 'is a', 'has property', 'has a', 'part of', 'belong to', 'animal order', 'animal family', 'capable of', 'specific', 'important', 'common', 'animal class', 'animal kingdom', 'good']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - our model predict fact = ['cow', 'sheep', 'grey']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - suppord fact predict = ['sheep-related to', 'sheep-animal order', 'grey-has property']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - correspond target = ['even toed ungulate', 'grass', 'elephant', 'lamp']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - test id = 1831, question = What can be found in the right top of this image around the table?, img = COCO_val2014_000000020641.jpg\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - real suppord fact in dataset=['chair', 'at location', 'kitchen'], real answer = chair\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - normal model predict = ['eat', 'prepare food', 'food', 'salad', 'dishes', 'sit outside', 'chair', 'monitor', 'cheese', 'cook food']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - our model predict = ['cup', 'desk', 'coffee', 'bottle', 'eat', 'prepare food', 'food', 'salad', 'dishes', 'sit outside']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - our model predict relation = ['at location', 'used for', 'has a', 'part of', 'related to', 'capable of', 'is a', 'animal order', 'belong to', 'specific', 'good', 'created by', 'has property', 'great', 'important']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - our model predict fact = ['table', 'coffee mug', 'hold coffee']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - suppord fact predict = ['hold coffee-capable of', 'hold coffee-used for', 'table-at location', 'table-is a', 'coffee mug-at location']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - correspond target = ['bottle', 'cup', 'coffee', 'desk']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - #################################################################################\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - test id = 2258, question = which object in this image is alive, img = ILSVRC2012_test_00030000.JPEG\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - real suppord fact in dataset=['goldfish', 'is a', 'live thing'], real answer = goldfish\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - normal model predict = ['goldfish', 'fish', 'jellyfish', 'butterfly', 'bird', 'dragonfly', 'lizard', 'banana', 'eat', 'turtle']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - our model predict = ['nail', 'lobster', 'computer', 'goldfish', 'fish', 'jellyfish', 'butterfly', 'bird', 'dragonfly', 'lizard']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - our model predict relation = ['belong to', 'has property', 'is a', 'related to', 'important', 'desires', 'capable of', 'part of', 'used for', 'has a', 'receives action', 'good', 'at location', 'protected', 'specific']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - our model predict fact = ['captcha', 'hermaphrodite', 'crustacean']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - suppord fact predict = ['crustacean-related to', 'hermaphrodite-is a', 'captcha-related to']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - correspond target = ['lobster', 'computer', 'nail']\n",
      "INFO - 08/13/22 23:30:34 - 0:00:52 - #################################################################################\n",
      " 34%|██████████████▍                            | 30/89 [00:20<00:40,  1.44it/s]INFO - 08/13/22 23:30:35 - 0:00:53 - #################################################################################\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - test id = 1029, question = Which object in this image can be found in the woodwind section?, img = ILSVRC2012_test_00010575.JPEG\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - real suppord fact in dataset=['flute', 'at location', 'woodwind section'], real answer = flute\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - normal model predict = ['flute', 'violin', 'clarinet', 'saxophone', 'cello', 'harmonica', 'trombone', 'trumpet', 'banjo', 'piano']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict = ['hammer', 'fence', 'dog', 'flute', 'violin', 'clarinet', 'saxophone', 'cello', 'harmonica', 'trombone']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict relation = ['at location', 'belong to', 'used for', 'capable of', 'part of', 'has a', 'animal order', 'human', 'specific', 'animal class', 'visible', 'related to', 'animal family', 'active', 'important']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict fact = ['petshop', 'construction site', 'mark boundary']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - suppord fact predict = ['petshop-at location', 'construction site-at location', 'mark boundary-used for']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - correspond target = ['fence', 'hammer', 'dog']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - #################################################################################\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - #################################################################################\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - test id = 2005, question = What is the place in this image used for?, img = COCO_val2014_000000011727.jpg\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - real suppord fact in dataset=['bathroom', 'used for', 'clean your tooth in'], real answer = clean your tooth in\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - normal model predict = ['pee', 'wash', 'swim', 'sleep', 'preventing from getting wet', 'laundromat', 'sleep away from home', 'toilet', 'cold and wet', 'sink']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict = ['pee', 'wash', 'cooking', 'prepare food', 'hotel room', 'breakfast', 'house', 'plunger', 'swim', 'sleep']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict relation = ['used for', 'belong to', 'capable of', 'related to', 'effective', 'good', 'receives action', 'part of', 'great', 'specific', 'easy', 'at location', 'popular', 'important', 'animal order']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict fact = ['kitchenette', 'shower', 'toilet']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - suppord fact predict = ['toilet-used for', 'kitchenette-used for', 'kitchenette-at location', 'shower-used for']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - correspond target = ['prepare food', 'house', 'hotel room', 'plunger', 'cooking', 'pee', 'wash', 'breakfast']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - #################################################################################\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - #################################################################################\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - test id = 1719, question = what thing has less fat than the object in the middle of this image?, img = COCO_val2014_000000020465.jpg\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - real suppord fact in dataset=['hot dog', 'fat', 'ham'], real answer = hot dog\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - normal model predict = ['hot dog', 'chocolate', 'hot room', 'big', 'dog', 'drink', 'coffee', 'donut', 'eat', 'hotdog']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict = ['human', 'animal', 'hot dog', 'chocolate', 'hot room', 'big', 'dog', 'drink', 'coffee', 'donut']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict relation = ['has property', 'safe', 'expensive', 'cheap', 'stable', 'popular', 'protected', 'strong', 'tough', 'good', 'common', 'belong to', 'healthy', 'fast', 'low']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict fact = ['hot dog', 'dog', 'this dog']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - suppord fact predict = ['dog-good', 'dog-belong to']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - correspond target = ['human', 'animal']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - #################################################################################\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - #################################################################################\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - test id = 2423, question = What is an item of stationary visible in this image?, img = ILSVRC2012_test_00002875.JPEG\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - real suppord fact in dataset=['paper', 'belong to', 'stationery'], real answer = paper\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - normal model predict = ['computer', 'desk', 'monitor', 'mouse', 'home office', 'laptop', 'your house', 'printer', 'pen', 'hand']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict = ['computer', 'desk', 'monitor', 'pen', 'work', 'keyboard', 'window', 'tall build', 'tv', 'mouse']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict relation = ['is a', 'related to', 'used for', 'has a', 'part of', 'belong to', 'at location', 'common', 'good', 'capable of', 'specific', 'important', 'fast', 'expensive', 'has property']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict fact = ['office', 'display image', 'in office']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - suppord fact predict = ['office-used for', 'office-has a', 'office-at location', 'in office-at location', 'display image-capable of']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - correspond target = ['pen', 'desk', 'tall build', 'monitor', 'computer', 'window', 'keyboard', 'tv', 'work']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - #################################################################################\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - #################################################################################\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - test id = 826, question = What objects in this image are inspirational, img = ILSVRC2012_test_00035105.JPEG\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - real suppord fact in dataset=['forest road', 'has property', 'inspirational'], real answer = forest road\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - normal model predict = ['stop sign', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car', 'bus', 'person']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict = ['stop sign', 'horse', 'tv', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict relation = ['capable of', 'is a', 'has property', 'receives action', 'has a', 'used for', 'related to', 'part of', 'desires', 'at location', 'belong to', 'created by', 'specific', 'good', 'animal order']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict fact = ['traffic sign', 'clop', 'advertise']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - suppord fact predict = ['advertise-used for', 'traffic sign-belong to', 'clop-related to']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - correspond target = ['stop sign', 'tv', 'horse']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - #################################################################################\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - #################################################################################\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - test id = 1781, question = which thing has a small hole in the middle as a part?, img = COCO_val2014_000000111024.jpg\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - real suppord fact in dataset=['donut', 'belong to', 'food'], real answer = donut\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - normal model predict = ['cup', 'ice', 'coffee', 'drink', 'donut', 'doughnut', 'cake', 'fork', 'pizza', 'orange']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict = ['chocolate', 'blanket', 'sofa', 'cup', 'ice', 'coffee', 'drink', 'donut', 'doughnut', 'cake']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict relation = ['related to', 'is a', 'has property', 'at location', 'has a', 'used for', 'red', 'specific', 'light', 'small', 'belong to', 'common', 'animal family', 'receives action', 'cool']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - our model predict fact = ['bar of chocolate', 'large than chair', 'large piece of cloth']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - suppord fact predict = ['bar of chocolate-related to', 'large piece of cloth-is a', 'large than chair-is a']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - correspond target = ['chocolate', 'blanket', 'sofa']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:53 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35%|██████████████▉                            | 31/89 [00:20<00:40,  1.43it/s]INFO - 08/13/22 23:30:35 - 0:00:54 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - test id = 197, question = normally where can you find this game?, img = COCO_val2014_000000122300.jpg\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - real suppord fact in dataset=['frisbee', 'used for', 'park'], real answer = park\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - normal model predict = ['africa', 'wii', 'racket', 'tennis racket', 'frisbee', 'airport', 'stadium', 'soccer ball', 'tennis ball', 'golf ball']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict = ['wii', 'chess board', 'cat', 'computer', 'africa', 'racket', 'tennis racket', 'frisbee', 'airport', 'stadium']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict relation = ['at location', 'belong to', 'related to', 'used for', 'capable of', 'specific', 'important', 'is a', 'accurate', 'visible', 'animal order', 'common', 'part of', 'cool', 'popular']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict fact = ['game room', 'video game', 'hunt mouse']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - suppord fact predict = ['video game-belong to', 'game room-at location', 'video game-related to', 'hunt mouse-capable of']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - correspond target = ['wii', 'cat', 'computer', 'chess board']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - test id = 2226, question = What is the stuff on the surface of the red fruit in the image?, img = ILSVRC2012_test_00023364.JPEG\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - real suppord fact in dataset=['strawberry', 'related to', 'seed'], real answer = seed\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - normal model predict = ['strawberry', 'pomegranate', 'fig', 'lemon', 'fruit', 'pineapple', 'orange', 'chocolate', 'vegetable', 'doughnut']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict = ['strawberry', 'pomegranate', 'fig', 'lemon', 'fruit', 'pineapple', 'orange', 'chocolate', 'vegetable', 'doughnut']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict relation = ['animal order', 'animal family', 'has a', 'is a', 'animal kingdom', 'animal class', 'part of', 'animal phylum', 'has property', 'at location', 'healthy', 'human', 'good', 'common', 'small']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict fact = ['small red fruit', 'red fruit', 'sweet red fruit']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - suppord fact predict = ['sweet red fruit-is a', 'small red fruit-is a']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - correspond target = ['strawberry']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - test id = 2569, question = Whether the animal in the image is slower or faster than turtles?, img = ILSVRC2012_test_00017099.JPEG\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - real suppord fact in dataset=['nail', 'is a', 'low'], real answer = low\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - normal model predict = ['big', 'low', 'chocolate', 'unhealthy', 'cheap', 'sandy', 'large ship', 'wild', 'mountainous area', 'donut']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict = ['ray', 'dog', 'big', 'low', 'chocolate', 'unhealthy', 'cheap', 'sandy', 'large ship', 'wild']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict relation = ['fast', 'slow', 'easy', 'long', 'light', 'fat', 'stable', 'comfortable', 'convenient', 'big', 'is a', 'good', 'maneuverable', 'tall', 'tough']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict fact = ['shark', 'turtle', 'humanoid']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - suppord fact predict = ['shark-long', 'humanoid-fast']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - correspond target = ['ray', 'dog']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - test id = 1264, question = What is often found in this place?, img = ILSVRC2012_test_00020083.JPEG\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - real suppord fact in dataset=['person', 'at location', 'room'], real answer = person\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - normal model predict = ['sound control room', 'control tv', 'music studio', 'modern device', 'tv', 'room', 'wall', 'living room', 'close to tv', 'control']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict = ['wall', 'toilet', 'use toilet', 'mirror', 'sink', 'thing', 'house', 'sleep', 'pee', 'toilet paper']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict relation = ['at location', 'used for', 'has a', 'part of', 'has property', 'belong to', 'receives action', 'related to', 'is a', 'animal order', 'specific', 'animal family', 'created by', 'animal class', 'good']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict fact = ['room', 'hotel room', 'bathroom']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - suppord fact predict = ['hotel room-used for', 'bathroom-at location', 'bathroom-has a', 'bathroom-part of', 'room-at location', 'bathroom-used for', 'room-has a']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - correspond target = ['wall', 'toilet', 'thing', 'sleep', 'toilet paper', 'sink', 'use toilet', 'house', 'pee', 'mirror']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - test id = 256, question = which object in this image can you use to go horseriding?, img = COCO_val2014_000000020779.jpg\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - real suppord fact in dataset=['horseriding', 'related to', 'horse'], real answer = horse\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - normal model predict = ['luggage', 'suitcase', 'horse', 'car', 'bus', 'person', 'computer', 'wall', 'cart', 'vehicle']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict = ['person', 'dog', 'bed', 'luggage', 'suitcase', 'horse', 'car', 'bus', 'computer', 'wall']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict relation = ['capable of', 'used for', 'related to', 'specific', 'accurate', 'important', 'high', 'belong to', 'fast', 'is a', 'efficient', 'easy', 'effective', 'long', 'has a']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict fact = ['come to it master', 'dare another to do something careless', 'go to sleep']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - suppord fact predict = ['dare another to do something careless-capable of', 'come to it master-capable of', 'go to sleep-used for']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - correspond target = ['bed', 'person', 'dog']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - test id = 908, question = Which object in this image is used in escargot?, img = ILSVRC2012_test_00003143.JPEG\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - real suppord fact in dataset=['escargot', 'related to', 'nail'], real answer = nail\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - normal model predict = ['lizard', 'snake', 'nail', 'ant', 'bee', 'armadillo', 'monkey', 'butterfly', 'tick', 'frog']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict = ['snake', 'elephant', 'computer', 'desk', 'person', 'lizard', 'nail', 'ant', 'bee', 'armadillo']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict relation = ['used for', 'at location', 'has property', 'receives action', 'belong to', 'is a', 'related to', 'has a', 'capable of', 'popular', 'part of', 'convenient', 'visible', 'specific', 'surface']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict fact = ['study archeology', 'study', 'india']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - suppord fact predict = ['study archeology-capable of', 'india-at location', 'study-used for']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - correspond target = ['desk', 'computer', 'elephant', 'person', 'snake']\r\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - #################################################################################\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:35 - 0:00:54 - #################################################################################\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - test id = 1261, question = Which object in this image has a keyboard, img = COCO_val2014_000000013659.jpg\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - real suppord fact in dataset=['computer', 'has a', 'keyboard'], real answer = computer\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - normal model predict = ['laptop', 'computer', 'desk', 'keyboard', 'chair', 'couch', 'ram', 'sofa', 'monitor', 'printer']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict = ['laptop', 'monitor', 'trombone', 'computer', 'desk', 'keyboard', 'chair', 'couch', 'ram', 'sofa']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict relation = ['has a', 'part of', 'related to', 'is a', 'specific', 'social', 'used for', 'important', 'common', 'frequent', 'capable of', 'large', 'great', 'animal order', 'low']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict fact = ['touchpad', 'slider', 'output']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - suppord fact predict = ['slider-related to', 'output-related to', 'touchpad-part of']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - correspond target = ['trombone', 'monitor', 'laptop']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - #################################################################################\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - #################################################################################\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - test id = 2786, question = which object can we find at the end of the line in this image, img = COCO_val2014_000000114634.jpg\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - real suppord fact in dataset=['kite', 'at location', 'end of line'], real answer = kite\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - normal model predict = ['kite', 'bird', 'airplane', 'fly', 'butterfly', 'dragonfly', 'person', 'beach', 'plane', 'shell']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict = ['shell', 'coast', 'turtle', 'swim', 'wave', 'ship', 'kite', 'bird', 'airplane', 'fly']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict relation = ['at location', 'safe', 'belong to', 'capable of', 'convenient', 'is a', 'part of', 'protected', 'surface', 'used for', 'crowded', 'primitive', 'active', 'visible', 'impassable']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - our model predict fact = ['in ocean', 'ocean', 'fly in sky']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - suppord fact predict = ['ocean-at location', 'ocean-part of', 'ocean-used for', 'in ocean-at location']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - correspond target = ['ship', 'coast', 'turtle', 'wave', 'swim', 'shell']\n",
      "INFO - 08/13/22 23:30:35 - 0:00:54 - #################################################################################\n",
      " 36%|███████████████▍                           | 32/89 [00:21<00:40,  1.39it/s]INFO - 08/13/22 23:30:36 - 0:00:54 - #################################################################################\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - test id = 48, question = Which object in this image can be used to heat food?, img = ILSVRC2012_test_00054961.JPEG\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - real suppord fact in dataset=['microwave', 'capable of', 'heat food'], real answer = microwave\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - normal model predict = ['microwave', 'oven', 'toaster', 'refrigerator', 'stove', 'hotdog', 'fridge', 'kitchenette', 'kitchen utensil', 'dishwasher']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - our model predict = ['refrigerator', 'microwave', 'oven', 'toaster', 'stove', 'hotdog', 'fridge', 'kitchenette', 'kitchen utensil', 'dishwasher']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - our model predict relation = ['used for', 'capable of', 'has property', 'belong to', 'related to', 'receives action', 'has a', 'at location', 'effective', 'specific', 'fast', 'easy', 'is a', 'efficient', 'convenient']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - our model predict fact = ['keep food cold', 'chill food', 'cold food storage']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - suppord fact predict = ['cold food storage-used for', 'keep food cold-used for', 'chill food-used for', 'keep food cold-capable of']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - correspond target = ['refrigerator']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - #################################################################################\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - #################################################################################\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - test id = 1641, question = How many legs does the animal in the image have?, img = COCO_val2014_000000017282.jpg\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - real suppord fact in dataset=['elephant', 'related to', 'four'], real answer = four\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - normal model predict = ['elephant', 'wild', 'big', 'tourist', 'forest road', 'park', 'river', 'zoo', 'beach', 'child']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - our model predict = ['elephant', 'big', 'horse', 'mountain', 'transport', 'wild', 'tourist', 'forest road', 'park', 'river']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - our model predict relation = ['has property', 'has a', 'at location', 'animal family', 'animal order', 'part of', 'receives action', 'is a', 'large', 'created by', 'small', 'animal kingdom', 'used for', 'capable of', 'animal class']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - our model predict fact = ['elephant', 'large animal', 'large']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - suppord fact predict = ['large-has property', 'elephant-used for', 'elephant-has property', 'large animal-is a']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - correspond target = ['horse', 'transport', 'elephant', 'mountain', 'big']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - #################################################################################\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - #################################################################################\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - test id = 1444, question = Which thin in the image can be used for carrying goods?, img = COCO_val2014_000000019032.jpg\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - real suppord fact in dataset=['horse', 'used for', 'carry good'], real answer = horse\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - normal model predict = ['luggage', 'horse', 'suitcase', 'handbag', 'bow', 'wooden', 'violin', 'elephant', 'ride', 'camel']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - our model predict = ['luggage', 'airplane', 'train', 'horse', 'suitcase', 'handbag', 'bow', 'wooden', 'violin', 'elephant']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - our model predict relation = ['used for', 'capable of', 'related to', 'belong to', 'specific', 'has property', 'receives action', 'desires', 'part of', 'important', 'is a', 'effective', 'accurate', 'has a', 'at location']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - our model predict fact = ['carry freight', 'carry freight or cargo', 'carry']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - suppord fact predict = ['carry freight or cargo-used for', 'carry freight-capable of', 'carry-used for']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - correspond target = ['luggage', 'train', 'airplane']\n",
      "INFO - 08/13/22 23:30:36 - 0:00:54 - #################################################################################\n",
      " 37%|███████████████▉                           | 33/89 [00:22<00:38,  1.46it/s]INFO - 08/13/22 23:30:37 - 0:00:55 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - test id = 825, question = What objects in this image are inspirational, img = ILSVRC2012_test_00035105.JPEG\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - real suppord fact in dataset=['forest road', 'has property', 'inspirational'], real answer = forest road\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - normal model predict = ['stop sign', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car', 'bus', 'person']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict = ['stop sign', 'horse', 'tv', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict relation = ['capable of', 'is a', 'has property', 'receives action', 'has a', 'used for', 'related to', 'part of', 'desires', 'at location', 'belong to', 'created by', 'specific', 'good', 'animal order']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict fact = ['traffic sign', 'clop', 'advertise']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - suppord fact predict = ['advertise-used for', 'traffic sign-belong to', 'clop-related to']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - correspond target = ['stop sign', 'tv', 'horse']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - test id = 1848, question = Which object in this image is capable of causing floods?, img = COCO_val2014_000000007394.jpg\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - real suppord fact in dataset=['rain', 'capable of', 'cause flood'], real answer = rain\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - normal model predict = ['person', 'make person happy', 'any place where person live', 'thing', 'transport person', 'snake', 'elephant', 'bird', 'stop sign', 'monkey']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict = ['person', 'dog', 'power drill', 'make person happy', 'any place where person live', 'thing', 'transport person', 'snake', 'elephant', 'bird']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict relation = ['capable of', 'stable', 'intelligent', 'high', 'powerful', 'efficient', 'fast', 'active', 'used for', 'accurate', 'visible', 'reliable', 'slow', 'effective', 'transportable']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict fact = ['cause injury when not use carefully', 'have mental illness', 'appear tire']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - suppord fact predict = ['appear tire-capable of', 'have mental illness-capable of', 'cause injury when not use carefully-capable of']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - correspond target = ['power drill', 'person', 'dog']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - test id = 401, question = Which object in this image is a kind of media, img = ILSVRC2012_test_00032881.JPEG\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - real suppord fact in dataset=['tv', 'is a', 'medium'], real answer = tv\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - normal model predict = ['tv', 'lamp', 'couch', 'chair', 'bed', 'clock', 'monitor', 'desk', 'wii', 'vase']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict = ['water', 'camel', 'flute', 'harp', 'giraffe', 'tv', 'lamp', 'couch', 'chair', 'bed']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict relation = ['belong to', 'is a', 'related to', 'has property', 'used for', 'has a', 'at location', 'part of', 'cool', 'easy', 'important', 'specific', 'good', 'animal class', 'convenient']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict fact = ['essential part of life', 'instrument of music', 'ruminant']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - suppord fact predict = ['ruminant-is a', 'instrument of music-is a', 'essential part of life-is a']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - correspond target = ['harp', 'water', 'camel', 'giraffe', 'flute']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:37 - 0:00:55 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - test id = 69, question = Which action is better than the action shown in this image, img = COCO_val2014_000000147025.jpg\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - real suppord fact in dataset=['position', 'good', 'standing'], real answer = position\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - normal model predict = ['person', 'camera', 'playing', 'ball', 'make person happy', 'tennis ball', 'golf ball', 'throw', 'corkscrew', 'frisbee']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict = ['playing', 'jumping', 'person', 'camera', 'ball', 'make person happy', 'tennis ball', 'golf ball', 'throw', 'corkscrew']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict relation = ['important', 'strenuous', 'prevalent', 'dangerous', 'tough', 'impassable', 'easy', 'safe', 'stressful', 'popular', 'vulnerable', 'effective', 'sensible', 'common', 'frequent']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict fact = ['god fire alarm', 'dressage', 'monkey']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - suppord fact predict = ['god fire alarm-important', 'dressage-strenuous']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - correspond target = ['jumping', 'playing']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - test id = 516, question = What is the place in this image used for?, img = COCO_val2014_000000108548.jpg\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - real suppord fact in dataset=['bathroom', 'used for', 'wash your hand'], real answer = wash your hand\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - normal model predict = ['sleep away from home', 'sit outside', 'prepare food', 'eat', 'sit down on', 'sleep', 'travel', 'entertain yourself on windy day', 'wash', 'preventing from getting wet']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict = ['sleep away from home', 'prepare food', 'sleep', 'cooking', 'breakfast', 'human', 'park space', 'temporary residence', 'house', 'hotel room']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict relation = ['used for', 'related to', 'capable of', 'specific', 'receives action', 'belong to', 'effective', 'has property', 'high', 'part of', 'at location', 'animal order', 'good', 'important', 'common']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict fact = ['kitchenette', 'hotel room', 'room']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - suppord fact predict = ['hotel room-used for', 'kitchenette-used for', 'room-important', 'room-at location', 'kitchenette-at location']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - correspond target = ['prepare food', 'sleep', 'house', 'hotel room', 'park space', 'cooking', 'temporary residence', 'sleep away from home', 'human', 'breakfast']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - test id = 196, question = Which thing is made from fermented grape juice?, img = COCO_val2014_000000016382.jpg\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - real suppord fact in dataset=['wine', 'receives action', 'make from ferment grape juice'], real answer = wine\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - normal model predict = ['glass', 'wine glass', 'lemon', 'wine', 'white', 'drink', 'pineapple', 'orange', 'light', 'apple']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict = ['glass', 'person', 'wine glass', 'lemon', 'wine', 'white', 'drink', 'pineapple', 'orange', 'light']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict relation = ['has a', 'is a', 'has property', 'created by', 'part of', 'small', 'capable of', 'acidic', 'green', 'red', 'stable', 'surface', 'protected', 'acid', 'at location']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict fact = ['grape juice', 'drink juice of pineapple', 'make from ferment grape juice']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - suppord fact predict = ['grape juice-has a', 'drink juice of pineapple-capable of']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - correspond target = ['glass', 'person']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - test id = 2008, question = What is the place in this image used for?, img = COCO_val2014_000000011727.jpg\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - real suppord fact in dataset=['bathroom', 'used for', 'clean your tooth in'], real answer = clean your tooth in\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - normal model predict = ['pee', 'wash', 'swim', 'sleep', 'preventing from getting wet', 'laundromat', 'sleep away from home', 'toilet', 'cold and wet', 'sink']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict = ['pee', 'wash', 'cooking', 'prepare food', 'hotel room', 'breakfast', 'house', 'plunger', 'swim', 'sleep']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict relation = ['used for', 'belong to', 'capable of', 'related to', 'effective', 'good', 'receives action', 'part of', 'great', 'specific', 'easy', 'at location', 'popular', 'important', 'animal order']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - our model predict fact = ['kitchenette', 'shower', 'toilet']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - suppord fact predict = ['toilet-used for', 'kitchenette-used for', 'kitchenette-at location', 'shower-used for']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - correspond target = ['prepare food', 'house', 'hotel room', 'plunger', 'cooking', 'pee', 'wash', 'breakfast']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:55 - #################################################################################\n",
      " 38%|████████████████▍                          | 34/89 [00:22<00:37,  1.45it/s]INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - test id = 1187, question = What object in this image is a means of water transport?, img = COCO_val2014_000000024921.jpg\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - real suppord fact in dataset=['boat', 'used for', 'transport'], real answer = boat\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - normal model predict = ['kite', 'cloud', 'airplane', 'surfboard', 'golfcart', 'boat', 'sail boat', 'spaceship', 'shore boat', 'bicycle']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict = ['cloud', 'jellyfish', 'whale', 'fire hydrant', 'lake', 'river', 'kite', 'airplane', 'surfboard', 'golfcart']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict relation = ['is a', 'belong to', 'related to', 'has a', 'part of', 'receives action', 'capable of', 'safe', 'at location', 'important', 'accurate', 'trustworthy', 'protected', 'good', 'cool']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict fact = ['transport across body of water', 'water', 'water supply']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - suppord fact predict = ['water-belong to', 'water-at location', 'water supply-belong to', 'water-has a']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - correspond target = ['jellyfish', 'river', 'whale', 'fire hydrant', 'cloud', 'lake']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - test id = 2654, question = What do rice belong to, img = COCO_val2014_000000003501.jpg\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - real suppord fact in dataset=['rice', 'is a', 'food'], real answer = food\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - normal model predict = ['vegetable', 'meat', 'fruit', 'salad', 'cheese', 'food', 'tomato', 'vegetarian', 'carrot', 'broccoli']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict = ['meat', 'cheese', 'carrot', 'bread', 'unhealthy', 'mushroom', 'cake', 'oven', 'italian', 'ye']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict relation = ['belong to', 'at location', 'used for', 'is a', 'related to', 'has a', 'receives action', 'good', 'created by', 'has property', 'expensive', 'animal order', 'easy', 'blind', 'clean']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict fact = ['pizza', 'sugar cure', 'carrot cake']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - suppord fact predict = ['sugar cure-easy', 'pizza-has a', 'pizza-related to', 'pizza-at location', 'pizza-has property', 'carrot cake-related to', 'pizza-belong to']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - correspond target = ['cake', 'mushroom', 'oven', 'bread', 'ye', 'unhealthy', 'carrot', 'italian', 'cheese', 'meat']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - test id = 703, question = Where does the vehicle in the middle of this image can be found in?, img = ILSVRC2012_test_00015539.JPEG\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - real suppord fact in dataset=['train', 'at location', 'station'], real answer = station\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - normal model predict = ['airport', 'mountainous area', 'hotel room', 'runway', 'land plane', 'tourist', 'flight', 'city', 'plane to land on', 'hot room']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict = ['airport', 'runway', 'travel', 'bathroom', 'airplane', 'luggage', 'toilet', 'fly', 'mountainous area', 'hotel room']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict relation = ['at location', 'has a', 'used for', 'is a', 'related to', 'has property', 'part of', 'specific', 'small', 'animal family', 'common', 'long', 'animal order', 'large', 'surface']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict fact = ['airplane', 'hotel', 'airport']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - suppord fact predict = ['airport-used for', 'airport-at location', 'airplane-used for', 'airport-has a', 'airplane-at location', 'hotel-at location']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - correspond target = ['toilet', 'fly', 'airplane', 'bathroom', 'runway', 'luggage', 'airport', 'travel']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - test id = 2239, question = What is the class of the animal in this image?, img = ILSVRC2012_test_00018998.JPEG\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - real suppord fact in dataset=['otter', 'animal class', 'mammal'], real answer = mammal\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - normal model predict = ['whale', 'dolphin', 'sea', 'jellyfish', 'fish', 'ocean', 'turtle', 'mammal', 'otter', 'human']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict = ['wave', 'water', 'shell', 'blue', 'low', 'whale', 'dolphin', 'sea', 'jellyfish', 'fish']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict relation = ['has property', 'has a', 'animal family', 'animal kingdom', 'animal class', 'belong to', 'is a', 'animal order', 'protected', 'animal phylum', 'strong', 'impassable', 'light', 'tough', 'independent']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict fact = ['ocean', 'turtle', 'shark']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - suppord fact predict = ['turtle-has a', 'ocean-has property', 'turtle-has property', 'ocean-has a']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - correspond target = ['blue', 'water', 'wave', 'shell', 'low']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - test id = 2683, question = Which object in this image belongs to the category Printing?, img = ILSVRC2012_test_00015342.JPEG\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - real suppord fact in dataset=['book', 'belong to', 'print'], real answer = book\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - normal model predict = ['monitor', 'computer', 'laptop', 'desk', 'printer', 'your house', 'mouse', 'clock', 'dining table', 'home office']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict = ['monitor', 'computer', 'laptop', 'desk', 'printer', 'your house', 'mouse', 'clock', 'dining table', 'home office']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict relation = ['belong to', 'desires', 'is a', 'loyal', 'animal kingdom', 'animal phylum', 'capable of', 'animal order', 'trustworthy', 'related to', 'comfortable', 'sensible', 'visible', 'human', 'at location']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict fact = ['print document', 'data process', 'digital technology']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - suppord fact predict = ['data process-related to', 'digital technology-belong to']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - correspond target = ['computer', 'monitor']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - test id = 2281, question = What is the place in this image used for?, img = COCO_val2014_000000104837.jpg\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - real suppord fact in dataset=['bathroom', 'used for', 'pee'], real answer = pee\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - normal model predict = ['sleep away from home', 'prepare food', 'travel in car', 'travel', 'eat', 'fight fire', 'cooking', 'cut', 'work', 'space to run and play']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict = ['sleep away from home', 'prepare food', 'cooking', 'sleep', 'house', 'temporary residence', 'breakfast', 'hotel room', 'tv', 'cat']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict relation = ['used for', 'related to', 'effective', 'specific', 'capable of', 'good', 'at location', 'great', 'belong to', 'efficient', 'animal order', 'easy', 'expensive', 'high', 'accurate']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict fact = ['kitchenette', 'hotel room', 'apartment']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - suppord fact predict = ['hotel room-used for', 'kitchenette-used for', 'kitchenette-at location', 'apartment-at location']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - correspond target = ['cat', 'prepare food', 'sleep', 'house', 'hotel room', 'cooking', 'temporary residence', 'tv', 'sleep away from home', 'breakfast']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - test id = 2577, question = Which object in this image has meat?, img = ILSVRC2012_test_00000138.JPEG\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - real suppord fact in dataset=['nail', 'belong to', 'meat'], real answer = nail\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - normal model predict = ['ray', 'armadillo', 'pizza', 'sandwich', 'hamburger', 'baseball', 'snake', 'corkscrew', 'baseball bat', 'knife']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict = ['person', 'cow', 'cat', 'ray', 'armadillo', 'pizza', 'sandwich', 'hamburger', 'baseball', 'snake']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict relation = ['related to', 'has a', 'part of', 'specific', 'has property', 'capable of', 'social', 'is a', 'desires', 'important', 'used for', 'receives action', 'at location', 'surface', 'common']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict fact = ['meat', 'eat meat', 'beef']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - suppord fact predict = ['meat-related to', 'eat meat-capable of']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - correspond target = ['cat', 'person', 'cow']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - test id = 1572, question = Which transportation topic is shown in this image?, img = COCO_val2014_000000145921.jpg\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - real suppord fact in dataset=['airplane', 'is a', 'transportation topic'], real answer = airplane\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - normal model predict = ['airplane', 'plane', 'land airplane', 'airport', 'spaceship', 'runway', 'flight', 'land plane', 'car', 'taxi']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict = ['bus', 'boat', 'airplane', 'plane', 'land airplane', 'airport', 'spaceship', 'runway', 'flight', 'land plane']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict relation = ['belong to', 'is a', 'related to', 'at location', 'part of', 'important', 'capable of', 'has property', 'long', 'has a', 'common', 'used for', 'small', 'safe', 'dangerous']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict fact = ['mode of public transportation', 'mode of transportation', 'form of public transportation']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - suppord fact predict = ['form of public transportation-is a', 'mode of public transportation-is a', 'mode of transportation-is a']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - correspond target = ['bus', 'boat']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - test id = 286, question = Where you can find the animal in this image?, img = ILSVRC2012_test_00017725.JPEG\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - real suppord fact in dataset=['camel', 'at location', 'desert'], real answer = desert\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - normal model predict = ['camel', 'beach', 'horse', 'tourist', 'desert', 'mountain', 'africa', 'zoo', 'mountainous area', 'park']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict = ['horse', 'sheep', 'dog', 'giraffe', 'zebra', 'camel', 'beach', 'tourist', 'desert', 'mountain']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict relation = ['at location', 'is a', 'related to', 'has a', 'belong to', 'capable of', 'part of', 'has property', 'used for', 'important', 'specific', 'created by', 'animal order', 'visible', 'small']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict fact = ['herd animal', 'domesticate animal', 'farm animal']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - suppord fact predict = ['farm animal-is a', 'herd animal-is a', 'domesticate animal-is a', 'farm animal-related to']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - correspond target = ['horse', 'dog', 'zebra', 'sheep', 'giraffe']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - test id = 1073, question = Which object in this image can take you to an island, img = COCO_val2014_000000135846.jpg\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - real suppord fact in dataset=['boat', 'capable of', 'take you to island'], real answer = boat\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - normal model predict = ['person', 'luggage', 'boat', 'trombone', 'suitcase', 'violin', 'canvas', 'cello', 'trumpet', 'backpack']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict = ['person', 'car', 'dog', 'luggage', 'boat', 'trombone', 'suitcase', 'violin', 'canvas', 'cello']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict relation = ['capable of', 'related to', 'used for', 'at location', 'has property', 'specific', 'has a', 'is a', 'desires', 'important', 'belong to', 'accurate', 'surface', 'reliable', 'visible']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict fact = ['be friend to human', 'turn leave', 'dare another to do something careless']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - suppord fact predict = ['be friend to human-capable of', 'turn leave-capable of', 'dare another to do something careless-capable of']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - correspond target = ['person', 'car', 'dog']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - test id = 254, question = Which bag is more comfortable than a shoulder bag?, img = ILSVRC2012_test_00010551.JPEG\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - real suppord fact in dataset=['backpack', 'comfortable', 'shoulder bag'], real answer = backpack\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - normal model predict = ['luggage', 'suitcase', 'handbag', 'furniture', 'umbrella', 'sunglasses', 'car', 'hand', 'suit', 'cheap']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict = ['sofa', 'luggage', 'suitcase', 'handbag', 'furniture', 'umbrella', 'sunglasses', 'car', 'hand', 'suit']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict relation = ['popular', 'is a', 'light', 'colorful', 'fast', 'expensive', 'convenient', 'warm', 'used for', 'low', 'sweet', 'common', 'easy', 'acid', 'efficient']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict fact = ['shoulder bag', 'soft cushion', 'large comfortable seat']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - suppord fact predict = ['large comfortable seat-is a']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - correspond target = ['sofa']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - test id = 1841, question = What musical instrument can be found in this place?, img = ILSVRC2012_test_00015696.JPEG\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - real suppord fact in dataset=['metronome', 'at location', 'music studio'], real answer = metronome\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - normal model predict = ['violin', 'drum', 'cello', 'piano', 'guitar', 'like violin but large', 'music studio', 'train', 'music', 'play music']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict = ['violin', 'drum', 'guitar', 'trombone', 'harp', 'saxophone', 'harmonica', 'banjo', 'accordion', 'french horn']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict relation = ['at location', 'is a', 'has a', 'used for', 'part of', 'receives action', 'has property', 'belong to', 'related to', 'animal class', 'animal family', 'capable of', 'good', 'animal order', 'convenient']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict fact = ['musical instrument', 'musical string instrument', 'string musical instrument']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - suppord fact predict = ['musical string instrument-is a', 'musical instrument-belong to', 'musical instrument-related to', 'string musical instrument-is a', 'musical instrument-is a']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - correspond target = ['harp', 'accordion', 'french horn', 'banjo', 'drum', 'violin', 'saxophone', 'guitar', 'trombone', 'harmonica']\r\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - test id = 906, question = Which things in this image can wave their antennae?, img = ILSVRC2012_test_00003143.JPEG\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - real suppord fact in dataset=['nail', 'capable of', 'wave their antenna'], real answer = nail\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - normal model predict = ['snake', 'lizard', 'nail', 'ant', 'monkey', 'butterfly', 'bee', 'bird', 'turtle', 'frog']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict = ['tree', 'hand', 'umbrella', 'snake', 'lizard', 'nail', 'ant', 'monkey', 'butterfly', 'bee']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict relation = ['capable of', 'is a', 'has a', 'used for', 'fast', 'part of', 'high', 'visible', 'related to', 'at location', 'accurate', 'belong to', 'powerful', 'stable', 'long']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict fact = ['high five', 'shield one from rain or sun', 'leave on their branch']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - suppord fact predict = ['shield one from rain or sun-capable of', 'high five-related to', 'leave on their branch-has a']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - correspond target = ['hand', 'umbrella', 'tree']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - test id = 225, question = Which object in this image is related to boomerang?, img = COCO_val2014_000000103579.jpg\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - real suppord fact in dataset=['boomerang', 'related to', 'frisbee'], real answer = frisbee\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - normal model predict = ['grass', 'fence', 'horse', 'crutch', 'flowers', 'sand', 'frisbee', 'tree', 'root', 'shade table']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict = ['sheep', 'desert', 'camel', 'work for day without water', 'hump', 'grass', 'fence', 'horse', 'crutch', 'flowers']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict relation = ['related to', 'belong to', 'specific', 'important', 'used for', 'capable of', 'desires', 'common', 'at location', 'animal order', 'accurate', 'social', 'part of', 'trustworthy', 'is a']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict fact = ['dromedary', 'camel', 'mutton']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - suppord fact predict = ['camel-at location', 'camel-capable of', 'mutton-related to', 'dromedary-related to', 'camel-related to']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - correspond target = ['desert', 'camel', 'work for day without water', 'sheep', 'hump']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - test id = 2769, question = Which part of the food can be eaten?, img = COCO_val2014_000000026611.jpg\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - real suppord fact in dataset=['carrot', 'is a', 'root'], real answer = root\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - normal model predict = ['vegetable', 'fruit', 'carrot', 'meat', 'tomato', 'orange', 'salad', 'banana', 'cucumber', 'broccoli']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict = ['banana', 'bread', 'apple', 'fork', 'cake', 'hot dog', 'person', 'vegetable', 'fruit', 'carrot']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict relation = ['used for', 'belong to', 'is a', 'related to', 'has property', 'receives action', 'at location', 'has a', 'part of', 'desires', 'specific', 'created by', 'easy', 'animal order', 'common']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - our model predict fact = ['eat food', 'eat', 'eat meat']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - suppord fact predict = ['eat-used for', 'eat food-related to', 'eat food-used for', 'eat-has a']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - correspond target = ['cake', 'apple', 'hot dog', 'bread', 'banana', 'person', 'fork']\n",
      "INFO - 08/13/22 23:30:37 - 0:00:56 - #################################################################################\n",
      " 39%|████████████████▉                          | 35/89 [00:23<00:36,  1.47it/s]INFO - 08/13/22 23:30:38 - 0:00:56 - #################################################################################\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - test id = 170, question = Who are humans in this image?, img = COCO_val2014_000000100895.jpg\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - real suppord fact in dataset=['child', 'belong to', 'human'], real answer = child\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - normal model predict = ['child', 'person', 'dog', 'police', 'toys', 'animal', 'human', 'cat', 'boy', 'hot dog']\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - our model predict = ['dog', 'human', 'child', 'person', 'police', 'toys', 'animal', 'cat', 'boy', 'hot dog']\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - our model predict relation = ['capable of', 'belong to', 'is a', 'loyal', 'trustworthy', 'stable', 'desires', 'intelligent', 'independent', 'dependable', 'related to', 'fast', 'important', 'reliable', 'strong']\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - our model predict fact = ['child', 'popular family pet', 'please little child']\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - suppord fact predict = ['popular family pet-is a', 'child-belong to']\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - correspond target = ['human', 'dog']\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - #################################################################################\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - #################################################################################\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - test id = 475, question = Which place is more expensive than the place shown in this image, img = COCO_val2014_000000105448.jpg\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - real suppord fact in dataset=['track', 'expensive', 'tire'], real answer = track\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - normal model predict = ['person', 'jumping', 'car', 'eat', 'house', 'swimming', 'fun', 'child', 'make person happy', 'dressage']\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - our model predict = ['person', 'car', 'animal', 'squirrel', 'skunk', 'mushroom', 'jumping', 'eat', 'house', 'swimming']\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - our model predict relation = ['at location', 'important', 'convenient', 'impassable', 'safe', 'strenuous', 'cheap', 'popular', 'fast', 'crowded', 'primitive', 'maneuverable', 'colorful', 'comfortable', 'frequent']\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - our model predict fact = ['forest', 'road', 'village']\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - suppord fact predict = ['road-at location', 'forest-at location', 'village-at location']\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - correspond target = ['animal', 'mushroom', 'squirrel', 'skunk', 'person', 'car']\n",
      "INFO - 08/13/22 23:30:38 - 0:00:56 - #################################################################################\n",
      " 40%|█████████████████▍                         | 36/89 [00:24<00:36,  1.45it/s]INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - test id = 2467, question = What is the musical instrument in the image made from?, img = ILSVRC2012_test_00010154.JPEG\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - real suppord fact in dataset=['guitar', 'has property', 'wood'], real answer = wood\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - normal model predict = ['guitar', 'playing', 'music studio', 'play music', 'saxophone', 'violin', 'harmonica', 'music', 'piano', 'banjo']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict = ['guitar', 'violin', 'harmonica', 'banjo', 'drum', 'accordion', 'trombone', 'harp', 'french horn', 'playing']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict relation = ['is a', 'receives action', 'part of', 'related to', 'has property', 'used for', 'capable of', 'at location', 'has a', 'important', 'animal order', 'animal class', 'desires', 'created by', 'specific']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict fact = ['musical string instrument', 'string musical instrument', 'musical instrument']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - suppord fact predict = ['string musical instrument-is a', 'musical instrument-related to', 'musical string instrument-is a', 'musical instrument-is a']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - correspond target = ['harp', 'accordion', 'french horn', 'banjo', 'drum', 'violin', 'guitar', 'trombone', 'harmonica']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - test id = 291, question = Which animal in this image can be found in a forest, img = COCO_val2014_000000015070.jpg\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - real suppord fact in dataset=['squirrel', 'at location', 'forest'], real answer = squirrel\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - normal model predict = ['cat', 'dog', 'kitten', 'dog poop', 'rabbit', 'monkey', 'squirrel', 'otter', 'skunk', 'mammal']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict = ['cat', 'dog', 'kitten', 'goldfish', 'mouse', 'person', 'any place where person live', 'dog poop', 'rabbit', 'monkey']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict relation = ['at location', 'capable of', 'belong to', 'related to', 'has a', 'specific', 'desires', 'used for', 'human', 'accurate', 'visible', 'good', 'active', 'great', 'important']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict fact = ['pet cat', 'pet', 'cat']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - suppord fact predict = ['pet-belong to', 'cat-active', 'pet-used for', 'cat-at location', 'pet cat-desires', 'cat-capable of', 'pet-related to', 'cat-belong to']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - correspond target = ['cat', 'dog', 'mouse', 'goldfish', 'person', 'kitten', 'any place where person live']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - test id = 501, question = Normally where can you find this thing?, img = ILSVRC2012_test_00007890.JPEG\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - real suppord fact in dataset=['traffic light', 'at location', 'street'], real answer = street\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - normal model predict = ['airport', 'park', 'house', 'bathroom', 'ski slope', 'zoo', 'park space', 'flight', 'runway', 'hotel room']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict = ['kite', 'beach', 'handbag', 'throw', 'elephant', 'airport', 'park', 'house', 'bathroom', 'ski slope']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict relation = ['at location', 'related to', 'used for', 'is a', 'specific', 'part of', 'capable of', 'has a', 'belong to', 'visible', 'has property', 'receives action', 'surface', 'accurate', 'important']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict fact = ['person', 'romantic', \"woman's closet\"]\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - suppord fact predict = [\"woman's closet-at location\", 'person-has property', 'person-capable of', 'romantic-has property']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - correspond target = ['handbag', 'throw', 'elephant', 'kite', 'beach']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - test id = 2365, question = Which object in this image is green before they are red, img = ILSVRC2012_test_00048262.JPEG\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - real suppord fact in dataset=['tomato', 'has property', 'green before they be red'], real answer = tomato\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - normal model predict = ['cucumber', 'carrot', 'shell', 'walnut', 'tomato', 'banana', 'lobster', 'fig', 'salad', 'mushroom']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict = ['apple', 'cell phone', 'person', 'cucumber', 'carrot', 'shell', 'walnut', 'tomato', 'banana', 'lobster']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict relation = ['has property', 'is a', 'belong to', 'used for', 'at location', 'created by', 'has a', 'receives action', 'protected', 'visible', 'capable of', 'safe', 'popular', 'red', 'related to']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict fact = ['not orange nor be they lemon', 'be sell thing', 'make call']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - suppord fact predict = ['make call-capable of', 'be sell thing-capable of', 'not orange nor be they lemon-is a']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - correspond target = ['apple', 'person', 'cell phone']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - test id = 772, question = This game is most populate in which country?, img = ILSVRC2012_test_00048422.JPEG\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - real suppord fact in dataset=['table tennis', 'has property', 'china'], real answer = china\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - normal model predict = ['basketball', 'stop sign', 'play basketball', 'tennis', 'volleyball', 'play baseball on it', 'soccer ball', 'tennis ball', 'play baseball', 'play tennis']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict = ['baseball', 'play', 'united states', 'basketball', 'stop sign', 'play basketball', 'tennis', 'volleyball', 'play baseball on it', 'soccer ball']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict relation = ['has property', 'at location', 'belong to', 'is a', 'related to', 'used for', 'receives action', 'capable of', 'important', 'good', 'dangerous', 'protected', 'desires', 'has a', 'common']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict fact = ['basketball', 'football', 'baseball game']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - suppord fact predict = ['football-used for', 'basketball-has property', 'baseball game-at location']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - correspond target = ['baseball', 'united states', 'play']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - test id = 2515, question = What object in this image can joing organizations?, img = ILSVRC2012_test_00005014.JPEG\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - real suppord fact in dataset=['person', 'capable of', 'join organization'], real answer = person\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - normal model predict = ['person', 'dog', 'make person happy', 'dog poop', 'horse', 'frisbee', 'grass', 'transport person', 'cat', 'snake']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict = ['camel', 'hump', 'desert', 'work for day without water', 'accordion', 'person', 'dog', 'make person happy', 'dog poop', 'horse']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict relation = ['capable of', 'used for', 'desires', 'related to', 'at location', 'has a', 'is a', 'accurate', 'receives action', 'intelligent', 'human', 'specific', 'has property', 'reliable', 'active']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict fact = ['bellow', 'hump', 'camel']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - suppord fact predict = ['hump-related to', 'camel-at location', 'camel-capable of', 'camel-related to', 'bellow-related to']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - correspond target = ['desert', 'accordion', 'camel', 'work for day without water', 'hump']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - test id = 491, question = Which object in this image is peelable?, img = ILSVRC2012_test_00037882.JPEG\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - real suppord fact in dataset=['banana', 'has property', 'peelable'], real answer = banana\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - normal model predict = ['banana', 'orange', 'fruit', 'coffee', 'strawberry', 'chocolate', 'lemon', 'apple', 'pineapple', 'cake']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict = ['coffee', 'dog', 'giraffe', 'camel', 'banana', 'orange', 'fruit', 'strawberry', 'chocolate', 'lemon']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict relation = ['is a', 'has property', 'related to', 'belong to', 'used for', 'has a', 'at location', 'important', 'part of', 'good', 'specific', 'easy', 'common', 'cool', 'accurate']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict fact = ['ruminant', 'stimulant', 'woof woof']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - suppord fact predict = ['ruminant-is a', 'stimulant-belong to', 'woof woof-related to']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - correspond target = ['camel', 'giraffe', 'coffee', 'dog']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - test id = 1949, question = Which object on the bottom of this image belongs to the category Gymnastics?, img = ILSVRC2012_test_00021252.JPEG\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - real suppord fact in dataset=['balance beam', 'belong to', 'gymnastics'], real answer = balance beam\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - normal model predict = ['volleyball', 'child', 'basketball', 'soccer ball', 'rugby ball', 'tennis', 'punching bag', 'tennis ball', 'dressage', 'balance beam']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict = ['neck brace', 'skateboard', 'sunglasses', 'volleyball', 'child', 'basketball', 'soccer ball', 'rugby ball', 'tennis', 'punching bag']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict relation = ['belong to', 'desires', 'is a', 'animal kingdom', 'animal phylum', 'loyal', 'trustworthy', 'animal order', 'related to', 'comfortable', 'animal family', 'sensible', 'protected', 'animal class', 'human']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict fact = ['orthopedics', 'boardsport', 'physician']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - suppord fact predict = ['orthopedics-belong to', 'physician-belong to', 'boardsport-belong to']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - correspond target = ['neck brace', 'sunglasses', 'skateboard']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - test id = 2808, question = What thing can the objects in this image do?, img = ILSVRC2012_test_00057349.JPEG\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - real suppord fact in dataset=['can opener', 'used for', 'open can'], real answer = open can\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - normal model predict = ['scissors', 'knife', 'hammer', 'corkscrew', 'clean your tooth in', 'fork', 'screwdriver', 'hair', 'knife in drawer', 'peel']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict = ['clock', 'crutch', 'carrot', 'tv', 'flute', 'scissors', 'knife', 'hammer', 'corkscrew', 'clean your tooth in']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict relation = ['used for', 'has property', 'at location', 'capable of', 'related to', 'receives action', 'belong to', 'created by', 'has a', 'animal order', 'specific', 'part of', 'fast', 'good', 'expensive']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - our model predict fact = ['advertise', 'tick', 'dental tool']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - suppord fact predict = ['advertise-used for', 'tick-related to', 'tick-good']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - correspond target = ['clock', 'tv', 'carrot', 'crutch', 'flute']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:57 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████▉                         | 37/89 [00:24<00:36,  1.42it/s]INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - test id = 731, question = What is the eight-sided object in this image?, img = ILSVRC2012_test_00004200.JPEG\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - real suppord fact in dataset=['stop sign', 'is a', 'eight side object'], real answer = stop sign\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - normal model predict = ['human', 'monkey', 'mouse', 'animal', 'mammal', 'carnivora', 'otter', 'tick', 'rabbit', 'cat']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict = ['bottle', 'basketball', 'desk', 'human', 'monkey', 'mouse', 'animal', 'mammal', 'carnivora', 'otter']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict relation = ['has property', 'is a', 'has a', 'animal order', 'animal family', 'animal kingdom', 'animal class', 'related to', 'at location', 'animal phylum', 'part of', 'common', 'belong to', 'important', 'protected']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict fact = ['round object', 'seat person', 'table']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - suppord fact predict = ['round object-is a', 'table-is a', 'table-at location']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - correspond target = ['bottle', 'basketball', 'desk']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - test id = 173, question = what's shown in the top of the image, img = ILSVRC2012_test_00059513.JPEG\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - real suppord fact in dataset=['monitor', 'at location', 'office'], real answer = monitor\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - normal model predict = ['monitor', 'mouse', 'clean your tooth in', 'work', 'cut', 'control', 'wash your hand', 'green', 'work for day without water', 'child']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict = ['bread', 'door', 'stadium', 'monitor', 'mouse', 'clean your tooth in', 'work', 'cut', 'control', 'wash your hand']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict relation = ['at location', 'part of', 'used for', 'animal order', 'receives action', 'animal class', 'related to', 'has property', 'good', 'important', 'animal family', 'capable of', 'is a', 'belong to', 'specific']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict fact = ['truth', 'part of wall', 'steroid']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - suppord fact predict = ['part of wall-at location', 'steroid-important', 'truth-important']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - correspond target = ['bread', 'door', 'stadium']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - test id = 1549, question = What object in this image might be used for friendship?, img = COCO_val2014_000000022892.jpg\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - real suppord fact in dataset=['dog', 'used for', 'provide friendship'], real answer = dog\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - normal model predict = ['dog', 'monkey', 'rabbit', 'cat', 'squirrel', 'dog poop', 'mouse', 'armadillo', 'bird', 'teddy bear']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict = ['tv', 'computer', 'person', 'dog', 'monkey', 'rabbit', 'cat', 'squirrel', 'dog poop', 'mouse']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict relation = ['used for', 'related to', 'capable of', 'good', 'receives action', 'specific', 'has property', 'effective', 'belong to', 'is a', 'efficient', 'important', 'accurate', 'part of', 'great']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict fact = ['advertise', 'cyberdating', 'pout']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - suppord fact predict = ['advertise-used for', 'pout-capable of', 'cyberdating-related to']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - correspond target = ['tv', 'computer', 'person']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - test id = 1754, question = Which object in this image contains brain?, img = COCO_val2014_000000104176.jpg\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - real suppord fact in dataset=['head', 'related to', 'brain'], real answer = head\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - normal model predict = ['coffee', 'grass', 'drink', 'harmonica', 'green', 'bicycle', 'screwdriver', 'beer', 'flowers', 'cell phone']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict = ['grass', 'apple', 'orange', 'coffee', 'drink', 'harmonica', 'green', 'bicycle', 'screwdriver', 'beer']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict relation = ['has a', 'has property', 'part of', 'is a', 'related to', 'capable of', 'at location', 'used for', 'common', 'important', 'social', 'popular', 'great', 'good', 'created by']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict fact = ['metalworking', 'chlorophyl', 'seed']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - suppord fact predict = ['seed-part of', 'chlorophyl-has a']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - correspond target = ['apple', 'grass', 'orange']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - test id = 77, question = Which object in this image has three keys?, img = ILSVRC2012_test_00027806.JPEG\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - real suppord fact in dataset=['french horn', 'has a', 'three key'], real answer = french horn\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - normal model predict = ['french horn', 'trombone', 'trumpet', 'guitar', 'saxophone', 'fork', 'monkey', 'bicycle', 'keyboard', 'dog']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict = ['guitar', 'bicycle', 'violin', 'french horn', 'trombone', 'trumpet', 'saxophone', 'fork', 'monkey', 'keyboard']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict relation = ['has a', 'related to', 'part of', 'large', 'frequent', 'is a', 'social', 'specific', 'small', 'common', 'long', 'used for', 'light', 'has property', 'animal order']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict fact = ['four string', 'six string', 'two weheels']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - suppord fact predict = ['six string-has a', 'two weheels-has a', 'four string-has a']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - correspond target = ['guitar', 'violin', 'bicycle']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - test id = 2331, question = What objects in this image are inspirational, img = ILSVRC2012_test_00035105.JPEG\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - real suppord fact in dataset=['forest road', 'has property', 'inspirational'], real answer = forest road\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - normal model predict = ['stop sign', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car', 'bus', 'person']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict = ['stop sign', 'horse', 'tv', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict relation = ['capable of', 'is a', 'has property', 'receives action', 'has a', 'used for', 'related to', 'part of', 'desires', 'at location', 'belong to', 'created by', 'specific', 'good', 'animal order']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict fact = ['traffic sign', 'clop', 'advertise']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - suppord fact predict = ['advertise-used for', 'traffic sign-belong to', 'clop-related to']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - correspond target = ['stop sign', 'tv', 'horse']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - test id = 1616, question = How colour dominates this image?, img = COCO_val2014_000000147482.jpg\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - real suppord fact in dataset=['sky', 'has property', 'blue'], real answer = blue\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - normal model predict = ['beach', 'kite', 'flowers', 'flower', 'park', 'stop sign', 'butterfly', 'mountain', 'your house', 'road']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict = ['stop sign', 'nail', 'lobster', 'beach', 'kite', 'flowers', 'flower', 'park', 'butterfly', 'mountain']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict relation = ['belong to', 'is a', 'has property', 'related to', 'at location', 'has a', 'used for', 'safe', 'common', 'protected', 'important', 'specific', 'animal order', 'easy', 'good']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict fact = ['traffic sign', 'delicacy', 'molluscs']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - suppord fact predict = ['delicacy-related to', 'molluscs-belong to', 'traffic sign-belong to']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - correspond target = ['stop sign', 'lobster', 'nail']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - test id = 1479, question = What object in this image is a furry mammal?, img = ILSVRC2012_test_00000622.JPEG\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - real suppord fact in dataset=['monkey', 'is a', 'furry mammal with long strong tail'], real answer = monkey\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - normal model predict = ['monkey', 'elephant', 'otter', 'cat', 'dog', 'squirrel', 'sheep', 'rabbit', 'mammal', 'bear']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict = ['elephant', 'otter', 'cat', 'dog', 'sheep', 'hippopotamus', 'giraffe', 'cow', 'seal', 'zebra']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict relation = ['is a', 'has a', 'related to', 'belong to', 'has property', 'animal class', 'animal order', 'animal phylum', 'cool', 'independent', 'created by', 'small', 'part of', 'visible', 'big']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict fact = ['mammal', 'playful aquatic mammal', 'mammal families']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - suppord fact predict = ['mammal-has property', 'mammal-animal class', 'mammal-is a', 'mammal families-belong to', 'mammal-related to', 'playful aquatic mammal-is a', 'mammal-belong to']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - correspond target = ['cat', 'dog', 'zebra', 'seal', 'sheep', 'otter', 'elephant', 'giraffe', 'hippopotamus', 'cow']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - test id = 1627, question = which object can be eaten?, img = ILSVRC2012_test_00040725.JPEG\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - real suppord fact in dataset=['fruit', 'belong to', 'food'], real answer = fruit\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - normal model predict = ['banana', 'fruit', 'orange', 'strawberry', 'carrot', 'pineapple', 'tomato', 'cucumber', 'salad', 'apple']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict = ['banana', 'apple', 'cake', 'bread', 'hot dog', 'fork', 'person', 'toddler', 'fruit', 'orange']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict relation = ['used for', 'is a', 'has a', 'has property', 'related to', 'part of', 'capable of', 'at location', 'belong to', 'receives action', 'specific', 'good', 'desires', 'long', 'common']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict fact = ['eat', 'eat food', 'eat banana']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - suppord fact predict = ['eat banana-capable of', 'eat-used for', 'eat-has a', 'eat food-capable of', 'eat food-related to', 'eat food-used for']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - correspond target = ['cake', 'apple', 'hot dog', 'bread', 'toddler', 'banana', 'person', 'fork']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - test id = 1900, question = Which object in this image can be used to make annoying noises?, img = ILSVRC2012_test_00024564.JPEG\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - real suppord fact in dataset=['violin', 'used for', 'mkae annoy noise'], real answer = violin\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - normal model predict = ['person', 'microphone', 'banjo', 'violin', 'umbrella', 'trombone', 'guitar', 'harmonica', 'trumpet', 'bow']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict = ['person', 'microphone', 'drum', 'banjo', 'violin', 'umbrella', 'trombone', 'guitar', 'harmonica', 'trumpet']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict relation = ['used for', 'related to', 'specific', 'capable of', 'effective', 'accurate', 'efficient', 'hot', 'frequent', 'easy', 'common', 'slow', 'important', 'surface', 'great']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - our model predict fact = ['listen to sound', 'make rhythm', 'amplify sound']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - suppord fact predict = ['make rhythm-used for', 'listen to sound-capable of', 'amplify sound-used for']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - correspond target = ['drum', 'person', 'microphone']\n",
      "INFO - 08/13/22 23:30:39 - 0:00:58 - #################################################################################\n",
      " 43%|██████████████████▎                        | 38/89 [00:25<00:35,  1.44it/s]INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - test id = 2720, question = Why these animal can hurt people?, img = COCO_val2014_000000016776.jpg\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - real suppord fact in dataset=['bear', 'related to', 'large claw'], real answer = large claw\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - normal model predict = ['animal', 'dog', 'rabbit', 'wild', 'dog poop', 'elephant', 'bear', 'bird', 'squirrel', 'monkey']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict = ['elephant', 'throw', 'hammer', 'axe', 'computer', 'kite', 'animal', 'dog', 'rabbit', 'wild']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict relation = ['is a', 'has a', 'capable of', 'related to', 'has property', 'at location', 'belong to', 'used for', 'receives action', 'good', 'desires', 'animal order', 'accurate', 'fast', 'part of']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict fact = ['hurt person', 'help person', 'person']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - suppord fact predict = ['hurt person-capable of', 'person-has property', 'person-capable of', 'hurt person-used for', 'help person-capable of']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - correspond target = ['axe', 'throw', 'computer', 'elephant', 'kite', 'hammer']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - test id = 1234, question = What kind of vitamin does the fruit in the image contain?, img = ILSVRC2012_test_00022357.JPEG\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - real suppord fact in dataset=['orange', 'has property', 'vitamin c'], real answer = vitamin c\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - normal model predict = ['orange', 'lemon', 'fruit', 'strawberry', 'fig', 'banana', 'apple', 'pomegranate', 'green', 'pineapple']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict = ['orange', 'lemon', 'fruit', 'strawberry', 'banana', 'apple', 'pomegranate', 'pineapple', 'fig', 'green']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict relation = ['has a', 'is a', 'has property', 'part of', 'belong to', 'capable of', 'at location', 'receives action', 'used for', 'created by', 'good', 'animal family', 'related to', 'animal order', 'animal class']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict fact = ['fruit', 'edible fruit', 'citrus fruit']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - suppord fact predict = ['edible fruit-is a', 'fruit-belong to', 'fruit-related to', 'fruit-is a', 'fruit-part of', 'citrus fruit-is a', 'citrus fruit-related to']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - correspond target = ['apple', 'strawberry', 'pineapple', 'pomegranate', 'orange', 'banana', 'lemon', 'fruit']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - test id = 89, question = Which object in this image is a cartilaginous fish?, img = ILSVRC2012_test_00000980.JPEG\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - real suppord fact in dataset=['batoidea', 'belong to', 'ray'], real answer = ray\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - normal model predict = ['ray', 'jellyfish', 'turtle', 'frog', 'lizard', 'snake', 'armadillo', 'lobster', 'fish', 'ant']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict = ['jellyfish', 'goldfish', 'boat', 'swim', 'cat', 'ray', 'turtle', 'frog', 'lizard', 'snake']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict relation = ['is a', 'belong to', 'related to', 'has a', 'part of', 'used for', 'cool', 'sweet', 'easy', 'visible', 'capable of', 'important', 'has property', 'good', 'common']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict fact = ['not fish', 'fish', 'eat fish']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - suppord fact predict = ['fish-capable of', 'not fish-is a', 'eat fish-capable of', 'fish-related to', 'fish-belong to']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - correspond target = ['jellyfish', 'cat', 'swim', 'boat', 'goldfish']\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - test id = 1320, question = Which transportation topic is shown in this image?, img = COCO_val2014_000000145921.jpg\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - real suppord fact in dataset=['airplane', 'is a', 'transportation topic'], real answer = airplane\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - normal model predict = ['airplane', 'plane', 'land airplane', 'airport', 'spaceship', 'runway', 'flight', 'land plane', 'car', 'taxi']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict = ['bus', 'boat', 'airplane', 'plane', 'land airplane', 'airport', 'spaceship', 'runway', 'flight', 'land plane']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict relation = ['belong to', 'is a', 'related to', 'at location', 'part of', 'important', 'capable of', 'has property', 'long', 'has a', 'common', 'used for', 'small', 'safe', 'dangerous']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict fact = ['mode of public transportation', 'mode of transportation', 'form of public transportation']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - suppord fact predict = ['form of public transportation-is a', 'mode of public transportation-is a', 'mode of transportation-is a']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - correspond target = ['bus', 'boat']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - test id = 2548, question = What kind of team game does this image describe?, img = ILSVRC2012_test_00005398.JPEG\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - real suppord fact in dataset=['basketball', 'is a', 'team game'], real answer = basketball\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - normal model predict = ['person', 'any place where person live', 'basketball', 'make person happy', 'romantic', 'play basketball', 'volleyball', 'cell phone', 'guitar', 'transport person']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict = ['volleyball', 'baseball', 'baseball glove', 'person', 'any place where person live', 'basketball', 'make person happy', 'romantic', 'play basketball', 'cell phone']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict relation = ['is a', 'capable of', 'belong to', 'has property', 'has a', 'related to', 'desires', 'part of', 'important', 'independent', 'used for', 'good', 'receives action', 'common', 'dangerous']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict fact = ['team sports', 'team sport', 'ball sport']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - suppord fact predict = ['team sports-belong to', 'ball sport-is a', 'team sport-is a']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - correspond target = ['volleyball', 'baseball glove', 'baseball']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - test id = 1262, question = What toy animal is in the image?, img = COCO_val2014_000000134688.jpg\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - real suppord fact in dataset=['teddy bear', 'belong to', 'toy animals'], real answer = teddy bear\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - normal model predict = ['dog', 'hot dog', 'cat', 'teddy bear', 'dog poop', 'rabbit', 'bear', 'animal', 'cow', 'hamburger']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict = ['dog', 'cat', 'animal', 'hair', 'goldfish', 'human', 'herd sheep', 'person', 'ant', 'hot dog']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict relation = ['related to', 'is a', 'belong to', 'at location', 'used for', 'specific', 'has property', 'important', 'has a', 'part of', 'animal order', 'good', 'common', 'created by', 'social']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict fact = ['dog', 'pet animal', 'pet']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - suppord fact predict = ['pet-is a', 'dog-used for', 'dog-good', 'pet-belong to', 'pet-used for', 'dog-has a', 'dog-social', 'dog-belong to', 'pet animal-related to', 'pet-related to', 'pet animal-has a']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - correspond target = ['cat', 'animal', 'dog', 'ant', 'herd sheep', 'hair', 'person', 'goldfish', 'human']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - test id = 133, question = which object in this image is a form of land transportation?, img = COCO_val2014_000000015827.jpg\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - real suppord fact in dataset=['motorcycle', 'belong to', 'land transport'], real answer = motorcycle\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - normal model predict = ['motorcycle', 'motorbike', 'bicycle', 'truck', 'snowmobile', 'vehicle', 'airplane', 'car', 'golfcart', 'pavement']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict = ['bicycle', 'airplane', 'bus', 'boat', 'train', 'motorcycle', 'motorbike', 'truck', 'snowmobile', 'vehicle']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict relation = ['is a', 'belong to', 'related to', 'has property', 'has a', 'visible', 'common', 'used for', 'dangerous', 'at location', 'accurate', 'safe', 'important', 'specific', 'easy']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict fact = ['form of transportation', 'non pollute form of transport', 'form of mass transportation']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - suppord fact predict = ['form of transportation-is a', 'form of mass transportation-is a', 'non pollute form of transport-is a']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - correspond target = ['airplane', 'bus', 'boat', 'train', 'bicycle']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - test id = 2247, question = What is the object in the left side of this image used for?, img = COCO_val2014_000000027658.jpg\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - real suppord fact in dataset=['fire hydrant', 'used for', 'fight fire'], real answer = fight fire\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - normal model predict = ['entertain yourself on windy day', 'sit down on', 'any place where person live', 'fight fire', 'plane to land on', 'play baseball on it', 'lay on', 'sleep away from home', 'protect person from sun and rain', 'space to run and play']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict = ['entertain yourself on windy day', 'sit down on', 'fun', 'child', 'park', 'string attach', 'airplane', 'any place where person live', 'fight fire', 'plane to land on']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict relation = ['used for', 'capable of', 'effective', 'good', 'at location', 'safe', 'efficient', 'animal order', 'great', 'related to', 'high', 'easy', 'fast', 'specific', 'convenient']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict fact = ['circle airfield', 'kite', 'bench']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - suppord fact predict = ['bench-used for', 'circle airfield-capable of', 'bench-at location', 'kite-used for', 'kite-related to']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - correspond target = ['string attach', 'airplane', 'child', 'fun', 'entertain yourself on windy day', 'sit down on', 'park']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - test id = 74, question = What are the green long object in the image?, img = ILSVRC2012_test_00021218.JPEG\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - real suppord fact in dataset=['cucumber', 'has property', 'green'], real answer = cucumber\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - normal model predict = ['vegetable', 'cucumber', 'tomato', 'fig', 'strawberry', 'fruit', 'zucchini', 'banana', 'plant', 'cheese']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict = ['pare apple', 'cut', 'fork', 'mountain', 'elephant', 'horse', 'vegetable', 'cucumber', 'tomato', 'fig']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict relation = ['has property', 'has a', 'at location', 'belong to', 'protected', 'related to', 'created by', 'used for', 'animal order', 'small', 'is a', 'animal family', 'animal class', 'impassable', 'common']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict fact = ['knife', 'kitchen utensil', 'large']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - suppord fact predict = ['large-has property', 'knife-used for', 'kitchen utensil-is a']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - correspond target = ['horse', 'elephant', 'mountain', 'fork', 'pare apple', 'cut']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - test id = 482, question = What is monitor used for?, img = ILSVRC2012_test_00059513.JPEG\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - real suppord fact in dataset=['monitor', 'used for', 'watch'], real answer = watch\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - normal model predict = ['work', 'cut', 'sleep away from home', 'use twice day', 'space to run and play', 'work for day without water', 'prepare food', 'fight fire', 'listen to music', 'sleep']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict = ['work', 'listen to music', 'monitor', 'computer', 'your house', 'pen', 'printer', 'keyboard', 'tall build', 'desk']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict relation = ['used for', 'related to', 'capable of', 'effective', 'belong to', 'receives action', 'specific', 'good', 'at location', 'efficient', 'easy', 'has property', 'expensive', 'accurate', 'high']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict fact = ['home office', 'office', 'ipod']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - suppord fact predict = ['home office-at location', 'office-at location', 'office-used for', 'ipod-used for']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - correspond target = ['pen', 'desk', 'your house', 'tall build', 'computer', 'monitor', 'keyboard', 'printer', 'work', 'listen to music']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - test id = 253, question = what can we find on the desk, img = ILSVRC2012_test_00010551.JPEG\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - real suppord fact in dataset=['luggage', 'used for', 'travel'], real answer = luggage\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - normal model predict = ['luggage', 'airport', 'car', 'hotel room', 'taxi', 'sit outside', 'toilet seat', 'travel in car', 'suitcase', 'bus']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict = ['sofa', 'dining table', 'cross river', 'person', 'luggage', 'airport', 'car', 'hotel room', 'taxi', 'sit outside']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict relation = ['at location', 'has a', 'used for', 'capable of', 'part of', 'animal order', 'belong to', 'animal family', 'human', 'surface', 'created by', 'has property', 'great', 'specific', 'social']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict fact = ['village', 'home', 'bridge']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - suppord fact predict = ['bridge-capable of', 'home-at location', 'home-belong to', 'village-at location']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - correspond target = ['cross river', 'sofa', 'person', 'dining table']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - test id = 899, question = Which object in this image can be difficult to bathe?, img = COCO_val2014_000000005617.jpg\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - real suppord fact in dataset=['cat', 'has property', 'difficult to wash in bath'], real answer = cat\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - normal model predict = ['cat', 'kitten', 'sofa', 'sink', 'bed', 'vase', 'couch', 'ant', 'frog', 'goldfish']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict = ['sofa', 'bed', 'person', 'cat', 'kitten', 'sink', 'vase', 'couch', 'ant', 'frog']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict relation = ['related to', 'capable of', 'specific', 'used for', 'belong to', 'desires', 'accurate', 'at location', 'important', 'common', 'visible', 'is a', 'animal order', 'receives action', 'human']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - our model predict fact = ['relax', 'go to sleep', 'learn to swim']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - suppord fact predict = ['relax-used for', 'learn to swim-capable of', 'go to sleep-used for']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - correspond target = ['sofa', 'person', 'bed']\r\n",
      "INFO - 08/13/22 23:30:40 - 0:00:58 - #################################################################################\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████▊                        | 39/89 [00:26<00:31,  1.58it/s]INFO - 08/13/22 23:30:41 - 0:00:59 - #################################################################################\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - test id = 1766, question = which object in this image is less active than goat?, img = ILSVRC2012_test_00008031.JPEG\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - real suppord fact in dataset=['goat', 'active', 'cow'], real answer = cow\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - normal model predict = ['cow', 'cattle', 'sheep', 'horse', 'herd sheep', 'meat', 'dog', 'animal', 'heifer', 'dog poop']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - our model predict = ['horse', 'cow', 'cattle', 'sheep', 'herd sheep', 'meat', 'dog', 'animal', 'heifer', 'dog poop']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - our model predict relation = ['efficient', 'high', 'reliable', 'stable', 'fast', 'low', 'intelligent', 'independent', 'effective', 'easy', 'dependable', 'healthy', 'flexible', 'maneuverable', 'important']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - our model predict fact = ['goat', 'sheep', 'cow']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - suppord fact predict = ['cow-fast']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - correspond target = ['horse']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - #################################################################################\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - #################################################################################\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - test id = 886, question = What object in this image is in most homes?, img = COCO_val2014_000000136466.jpg\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - real suppord fact in dataset=['most home', 'has a', 'oven'], real answer = oven\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - normal model predict = ['pizza', 'bakery', 'oven', 'toaster', 'microwave', 'hamburger', 'toast bread', 'bread', 'refrigerator', 'sandwich']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - our model predict = ['tv', 'cat', 'bedroom', 'pizza', 'bakery', 'oven', 'toaster', 'microwave', 'hamburger', 'toast bread']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - our model predict relation = ['has property', 'used for', 'at location', 'capable of', 'related to', 'is a', 'good', 'belong to', 'expensive', 'efficient', 'high', 'has a', 'easy', 'low', 'effective']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - our model predict fact = ['apartment', 'your house', 'advertise']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - suppord fact predict = ['advertise-used for', 'your house-at location', 'apartment-at location']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - correspond target = ['cat', 'tv', 'bedroom']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - #################################################################################\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - #################################################################################\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - test id = 1379, question = What is the object in the man's left hand used for, img = ILSVRC2012_test_00037171.JPEG\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - real suppord fact in dataset=['power drill', 'used for', 'drive screw'], real answer = drive screw\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - normal model predict = ['cake', 'knife', 'plate', 'hair', 'tie', 'person', 'pizza', 'fork', 'ice', 'cut']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - our model predict = ['cut', 'bagel', 'pare apple', 'cake', 'knife', 'plate', 'hair', 'tie', 'person', 'pizza']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - our model predict relation = ['used for', 'capable of', 'belong to', 'is a', 'has property', 'receives action', 'part of', 'has a', 'at location', 'related to', 'animal order', 'good', 'animal class', 'desires', 'created by']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - our model predict fact = ['shape like doughnut', 'knife', 'doughnut shape roll']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - suppord fact predict = ['shape like doughnut-has property', 'knife-used for', 'doughnut shape roll-is a']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - correspond target = ['bagel', 'pare apple', 'cut']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - #################################################################################\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - #################################################################################\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - test id = 1080, question = What in this image is related to boxen?, img = ILSVRC2012_test_00059513.JPEG\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - real suppord fact in dataset=['boxen', 'related to', 'computer'], real answer = computer\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - normal model predict = ['monitor', 'cut', 'sound control room', 'work', 'hand', 'use toilet', 'control', 'sleep away from home', 'wood', 'lay on']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - our model predict = ['ray', 'elephant', 'trombone', 'monitor', 'cut', 'sound control room', 'work', 'hand', 'use toilet', 'control']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - our model predict relation = ['related to', 'specific', 'belong to', 'used for', 'important', 'common', 'part of', 'at location', 'animal order', 'social', 'accurate', 'receives action', 'prevalent', 'has property', 'capable of']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - our model predict fact = ['batoidea', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - suppord fact predict = ['batoidea-belong to', 'therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - correspond target = ['trombone', 'ray', 'elephant']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - #################################################################################\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - #################################################################################\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - test id = 2807, question = Where can you find the object in this image?, img = ILSVRC2012_test_00057349.JPEG\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - real suppord fact in dataset=['can opener', 'at location', 'kitchen'], real answer = kitchen\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - normal model predict = ['your house', 'house', 'airport', 'wedding', 'apartment', 'park', 'kitchen', 'africa', 'bakery', 'hammer']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - our model predict = ['bathroom', 'bottle', 'fork', 'bowl', 'plate', 'your house', 'house', 'airport', 'wedding', 'apartment']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - our model predict relation = ['at location', 'used for', 'related to', 'has property', 'belong to', 'is a', 'specific', 'created by', 'has a', 'part of', 'animal order', 'capable of', 'good', 'protected', 'important']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - our model predict fact = ['kitchen utensil', 'toothbrush', 'kitchenware']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - suppord fact predict = ['kitchenware-belong to', 'toothbrush-at location', 'kitchen utensil-is a']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - correspond target = ['bottle', 'plate', 'bowl', 'bathroom', 'fork']\n",
      "INFO - 08/13/22 23:30:41 - 0:00:59 - #################################################################################\n",
      " 45%|███████████████████▎                       | 40/89 [00:26<00:33,  1.47it/s]INFO - 08/13/22 23:30:41 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - test id = 1793, question = which kind of fungus can we see in this image, img = ILSVRC2012_test_00009605.JPEG\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - real suppord fact in dataset=['mushroom', 'is a', 'fungus'], real answer = mushroom\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - normal model predict = ['dragonfly', 'butterfly', 'poisonous', 'fish', 'snake', 'goldfish', 'scissors', 'bird', 'jellyfish', 'mushroom']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - our model predict = ['dragonfly', 'butterfly', 'ant', 'giraffe', 'poisonous', 'fish', 'snake', 'goldfish', 'scissors', 'bird']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - our model predict relation = ['at location', 'belong to', 'is a', 'related to', 'has property', 'used for', 'capable of', 'has a', 'important', 'visible', 'specific', 'part of', 'common', 'surface', 'accurate']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - our model predict fact = ['insect', 'mammal orders', 'moth']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - suppord fact predict = ['mammal orders-belong to', 'insect-belong to', 'insect-is a']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - correspond target = ['dragonfly', 'ant', 'giraffe', 'butterfly']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - test id = 2243, question = what can we find on the desk, img = ILSVRC2012_test_00057293.JPEG\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - real suppord fact in dataset=['computer', 'at location', 'office'], real answer = computer\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - normal model predict = ['desk', 'sound control room', 'button', 'computer', 'wash machine', 'remote', 'window', 'use toilet', 'control tv', 'wash your hand']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - our model predict = ['sound control room', 'printer', 'dining table', 'sofa', 'your house', 'metronome', 'clarinet', 'desk', 'button', 'computer']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - our model predict relation = ['at location', 'has a', 'used for', 'capable of', 'part of', 'animal order', 'animal family', 'great', 'belong to', 'surface', 'large', 'human', 'created by', 'specific', 'related to']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - our model predict fact = ['music studio', 'home office', 'home']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - suppord fact predict = ['home office-at location', 'home-at location', 'music studio-at location', 'home-belong to']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - correspond target = ['clarinet', 'sofa', 'your house', 'printer', 'metronome', 'sound control room', 'dining table']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - test id = 2076, question = What substance in this image might an antifluoridationst be concerned with?, img = COCO_val2014_000000019608.jpg\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - real suppord fact in dataset=['antifluoridationist', 'related to', 'water'], real answer = water\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - normal model predict = ['person', 'blue', 'white', 'any place where person live', 'make person happy', 'hat with a wide brim', 'protect person from sun and rain', 'play baseball on it', 'thing', 'water']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - our model predict = ['person', 'elephant', 'plant', 'trombone', 'blue', 'white', 'any place where person live', 'make person happy', 'hat with a wide brim', 'protect person from sun and rain']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - our model predict relation = ['related to', 'belong to', 'capable of', 'receives action', 'used for', 'at location', 'desires', 'specific', 'has property', 'has a', 'important', 'part of', 'is a', 'good', 'accurate']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - our model predict fact = ['talk', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - suppord fact predict = ['talk-capable of', 'therapsida-belong to', 'tromboner-related to', 'talk-related to']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - correspond target = ['trombone', 'plant', 'elephant', 'person']\n",
      "INFO - 08/13/22 23:30:41 - 0:01:00 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - test id = 848, question = Is there water here?, img = COCO_val2014_000000101088.jpg\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - real suppord fact in dataset=['ye', 'has a', 'hydrogen and oxygen atom'], real answer = ye\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - normal model predict = ['water', 'boat', 'sea', 'lake', 'swimming', 'shore boat', 'raft', 'shell', 'umbrella', 'fish']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict = ['lake', 'river', 'cloud', 'jellyfish', 'whale', 'cup', 'dog', 'cat', 'giraffe', 'water']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict relation = ['belong to', 'used for', 'is a', 'has property', 'related to', 'has a', 'easy', 'important', 'long', 'safe', 'good', 'dangerous', 'capable of', 'popular', 'at location']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict fact = ['water', 'drink water', 'sea water']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - suppord fact predict = ['drink water-used for', 'water-belong to', 'water-has a', 'sea water-at location', 'water-at location', 'drink water-capable of']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - correspond target = ['jellyfish', 'cat', 'dog', 'river', 'whale', 'cup', 'giraffe', 'cloud', 'lake']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - test id = 2282, question = which object in this image should be paid mcuh more than a desktop, img = COCO_val2014_000000014088.jpg\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - real suppord fact in dataset=['laptop', 'expensive', 'desktop'], real answer = laptop\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - normal model predict = ['laptop', 'computer', 'tv', 'printer', 'monitor', 'ram', 'control tv', 'furniture', 'sofa', 'keyboard']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict = ['ipod', 'laptop', 'computer', 'tv', 'printer', 'monitor', 'ram', 'control tv', 'furniture', 'sofa']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict relation = ['frequent', 'efficient', 'reliable', 'low', 'good', 'prevalent', 'important', 'blind', 'dependable', 'fast', 'cheap', 'strong', 'easy', 'expensive', 'heavy']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict fact = ['walkman', 'musician', 'bookshelf']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - suppord fact predict = ['walkman-good']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - correspond target = ['ipod']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - test id = 0, question = Tell me the name of the cosmetics shown in this image?, img = ILSVRC2012_test_00000444.JPEG\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - real suppord fact in dataset=['lipstick', 'belong to', 'cosmetics'], real answer = lipstick\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - normal model predict = ['drum', 'corkscrew', 'bottle', 'lipstick', 'wine', 'metronome', 'guitar', 'railroad track', 'airplane', 'toothbrush']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict = ['toothbrush', 'scissors', 'hammer', 'golfcart', 'skateboard', 'power drill', 'screwdriver', 'soccer ball', 'tennis racket', 'drum']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict relation = ['is a', 'belong to', 'part of', 'used for', 'related to', 'has a', 'good', 'capable of', 'animal order', 'at location', 'receives action', 'safe', 'animal class', 'animal family', 'important']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict fact = ['dental tool', 'game equipment', 'tool']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - suppord fact predict = ['tool-is a', 'game equipment-belong to', 'tool-belong to', 'dental tool-is a']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - correspond target = ['golfcart', 'skateboard', 'tennis racket', 'toothbrush', 'soccer ball', 'screwdriver', 'scissors', 'power drill', 'hammer']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - test id = 1953, question = Which object in this image has a bladder?, img = ILSVRC2012_test_00011383.JPEG\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - real suppord fact in dataset=['bladder', 'related to', 'rugby ball'], real answer = rugby ball\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - normal model predict = ['soccer ball', 'rugby ball', 'ball', 'person', 'tennis ball', 'golf ball', 'frisbee', 'unicycle', 'baseball field', 'volleyball']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict = ['unicycle', 'bicycle', 'skateboard', 'car', 'airplane', 'cart', 'soccer ball', 'rugby ball', 'ball', 'person']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict relation = ['part of', 'has a', 'related to', 'is a', 'has property', 'capable of', 'specific', 'social', 'important', 'human', 'common', 'animal family', 'large', 'used for', 'surface']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict fact = ['one wheel', 'wheel', 'wheel box']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - suppord fact predict = ['wheel-part of', 'wheel box-is a', 'wheel-related to', 'one wheel-has a', 'wheel-has a']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - correspond target = ['airplane', 'skateboard', 'bicycle', 'unicycle', 'car', 'cart']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      " 46%|███████████████████▊                       | 41/89 [00:27<00:33,  1.42it/s]INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - test id = 1518, question = Which action is less strenuous than the action shown in this image?, img = COCO_val2014_000000135361.jpg\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - real suppord fact in dataset=['jumping', 'strenuous', 'dressage'], real answer = dressage\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - normal model predict = ['jumping', 'kite', 'frisbee', 'tennis ball', 'person', 'soccer ball', 'swimming', 'volleyball', 'ball', 'rugby ball']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict = ['car', 'camel', 'cow', 'jumping', 'kite', 'frisbee', 'tennis ball', 'person', 'soccer ball', 'swimming']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict relation = ['important', 'tough', 'fast', 'impassable', 'soft', 'safe', 'dense', 'tall', 'healthy', 'warm', 'colorful', 'strong', 'long', 'common', 'energetic']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict fact = ['horse', 'giraffe', 'horse driving']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - suppord fact predict = ['horse-fast', 'horse-strong', 'horse-tall']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - correspond target = ['camel', 'car', 'cow']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - test id = 1267, question = What animal in this image is carrying person?, img = COCO_val2014_000000104691.jpg\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - real suppord fact in dataset=['horse', 'capable of', 'carry person'], real answer = horse\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - normal model predict = ['horse', 'dog', 'elephant', 'cow', 'camel', 'cattle', 'hot dog', 'giraffe', 'bench', 'dog poop']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict = ['bench', 'couch', 'car', 'airplane', 'horse', 'dog', 'elephant', 'cow', 'camel', 'cattle']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict relation = ['is a', 'related to', 'capable of', 'used for', 'belong to', 'has a', 'part of', 'important', 'at location', 'specific', 'accurate', 'good', 'receives action', 'easy', 'great']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict fact = ['seat more than one person', 'seat person', 'transport person']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - suppord fact predict = ['seat person-capable of', 'seat more than one person-capable of', 'transport person-used for']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - correspond target = ['couch', 'airplane', 'bench', 'car']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - test id = 2371, question = Which thing in the image can produce heat?, img = COCO_val2014_000000122954.jpg\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - real suppord fact in dataset=['lamp', 'related to', 'heat'], real answer = lamp\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - normal model predict = ['lamp', 'toaster', 'refrigerator', 'microwave', 'tv', 'cake', 'electric fan', 'umbrella', 'wall', 'car']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict = ['umbrella', 'lamp', 'toaster', 'refrigerator', 'microwave', 'tv', 'cake', 'electric fan', 'wall', 'car']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict relation = ['capable of', 'used for', 'has a', 'fast', 'high', 'efficient', 'long', 'powerful', 'stable', 'effective', 'is a', 'easy', 'compact', 'part of', 'surface']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict fact = ['heat', 'cold cut', 'stay dry']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - suppord fact predict = ['stay dry-used for']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - correspond target = ['umbrella']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - test id = 2625, question = Which object in this image is used for Gymnastics?, img = ILSVRC2012_test_00030469.JPEG\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - real suppord fact in dataset=['horizontal bar', 'belong to', 'gymnastics'], real answer = horizontal bar\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - normal model predict = ['beam', 'balance beam', 'plane', 'jumping', 'dumbbell', 'land plane', 'airplane', 'frisbee', 'microwave', 'tennis ball']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict = ['couch', 'saxophone', 'bed', 'trombone', 'cat', 'trumpet', 'beam', 'balance beam', 'plane', 'jumping']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict relation = ['used for', 'related to', 'specific', 'effective', 'important', 'efficient', 'common', 'belong to', 'easy', 'accurate', 'popular', 'capable of', 'great', 'good', 'light']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict fact = ['jazz', 'laze', 'nap']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - suppord fact predict = ['nap-capable of', 'nap-used for', 'jazz-used for', 'jazz-belong to', 'laze-used for']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - correspond target = ['cat', 'saxophone', 'couch', 'trumpet', 'trombone', 'bed']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - test id = 1127, question = What is the class of the animal in this image?, img = ILSVRC2012_test_00042080.JPEG\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - real suppord fact in dataset=['goldfish', 'animal class', 'actinopterygii'], real answer = actinopterygii\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - normal model predict = ['fish', 'goldfish', 'jellyfish', 'whale', 'dolphin', 'sea', 'swimming', 'swim', 'ocean', 'water']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict = ['mammal', 'green', 'wild', 'low', 'shell', 'carnivora', 'fish', 'goldfish', 'jellyfish', 'whale']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict relation = ['belong to', 'has property', 'related to', 'is a', 'animal order', 'animal class', 'has a', 'animal family', 'animal kingdom', 'at location', 'animal phylum', 'common', 'protected', 'specific', 'safe']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - our model predict fact = ['frog', 'otter', 'turtle']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - suppord fact predict = ['otter-animal order', 'turtle-has a', 'turtle-has property', 'otter-animal class', 'frog-at location', 'frog-has property']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - correspond target = ['wild', 'shell', 'green', 'low', 'mammal', 'carnivora']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:00 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:01 - #################################################################################\n",
      "INFO - 08/13/22 23:30:42 - 0:01:01 - test id = 589, question = What is the another name of this game?, img = ILSVRC2012_test_00029063.JPEG\n",
      "INFO - 08/13/22 23:30:42 - 0:01:01 - real suppord fact in dataset=['table tennis', 'is a', 'ping pong'], real answer = ping pong\n",
      "INFO - 08/13/22 23:30:42 - 0:01:01 - normal model predict = ['racquet', 'tennis racket', 'wii', 'volleyball', 'tennis ball', 'tennis', 'racket', 'soccer ball', 'basketball', 'play tennis']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:01 - our model predict = ['racquet', 'wii', 'volleyball', 'tennis ball', 'racket', 'baseball', 'computer', 'tennis racket', 'tennis', 'soccer ball']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:01 - our model predict relation = ['is a', 'belong to', 'has property', 'related to', 'animal class', 'at location', 'important', 'part of', 'receives action', 'animal kingdom', 'animal order', 'has a', 'common', 'animal family', 'dangerous']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:01 - our model predict fact = ['ball games', 'baseball game', 'video game']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:01 - suppord fact predict = ['video game-belong to', 'baseball game-at location', 'video game-related to', 'ball games-belong to']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:01 - correspond target = ['racquet', 'computer', 'wii', 'volleyball', 'racket', 'tennis ball', 'baseball']\n",
      "INFO - 08/13/22 23:30:42 - 0:01:01 - #################################################################################\n",
      " 47%|████████████████████▎                      | 42/89 [00:28<00:33,  1.40it/s]INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - test id = 2699, question = What is likely to be found in this place?, img = COCO_val2014_000000106392.jpg\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - real suppord fact in dataset=['microwave', 'at location', 'kitchen'], real answer = microwave\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - normal model predict = ['sound control room', 'toilet', 'use toilet', 'house', 'toilet paper', 'sink', 'room', 'thing', 'kitchen', 'wash machine']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict = ['toilet', 'use toilet', 'house', 'toilet paper', 'sink', 'thing', 'wash machine', 'toilet seat', 'kitchen utensil', 'cup']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict relation = ['at location', 'used for', 'has a', 'part of', 'related to', 'specific', 'animal order', 'frequent', 'receives action', 'social', 'animal family', 'good', 'great', 'capable of', 'human']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict fact = ['bathroom', 'kitchen', 'laundromat']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - suppord fact predict = ['kitchen-at location', 'bathroom-at location', 'bathroom-has a', 'bathroom-part of', 'laundromat-at location', 'bathroom-used for']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - correspond target = ['toilet', 'thing', 'kitchen utensil', 'toilet paper', 'sink', 'use toilet', 'house', 'wash machine', 'cup', 'toilet seat']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - test id = 295, question = Which object in this image is a type of food?, img = COCO_val2014_000000131841.jpg\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - real suppord fact in dataset=['bread', 'is a', 'type of food'], real answer = bread\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - normal model predict = ['sandwich', 'bread', 'toast bread', 'fry bread', 'bagel', 'doughnut', 'donut', 'hamburger', 'cake', 'fork']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict = ['donut', 'hamburger', 'cake', 'fork', 'pretzel', 'salad', 'pizza', 'fruit', 'apple', 'vegetable']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict relation = ['is a', 'belong to', 'related to', 'has a', 'important', 'at location', 'used for', 'part of', 'capable of', 'good', 'has property', 'specific', 'cool', 'receives action', 'animal class']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict fact = ['food', 'eat food', 'stock food']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - suppord fact predict = ['food-related to', 'food-is a', 'eat food-related to', 'food-belong to', 'eat food-used for']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - correspond target = ['cake', 'apple', 'fruit', 'salad', 'pizza', 'pretzel', 'donut', 'vegetable', 'fork', 'hamburger']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - test id = 2622, question = Where can you find something to drink in the image?, img = COCO_val2014_000000135748.jpg\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - real suppord fact in dataset=['bottle', 'related to', 'drink'], real answer = bottle\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - normal model predict = ['zoo', 'house', 'your house', 'africa', 'mountainous area', 'park', 'animal', 'food', 'airport', 'police']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict = ['vegetable', 'dog', 'hot dog', 'fruit', 'cat', 'donut', 'cup', 'fig', 'broccoli', 'hotdog']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict relation = ['at location', 'belong to', 'related to', 'used for', 'desires', 'capable of', 'is a', 'specific', 'blind', 'animal order', 'important', 'good', 'has a', 'great', 'part of']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict fact = ['food and drink', 'drink water', 'drink from']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - suppord fact predict = ['drink from-used for', 'food and drink-belong to', 'drink water-used for', 'drink water-capable of']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - correspond target = ['hotdog', 'fig', 'cat', 'dog', 'hot dog', 'broccoli', 'cup', 'donut', 'vegetable', 'fruit']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - test id = 1639, question = What is usually found at this place?, img = COCO_val2014_000000100553.jpg\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - real suppord fact in dataset=['drink', 'at location', 'bar'], real answer = drink\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - normal model predict = ['eat', 'thing', 'food', 'kitchen', 'sound control room', 'cook food', 'cheese', 'lobster', 'restaurant', 'vegetarian']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict = ['coffee', 'hammer', 'tv', 'eat', 'thing', 'food', 'kitchen', 'sound control room', 'cook food', 'cheese']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict relation = ['at location', 'used for', 'part of', 'belong to', 'capable of', 'has a', 'is a', 'good', 'great', 'has property', 'important', 'specific', 'related to', 'animal family', 'animal order']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict fact = ['coffee shop', 'winery', 'construction site']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - suppord fact predict = ['winery-at location', 'coffee shop-at location', 'construction site-at location']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - correspond target = ['tv', 'coffee', 'hammer']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - test id = 1369, question = What are you likely to find in a catlover's home ?, img = COCO_val2014_000000000599.jpg\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - real suppord fact in dataset=['cat', 'at location', \"catlover's home\"], real answer = cat\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - normal model predict = ['cat', 'animal', 'mouse', 'wii', 'furniture', 'kept as pets', 'food', 'human', 'monitor', 'tv']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict = ['printer', 'your house', 'sofa', 'cat', 'animal', 'mouse', 'wii', 'furniture', 'kept as pets', 'food']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict relation = ['at location', 'capable of', 'part of', 'stable', 'has a', 'good', 'is a', 'has property', 'active', 'visible', 'surface', 'safe', 'human', 'clean', 'used for']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict fact = ['house', 'home', 'home office']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - suppord fact predict = ['home office-at location', 'home-at location', 'house-at location']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - correspond target = ['your house', 'sofa', 'printer']\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - test id = 582, question = Which object is related to jazz in this image?, img = ILSVRC2012_test_00000499.JPEG\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - real suppord fact in dataset=['trombone', 'belong to', 'jazz'], real answer = trombone\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - normal model predict = ['saxophone', 'flute', 'trombone', 'clarinet', 'trumpet', 'violin', 'cello', 'piano', 'guitar', 'harmonica']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict = ['saxophone', 'clarinet', 'violin', 'metronome', 'sound control room', 'flute', 'trombone', 'trumpet', 'cello', 'piano']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict relation = ['is a', 'part of', 'belong to', 'related to', 'has a', 'at location', 'has property', 'important', 'receives action', 'fast', 'capable of', 'common', 'used for', 'created by', 'specific']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict fact = ['use in classical music', 'use in jazz music', 'music studio']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - suppord fact predict = ['use in jazz music-has property', 'music studio-at location', 'use in classical music-has property']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - correspond target = ['clarinet', 'violin', 'metronome', 'sound control room', 'saxophone']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - test id = 107, question = What property does the place in this image have?, img = COCO_val2014_000000006608.jpg\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - real suppord fact in dataset=['home office', 'has property', 'hard to keep tidy'], real answer = home office\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - normal model predict = ['desk', 'romantic', 'home office', 'computer', 'monitor', 'smooth', 'pleasant', 'hair', 'clean your tooth in', 'couch']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict = ['desk', 'computer', 'monitor', 'work', 'your house', 'printer', 'keyboard', 'window', 'pen', 'tall build']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict relation = ['has property', 'has a', 'part of', 'at location', 'receives action', 'firm', 'created by', 'animal family', 'used for', 'belong to', 'animal order', 'protected', 'social', 'animal kingdom', 'related to']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict fact = ['office', 'home office', 'in office']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - suppord fact predict = ['home office-at location', 'office-used for', 'office-has a', 'office-at location', 'in office-at location']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - correspond target = ['pen', 'desk', 'your house', 'tall build', 'monitor', 'computer', 'window', 'keyboard', 'printer', 'work']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - test id = 1312, question = What type of food is that on the right side of the plate ?, img = COCO_val2014_000000136795.jpg\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - real suppord fact in dataset=['vegetable', 'belong to', 'food'], real answer = vegetable\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - normal model predict = ['fork', 'pizza', 'food', 'cut', 'restaurant', 'bowl', 'prepare food', 'cup', 'cheese', 'drink']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict = ['fork', 'toddler', 'frisbee', 'pizza', 'food', 'cut', 'restaurant', 'bowl', 'prepare food', 'cup']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict relation = ['belong to', 'is a', 'related to', 'has property', 'used for', 'has a', 'good', 'at location', 'receives action', 'easy', 'capable of', 'animal order', 'fast', 'animal class', 'important']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict fact = ['plate', 'lift food from plate to mouth', 'drink glass of milk']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - suppord fact predict = ['plate-related to', 'drink glass of milk-capable of', 'lift food from plate to mouth-used for']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - correspond target = ['frisbee', 'toddler', 'fork']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - test id = 972, question = What's in the bowl that you can eat?, img = COCO_val2014_000000004936.jpg\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - real suppord fact in dataset=['vegetable', 'belong to', 'plant'], real answer = vegetable\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - normal model predict = ['vegetable', 'broccoli', 'carrot', 'cucumber', 'meat', 'tomato', 'fruit', 'cheese', 'lettuce', 'zucchini']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict = ['banana', 'fork', 'apple', 'bread', 'cake', 'cat', 'hot dog', 'person', 'vegetable', 'broccoli']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict relation = ['is a', 'used for', 'related to', 'capable of', 'has a', 'easy', 'receives action', 'at location', 'good', 'belong to', 'part of', 'specific', 'important', 'accurate', 'fast']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict fact = ['eat food', 'eat', 'eat meat']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - suppord fact predict = ['eat-used for', 'eat-has a', 'eat meat-capable of', 'eat food-capable of', 'eat food-related to', 'eat food-used for']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - correspond target = ['cake', 'apple', 'cat', 'hot dog', 'bread', 'banana', 'person', 'fork']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - test id = 2307, question = Which things in this picture would a squirrel be most interested in?, img = ILSVRC2012_test_00021198.JPEG\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - real suppord fact in dataset=['squirrel', 'related to', 'walnut'], real answer = walnut\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - normal model predict = ['strawberry', 'orange', 'lemon', 'banana', 'fruit', 'apple', 'pomegranate', 'chocolate', 'fig', 'box']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict = ['box', 'tomato', 'chair', 'strawberry', 'orange', 'lemon', 'banana', 'fruit', 'apple', 'pomegranate']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict relation = ['is a', 'has property', 'used for', 'at location', 'has a', 'related to', 'part of', 'good', 'receives action', 'belong to', 'common', 'important', 'acid', 'popular', 'specific']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict fact = ['what person sit in', 'put thing in', 'fruit but person call it vegetable']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - suppord fact predict = ['fruit but person call it vegetable-is a', 'what person sit in-is a', 'put thing in-used for']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - correspond target = ['box', 'chair', 'tomato']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - test id = 2681, question = What can be found in this place?, img = COCO_val2014_000000106624.jpg\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - real suppord fact in dataset=['sand', 'at location', 'ocean'], real answer = ocean\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - normal model predict = ['lot of sand', 'boat', 'sand', 'fish', 'surf board', 'wave', 'sea', 'shore boat', 'store boat', 'big']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict = ['lot of sand', 'boat', 'sand', 'surf board', 'wave', 'beach', 'pretty girl', 'sandy', 'shell', 'human']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict relation = ['at location', 'used for', 'has a', 'part of', 'related to', 'belong to', 'capable of', 'specific', 'animal order', 'animal family', 'surface', 'has property', 'receives action', 'human', 'great']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - our model predict fact = ['beach', 'ocean beach', 'sandy']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - suppord fact predict = ['sandy-has property', 'beach-at location', 'beach-has property', 'ocean beach-used for', 'beach-has a']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - correspond target = ['sand', 'sandy', 'wave', 'boat', 'shell', 'human', 'lot of sand', 'beach', 'surf board', 'pretty girl']\r\n",
      "INFO - 08/13/22 23:30:43 - 0:01:01 - #################################################################################\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████▊                      | 43/89 [00:29<00:34,  1.35it/s]INFO - 08/13/22 23:30:44 - 0:01:02 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - test id = 513, question = What is the round, disc-like stuff?, img = COCO_val2014_000000108327.jpg\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - real suppord fact in dataset=['frisbee', 'is a', 'round fly disc'], real answer = frisbee\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - normal model predict = ['shell', 'donut', 'ice', 'glass', 'doughnut', 'water', 'fork', 'white', 'beach', 'orange']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict = ['knife', 'refrigerator', 'shell', 'donut', 'ice', 'glass', 'doughnut', 'water', 'fork', 'white']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict relation = ['is a', 'has property', 'has a', 'belong to', 'related to', 'capable of', 'part of', 'used for', 'important', 'animal class', 'receives action', 'common', 'animal order', 'animal family', 'desires']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict fact = ['cool thing', 'cut many thing', 'something']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - suppord fact predict = ['cool thing-used for', 'cut many thing-used for']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - correspond target = ['refrigerator', 'knife']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - test id = 1701, question = Which object in this image contains bromelain?, img = ILSVRC2012_test_00036186.JPEG\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - real suppord fact in dataset=['bromelein', 'related to', 'pineapple'], real answer = pineapple\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - normal model predict = ['fruit', 'banana', 'strawberry', 'vegetable', 'flowers', 'lemon', 'potted plant', 'pineapple', 'pomegranate', 'orange']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict = ['orange', 'vase', 'apple', 'beaker', 'pencil box', 'handbag', 'suitcase', 'fruit', 'banana', 'strawberry']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict relation = ['has a', 'related to', 'is a', 'part of', 'has property', 'used for', 'belong to', 'common', 'specific', 'important', 'social', 'popular', 'good', 'created by', 'animal order']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict fact = ['container', 'seed', 'urn']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - suppord fact predict = ['urn-related to', 'container-is a', 'seed-part of', 'container-belong to']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - correspond target = ['beaker', 'apple', 'handbag', 'suitcase', 'pencil box', 'orange', 'vase']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - test id = 1838, question = Which object in the image is related to archery?, img = ILSVRC2012_test_00024387.JPEG\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - real suppord fact in dataset=['bow', 'used for', 'archery'], real answer = bow\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - normal model predict = ['grass', 'crutch', 'horse', 'fire hydrant', 'bicycle', 'fence', 'kite', 'golfcart', 'cow', 'tree']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict = ['grass', 'skateboard', 'sand', 'elephant', 'trombone', 'crutch', 'horse', 'fire hydrant', 'bicycle', 'fence']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict relation = ['related to', 'belong to', 'specific', 'important', 'used for', 'common', 'at location', 'part of', 'capable of', 'animal order', 'social', 'accurate', 'prevalent', 'surface', 'has property']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict fact = ['grind', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - suppord fact predict = ['grind-at location', 'therapsida-belong to', 'tromboner-related to', 'grind-related to']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - correspond target = ['grass', 'skateboard', 'elephant', 'trombone', 'sand']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - test id = 551, question = which object in this picture can connect with an ibook, img = ILSVRC2012_test_00060109.JPEG\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - real suppord fact in dataset=['ibook', 'related to', 'laptop'], real answer = laptop\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - normal model predict = ['printer', 'listen to music', 'ipod', 'toaster', 'keyboard', 'bus', 'box', 'drum', 'drive screw', 'station']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict = ['dog', 'person', 'printer', 'listen to music', 'ipod', 'toaster', 'keyboard', 'bus', 'box', 'drum']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict relation = ['related to', 'used for', 'capable of', 'has property', 'at location', 'has a', 'specific', 'part of', 'is a', 'important', 'belong to', 'good', 'common', 'desires', 'accurate']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict fact = ['follow it master', 'reason with another person', 'listen to music with earphone']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - suppord fact predict = ['listen to music with earphone-capable of', 'reason with another person-capable of', 'follow it master-capable of']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - correspond target = ['person', 'dog']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - test id = 505, question = Where does the objects shown in this image can be found?, img = COCO_val2014_000000100132.jpg\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - real suppord fact in dataset=['sandwich', 'at location', 'fridge'], real answer = fridge\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - normal model predict = ['cheese', 'fork', 'broccoli', 'vegetable', 'flour', 'bread', 'meat', 'fry bread', 'mustard', 'zucchini']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict = ['cheese', 'flour', 'bread', 'bakery', 'kitchen', 'mushroom', 'oven', 'italian', 'unhealthy', 'wedding']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict relation = ['at location', 'used for', 'is a', 'related to', 'belong to', 'good', 'part of', 'has property', 'created by', 'capable of', 'important', 'great', 'specific', 'has a', 'accurate']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict fact = ['pizza', 'kitchenware', 'cake']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - suppord fact predict = ['pizza-has a', 'cake-at location', 'pizza-related to', 'pizza-at location', 'cake-related to', 'pizza-has property', 'pizza-belong to']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - correspond target = ['cheese', 'mushroom', 'flour', 'oven', 'kitchen', 'bread', 'italian', 'unhealthy', 'wedding', 'bakery']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - test id = 541, question = What thing is likely to be found in this place, img = COCO_val2014_000000117788.jpg\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - real suppord fact in dataset=['stove', 'at location', 'kitchen'], real answer = stove\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - normal model predict = ['furniture', 'kitchen', 'bedroom', 'cup', 'house', 'kitchen table', 'knife in drawer', 'toilet paper', 'wall', 'metal']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict = ['furniture', 'house', 'wall', 'sleep', 'couch', 'sleep away from home', 'chair', 'temporary residence', 'human', 'person']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict relation = ['at location', 'used for', 'has a', 'belong to', 'part of', 'animal family', 'animal order', 'good', 'has property', 'convenient', 'expensive', 'capable of', 'animal class', 'great', 'active']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict fact = ['room', 'hotel room', 'dorm room']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - suppord fact predict = ['hotel room-used for', 'room-at location', 'room-has a']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - correspond target = ['wall', 'sleep', 'house', 'furniture', 'couch', 'temporary residence', 'chair', 'person', 'sleep away from home', 'human']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - test id = 86, question = Where does the place in this image can be found in?, img = COCO_val2014_000000103723.jpg\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - real suppord fact in dataset=['zoo', 'at location', 'city'], real answer = city\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - normal model predict = ['elephant', 'zoo', 'mountainous area', 'park', 'africa', 'river', 'tourist', 'park space', 'big', 'desert']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict = ['zoo', 'africa', 'big', 'animal', 'transport', 'long necked', 'extremely high blood pressure', 'giraffidae', 'elephant', 'mountainous area']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict relation = ['at location', 'used for', 'has a', 'has property', 'capable of', 'belong to', 'animal family', 'small', 'surface', 'is a', 'human', 'expensive', 'large', 'great', 'active']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict fact = ['giraffe', 'elephant', 'monkey']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - suppord fact predict = ['giraffe-animal family', 'giraffe-has a', 'elephant-has property', 'elephant-used for', 'giraffe-has property', 'giraffe-at location', 'elephant-belong to', 'monkey-at location']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - correspond target = ['giraffidae', 'extremely high blood pressure', 'animal', 'transport', 'zoo', 'long necked', 'africa', 'big']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - test id = 2533, question = What kind of seafood does the animal in the image likes to eat?, img = COCO_val2014_000000127955.jpg\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - real suppord fact in dataset=['bear', 'related to', 'fish'], real answer = fish\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - normal model predict = ['animal', 'mammal', 'human', 'elephant', 'otter', 'cat', 'dog', 'rabbit', 'bear', 'whale']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict = ['cat', 'bread', 'apple', 'cake', 'banana', 'hot dog', 'person', 'animal', 'mammal', 'human']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict relation = ['capable of', 'has a', 'desires', 'has property', 'is a', 'related to', 'animal order', 'at location', 'belong to', 'human', 'used for', 'stable', 'receives action', 'good', 'specific']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - our model predict fact = ['eat fish', 'eat cat food', 'eat']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - suppord fact predict = ['eat fish-desires', 'eat-used for', 'eat-has a', 'eat fish-capable of', 'eat cat food-capable of']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - correspond target = ['cake', 'apple', 'cat', 'hot dog', 'bread', 'banana', 'person']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:02 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████▎                     | 44/89 [00:29<00:34,  1.31it/s]INFO - 08/13/22 23:30:44 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - test id = 1594, question = Which place is more important than the place shown in this image, img = COCO_val2014_000000101985.jpg\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - real suppord fact in dataset=['stadium', 'important', 'steroid'], real answer = stadium\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - normal model predict = ['soccer ball', 'tennis ball', 'golf ball', 'rugby ball', 'frisbee', 'ball', 'volleyball', 'dressage', 'tennis', 'play baseball']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - our model predict = ['soccer ball', 'tennis ball', 'frisbee', 'play baseball', 'baseball', 'play game of baseball', 'play baseball on it', 'play', 'horse', 'green']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - our model predict relation = ['important', 'at location', 'strenuous', 'dangerous', 'safe', 'impassable', 'common', 'has property', 'popular', 'capable of', 'convenient', 'prevalent', 'natural', 'used for', 'protected']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - our model predict fact = ['round', 'baseball field', 'racecourse']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - suppord fact predict = ['baseball field-used for', 'baseball field-has property', 'racecourse-at location', 'round-has property', 'baseball field-at location']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - correspond target = ['horse', 'frisbee', 'green', 'play', 'play baseball on it', 'soccer ball', 'play baseball', 'tennis ball', 'baseball', 'play game of baseball']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - test id = 2649, question = Which kind of creature can be found in this place?, img = COCO_val2014_000000025358.jpg\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - real suppord fact in dataset=['child', 'at location', 'playground'], real answer = child\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - normal model predict = ['frisbee', 'soccer ball', 'rugby ball', 'play baseball', 'play game of baseball', 'baseball', 'basketball', 'play basketball', 'baseball field', 'play baseball on it']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - our model predict = ['frisbee', 'soccer ball', 'baseball', 'basketball', 'tennis ball', 'cow', 'horse', 'heifer', 'orange', 'apple']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - our model predict relation = ['at location', 'belong to', 'used for', 'has a', 'has property', 'is a', 'related to', 'capable of', 'part of', 'human', 'specific', 'visible', 'animal family', 'desires', 'receives action']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - our model predict fact = ['pasture', 'round', 'countryside']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - suppord fact predict = ['pasture-at location', 'round-is a', 'countryside-at location', 'round-has property', 'round-related to']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - correspond target = ['apple', 'basketball', 'horse', 'orange', 'frisbee', 'cow', 'heifer', 'soccer ball', 'tennis ball', 'baseball']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - test id = 1689, question = Which object in this image could likely be moved by a bellhop?, img = ILSVRC2012_test_00010551.JPEG\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - real suppord fact in dataset=['bellhop', 'related to', 'luggage'], real answer = luggage\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - normal model predict = ['luggage', 'suitcase', 'accordion', 'wood', 'furniture', 'car', 'handbag', 'backpack', 'wooden', 'motorcycle']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - our model predict = ['violin', 'trumpet', 'dog', 'luggage', 'suitcase', 'accordion', 'wood', 'furniture', 'car', 'handbag']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - our model predict relation = ['has a', 'related to', 'is a', 'part of', 'has property', 'used for', 'capable of', 'belong to', 'at location', 'specific', 'desires', 'receives action', 'created by', 'common', 'social']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - our model predict fact = ['violinist', 'musician', 'name']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - suppord fact predict = ['musician-related to', 'violinist-related to', 'name-has a']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - correspond target = ['violin', 'trumpet', 'dog']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - test id = 2422, question = What property does the place in this image have?, img = COCO_val2014_000000106331.jpg\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - real suppord fact in dataset=['baseball field', 'has property', 'green'], real answer = baseball field\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - normal model predict = ['baseball bat', 'baseball', 'baseball field', 'baseball glove', 'play baseball', 'play baseball on it', 'play game of baseball', 'soccer ball', 'golf ball', 'grass']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - our model predict = ['wild', 'two set of wing', 'feather', 'bird', 'airplane', 'baseball bat', 'baseball', 'baseball field', 'baseball glove', 'play baseball']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - our model predict relation = ['has property', 'at location', 'protected', 'related to', 'used for', 'animal family', 'part of', 'belong to', 'firm', 'created by', 'animal order', 'has a', 'capable of', 'animal kingdom', 'expensive']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - our model predict fact = ['dragonfly', 'birdbath', 'bird']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - suppord fact predict = ['birdbath-at location', 'bird-at location', 'bird-related to', 'bird-has a', 'dragonfly-has a']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - correspond target = ['two set of wing', 'airplane', 'feather', 'wild', 'bird']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - test id = 2530, question = Which device in the image can free people's hand?, img = COCO_val2014_000000009236.jpg\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - real suppord fact in dataset=['dishwasher', 'efficient', 'hand wash'], real answer = dishwasher\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - normal model predict = ['toothbrush', 'sink', 'microwave', 'lamp', 'refrigerator', 'mirror', 'wash machine', 'kitchen utensil', 'toilet paper', 'toilet']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - our model predict = ['dog', 'kite', 'toothbrush', 'sink', 'microwave', 'lamp', 'refrigerator', 'mirror', 'wash machine', 'kitchen utensil']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - our model predict relation = ['used for', 'capable of', 'at location', 'related to', 'belong to', 'has a', 'fast', 'is a', 'good', 'part of', 'specific', 'accurate', 'great', 'important', 'blind']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - our model predict fact = [\"child's hand\", \"call man's best friend\", \"man's best friend\"]\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - suppord fact predict = [\"child's hand-at location\", \"call man's best friend-is a\", \"man's best friend-is a\"]\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - correspond target = ['kite', 'dog']\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - test id = 1558, question = Who has a long nose in the image?, img = COCO_val2014_000000139555.jpg\n",
      "INFO - 08/13/22 23:30:44 - 0:01:03 - real suppord fact in dataset=['elephant', 'has a', 'long nose call trunk'], real answer = elephant\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - normal model predict = ['elephant', 'police', 'monkey', 'zoo', 'hippopotamus', 'park', 'human', 'child', 'beach', 'taxi']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict = ['giraffe', 'snake', 'sofa', 'elephant', 'police', 'monkey', 'zoo', 'hippopotamus', 'park', 'human']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict relation = ['has property', 'has a', 'is a', 'long', 'capable of', 'high', 'related to', 'strong', 'common', 'good', 'important', 'low', 'large', 'slow', 'great']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict fact = ['soft cushion', 'long neck animal', 'reptile with long narrow body and no leg']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - suppord fact predict = ['reptile with long narrow body and no leg-is a', 'soft cushion-has a', 'long neck animal-has property']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - correspond target = ['giraffe', 'sofa', 'snake']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████▋                     | 45/89 [00:30<00:31,  1.38it/s]INFO - 08/13/22 23:30:45 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - test id = 828, question = What objects in this image are inspirational, img = ILSVRC2012_test_00035105.JPEG\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - real suppord fact in dataset=['forest road', 'has property', 'inspirational'], real answer = forest road\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - normal model predict = ['stop sign', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car', 'bus', 'person']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict = ['stop sign', 'horse', 'tv', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict relation = ['capable of', 'is a', 'has property', 'receives action', 'has a', 'used for', 'related to', 'part of', 'desires', 'at location', 'belong to', 'created by', 'specific', 'good', 'animal order']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict fact = ['traffic sign', 'clop', 'advertise']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - suppord fact predict = ['advertise-used for', 'traffic sign-belong to', 'clop-related to']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - correspond target = ['stop sign', 'tv', 'horse']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - test id = 2682, question = What can be found in this place?, img = COCO_val2014_000000106624.jpg\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - real suppord fact in dataset=['sand', 'at location', 'ocean'], real answer = ocean\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - normal model predict = ['lot of sand', 'boat', 'sand', 'fish', 'surf board', 'wave', 'sea', 'shore boat', 'store boat', 'big']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict = ['lot of sand', 'boat', 'sand', 'surf board', 'wave', 'beach', 'pretty girl', 'sandy', 'shell', 'human']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict relation = ['at location', 'used for', 'has a', 'part of', 'related to', 'belong to', 'capable of', 'specific', 'animal order', 'animal family', 'surface', 'has property', 'receives action', 'human', 'great']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict fact = ['beach', 'ocean beach', 'sandy']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - suppord fact predict = ['sandy-has property', 'beach-at location', 'beach-has property', 'ocean beach-used for', 'beach-has a']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - correspond target = ['sand', 'sandy', 'wave', 'boat', 'shell', 'human', 'lot of sand', 'beach', 'surf board', 'pretty girl']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - test id = 2719, question = Whether this animal lives in the sea or on land?, img = ILSVRC2012_test_00008683.JPEG\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - real suppord fact in dataset=['jellyfish', 'at location', 'sea'], real answer = sea\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - normal model predict = ['jellyfish', 'coast', 'sea', 'unhealthy', 'mountainous area', 'ocean', 'sandy', 'shell', 'desert', 'poisonous']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict = ['jellyfish', 'shell', 'whale', 'dolphin', 'low', 'large ship', 'seal', 'coast', 'sea', 'unhealthy']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict relation = ['at location', 'related to', 'capable of', 'used for', 'belong to', 'is a', 'has a', 'accurate', 'good', 'receives action', 'specific', 'visible', 'surface', 'has property', 'blind']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict fact = ['turtle', 'sea', 'sea water']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - suppord fact predict = ['sea water-at location', 'turtle-has a', 'turtle-has property', 'sea-at location']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - correspond target = ['jellyfish', 'whale', 'shell', 'seal', 'large ship', 'low', 'dolphin']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - test id = 2531, question = What is burning in the fireplace?, img = COCO_val2014_000000014088.jpg\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - real suppord fact in dataset=['wood', 'receives action', 'burn in fireplace'], real answer = wood\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - normal model predict = ['kitchen table', 'couch', 'dining table', 'tv', 'desk', 'monitor', 'kitchen', 'sofa', 'control tv', 'room']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict = ['cup', 'house', 'chair', 'kitchen utensil', 'toilet paper', 'refrigerator', 'knife in drawer', 'microwave', 'oven', 'stove']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict relation = ['used for', 'at location', 'has property', 'related to', 'belong to', 'capable of', 'is a', 'receives action', 'has a', 'good', 'part of', 'specific', 'important', 'high', 'easy']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict fact = ['living room', 'kitchen', 'burn in fireplace']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - suppord fact predict = ['kitchen-at location', 'kitchen-belong to']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - correspond target = ['kitchen utensil', 'oven', 'toilet paper', 'refrigerator', 'knife in drawer', 'house', 'microwave', 'cup', 'chair', 'stove']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - test id = 1586, question = What kind people are you likely to find in a ballroom?, img = COCO_val2014_000000125983.jpg\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - real suppord fact in dataset=['dancer', 'at location', 'ballroom'], real answer = dancer\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - normal model predict = ['person', 'any place where person live', 'make person happy', 'romantic', 'child', 'tie', 'thing', 'wedding', 'baseball', 'pretty girl']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict = ['dog', 'tv', 'sofa', 'cat', 'person', 'any place where person live', 'make person happy', 'romantic', 'child', 'tie']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict relation = ['at location', 'capable of', 'used for', 'belong to', 'related to', 'has property', 'expensive', 'active', 'part of', 'good', 'convenient', 'has a', 'important', 'specific', 'surface']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict fact = ['petshop', 'house', 'apartment']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - suppord fact predict = ['petshop-at location', 'apartment-at location', 'house-at location']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - correspond target = ['tv', 'cat', 'sofa', 'dog']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - test id = 2171, question = ￼Which object in this image is capable of running much faster than a person?, img = COCO_val2014_000000139140.jpg\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - real suppord fact in dataset=['horse', 'capable of', 'run much fast than person'], real answer = horse\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - normal model predict = ['horse', 'person', 'dog', 'elephant', 'make person happy', 'cow', 'hot dog', 'transport person', 'camel', 'giraffe']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict = ['dog', 'elephant', 'bear', 'computer', 'horse', 'person', 'make person happy', 'cow', 'hot dog', 'transport person']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict relation = ['capable of', 'fast', 'efficient', 'intelligent', 'slow', 'stable', 'high', 'powerful', 'reliable', 'accurate', 'effective', 'active', 'easy', 'used for', 'energetic']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict fact = ['man', 'human', 'human being']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - suppord fact predict = ['human-fast', 'man-fast', 'human-accurate', 'human-intelligent']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - correspond target = ['bear', 'elephant', 'computer', 'dog']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:45 - 0:01:03 - #################################################################################\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - test id = 1209, question = What are the blue things around the tables?, img = COCO_val2014_000000127050.jpg\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - real suppord fact in dataset=['chair', 'receives action', 'place around table'], real answer = chair\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - normal model predict = ['sit down on', 'sit outside', 'chair', 'bench', 'lot of sand', 'sand', 'entertain yourself on windy day', 'lay on', 'desk', 'work']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict = ['desk', 'bottle', 'sit down on', 'sit outside', 'chair', 'bench', 'lot of sand', 'sand', 'entertain yourself on windy day', 'lay on']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict relation = ['at location', 'has a', 'has property', 'is a', 'related to', 'belong to', 'used for', 'animal order', 'animal family', 'part of', 'animal class', 'animal kingdom', 'created by', 'surface', 'receives action']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - our model predict fact = ['office table', 'table', 'sit around table']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - suppord fact predict = ['office table-related to', 'table-is a', 'table-at location']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - correspond target = ['bottle', 'desk']\n",
      "INFO - 08/13/22 23:30:45 - 0:01:03 - #################################################################################\n",
      " 52%|██████████████████████▏                    | 46/89 [00:31<00:31,  1.37it/s]INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - test id = 1507, question = What is this place usually located?, img = COCO_val2014_000000022969.jpg\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - real suppord fact in dataset=['zoo', 'at location', 'city'], real answer = city\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - normal model predict = ['giraffe', 'window', 'lizard', 'actinopterygii', 'giraffidae', 'gastropoda', 'bovidae', 'wall', 'hippopotamus', 'zebra']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict = ['bathroom', 'temporary residence', 'dog poop', 'dog', 'toilet', 'sleep', 'sleep away from home', 'space to run and play', 'frisbee', 'vend stand']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict relation = ['at location', 'used for', 'capable of', 'has property', 'is a', 'related to', 'has a', 'animal family', 'part of', 'receives action', 'good', 'important', 'human', 'accurate', 'animal order']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict fact = ['hotel', 'hotel room', 'park']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - suppord fact predict = ['hotel room-used for', 'park-at location', 'hotel-at location', 'park-used for']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - correspond target = ['toilet', 'dog poop', 'sleep', 'dog', 'bathroom', 'frisbee', 'space to run and play', 'vend stand', 'temporary residence', 'sleep away from home']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - test id = 1835, question = Which object in this image can be used for cutting, img = COCO_val2014_000000151790.jpg\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - real suppord fact in dataset=['scissors', 'used for', 'cut'], real answer = scissors\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - normal model predict = ['pen', 'scissors', 'screwdriver', 'plane', 'airplane', 'mouse', 'pencil box', 'ruler', 'corkscrew', 'camera']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict = ['remote', 'computer', 'pen', 'scissors', 'screwdriver', 'plane', 'airplane', 'mouse', 'pencil box', 'ruler']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict relation = ['belong to', 'related to', 'used for', 'specific', 'at location', 'capable of', 'has property', 'important', 'accurate', 'common', 'animal order', 'desires', 'easy', 'good', 'visible']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict fact = ['cyberdating', 'send email', 'telecommunications engineering']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - suppord fact predict = ['telecommunications engineering-belong to', 'send email-used for', 'cyberdating-related to']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - correspond target = ['remote', 'computer']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - test id = 2160, question = What property does the action in this image have?, img = COCO_val2014_000000123810.jpg\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - real suppord fact in dataset=['wedding', 'has property', 'happy for bride and groom'], real answer = happy for bride and groom\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - normal model predict = ['cake', 'pleasant', 'chocolate', 'bread', 'sweet and juicy', 'banana', 'strawberry', 'romantic', 'bakery', 'fruit']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict = ['breakfast', 'clean your tooth in', 'cheese', 'cup', 'cook food', 'prepare food', 'sink', 'cooking', 'house', 'oven']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict relation = ['has property', 'at location', 'has a', 'belong to', 'used for', 'animal family', 'animal order', 'firm', 'related to', 'protected', 'created by', 'part of', 'animal class', 'receives action', 'animal kingdom']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict fact = ['kitchen', 'kitchenette', 'bathroom']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - suppord fact predict = ['kitchen-at location', 'kitchenette-used for', 'kitchen-used for', 'bathroom-at location', 'bathroom-has a', 'bathroom-part of', 'bathroom-used for', 'kitchenette-at location', 'kitchen-belong to']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - correspond target = ['prepare food', 'oven', 'sink', 'house', 'cup', 'cooking', 'clean your tooth in', 'cheese', 'breakfast', 'cook food']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - test id = 281, question = which object in this image may be dangerous to human, img = COCO_val2014_000000132554.jpg\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - real suppord fact in dataset=['horse', 'has property', 'dangerous'], real answer = horse\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - normal model predict = ['horse', 'person', 'wood', 'cow', 'dog', 'camel', 'fence', 'transport person', 'tree', 'cattle']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict = ['person', 'knife', 'horse', 'wood', 'cow', 'dog', 'camel', 'fence', 'transport person', 'tree']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict relation = ['related to', 'used for', 'capable of', 'belong to', 'specific', 'desires', 'has property', 'important', 'at location', 'dangerous', 'accurate', 'common', 'visible', 'receives action', 'is a']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict fact = ['dare another to do something careless', 'breathe to survive', 'hurt you']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - suppord fact predict = ['dare another to do something careless-capable of', 'hurt you-capable of', 'breathe to survive-capable of']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - correspond target = ['person', 'knife']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - test id = 1336, question = Which object in this image is a hermaphrodite?, img = ILSVRC2012_test_00000138.JPEG\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - real suppord fact in dataset=['nail', 'is a', 'hermaphrodite'], real answer = nail\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - normal model predict = ['screwdriver', 'baseball', 'baseball bat', 'bicycle', 'corkscrew', 'baseball field', 'play baseball', 'armadillo', 'ray', 'car']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict = ['motorcycle', 'camel', 'trumpet', 'giraffe', 'child', 'screwdriver', 'baseball', 'baseball bat', 'bicycle', 'corkscrew']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict relation = ['is a', 'belong to', 'has property', 'related to', 'cool', 'has a', 'visible', 'at location', 'capable of', 'important', 'part of', 'protected', 'safe', 'convenient', 'trustworthy']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict fact = ['musician', 'ruminant', 'subculture']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - suppord fact predict = ['ruminant-is a', 'subculture-belong to', 'musician-related to']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - correspond target = ['child', 'camel', 'motorcycle', 'giraffe', 'trumpet']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - test id = 598, question = which object in this image is made of grain, img = ILSVRC2012_test_00002238.JPEG\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - real suppord fact in dataset=['bread', 'has property', 'make from grain'], real answer = bread\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - normal model predict = ['pretzel', 'doughnut', 'bagel', 'sandwich', 'bread', 'donut', 'chocolate', 'toast bread', 'flour', 'hamburger']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict = ['banana', 'dog', 'sheep', 'pretzel', 'doughnut', 'bagel', 'sandwich', 'bread', 'donut', 'chocolate']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict relation = ['has property', 'is a', 'related to', 'belong to', 'used for', 'part of', 'at location', 'has a', 'receives action', 'capable of', 'important', 'created by', 'specific', 'good', 'common']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict fact = ['fiber', 'woof woof', 'wool']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - suppord fact predict = ['fiber-belong to', 'woof woof-related to', 'wool-related to']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - correspond target = ['sheep', 'banana', 'dog']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - test id = 493, question = Which object in this image belongs to the category Capsicum?, img = ILSVRC2012_test_00045779.JPEG\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - real suppord fact in dataset=['bell pepper', 'belong to', 'capsicum'], real answer = bell pepper\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - normal model predict = ['child', 'flowers', 'fruit', 'vegetable', 'toddler', 'flower', 'prepare food', 'food', 'toys', 'basket']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict = ['child', 'sunglasses', 'motorcycle', 'flowers', 'fruit', 'vegetable', 'toddler', 'flower', 'prepare food', 'food']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict relation = ['belong to', 'desires', 'is a', 'animal kingdom', 'animal phylum', 'loyal', 'related to', 'animal order', 'trustworthy', 'sensible', 'comfortable', 'animal family', 'important', 'human', 'animal class']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict fact = ['subculture', 'petshop', 'physician']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - suppord fact predict = ['physician-belong to', 'subculture-belong to']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - correspond target = ['motorcycle', 'child', 'sunglasses']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - test id = 166, question = Which object in this image has three keys?, img = ILSVRC2012_test_00019551.JPEG\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - real suppord fact in dataset=['french horn', 'has a', 'three key'], real answer = french horn\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - normal model predict = ['saxophone', 'flute', 'clarinet', 'trombone', 'violin', 'cello', 'piano', 'guitar', 'trumpet', 'harmonica']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict = ['violin', 'guitar', 'stop sign', 'saxophone', 'flute', 'clarinet', 'trombone', 'cello', 'piano', 'trumpet']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict relation = ['has a', 'related to', 'part of', 'large', 'is a', 'frequent', 'social', 'specific', 'small', 'light', 'common', 'long', 'has property', 'muscular', 'low']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict fact = ['four string', 'six string', 'eight side object']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - suppord fact predict = ['six string-has a', 'four string-has a', 'eight side object-is a']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - correspond target = ['guitar', 'violin', 'stop sign']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - test id = 666, question = Which food shown here is softer than a plantain?, img = ILSVRC2012_test_00040162.JPEG\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - real suppord fact in dataset=['plantain', 'firm', 'banana'], real answer = banana\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - normal model predict = ['banana', 'apple', 'fruit', 'pare apple', 'peel', 'pineapple', 'cold and wet', 'sweet and juicy', 'coffee', 'palm tree']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict = ['ipod', 'cut', 'fork', 'banana', 'apple', 'fruit', 'pare apple', 'peel', 'pineapple', 'cold and wet']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict relation = ['is a', 'popular', 'acid', 'good', 'colorful', 'safe', 'green', 'healthy', 'belong to', 'cool', 'prevalent', 'stable', 'light', 'important', 'common']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - our model predict fact = ['scissors', 'chopstick', 'walkman']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - suppord fact predict = ['scissors-belong to', 'chopstick-good', 'walkman-good']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - correspond target = ['fork', 'cut', 'ipod']\n",
      "INFO - 08/13/22 23:30:46 - 0:01:04 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████▋                    | 47/89 [00:32<00:30,  1.38it/s]INFO - 08/13/22 23:30:47 - 0:01:05 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - test id = 1233, question = Which thing does the place shown in this image have as a part?, img = ILSVRC2012_test_00002135.JPEG\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - real suppord fact in dataset=['floor', 'part of', 'room'], real answer = room\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - normal model predict = ['sofa', 'bed', 'couch', 'bedroom', 'furniture', 'baby bed', 'tv', 'pillows', 'bathroom', 'sleep']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict = ['sofa', 'kitchen', 'door', 'ice', 'oven', 'wedding', 'flour', 'bakery', 'bed', 'couch']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict relation = ['part of', 'has a', 'related to', 'is a', 'capable of', 'social', 'used for', 'specific', 'frequent', 'large', 'small', 'receives action', 'important', 'common', 'at location']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict fact = ['part of wall', 'cake', 'house']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - suppord fact predict = ['cake-part of', 'cake-at location', 'cake-related to', 'house-at location', 'part of wall-at location']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - correspond target = ['sofa', 'flour', 'ice', 'oven', 'kitchen', 'door', 'wedding', 'bakery']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - test id = 2228, question = what is a skateboard used for?, img = COCO_val2014_000000008589.jpg\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - real suppord fact in dataset=['skateboard', 'related to', 'skateboard'], real answer = skateboard\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - normal model predict = ['preventing from getting wet', 'travel in car', 'sit down on', 'travel across water', 'cut', 'store boat', 'snowboard', 'lay on', 'travel', 'sit outside']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict = ['bicycle', 'motorcycle', 'racing', 'horse', 'preventing from getting wet', 'travel in car', 'sit down on', 'travel across water', 'cut', 'store boat']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict relation = ['used for', 'is a', 'belong to', 'capable of', 'related to', 'easy', 'good', 'fast', 'effective', 'cool', 'popular', 'at location', 'convenient', 'great', 'safe']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict fact = ['bicycle', 'ride', 'bike']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - suppord fact predict = ['ride-related to', 'bicycle-used for', 'bike-related to', 'ride-used for']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - correspond target = ['motorcycle', 'racing', 'bicycle', 'horse']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - test id = 1105, question = Whether this game belongs to the Summer Olympic or the Winter Olympic?, img = ILSVRC2012_test_00000992.JPEG\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - real suppord fact in dataset=['tennis ball', 'belong to', 'summer'], real answer = summer\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - normal model predict = ['tennis racket', 'racket', 'tennis', 'racquet', 'tennis ball', 'play tennis', 'frisbee', 'ambition', 'baseball', 'basketball']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict = ['volleyball', 'snowboard', 'tennis racket', 'racket', 'tennis', 'racquet', 'tennis ball', 'play tennis', 'frisbee', 'ambition']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict relation = ['belong to', 'at location', 'related to', 'used for', 'is a', 'capable of', 'has property', 'important', 'easy', 'specific', 'fast', 'good', 'animal order', 'accurate', 'desires']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict fact = ['winter olympic sports', 'winter olympic games', 'summer olympic sports']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - suppord fact predict = ['winter olympic sports-belong to', 'summer olympic sports-belong to', 'winter olympic games-belong to']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - correspond target = ['volleyball', 'snowboard']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - test id = 679, question = Which object in this image can be used for stirring?, img = COCO_val2014_000000002759.jpg\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - real suppord fact in dataset=['spoon', 'used for', 'stir'], real answer = spoon\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - normal model predict = ['fork', 'broccoli', 'dishes', 'spoon', 'bowl', 'fry bread', 'vegetable', 'meat', 'cheese', 'salad']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict = ['bowl', 'couch', 'computer', 'fork', 'broccoli', 'dishes', 'spoon', 'fry bread', 'vegetable', 'meat']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict relation = ['used for', 'related to', 'has property', 'belong to', 'good', 'specific', 'easy', 'at location', 'capable of', 'effective', 'receives action', 'is a', 'accurate', 'expensive', 'convenient']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict fact = ['cyberdating', 'hold cranberry', 'laze']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - suppord fact predict = ['hold cranberry-used for', 'laze-used for', 'cyberdating-related to']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - correspond target = ['couch', 'computer', 'bowl']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - test id = 1025, question = Which object in this image is related to hydrography?, img = COCO_val2014_000000001987.jpg\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - real suppord fact in dataset=['hydrography', 'related to', 'water'], real answer = water\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - normal model predict = ['kite', 'frisbee', 'grass', 'surfboard', 'sand', 'surf board', 'crutch', 'wave', 'fire hydrant', 'unicycle']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict = ['grass', 'sand', 'skateboard', 'whale', 'scissors', 'kite', 'frisbee', 'surfboard', 'surf board', 'crutch']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict relation = ['related to', 'belong to', 'specific', 'important', 'used for', 'common', 'animal order', 'social', 'at location', 'part of', 'capable of', 'has property', 'prevalent', 'accurate', 'visible']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict fact = ['grind', 'sew', 'moby dick']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - suppord fact predict = ['sew-belong to', 'moby dick-related to', 'grind-at location', 'grind-related to']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - correspond target = ['grass', 'whale', 'skateboard', 'scissors', 'sand']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - test id = 1357, question = What is on the surface of the fruit in the image?, img = ILSVRC2012_test_00044733.JPEG\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - real suppord fact in dataset=['pineapple', 'related to', 'peel'], real answer = peel\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - normal model predict = ['pineapple', 'fruit', 'strawberry', 'lemon', 'fig', 'pomegranate', 'orange', 'vegetable', 'donut', 'doughnut']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict = ['pineapple', 'strawberry', 'lemon', 'pomegranate', 'orange', 'banana', 'apple', 'fruit', 'fig', 'vegetable']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict relation = ['animal order', 'animal kingdom', 'animal family', 'part of', 'has a', 'animal phylum', 'animal class', 'is a', 'human', 'healthy', 'common', 'important', 'small', 'social', 'related to']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict fact = ['fruit morphology', 'fruit', 'frog']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - suppord fact predict = ['fruit-is a', 'fruit-related to', 'fruit-part of']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - correspond target = ['apple', 'strawberry', 'pineapple', 'pomegranate', 'orange', 'banana', 'lemon']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - test id = 1071, question = What place is less important than the place in the image?, img = COCO_val2014_000000138070.jpg\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - real suppord fact in dataset=['room', 'important', 'park space'], real answer = park space\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - normal model predict = ['bedroom', 'sofa', 'couch', 'apartment', 'furniture', 'house', 'bed', 'bathroom', 'kitchen', 'living room']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict = ['bedroom', 'couch', 'apartment', 'furniture', 'house', 'wall', 'chair', 'human', 'person', 'sofa']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict relation = ['cheap', 'at location', 'warm', 'used for', 'expensive', 'convenient', 'fast', 'comfortable', 'part of', 'popular', 'good', 'safe', 'soft', 'has a', 'low']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - our model predict fact = ['room', 'dorm room', 'living room']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - suppord fact predict = ['dorm room-cheap', 'room-at location', 'living room-warm', 'room-has a']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - correspond target = ['wall', 'house', 'furniture', 'bedroom', 'apartment', 'couch', 'chair', 'person', 'human']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:05 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████▏                   | 48/89 [00:32<00:29,  1.39it/s]INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - test id = 251, question = What is the weather in the image?, img = COCO_val2014_000000007088.jpg\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - real suppord fact in dataset=['rain', 'at location', 'weather'], real answer = rain\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - normal model predict = ['grass', 'car', 'apartment', 'beach', 'green', 'park', 'skateboard', 'water', 'mountain', 'city']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict = ['sand', 'camel', 'cake', 'carnivora', 'mammal', 'giraffe', 'grass', 'car', 'apartment', 'beach']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict relation = ['is a', 'belong to', 'related to', 'has property', 'has a', 'part of', 'animal class', 'animal order', 'at location', 'important', 'animal family', 'animal kingdom', 'common', 'good', 'used for']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict fact = ['otter', 'desert', 'ruminant']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - suppord fact predict = ['otter-animal order', 'desert-at location', 'desert-is a', 'desert-related to', 'ruminant-is a', 'otter-animal class']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - correspond target = ['cake', 'camel', 'giraffe', 'mammal', 'carnivora', 'sand']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - test id = 2229, question = Whether the animal in the image has high or low blood pressure?, img = COCO_val2014_000000143129.jpg\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - real suppord fact in dataset=['giraffe', 'has a', 'extremely high blood pressure'], real answer = extremely high blood pressure\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - normal model predict = ['giraffe', 'africa', 'camel', 'long necked', 'vitamin c', 'horse', 'mouth', 'rich in vitamin c', 'blanket', 'zebra']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict = ['giraffe', 'lizard', 'turtle', 'africa', 'camel', 'long necked', 'vitamin c', 'horse', 'mouth', 'rich in vitamin c']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict relation = ['has a', 'has property', 'large', 'animal family', 'big', 'part of', 'light', 'related to', 'is a', 'small', 'strong', 'animal order', 'capable of', 'stable', 'animal phylum']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict fact = ['extremely high blood pressure', 'cold blood animal', 'reptile and therefore cold blood']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - suppord fact predict = ['cold blood animal-is a', 'extremely high blood pressure-has a', 'reptile and therefore cold blood-is a']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - correspond target = ['turtle', 'giraffe', 'lizard']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - test id = 2605, question = what do you feel with the action in this image, img = ILSVRC2012_test_00019930.JPEG\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - real suppord fact in dataset=['wedding', 'has property', 'fun'], real answer = fun\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - normal model predict = ['expensive', 'unhealthy', 'work', 'any place where person live', 'ice', 'car', 'fun', 'knife in drawer', 'clean your tooth in', 'vehicle']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict = ['furniture', 'human', 'sound control room', 'sleep', 'pillows', 'bookshelf', 'lamp', 'bed', 'metronome', 'clarinet']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict relation = ['at location', 'used for', 'has property', 'related to', 'belong to', 'receives action', 'has a', 'animal order', 'specific', 'important', 'created by', 'capable of', 'expensive', 'good', 'common']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict fact = ['bedroom', 'happyness', 'music studio']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - suppord fact predict = ['bedroom-used for', 'bedroom-at location', 'bedroom-capable of', 'bedroom-has a', 'bedroom-related to', 'music studio-at location']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - correspond target = ['clarinet', 'sleep', 'bookshelf', 'furniture', 'pillows', 'lamp', 'metronome', 'human', 'sound control room', 'bed']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - test id = 2120, question = Which animal is a nice friend, img = COCO_val2014_000000142722.jpg\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - real suppord fact in dataset=['dog', 'is a', 'nice friend'], real answer = dog\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - normal model predict = ['dog', 'horse', 'giraffe', 'cow', 'dog poop', 'sheep', 'rabbit', 'hot dog', 'elephant', 'zebra']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict = ['horse', 'cat', 'dog', 'giraffe', 'cow', 'dog poop', 'sheep', 'rabbit', 'hot dog', 'elephant']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict relation = ['is a', 'has property', 'related to', 'belong to', 'has a', 'capable of', 'important', 'part of', 'independent', 'visible', 'trustworthy', 'animal class', 'sweet', 'dangerous', 'cool']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict fact = ['friendly animal', 'cute smart furry animal', 'be very good companion']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - suppord fact predict = ['friendly animal-is a', 'cute smart furry animal-is a', 'be very good companion-capable of']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - correspond target = ['cat', 'horse']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - test id = 1896, question = what object in this image sometimes has fish in it?, img = ILSVRC2012_test_00003117.JPEG\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - real suppord fact in dataset=['sea', 'related to', 'hold fish'], real answer = sea\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - normal model predict = ['sand', 'boat', 'fish', 'water', 'blue', 'snake', 'beach', 'lake', 'shore boat', 'lot of sand']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict = ['turtle', 'airplane', 'box', 'sand', 'boat', 'fish', 'water', 'blue', 'snake', 'beach']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict relation = ['has a', 'related to', 'used for', 'has property', 'at location', 'part of', 'belong to', 'capable of', 'light', 'large', 'specific', 'surface', 'small', 'receives action', 'good']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict fact = ['hide in it shell', 'put thing in', 'in sky']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - suppord fact predict = ['hide in it shell-capable of', 'in sky-at location', 'put thing in-used for']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - correspond target = ['box', 'turtle', 'airplane']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - test id = 1664, question = Where does the place in this image can be found in?, img = COCO_val2014_000000133042.jpg\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - real suppord fact in dataset=['baseball field', 'at location', 'shape of diamond'], real answer = baseball field\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - normal model predict = ['baseball', 'play baseball', 'baseball field', 'baseball bat', 'play baseball on it', 'play game of baseball', 'baseball glove', 'soccer ball', 'rugby ball', 'play basketball']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict = ['horse', 'chair', 'couch', 'sofa', 'baseball', 'play baseball', 'baseball field', 'baseball bat', 'play baseball on it', 'play game of baseball']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict relation = ['at location', 'used for', 'capable of', 'related to', 'specific', 'belong to', 'part of', 'has property', 'surface', 'important', 'convenient', 'human', 'active', 'animal family', 'has a']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict fact = ['countryside', 'sit in', 'armchair']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - suppord fact predict = ['sit in-used for', 'armchair-related to', 'countryside-at location']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - correspond target = ['couch', 'sofa', 'chair', 'horse']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - test id = 1368, question = What thing is less independent than the object in the centre of this image?, img = COCO_val2014_000000000599.jpg\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - real suppord fact in dataset=['cat', 'independent', 'dog'], real answer = dog\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - normal model predict = ['cat', 'mouse', 'human', 'kitten', 'animal', 'monitor', 'mammal', 'laboratory', 'home office', 'computer']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict = ['cat', 'human', 'mammal', 'mouse', 'kitten', 'animal', 'monitor', 'laboratory', 'home office', 'computer']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict relation = ['safe', 'good', 'healthy', 'fast', 'cheap', 'capable of', 'reliable', 'sensible', 'stable', 'animal class', 'expensive', 'efficient', 'dependable', 'tough', 'clean']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict fact = ['dog', 'otter', 'this dog']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - suppord fact predict = ['dog-sensible', 'dog-clean', 'dog-good', 'otter-animal class']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - correspond target = ['mammal', 'cat', 'human']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - test id = 1779, question = Which object in this image is used for strumming?, img = ILSVRC2012_test_00001251.JPEG\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - real suppord fact in dataset=['banjo', 'used for', 'strum'], real answer = banjo\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - normal model predict = ['guitar', 'drum', 'saxophone', 'banjo', 'music studio', 'piano', 'microphone', 'violin', 'trombone', 'cello']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict = ['guitar', 'saxophone', 'trombone', 'trumpet', 'mouse', 'banana', 'person', 'train', 'drum', 'banjo']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict relation = ['used for', 'related to', 'belong to', 'specific', 'important', 'effective', 'common', 'easy', 'capable of', 'accurate', 'efficient', 'good', 'popular', 'has property', 'receives action']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict fact = ['a', 'jazz', 'make list']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - suppord fact predict = ['make list-capable of', 'a-related to', 'jazz-used for', 'jazz-belong to']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - correspond target = ['banana', 'train', 'mouse', 'trumpet', 'person', 'guitar', 'trombone', 'saxophone']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - test id = 455, question = Where can the object in the middle of this image be found?, img = COCO_val2014_000000024195.jpg\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - real suppord fact in dataset=['bus', 'at location', 'street'], real answer = street\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - normal model predict = ['bus', 'taxi', 'tourist', 'hotel room', 'city', 'bakery', 'airport', 'hot room', 'road', 'travel']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict = ['airport', 'travel', 'wild', 'bottle', 'fly', 'bowl', 'plate', 'airplane', 'feather', 'kite']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict relation = ['at location', 'related to', 'has property', 'used for', 'belong to', 'part of', 'has a', 'important', 'specific', 'is a', 'long', 'animal order', 'common', 'desires', 'good']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict fact = ['airplane', 'bird', 'kitchenware']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - suppord fact predict = ['kitchenware-belong to', 'bird-at location', 'airplane-used for', 'bird-related to', 'bird-has a', 'bird-is a', 'airplane-at location']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - correspond target = ['airplane', 'fly', 'feather', 'wild', 'bottle', 'plate', 'bowl', 'travel', 'kite', 'airport']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - test id = 2534, question = Who run faster? human or the animal in the image?, img = COCO_val2014_000000127955.jpg\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - real suppord fact in dataset=['bear', 'fast', 'human'], real answer = bear\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - normal model predict = ['human', 'animal', 'police', 'mammal', 'even toed ungulate', 'wild', 'zoo', 'elephant', 'desert', 'mountainous area']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict = ['human', 'cat', 'hair', 'shell', 'animal', 'police', 'mammal', 'even toed ungulate', 'wild', 'zoo']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict relation = ['fast', 'good', 'capable of', 'great', 'slow', 'important', 'stable', 'impassable', 'long', 'easy', 'has a', 'high', 'strong', 'safe', 'clean']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict fact = ['dog', 'fox', 'turtle']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - suppord fact predict = ['dog-has a', 'turtle-has a', 'dog-good', 'dog-clean']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - correspond target = ['hair', 'shell', 'cat', 'human']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - test id = 2200, question = Which object in this image is clearly more complex than a car?, img = ILSVRC2012_test_00000705.JPEG\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - real suppord fact in dataset=['computer', 'complex', 'car'], real answer = computer\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - normal model predict = ['laptop', 'keyboard', 'computer', 'mouse', 'monitor', 'ipod', 'printer', 'ram', 'window', 'ship']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict = ['laptop', 'truck', 'airplane', 'motorcycle', 'train', 'keyboard', 'computer', 'mouse', 'monitor', 'ipod']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict relation = ['prevalent', 'related to', 'dangerous', 'important', 'visible', 'common', 'expensive', 'blind', 'low', 'safe', 'efficient', 'specific', 'reliable', 'green', 'cheap']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict fact = ['car', 'automobile', 'stop car']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - suppord fact predict = ['car-dangerous', 'automobile-blind', 'car-visible', 'car-safe', 'automobile-safe', 'automobile-dangerous', 'car-efficient', 'car-expensive']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - correspond target = ['airplane', 'laptop', 'truck', 'motorcycle', 'train']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - test id = 2169, question = Which animal in this image is good to teach?, img = COCO_val2014_000000139140.jpg\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - real suppord fact in dataset=['horse', 'is a', 'good aniamls to teach'], real answer = horse\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - normal model predict = ['horse', 'dog', 'giraffe', 'elephant', 'cow', 'cattle', 'dog poop', 'hot dog', 'monkey', 'person']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict = ['dog', 'cart', 'horse', 'giraffe', 'elephant', 'cow', 'cattle', 'dog poop', 'hot dog', 'monkey']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict relation = ['is a', 'has property', 'related to', 'capable of', 'belong to', 'important', 'has a', 'used for', 'desires', 'part of', 'independent', 'specific', 'at location', 'dangerous', 'receives action']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict fact = ['follow it master', 'follow horse', 'please it master']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - suppord fact predict = ['follow horse-capable of', 'please it master-capable of', 'follow it master-capable of']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - correspond target = ['cart', 'dog']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - test id = 2744, question = What is the place in this image capable of?, img = COCO_val2014_000000001268.jpg\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - real suppord fact in dataset=['bridge', 'capable of', 'cross river'], real answer = cross river\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - normal model predict = ['shore boat', 'boat', 'sail boat', 'river', 'lake', 'railroad track', 'move', 'coast', 'cross river', 'ship']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict = ['shore boat', 'boat', 'cat', 'banana', 'sail boat', 'river', 'lake', 'railroad track', 'move', 'coast']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict relation = ['capable of', 'used for', 'high', 'effective', 'has a', 'fast', 'efficient', 'is a', 'accurate', 'at location', 'has property', 'intelligent', 'good', 'stable', 'specific']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - our model predict fact = ['dock', 'a', 'purr']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - suppord fact predict = ['purr-capable of', 'a-is a', 'dock-capable of', 'dock-at location']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - correspond target = ['banana', 'shore boat', 'cat', 'boat']\n",
      "INFO - 08/13/22 23:30:47 - 0:01:06 - #################################################################################\n",
      " 55%|███████████████████████▋                   | 49/89 [00:33<00:29,  1.38it/s]INFO - 08/13/22 23:30:48 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:48 - 0:01:06 - test id = 597, question = which object in this image belongs to the category 'baked goods'?, img = ILSVRC2012_test_00002238.JPEG\n",
      "INFO - 08/13/22 23:30:48 - 0:01:06 - real suppord fact in dataset=['bagel', 'belong to', 'baked goods'], real answer = bagel\n",
      "INFO - 08/13/22 23:30:48 - 0:01:06 - normal model predict = ['donut', 'doughnut', 'pretzel', 'bagel', 'chocolate', 'bread', 'sandwich', 'unhealthy', 'eat', 'ice']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:06 - our model predict = ['donut', 'pretzel', 'hamburger', 'fig', 'fruit', 'pizza', 'grass', 'banana', 'hot dog', 'hotdog']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:06 - our model predict relation = ['belong to', 'desires', 'loyal', 'animal kingdom', 'animal phylum', 'trustworthy', 'animal order', 'related to', 'is a', 'important', 'sensible', 'comfortable', 'animal family', 'protected', 'visible']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:06 - our model predict fact = ['food truck', 'food', 'cow food']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:06 - suppord fact predict = ['food-is a', 'food truck-belong to', 'cow food-related to', 'food-belong to']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:06 - correspond target = ['grass', 'hotdog', 'fig', 'hamburger', 'hot dog', 'banana', 'pizza', 'pretzel', 'donut', 'fruit']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:48 - 0:01:06 - #################################################################################\n",
      "INFO - 08/13/22 23:30:48 - 0:01:06 - test id = 1349, question = which object in this image can fly, img = ILSVRC2012_test_00049970.JPEG\n",
      "INFO - 08/13/22 23:30:48 - 0:01:06 - real suppord fact in dataset=['bird', 'related to', 'fly'], real answer = bird\n",
      "INFO - 08/13/22 23:30:48 - 0:01:06 - normal model predict = ['monkey', 'person', 'snake', 'make person happy', 'elephant', 'bird', 'lizard', 'horse', 'hippopotamus', 'giraffe']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:06 - our model predict = ['frog', 'whale', 'computer', 'monkey', 'person', 'snake', 'make person happy', 'elephant', 'bird', 'lizard']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:06 - our model predict relation = ['capable of', 'has a', 'has property', 'related to', 'used for', 'is a', 'long', 'high', 'visible', 'fast', 'easy', 'stable', 'part of', 'surface', 'important']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:06 - our model predict fact = ['moby dick', 'transcribe', 'croak']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - suppord fact predict = ['croak-related to', 'moby dick-related to', 'transcribe-related to']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - correspond target = ['whale', 'frog', 'computer']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - test id = 605, question = What object in this image is a type of sports equipment?, img = COCO_val2014_000000100238.jpg\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - real suppord fact in dataset=['flying disc', 'belong to', 'frisbee'], real answer = frisbee\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - normal model predict = ['surfboard', 'skateboard', 'frisbee', 'bicycle', 'camera', 'golfcart', 'cell phone', 'racket', 'donut', 'racquet']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - our model predict = ['surfboard', 'skateboard', 'bicycle', 'racket', 'punching bag', 'snowboard', 'golf ball', 'tennis racket', 'balance beam', 'ski']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - our model predict relation = ['belong to', 'is a', 'related to', 'has a', 'capable of', 'important', 'has property', 'at location', 'animal order', 'part of', 'easy', 'used for', 'receives action', 'specific', 'desires']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - our model predict fact = ['sports equipment', 'sport equipment', 'piece of sport equipment']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - suppord fact predict = ['sport equipment-is a', 'sports equipment-belong to']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - correspond target = ['golf ball', 'balance beam', 'ski', 'skateboard', 'surfboard', 'bicycle', 'snowboard', 'tennis racket', 'racket', 'punching bag']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - test id = 1027, question = what object is used for playing in this image?, img = COCO_val2014_000000001987.jpg\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - real suppord fact in dataset=['frisbee', 'used for', 'play'], real answer = frisbee\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - normal model predict = ['kite', 'frisbee', 'golf ball', 'tennis ball', 'surfboard', 'ball', 'soccer ball', 'ping pong ball', 'tennis racket', 'rugby ball']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - our model predict = ['person', 'snake', 'harp', 'kite', 'frisbee', 'golf ball', 'tennis ball', 'surfboard', 'ball', 'soccer ball']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - our model predict relation = ['used for', 'belong to', 'related to', 'capable of', 'has property', 'easy', 'specific', 'strong', 'is a', 'good', 'important', 'safe', 'fast', 'effective', 'at location']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - our model predict fact = ['hard to play', 'analyze character in play', 'live in']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - suppord fact predict = ['hard to play-has property', 'live in-used for', 'analyze character in play-capable of']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - correspond target = ['harp', 'snake', 'person']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - test id = 2272, question = Which vegetable in the image can be found around old trees?, img = COCO_val2014_000000016848.jpg\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - real suppord fact in dataset=['mushroom', 'at location', 'old tree'], real answer = mushroom\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - normal model predict = ['broccoli', 'carrot', 'tomato', 'mushroom', 'artichoke', 'zucchini', 'cucumber', 'pineapple', 'lettuce', 'salad']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - our model predict = ['broccoli', 'tree', 'fig', 'flowers', 'carrot', 'tomato', 'mushroom', 'artichoke', 'zucchini', 'cucumber']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - our model predict relation = ['at location', 'used for', 'related to', 'created by', 'is a', 'belong to', 'easy', 'convenient', 'specific', 'red', 'good', 'visible', 'part of', 'cool', 'popular']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - our model predict fact = ['garden plants', 'garden', 'hang from tree']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - suppord fact predict = ['garden-at location', 'garden plants-belong to']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - correspond target = ['broccoli', 'tree', 'fig', 'flowers']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:48 - 0:01:07 - test id = 6, question = What is this place used for?, img = COCO_val2014_000000100187.jpg\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - real suppord fact in dataset=['hotel room', 'used for', 'temporary residence'], real answer = temporary residence\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - normal model predict = ['sleep', 'couch', 'sleep away from home', 'bed', 'sofa', 'bedroom', 'baby bed', 'pillows', 'living room', 'lay on']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - our model predict = ['sleep', 'couch', 'bed', 'pillows', 'furniture', 'house', 'chair', 'human', 'wall', 'bookshelf']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - our model predict relation = ['used for', 'capable of', 'related to', 'at location', 'belong to', 'effective', 'good', 'high', 'efficient', 'specific', 'receives action', 'part of', 'great', 'easy', 'convenient']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - our model predict fact = ['room', 'bedroom', 'dorm room']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - suppord fact predict = ['bedroom-at location', 'bedroom-used for', 'bedroom-capable of', 'bedroom-related to', 'room-at location']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - correspond target = ['wall', 'sleep', 'house', 'furniture', 'bookshelf', 'pillows', 'couch', 'chair', 'human', 'bed']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - test id = 2597, question = Which food is related to bake good?, img = COCO_val2014_000000009270.jpg\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - real suppord fact in dataset=['cake', 'related to', 'bake good'], real answer = cake\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - normal model predict = ['cake', 'spoon', 'oven', 'pizza', 'person', 'kitchen utensil', 'microwave', 'cup', 'sandwich', 'hotdog']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - our model predict = ['oven', 'bread', 'wedding', 'kitchen', 'flour', 'bakery', 'cheese', 'ice', 'ye', 'italian']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - our model predict relation = ['related to', 'belong to', 'specific', 'used for', 'desires', 'important', 'has property', 'capable of', 'at location', 'part of', 'common', 'animal order', 'social', 'accurate', 'acid']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - our model predict fact = ['cake', 'pizza', 'bake cake']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - suppord fact predict = ['cake-part of', 'cake-at location', 'bake cake-used for', 'pizza-related to', 'cake-related to', 'pizza-has property', 'pizza-at location', 'pizza-belong to']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - correspond target = ['cheese', 'flour', 'oven', 'wedding', 'bread', 'kitchen', 'ice', 'ye', 'italian', 'bakery']\n",
      "INFO - 08/13/22 23:30:48 - 0:01:07 - #################################################################################\n",
      " 56%|████████████████████████▏                  | 50/89 [00:34<00:30,  1.29it/s]INFO - 08/13/22 23:30:49 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - test id = 1301, question = Which animal in this image is called 'slow mover', img = ILSVRC2012_test_00034257.JPEG\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - real suppord fact in dataset=['turtle', 'related to', 'slow mover'], real answer = turtle\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - normal model predict = ['turtle', 'frog', 'armadillo', 'elephant', 'lizard', 'giraffe', 'monkey', 'snake', 'otter', 'jellyfish']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict = ['elephant', 'ray', 'trombone', 'turtle', 'frog', 'armadillo', 'lizard', 'giraffe', 'monkey', 'snake']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict relation = ['is a', 'has property', 'related to', 'has a', 'belong to', 'part of', 'receives action', 'important', 'used for', 'capable of', 'dangerous', 'specific', 'independent', 'good', 'easy']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict fact = ['batoidea', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - suppord fact predict = ['batoidea-belong to', 'therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - correspond target = ['trombone', 'ray', 'elephant']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - test id = 46, question = Which object in this image is related to lignify?, img = ILSVRC2012_test_00054961.JPEG\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - real suppord fact in dataset=['lignify', 'related to', 'wood'], real answer = wood\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - normal model predict = ['station', 'microwave', 'bed', 'toilet', 'sound control room', 'room', 'drum', 'wash machine', 'beam', 'use toilet']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict = ['bed', 'scissors', 'baby bed', 'guitar', 'sofa', 'cat', 'station', 'microwave', 'toilet', 'sound control room']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict relation = ['related to', 'specific', 'belong to', 'used for', 'important', 'common', 'animal order', 'part of', 'at location', 'social', 'has property', 'accurate', 'has a', 'is a', 'prevalent']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict fact = ['sew', 'luthier', 'sleep']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - suppord fact predict = ['sleep-used for', 'luthier-related to', 'sleep-related to', 'sleep-belong to', 'sew-belong to', 'sleep-at location']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - correspond target = ['sofa', 'baby bed', 'cat', 'guitar', 'scissors', 'bed']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - test id = 1752, question = Which object in this image belongs to a human being?, img = COCO_val2014_000000104176.jpg\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - real suppord fact in dataset=['all live human', 'has a', 'head'], real answer = head\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - normal model predict = ['person', 'hair', 'harmonica', 'snake', 'screwdriver', 'hand', 'drink', 'grass', 'thing', 'cat']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict = ['person', 'dog', 'bicycle', 'child', 'computer', 'hair', 'harmonica', 'snake', 'screwdriver', 'hand']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict relation = ['is a', 'belong to', 'has property', 'has a', 'capable of', 'at location', 'desires', 'part of', 'related to', 'important', 'used for', 'good', 'receives action', 'trustworthy', 'independent']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict fact = ['human', 'human being', 'human power']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - suppord fact predict = ['human-belong to', 'human-trustworthy', 'human power-has property', 'human-related to', 'human-good']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - correspond target = ['child', 'dog', 'computer', 'bicycle', 'person']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - test id = 2655, question = Which thing in this picture is a cultivar?, img = COCO_val2014_000000003501.jpg\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - real suppord fact in dataset=['broccoli', 'belong to', 'cultivars'], real answer = broccoli\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - normal model predict = ['broccoli', 'pizza', 'cheese', 'strawberry', 'italian', 'chocolate', 'pomegranate', 'zucchini', 'artichoke', 'salad']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict = ['strawberry', 'pomegranate', 'pineapple', 'lemon', 'fruit', 'banana', 'apple', 'orange', 'camel', 'giraffe']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict relation = ['is a', 'related to', 'has property', 'used for', 'belong to', 'easy', 'good', 'important', 'cool', 'has a', 'sweet', 'convenient', 'safe', 'at location', 'accurate']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict fact = ['fruit', 'round fruit', 'ruminant']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - suppord fact predict = ['round fruit-related to', 'fruit-belong to', 'fruit-related to', 'fruit-is a', 'ruminant-is a']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - correspond target = ['apple', 'strawberry', 'camel', 'pineapple', 'pomegranate', 'orange', 'banana', 'lemon', 'giraffe', 'fruit']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - test id = 1760, question = What in this image is most closely related to tabbouleh?, img = ILSVRC2012_test_00003523.JPEG\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - real suppord fact in dataset=['tabbouleh', 'related to', 'salad'], real answer = salad\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - normal model predict = ['carrot', 'broccoli', 'cheese', 'vegetable', 'pomegranate', 'salad', 'cucumber', 'mushroom', 'artichoke', 'tomato']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict = ['pomegranate', 'mushroom', 'wine', 'carrot', 'broccoli', 'cheese', 'vegetable', 'salad', 'cucumber', 'artichoke']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict relation = ['related to', 'used for', 'specific', 'belong to', 'important', 'is a', 'common', 'at location', 'part of', 'good', 'accurate', 'social', 'animal order', 'receives action', 'easy']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict fact = ['grenadine', 'prosecco', 'toadstool']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - suppord fact predict = ['prosecco-related to', 'toadstool-related to', 'grenadine-related to']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - correspond target = ['wine', 'mushroom', 'pomegranate']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - test id = 1553, question = which action in this image makes player feel more pressure than fun, img = COCO_val2014_000000015596.jpg\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - real suppord fact in dataset=['racing', 'stressful', 'fun'], real answer = racing\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - normal model predict = ['car', 'motorcycle', 'person', 'helmet', 'baseball', 'truck', 'vehicle', 'baseball glove', 'driving', 'stop sign']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict = ['dog', 'car', 'motorcycle', 'person', 'helmet', 'baseball', 'truck', 'vehicle', 'baseball glove', 'driving']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict relation = ['frequent', 'long', 'heavy', 'vulnerable', 'prevalent', 'strong', 'stable', 'low', 'high', 'tough', 'aggressive', 'slow', 'maneuverable', 'important', 'weak']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict fact = ['man', 'human', 'policeman']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - suppord fact predict = ['human-long']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - correspond target = ['dog']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - test id = 2362, question = What human powered transportation device is seen in this image?, img = COCO_val2014_000000120745.jpg\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - real suppord fact in dataset=['bicycle', 'is a', 'human power transport'], real answer = bicycle\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - normal model predict = ['bicycle', 'surfboard', 'skateboard', 'dog', 'horse', 'hot dog', 'street', 'motorcycle', 'cat', 'dog poop']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict = ['horse', 'unicycle', 'boat', 'bicycle', 'surfboard', 'skateboard', 'dog', 'hot dog', 'street', 'motorcycle']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict relation = ['is a', 'belong to', 'has property', 'has a', 'popular', 'related to', 'strong', 'part of', 'capable of', 'important', 'cool', 'easy', 'convenient', 'good', 'fast']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict fact = ['mode of transportation', 'inefficent mode of transportation', 'user power device']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - suppord fact predict = ['inefficent mode of transportation-is a', 'user power device-is a', 'mode of transportation-is a']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - correspond target = ['boat', 'unicycle', 'horse']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - #################################################################################\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - test id = 1873, question = what is weapon in the image?, img = ILSVRC2012_test_00034423.JPEG\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - real suppord fact in dataset=['bow', 'related to', 'weapon'], real answer = bow\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - normal model predict = ['person', 'frisbee', 'dog', 'tennis ball', 'golf ball', 'grass', 'baseball bat', 'kite', 'ball', 'horse']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict = ['person', 'dog', 'stop sign', 'frisbee', 'tennis ball', 'golf ball', 'grass', 'baseball bat', 'kite', 'ball']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict relation = ['capable of', 'is a', 'part of', 'has a', 'related to', 'used for', 'important', 'at location', 'good', 'animal order', 'fast', 'belong to', 'animal family', 'has property', 'animal class']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - our model predict fact = ['growl', 'traffic sign', 'village']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - suppord fact predict = ['village-at location', 'traffic sign-belong to', 'growl-capable of']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - correspond target = ['stop sign', 'person', 'dog']\n",
      "INFO - 08/13/22 23:30:49 - 0:01:07 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████▋                  | 51/89 [00:34<00:27,  1.40it/s]INFO - 08/13/22 23:30:50 - 0:01:08 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - test id = 1220, question = What thing does the animal in this image have as a part?, img = COCO_val2014_000000010822.jpg\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - real suppord fact in dataset=['zebra', 'has a', 'stripe'], real answer = stripe\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - normal model predict = ['zebra', 'stripe', 'blue', 'long necked', 'cloud', 'bikini', 'giraffe', 'jazz blue', 'camel', 'ocean']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - our model predict = ['long necked', 'africa', 'animal', 'giraffidae', 'tree', 'skunk', 'even toed ungulate', 'dog', 'zoo', 'squirrel']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - our model predict relation = ['has a', 'part of', 'is a', 'related to', 'animal family', 'animal order', 'large', 'receives action', 'small', 'has property', 'capable of', 'social', 'used for', 'animal kingdom', 'at location']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - our model predict fact = ['giraffe', 'wolf', 'forest']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - suppord fact predict = ['giraffe-animal family', 'giraffe-animal order', 'giraffe-receives action', 'wolf-related to', 'forest-part of', 'forest-at location', 'giraffe-has property', 'giraffe-at location']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - correspond target = ['giraffidae', 'tree', 'animal', 'dog', 'zoo', 'squirrel', 'skunk', 'even toed ungulate', 'long necked', 'africa']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - test id = 76, question = Which object in this image is made of brass?, img = ILSVRC2012_test_00027806.JPEG\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - real suppord fact in dataset=['french horn', 'related to', 'brass'], real answer = french horn\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - normal model predict = ['french horn', 'trumpet', 'trombone', 'saxophone', 'clarinet', 'flute', 'bell', 'violin', 'banjo', 'harp']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - our model predict = ['saxophone', 'tree', 'book', 'french horn', 'trumpet', 'trombone', 'clarinet', 'flute', 'bell', 'violin']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - our model predict relation = ['has property', 'is a', 'belong to', 'used for', 'has a', 'at location', 'related to', 'receives action', 'created by', 'part of', 'desires', 'capable of', 'animal class', 'animal order', 'common']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - our model predict fact = ['make out of brass', 'make of wood', 'make of paper']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - suppord fact predict = ['make of wood-has property', 'make out of brass-has property', 'make of paper-has property']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - correspond target = ['tree', 'book', 'saxophone']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - test id = 1273, question = What in this image belongs to the category Industries?, img = ILSVRC2012_test_00053268.JPEG\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - real suppord fact in dataset=['truck', 'belong to', 'industry'], real answer = truck\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - normal model predict = ['motorcycle', 'truck', 'car', 'police', 'child', 'buy and sell', 'vehicle', 'gift shop', 'travel in car', 'build']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - our model predict = ['motorcycle', 'child', 'elephant', 'trombone', 'truck', 'car', 'police', 'buy and sell', 'vehicle', 'gift shop']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - our model predict relation = ['belong to', 'desires', 'is a', 'animal order', 'related to', 'animal kingdom', 'animal phylum', 'capable of', 'loyal', 'trustworthy', 'human', 'animal family', 'important', 'sensible', 'animal class']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - our model predict fact = ['subculture', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - suppord fact predict = ['subculture-belong to', 'therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - correspond target = ['trombone', 'motorcycle', 'elephant', 'child']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - test id = 1178, question = What object in this image is used by a tromboner?, img = ILSVRC2012_test_00000499.JPEG\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - real suppord fact in dataset=['tromboner', 'related to', 'trombone'], real answer = trombone\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - normal model predict = ['trumpet', 'flute', 'clarinet', 'saxophone', 'trombone', 'violin', 'cello', 'accordion', 'piano', 'harp']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - our model predict = ['trumpet', 'violin', 'piano', 'flute', 'clarinet', 'saxophone', 'trombone', 'cello', 'accordion', 'harp']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - our model predict relation = ['part of', 'receives action', 'related to', 'created by', 'used for', 'belong to', 'is a', 'has a', 'has property', 'capable of', 'at location', 'specific', 'animal order', 'important', 'social']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - our model predict fact = ['pianist', 'violinist', 'musician']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - suppord fact predict = ['musician-related to', 'violinist-related to', 'pianist-related to']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - correspond target = ['violin', 'piano', 'trumpet']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:08 - #################################################################################\n",
      " 58%|█████████████████████████                  | 52/89 [00:35<00:26,  1.40it/s]INFO - 08/13/22 23:30:50 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - test id = 2564, question = What in this image could be used for holding cereal?, img = ILSVRC2012_test_00027426.JPEG\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - real suppord fact in dataset=['bowl', 'used for', 'cereal'], real answer = bowl\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - normal model predict = ['bowl', 'spoon', 'basket', 'cup', 'vase', 'sink', 'dishes', 'cake', 'rice cooker', 'large container']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict = ['basket', 'cup', 'fork', 'bowl', 'spoon', 'vase', 'sink', 'dishes', 'cake', 'rice cooker']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict relation = ['used for', 'related to', 'at location', 'belong to', 'capable of', 'receives action', 'specific', 'accurate', 'good', 'effective', 'animal order', 'has property', 'easy', 'fast', 'is a']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict fact = ['hold coffee', 'hold bread', 'hold food']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - suppord fact predict = ['hold food-used for', 'hold bread-used for', 'hold coffee-capable of', 'hold coffee-used for']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - correspond target = ['cup', 'fork', 'basket']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - test id = 322, question = what in this image is thicker than door?, img = ILSVRC2012_test_00002037.JPEG\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - real suppord fact in dataset=['water', 'thick', 'door'], real answer = water\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - normal model predict = ['boat', 'sand', 'shore boat', 'big', 'water', 'sail boat', 'store boat', 'lot of sand', 'work for day without water', 'blue']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict = ['car', 'boat', 'sand', 'shore boat', 'big', 'water', 'sail boat', 'store boat', 'lot of sand', 'work for day without water']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict relation = ['light', 'stable', 'has a', 'low', 'clean', 'high', 'compact', 'long', 'good', 'large', 'solar', 'strong', 'efficient', 'fast', 'heavy']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict fact = ['door', 'windshield', 'lift']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - suppord fact predict = ['door-has a']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - correspond target = ['car']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:50 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - test id = 304, question = What object in this image is used for food?, img = COCO_val2014_000000142500.jpg\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - real suppord fact in dataset=['broccoli', 'belong to', 'food and drink'], real answer = broccoli\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - normal model predict = ['broccoli', 'vegetable', 'fry bread', 'lettuce', 'zucchini', 'fork', 'tomato', 'cheese', 'bread', 'fruit']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict = ['vegetable', 'fork', 'fruit', 'salad', 'pretzel', 'cake', 'pizza', 'fig', 'banana', 'donut']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict relation = ['used for', 'belong to', 'at location', 'related to', 'easy', 'has property', 'expensive', 'good', 'effective', 'specific', 'convenient', 'capable of', 'safe', 'efficient', 'receives action']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict fact = ['food', 'eat food', 'hold food']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - suppord fact predict = ['hold food-used for', 'food-related to', 'eat food-related to', 'food-belong to', 'eat food-used for']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - correspond target = ['cake', 'fig', 'salad', 'banana', 'pizza', 'pretzel', 'donut', 'vegetable', 'fork', 'fruit']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - test id = 1345, question = What thing does the place shown in this image have as a part?, img = COCO_val2014_000000020395.jpg\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - real suppord fact in dataset=['harbor', 'has a', 'boat'], real answer = boat\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - normal model predict = ['beach', 'boat', 'water', 'shore boat', 'sea', 'sail boat', 'ocean', 'umbrella', 'cloud', 'travel across water']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict = ['beach', 'water', 'cloud', 'swimming', 'mountainous area', 'fish', 'kite', 'boat', 'shore boat', 'sea']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict relation = ['has a', 'part of', 'large', 'small', 'is a', 'capable of', 'related to', 'animal family', 'receives action', 'at location', 'big', 'social', 'used for', 'animal order', 'great']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict fact = ['lot of sand', 'sky', 'river']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - suppord fact predict = ['sky-at location', 'lot of sand-has a', 'sky-related to', 'river-has a', 'sky-part of', 'river-at location', 'river-used for']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - correspond target = ['mountainous area', 'swimming', 'water', 'kite', 'beach', 'cloud', 'fish']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - test id = 1223, question = Which object in this image is a sphere?, img = COCO_val2014_000000138180.jpg\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - real suppord fact in dataset=['tennis ball', 'is a', 'sphere'], real answer = tennis ball\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - normal model predict = ['tennis ball', 'tennis racket', 'tennis', 'golf ball', 'soccer ball', 'frisbee', 'volleyball', 'play tennis', 'ping pong ball', 'racket']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict = ['play baseball', 'play game of baseball', 'play baseball on it', 'unicycle', 'play', 'green', 'camel', 'giraffe', 'tennis ball', 'tennis racket']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict relation = ['is a', 'related to', 'belong to', 'has property', 'part of', 'important', 'capable of', 'cool', 'has a', 'used for', 'sensible', 'desires', 'visible', 'specific', 'trustworthy']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict fact = ['ruminant', 'baseball field', 'one wheel']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - suppord fact predict = ['ruminant-is a', 'baseball field-used for', 'baseball field-has property', 'one wheel-has a']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - correspond target = ['camel', 'green', 'giraffe', 'unicycle', 'play', 'play baseball on it', 'play baseball', 'play game of baseball']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - test id = 2063, question = Which object in this image can have a virus, img = COCO_val2014_000000137573.jpg\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - real suppord fact in dataset=['computer', 'has a', 'virus'], real answer = computer\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - normal model predict = ['butterfly', 'clock', 'person', 'umbrella', 'computer', 'string', 'guitar', 'laptop', 'piano', 'keyboard']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict = ['person', 'cat', 'butterfly', 'clock', 'umbrella', 'computer', 'string', 'guitar', 'laptop', 'piano']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict relation = ['related to', 'has a', 'capable of', 'part of', 'used for', 'specific', 'is a', 'important', 'common', 'frequent', 'large', 'social', 'has property', 'blind', 'long']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict fact = ['purr', 'meow', 'handwrite']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - suppord fact predict = ['handwrite-related to', 'meow-capable of', 'purr-capable of']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - correspond target = ['cat', 'person']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - test id = 2667, question = Which object in this image contains a key, img = COCO_val2014_000000140122.jpg\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - real suppord fact in dataset=['key', 'part of', 'keyboard'], real answer = keyboard\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - normal model predict = ['laptop', 'computer', 'ram', 'keyboard', 'monitor', 'coffee', 'desk', 'bed', 'clock', 'tv']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict = ['computer', 'tv', 'ipod', 'laptop', 'ram', 'keyboard', 'monitor', 'coffee', 'desk', 'bed']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict relation = ['part of', 'has a', 'related to', 'is a', 'specific', 'used for', 'important', 'social', 'small', 'belong to', 'common', 'capable of', 'large', 'great', 'has property']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - our model predict fact = ['itunes', 'button', 'programmable']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - suppord fact predict = ['itunes-belong to', 'programmable-related to', 'button-part of']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - correspond target = ['ipod', 'tv', 'computer']\n",
      "INFO - 08/13/22 23:30:50 - 0:01:09 - #################################################################################\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:36<00:26,  1.34it/s]INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - test id = 2452, question = Which object in this image can carry few people?, img = COCO_val2014_000000006789.jpg\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - real suppord fact in dataset=['car', 'capable of', 'carry few person'], real answer = car\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - normal model predict = ['railroad track', 'train', 'bus', 'road', 'car', 'track', 'ride', 'person', 'taxi', 'traffic light']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict = ['bus', 'airplane', 'railroad track', 'train', 'road', 'car', 'track', 'ride', 'person', 'taxi']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict relation = ['capable of', 'has a', 'related to', 'used for', 'belong to', 'has property', 'is a', 'at location', 'specific', 'desires', 'visible', 'long', 'part of', 'common', 'surface']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict fact = ['wheel and can transport many person at one time', 'transport person or thing more quickly than by road or rail', 'transport many person at once']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - suppord fact predict = ['wheel and can transport many person at one time-part of', 'transport many person at once-capable of', 'transport person or thing more quickly than by road or rail-used for']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - correspond target = ['bus', 'airplane']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - test id = 2628, question = which object in this image is used by the woman for sport, img = COCO_val2014_000000135361.jpg\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - real suppord fact in dataset=['tennis ball', 'used for', 'sport'], real answer = tennis ball\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - normal model predict = ['kite', 'tennis ball', 'frisbee', 'golf ball', 'person', 'tennis', 'tennis racket', 'jumping', 'volleyball', 'ball']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict = ['dog', 'helmet', 'cat', 'hat', 'kite', 'tennis ball', 'frisbee', 'golf ball', 'person', 'tennis']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict relation = ['used for', 'related to', 'belong to', 'desires', 'is a', 'capable of', 'receives action', 'has property', 'easy', 'hot', 'specific', 'animal order', 'effective', 'popular', 'accurate']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict fact = ['please human', 'protect your head', \"call man's best friend\"]\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - suppord fact predict = [\"call man's best friend-is a\", 'please human-capable of', 'protect your head-used for']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - correspond target = ['dog', 'cat', 'hat', 'helmet']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - test id = 430, question = Which object in this image might be bought by the punnet?, img = COCO_val2014_000000118607.jpg\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - real suppord fact in dataset=['punnet', 'related to', 'strawberry'], real answer = strawberry\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - normal model predict = ['fork', 'carrot', 'bowl', 'salad', 'plate', 'spoon', 'bread', 'cheese', 'cup', 'broccoli']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict = ['carrot', 'salad', 'bread', 'broccoli', 'bell pepper', 'tomato', 'artichoke', 'vegetarian', 'fork', 'bowl']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict relation = ['used for', 'at location', 'has property', 'belong to', 'created by', 'receives action', 'part of', 'related to', 'is a', 'has a', 'specific', 'animal order', 'red', 'good', 'desires']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict fact = ['pastry shop', 'vegetable', 'be sell thing']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - suppord fact predict = ['vegetable-created by', 'vegetable-is a', 'pastry shop-at location', 'vegetable-belong to']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - correspond target = ['bread', 'salad', 'bell pepper', 'broccoli', 'artichoke', 'carrot', 'vegetarian', 'tomato']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - test id = 2635, question = Which object in this image pertains to the category Personal life?, img = ILSVRC2012_test_00002135.JPEG\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - real suppord fact in dataset=['couch', 'belong to', 'sofa'], real answer = sofa\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - normal model predict = ['couch', 'monitor', 'sofa', 'bedroom', 'bed', 'pillows', 'baby bed', 'laptop', 'sleep', 'tv']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict = ['water', 'person', 'potted plant', 'zoo', 'couch', 'monitor', 'sofa', 'bedroom', 'bed', 'pillows']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict relation = ['belong to', 'desires', 'capable of', 'loyal', 'at location', 'is a', 'primitive', 'part of', 'human', 'trustworthy', 'comfortable', 'animal kingdom', 'important', 'animal order', 'visible']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict fact = ['life', 'life and liberty', 'essential part of life']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - suppord fact predict = ['life-at location', 'life-belong to', 'life and liberty-desires', 'essential part of life-is a']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - correspond target = ['water', 'potted plant', 'zoo', 'person']\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - test id = 1383, question = What kind of pet is in this image?, img = ILSVRC2012_test_00002369.JPEG\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - real suppord fact in dataset=['turtle', 'capable of', 'be pet'], real answer = turtle\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - normal model predict = ['turtle', 'jellyfish', 'dolphin', 'goldfish', 'whale', 'zebra', 'butterfly', 'lizard', 'cat', 'beach']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict = ['goldfish', 'cat', 'ant', 'dog', 'person', 'turtle', 'jellyfish', 'dolphin', 'whale', 'zebra']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict relation = ['belong to', 'is a', 'related to', 'at location', 'has property', 'safe', 'good', 'important', 'has a', 'easy', 'animal class', 'receives action', 'protected', 'tough', 'independent']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict fact = ['popular pet', 'pet', 'pet animal']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - suppord fact predict = ['pet-is a', 'pet-belong to', 'popular pet-is a', 'pet animal-related to', 'pet-related to', 'pet animal-has a']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - correspond target = ['cat', 'dog', 'ant', 'person', 'goldfish']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - test id = 1527, question = What clothing is the man in the foreground wearing, img = COCO_val2014_000000009007.jpg\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - real suppord fact in dataset=['shirt', 'belong to', 'clothing'], real answer = shirt\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - normal model predict = ['wine', 'salad', 'pizza', 'wine glass', 'cake', 'dishes', 'lobster', 'plate', 'pineapple', 'carrot']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict = ['cut', 'head', 'pare apple', 'vase', 'wine', 'salad', 'pizza', 'wine glass', 'cake', 'dishes']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict relation = ['is a', 'belong to', 'at location', 'related to', 'has property', 'capable of', 'used for', 'part of', 'receives action', 'important', 'has a', 'good', 'specific', 'easy', 'animal order']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict fact = ['crown', 'urn', 'knife']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - suppord fact predict = ['urn-related to', 'crown-related to', 'knife-used for']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - correspond target = ['vase', 'pare apple', 'head', 'cut']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - test id = 80, question = Why people can be killed by this animal?, img = ILSVRC2012_test_00000165.JPEG\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - real suppord fact in dataset=['snake', 'has property', 'poisonous'], real answer = poisonous\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - normal model predict = ['bird', 'wild', 'tick', 'feather', 'animal', 'snake', 'giraffe', 'long necked', 'armadillo', 'zoo']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict = ['giraffe', 'armadillo', 'dragonfly', 'elephant', 'antelope', 'squirrel', 'whale', 'frog', 'zebra', 'teddy bear']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict relation = ['has a', 'is a', 'belong to', 'receives action', 'used for', 'has property', 'related to', 'capable of', 'part of', 'at location', 'animal order', 'created by', 'independent', 'fast', 'long']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict fact = ['toy animals', 'animal', 'pet animal']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - suppord fact predict = ['toy animals-belong to', 'animal-is a', 'animal-belong to']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - correspond target = ['whale', 'armadillo', 'dragonfly', 'antelope', 'zebra', 'squirrel', 'frog', 'elephant', 'giraffe', 'teddy bear']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - test id = 1164, question = which object in this image is on the top of head, img = ILSVRC2012_test_00031079.JPEG\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - real suppord fact in dataset=['hair', 'has property', 'top of head'], real answer = hair\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - normal model predict = ['child', 'person', 'punching bag', 'make person happy', 'tie', 'tennis ball', 'hand', 'shirt', 'neck brace', 'throw']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict = ['shirt', 'food', 'door', 'child', 'person', 'punching bag', 'make person happy', 'tie', 'tennis ball', 'hand']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict relation = ['has property', 'is a', 'belong to', 'capable of', 'at location', 'related to', 'has a', 'used for', 'part of', 'desires', 'receives action', 'blind', 'important', 'animal order', 'specific']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict fact = ['sociology of culture', 'form of clothe', 'part of wall']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - suppord fact predict = ['form of clothe-is a', 'part of wall-at location', 'sociology of culture-belong to']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - correspond target = ['shirt', 'door', 'food']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - test id = 171, question = Which object in this image has a string, img = ILSVRC2012_test_00001209.JPEG\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - real suppord fact in dataset=['harp', 'has a', 'string'], real answer = harp\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - normal model predict = ['harp', 'piano', 'violin', 'accordion', 'mountain', 'flute', 'guitar', 'harmonica', 'cello', 'cross river']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict = ['saxophone', 'play music', 'tree', 'harp', 'piano', 'violin', 'accordion', 'mountain', 'flute', 'guitar']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict relation = ['related to', 'part of', 'has a', 'is a', 'specific', 'important', 'used for', 'social', 'common', 'at location', 'has property', 'animal order', 'animal family', 'frequent', 'great']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict fact = ['reed', 'harp', 'branch']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - suppord fact predict = ['branch-related to', 'harp-used for', 'reed-related to']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - correspond target = ['tree', 'play music', 'saxophone']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - test id = 2024, question = Which object in this image are dangerous?, img = ILSVRC2012_test_00048011.JPEG\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - real suppord fact in dataset=['axe', 'has property', 'dangerous'], real answer = axe\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - normal model predict = ['hammer', 'scissors', 'screwdriver', 'corkscrew', 'knife', 'wood', 'chain saw', 'ruler', 'metal', 'axe']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict = ['snake', 'clock', 'person', 'flute', 'crutch', 'hammer', 'scissors', 'screwdriver', 'corkscrew', 'knife']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict relation = ['related to', 'used for', 'is a', 'has property', 'capable of', 'has a', 'belong to', 'part of', 'at location', 'specific', 'receives action', 'important', 'dangerous', 'desires', 'common']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict fact = ['be dangerous', 'tick', 'feel pain both physically and emotionally']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - suppord fact predict = ['tick-related to', 'feel pain both physically and emotionally-capable of', 'be dangerous-capable of']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - correspond target = ['clock', 'person', 'crutch', 'flute', 'snake']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - test id = 2619, question = Whether the animal in the image has brain or not?, img = ILSVRC2012_test_00002915.JPEG\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - real suppord fact in dataset=['starfish', 'has a', 'no brain'], real answer = no brain\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - normal model predict = ['shell', 'mountainous area', 'unhealthy', 'big', 'low', 'sandy', 'preventing from getting wet', 'coast', 'beach', 'jellyfish']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict = ['big', 'africa', 'extremely high blood pressure', 'long necked', 'whale', 'even toed ungulate', 'animal', 'four', 'banana', 'zoo']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict relation = ['has a', 'has property', 'related to', 'receives action', 'part of', 'is a', 'light', 'used for', 'at location', 'animal order', 'long', 'belong to', 'independent', 'big', 'specific']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict fact = ['giraffe', 'elephant', 'monkey']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - suppord fact predict = ['elephant-related to', 'giraffe-animal order', 'giraffe-receives action', 'giraffe-has a', 'elephant-has property', 'elephant-big', 'giraffe-has property', 'giraffe-at location', 'elephant-belong to', 'monkey-at location', 'monkey-related to']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - correspond target = ['extremely high blood pressure', 'animal', 'whale', 'zoo', 'banana', 'four', 'even toed ungulate', 'long necked', 'africa', 'big']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - test id = 1684, question = Where are these animals come from? , img = COCO_val2014_000000132814.jpg\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - real suppord fact in dataset=['zebra', 'at location', 'africa'], real answer = africa\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - normal model predict = ['africa', 'zoo', 'animal', 'giraffe', 'wild', 'zebra', 'antelope', 'mountainous area', 'bird', 'tourist']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict = ['horse', 'elephant', 'lizard', 'africa', 'zoo', 'animal', 'giraffe', 'wild', 'zebra', 'antelope']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict relation = ['is a', 'has property', 'at location', 'has a', 'desires', 'belong to', 'receives action', 'related to', 'used for', 'created by', 'capable of', 'visible', 'animal class', 'primitive', 'animal order']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - our model predict fact = ['large animal', 'our large land animal', 'small animal']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - suppord fact predict = ['small animal-is a', 'our large land animal-is a', 'large animal-is a']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - correspond target = ['elephant', 'lizard', 'horse']\r\n",
      "INFO - 08/13/22 23:30:51 - 0:01:09 - #################################################################################\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████                 | 54/89 [00:37<00:26,  1.34it/s]INFO - 08/13/22 23:30:52 - 0:01:10 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - test id = 630, question = What can the object in this image do?, img = ILSVRC2012_test_00045390.JPEG\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - real suppord fact in dataset=['remote', 'capable of', 'control tv'], real answer = control tv\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - normal model predict = ['control', 'drive screw', 'cell phone', 'mouse', 'laboratory', 'wash machine', 'vend stand', 'bakery', 'computer', 'clock']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict = ['computer', 'apple', 'listen to music', 'pen', 'work', 'window', 'monitor', 'keyboard', 'desk', 'tall build']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict relation = ['has property', 'used for', 'capable of', 'has a', 'belong to', 'at location', 'is a', 'related to', 'created by', 'receives action', 'animal order', 'part of', 'specific', 'common', 'good']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict fact = ['office', 'ipod', 'office build']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - suppord fact predict = ['office-used for', 'ipod-belong to', 'office-has a', 'office-at location', 'ipod-used for', 'office build-at location']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - correspond target = ['pen', 'apple', 'desk', 'tall build', 'computer', 'window', 'monitor', 'keyboard', 'work', 'listen to music']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - test id = 1905, question = Which sport is better than the action shown in this image, img = ILSVRC2012_test_00002037.JPEG\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - real suppord fact in dataset=['walking', 'good', 'driving'], real answer = driving\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - normal model predict = ['boat', 'surfboard', 'sail boat', 'fish', 'toys', 'goldfish', 'whale', 'surf board', 'store boat', 'ship']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict = ['blue', 'desert', 'boat', 'surfboard', 'sail boat', 'fish', 'toys', 'goldfish', 'whale', 'surf board']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict relation = ['important', 'impassable', 'light', 'dangerous', 'popular', 'strenuous', 'tough', 'safe', 'visible', 'long', 'prevalent', 'dense', 'has property', 'easy', 'strong']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict fact = ['boat', 'ocean', 'sea']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - suppord fact predict = ['sea-impassable', 'ocean-has property']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - correspond target = ['desert', 'blue']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - test id = 779, question = Which object in this image belongs to the category Botany?, img = COCO_val2014_000000025286.jpg\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - real suppord fact in dataset=['flowers', 'belong to', 'botany'], real answer = flowers\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - normal model predict = ['flowers', 'flower', 'kite', 'fruit', 'butterfly', 'child', 'potted plant', 'dragonfly', 'protect person from sun and rain', 'plant']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict = ['zebra', 'monkey', 'axe', 'flowers', 'flower', 'kite', 'fruit', 'butterfly', 'child', 'potted plant']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict relation = ['belong to', 'desires', 'related to', 'animal phylum', 'animal kingdom', 'is a', 'animal order', 'loyal', 'trustworthy', 'human', 'sensible', 'animal class', 'animal family', 'specific', 'visible']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict fact = ['eukaryote', 'primate', 'forestry occupations']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - suppord fact predict = ['forestry occupations-belong to', 'primate-is a', 'eukaryote-belong to', 'primate-related to']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - correspond target = ['zebra', 'axe', 'monkey']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - test id = 1470, question = What is the class of the animal in the middle of this image?, img = ILSVRC2012_test_00001734.JPEG\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - real suppord fact in dataset=['nail', 'animal class', 'gastropoda'], real answer = gastropoda\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - normal model predict = ['fig', 'tick', 'shell', 'donut', 'ant', 'doughnut', 'turtle', 'human', 'tourist', 'cake']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict = ['africa', 'zoo', 'giraffidae', 'mammal', 'even toed ungulate', 'extremely high blood pressure', 'carnivora', 'green', 'wild', 'long necked']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict relation = ['animal kingdom', 'is a', 'animal class', 'has property', 'animal family', 'animal order', 'belong to', 'at location', 'part of', 'related to', 'safe', 'important', 'common', 'animal phylum', 'has a']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict fact = ['frog', 'giraffe', 'fox']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - suppord fact predict = ['giraffe-animal family', 'giraffe-animal order', 'giraffe-has a', 'fox-animal class', 'giraffe-has property', 'frog-at location', 'giraffe-at location', 'frog-has property', 'fox-animal order']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - correspond target = ['giraffidae', 'extremely high blood pressure', 'wild', 'zoo', 'green', 'even toed ungulate', 'long necked', 'africa', 'mammal', 'carnivora']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - test id = 1, question = Which object in this image has a tail, img = COCO_val2014_000000005599.jpg\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - real suppord fact in dataset=['kite', 'has a', 'tail'], real answer = kite\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - normal model predict = ['jellyfish', 'kite', 'beach', 'surf board', 'butterfly', 'sandy', 'sea', 'sand', 'swimming', 'surfboard']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict = ['bicycle', 'person', 'skateboard', 'airplane', 'car', 'trombone', 'cart', 'jellyfish', 'kite', 'beach']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict relation = ['has a', 'part of', 'related to', 'is a', 'used for', 'specific', 'capable of', 'at location', 'common', 'has property', 'social', 'large', 'important', 'animal order', 'human']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict fact = ['wheel', 'slider', 'blog']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - suppord fact predict = ['wheel-part of', 'blog-capable of', 'wheel-related to', 'slider-related to', 'wheel-has a']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - correspond target = ['airplane', 'skateboard', 'bicycle', 'person', 'car', 'trombone', 'cart']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - test id = 310, question = Normally where can you find the object in the middle?, img = COCO_val2014_000000147338.jpg\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - real suppord fact in dataset=['fire hydrant', 'belong to', 'street'], real answer = street\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - normal model predict = ['airport', 'house', 'toilet', 'bathroom', 'park', 'city', 'kitchen', 'africa', 'fair', 'toilet seat']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict = ['car', 'motorcycle', 'person', 'airport', 'house', 'toilet', 'bathroom', 'park', 'city', 'kitchen']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict relation = ['at location', 'used for', 'related to', 'capable of', 'specific', 'visible', 'belong to', 'has a', 'animal order', 'is a', 'part of', 'has property', 'surface', 'created by', 'human']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict fact = ['head north', 'moto cross', 'train dog']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - suppord fact predict = ['train dog-capable of', 'moto cross-related to', 'head north-capable of']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - correspond target = ['motorcycle', 'person', 'car']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:52 - 0:01:10 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - test id = 760, question = Which object in this image has a keel?, img = ILSVRC2012_test_00001992.JPEG\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - real suppord fact in dataset=['keel', 'related to', 'ship'], real answer = ship\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - normal model predict = ['boat', 'airplane', 'sail boat', 'shore boat', 'plane', 'spaceship', 'taxi', 'truck', 'land airplane', 'ship']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict = ['laptop', 'unicycle', 'tv', 'boat', 'airplane', 'sail boat', 'shore boat', 'plane', 'spaceship', 'taxi']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict relation = ['has a', 'part of', 'related to', 'is a', 'large', 'specific', 'social', 'frequent', 'small', 'used for', 'capable of', 'common', 'heavy', 'long', 'has property']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - our model predict fact = ['touchpad', 'button', 'one wheel']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - suppord fact predict = ['one wheel-has a', 'touchpad-part of', 'button-part of']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - correspond target = ['tv', 'unicycle', 'laptop']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:10 - #################################################################################\n",
      " 62%|██████████████████████████▌                | 55/89 [00:37<00:24,  1.37it/s]INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - test id = 1394, question = Which object in this image pertain the category Human habitats?, img = ILSVRC2012_test_00002135.JPEG\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - real suppord fact in dataset=['sofa', 'belong to', 'human habitats'], real answer = sofa\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - normal model predict = ['couch', 'sofa', 'bed', 'pillows', 'monitor', 'sleep', 'bedroom', 'baby bed', 'tv', 'furniture']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict = ['child', 'dog', 'head', 'person', 'jellyfish', 'couch', 'sofa', 'bed', 'pillows', 'monitor']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict relation = ['belong to', 'desires', 'loyal', 'is a', 'animal phylum', 'animal kingdom', 'related to', 'animal order', 'trustworthy', 'part of', 'important', 'primitive', 'human', 'capable of', 'sensible']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict fact = ['human', 'human being', 'brain']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - suppord fact predict = ['human-belong to', 'human-trustworthy', 'human being-primitive', 'human-related to', 'brain-related to']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - correspond target = ['jellyfish', 'child', 'dog', 'head', 'person']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - test id = 308, question = Which vehicle is faster than the object on the right of this image?, img = COCO_val2014_000000138601.jpg\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - real suppord fact in dataset=['bus', 'slow', 'plane'], real answer = plane\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - normal model predict = ['bus', 'taxi', 'travel', 'airport', 'flight', 'train', 'train station', 'transport', 'cheap', 'track']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict = ['bus', 'flight', 'train', 'cheap', 'truck', 'airplane', 'bicycle', 'motorcycle', 'taxi', 'travel']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict relation = ['is a', 'long', 'cheap', 'fast', 'important', 'common', 'part of', 'small', 'animal kingdom', 'high', 'healthy', 'has a', 'safe', 'low', 'animal order']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict fact = ['train', 'car', 'horse driving']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - suppord fact predict = ['car-long', 'car-high', 'car-safe', 'train-fast', 'train-cheap', 'car-fast', 'car-small']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - correspond target = ['airplane', 'bus', 'truck', 'cheap', 'motorcycle', 'bicycle', 'train', 'flight']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - test id = 2090, question = Which device in the image can be used for playing game?, img = COCO_val2014_000000124601.jpg\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - real suppord fact in dataset=['laptop', 'used for', 'play game'], real answer = laptop\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - normal model predict = ['wii', 'racket', 'racquet', 'ping pong ball', 'tennis racket', 'ping pong', 'violin', 'computer', 'ray', 'guitar']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict = ['racquet', 'guitar', 'piano', 'tennis ball', 'cello', 'frisbee', 'toy', 'saxophone', 'french horn', 'play baseball']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict relation = ['used for', 'belong to', 'related to', 'at location', 'easy', 'convenient', 'capable of', 'specific', 'efficient', 'accurate', 'fast', 'effective', 'has property', 'desires', 'important']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict fact = ['play', 'play game', 'play music']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - suppord fact predict = ['play-related to', 'play music-used for', 'play-belong to', 'play-used for']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - correspond target = ['racquet', 'piano', 'toy', 'french horn', 'frisbee', 'cello', 'guitar', 'play baseball', 'tennis ball', 'saxophone']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - test id = 192, question = what is it in this image is related to shedhand?, img = COCO_val2014_000000003926.jpg\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - real suppord fact in dataset=['shedhand', 'related to', 'sheep'], real answer = sheep\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - normal model predict = ['sheep', 'herd sheep', 'grass', 'cattle', 'otter', 'human', 'mammal', 'ant', 'rabbit', 'flour']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict = ['elephant', 'ray', 'trombone', 'sheep', 'herd sheep', 'grass', 'cattle', 'otter', 'human', 'mammal']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict relation = ['related to', 'belong to', 'specific', 'important', 'used for', 'animal order', 'common', 'at location', 'part of', 'social', 'accurate', 'is a', 'capable of', 'good', 'prevalent']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict fact = ['batoidea', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - suppord fact predict = ['batoidea-belong to', 'therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - correspond target = ['trombone', 'ray', 'elephant']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - test id = 594, question = What is one prominent architectural element pictured here?, img = COCO_val2014_000000100848.jpg\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - real suppord fact in dataset=['window', 'belong to', 'architectural elements'], real answer = window\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - normal model predict = ['couch', 'wall', 'bedroom', 'sleep', 'bed', 'monitor', 'shelf', 'sofa', 'baby bed', 'living room']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict = ['couch', 'wall', 'lamp', 'house', 'furniture', 'chair', 'human', 'person', 'bedroom', 'sleep']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict relation = ['is a', 'part of', 'has a', 'at location', 'receives action', 'has property', 'used for', 'animal family', 'capable of', 'animal class', 'created by', 'belong to', 'small', 'animal order', 'related to']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict fact = ['light room', 'room', 'lighten room and place']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - suppord fact predict = ['lighten room and place-used for', 'room-at location', 'room-has a', 'light room-used for']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - correspond target = ['wall', 'house', 'furniture', 'couch', 'chair', 'person', 'lamp', 'human']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - test id = 1373, question = What are you likely to find in a catlover's home ?, img = COCO_val2014_000000000599.jpg\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - real suppord fact in dataset=['cat', 'at location', \"catlover's home\"], real answer = cat\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - normal model predict = ['cat', 'animal', 'mouse', 'wii', 'furniture', 'kept as pets', 'food', 'human', 'monitor', 'tv']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict = ['printer', 'your house', 'sofa', 'cat', 'animal', 'mouse', 'wii', 'furniture', 'kept as pets', 'food']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict relation = ['at location', 'capable of', 'part of', 'stable', 'has a', 'good', 'is a', 'has property', 'active', 'visible', 'surface', 'safe', 'human', 'clean', 'used for']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict fact = ['house', 'home', 'home office']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - suppord fact predict = ['home office-at location', 'home-at location', 'house-at location']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - correspond target = ['your house', 'sofa', 'printer']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - test id = 43, question = What are they making?, img = COCO_val2014_000000125106.jpg\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - real suppord fact in dataset=['chocolate', 'related to', 'cake'], real answer = cake\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - normal model predict = ['fruit', 'food', 'spoon', 'cook food', 'bread', 'dishes', 'flour', 'fry bread', 'basket', 'prepare food']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict = ['cook food', 'kitchen utensil', 'rice cooker', 'cheese', 'cup', 'knife in drawer', 'cooking', 'restaurant', 'oven', 'toilet paper']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict relation = ['belong to', 'used for', 'has property', 'is a', 'at location', 'has a', 'capable of', 'receives action', 'related to', 'part of', 'desires', 'good', 'created by', 'important', 'great']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict fact = ['make popcorn', 'make person dance', 'kitchen']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - suppord fact predict = ['kitchen-at location', 'kitchen-belong to', 'kitchen-used for']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - correspond target = ['kitchen utensil', 'oven', 'toilet paper', 'knife in drawer', 'restaurant', 'cup', 'cooking', 'rice cooker', 'cheese', 'cook food']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - test id = 2508, question = Which vehicle is faster than a bucycle, img = ILSVRC2012_test_00004254.JPEG\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - real suppord fact in dataset=['car', 'is a', 'fast than bicycle'], real answer = car\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - normal model predict = ['car', 'motorbike', 'truck', 'motorcycle', 'spaceship', 'vehicle', 'travel in car', 'taxi', 'ship', 'cheap']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict = ['motorbike', 'truck', 'motorcycle', 'train', 'bus', 'airplane', 'bicycle', 'light', 'car', 'spaceship']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict relation = ['fast', 'slow', 'stable', 'light', 'easy', 'soft', 'dense', 'efficient', 'tall', 'long', 'low', 'high', 'reliable', 'warm', 'popular']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict fact = ['car', 'taxi', 'stop car']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - suppord fact predict = ['car-slow', 'car-light', 'car-long', 'car-high', 'car-popular', 'car-efficient', 'car-fast', 'car-stable']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - correspond target = ['light', 'airplane', 'bus', 'truck', 'motorcycle', 'bicycle', 'train', 'motorbike']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - test id = 1965, question = Which object in this image is a member of an African equine species?, img = COCO_val2014_000000010211.jpg\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - real suppord fact in dataset=['zebra', 'is a', 'african equine specie'], real answer = zebra\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - normal model predict = ['giraffe', 'hippopotamus', 'zebra', 'elephant', 'monkey', 'antelope', 'dog', 'camel', 'otter', 'rabbit']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict = ['giraffe', 'cat', 'hippopotamus', 'zebra', 'elephant', 'monkey', 'antelope', 'dog', 'camel', 'otter']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict relation = ['is a', 'belong to', 'has a', 'has property', 'animal phylum', 'tall', 'related to', 'animal class', 'cool', 'independent', 'animal kingdom', 'dangerous', 'animal family', 'popular', 'created by']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict fact = ['mammals by continent', 'small mammal', 'native to africa']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - suppord fact predict = ['small mammal-is a', 'mammals by continent-belong to', 'native to africa-has property']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - correspond target = ['cat', 'giraffe']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - test id = 1070, question = Which object in this image is used for input onto a monitor?, img = COCO_val2014_000000116252.jpg\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - real suppord fact in dataset=['keyboard', 'used for', 'type letter onto window'], real answer = keyboard\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - normal model predict = ['computer', 'keyboard', 'monitor', 'mouse', 'cell phone', 'pen', 'clock', 'desk', 'metronome', 'phone']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict = ['computer', 'remote', 'watch', 'keyboard', 'monitor', 'mouse', 'cell phone', 'pen', 'clock', 'desk']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict relation = ['used for', 'related to', 'specific', 'is a', 'capable of', 'common', 'accurate', 'easy', 'effective', 'transportable', 'belong to', 'efficient', 'important', 'good', 'hot']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - our model predict fact = ['monitor', 'monitor cpu box keyboard and mouse', 'control tv']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - suppord fact predict = ['monitor-used for', 'control tv-capable of', 'monitor-related to']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - correspond target = ['watch', 'computer', 'remote']\n",
      "INFO - 08/13/22 23:30:52 - 0:01:11 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████                | 56/89 [00:38<00:21,  1.54it/s]INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - test id = 797, question = Which object in this image is used for heating food?, img = ILSVRC2012_test_00007262.JPEG\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - real suppord fact in dataset=['microwave', 'used for', 'heat food'], real answer = microwave\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - normal model predict = ['microwave', 'refrigerator', 'oven', 'fridge', 'stove', 'sink', 'toaster', 'dishwasher', 'kitchen utensil', 'toilet']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict = ['refrigerator', 'oven', 'kitchen', 'cake', 'plate', 'pizza', 'salad', 'hot dog', 'wine', 'pretzel']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict relation = ['used for', 'related to', 'belong to', 'efficient', 'capable of', 'specific', 'effective', 'easy', 'accurate', 'good', 'convenient', 'fast', 'receives action', 'expensive', 'high']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict fact = ['prepare food', 'keep food cold', 'food']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - suppord fact predict = ['food-related to', 'keep food cold-capable of', 'food-belong to', 'keep food cold-used for', 'prepare food-used for']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - correspond target = ['cake', 'oven', 'kitchen', 'refrigerator', 'hot dog', 'wine', 'plate', 'salad', 'pizza', 'pretzel']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - test id = 1156, question = What thing does the place shown in this image have as a part?, img = COCO_val2014_000000024845.jpg\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - real suppord fact in dataset=['toilet', 'part of', 'bathroom'], real answer = toilet\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - normal model predict = ['sink', 'water', 'bathroom', 'ice', 'toilet', 'bathtub', 'wash', 'window', 'use toilet', 'bedroom']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict = ['ice', 'stove', 'refrigerator', 'toilet paper', 'cup', 'kitchen', 'light', 'kitchen utensil', 'knife in drawer', 'microwave']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict relation = ['part of', 'has a', 'related to', 'capable of', 'is a', 'large', 'animal order', 'social', 'small', 'used for', 'animal family', 'receives action', 'specific', 'at location', 'great']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict fact = ['kitchen', 'cake', 'office build']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - suppord fact predict = ['cake-part of', 'cake-at location', 'kitchen-at location', 'kitchen-part of']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - correspond target = ['light', 'kitchen utensil', 'ice', 'toilet paper', 'refrigerator', 'knife in drawer', 'microwave', 'kitchen', 'cup', 'stove']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - test id = 2127, question = Which object in this image desires trick others?, img = ILSVRC2012_test_00027147.JPEG\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - real suppord fact in dataset=['trumpet', 'used for', 'play music'], real answer = trumpet\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - normal model predict = ['person', 'house', 'fruit', 'your house', 'any place where person live', 'transport person', 'make person happy', 'temporary residence', 'car', 'home office']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict = ['person', 'dog', 'house', 'fruit', 'your house', 'any place where person live', 'transport person', 'make person happy', 'temporary residence', 'car']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict relation = ['desires', 'capable of', 'belong to', 'human', 'is a', 'at location', 'intelligent', 'related to', 'primitive', 'loyal', 'used for', 'blind', 'specific', 'animal order', 'sensible']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict fact = ['have pleasant vacation', 'please it master', 'follow it master']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - suppord fact predict = ['follow it master-capable of', 'have pleasant vacation-desires', 'please it master-capable of']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - correspond target = ['person', 'dog']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - test id = 1588, question = Which object in this image is capable of land in a lane?, img = COCO_val2014_000000145383.jpg\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - real suppord fact in dataset=['airplane', 'capable of', 'land in field'], real answer = airplane\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - normal model predict = ['person', 'car', 'frisbee', 'make person happy', 'baseball', 'jumping', 'thing', 'soccer ball', 'baseball field', 'racing']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict = ['grass', 'person', 'car', 'frisbee', 'make person happy', 'baseball', 'jumping', 'thing', 'soccer ball', 'baseball field']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict relation = ['capable of', 'used for', 'efficient', 'intelligent', 'high', 'active', 'stable', 'reliable', 'accurate', 'powerful', 'slow', 'effective', 'visible', 'transportable', 'fast']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict fact = ['grow on hill', 'outside in grass', 'difficult to walk in']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - suppord fact predict = ['grow on hill-capable of']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - correspond target = ['grass']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - test id = 1544, question = What object is less social than the object in the left of this image?, img = COCO_val2014_000000022892.jpg\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - real suppord fact in dataset=['cat', 'social', 'dog'], real answer = cat\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - normal model predict = ['cat', 'dog', 'mouse', 'animal', 'human', 'dog poop', 'tick', 'rabbit', 'chicken', 'monkey']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict = ['human', 'even toed ungulate', 'cat', 'dog', 'mouse', 'animal', 'dog poop', 'tick', 'rabbit', 'chicken']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict relation = ['good', 'fast', 'cheap', 'important', 'great', 'expensive', 'part of', 'animal order', 'healthy', 'safe', 'capable of', 'slow', 'animal class', 'effective', 'low']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict fact = ['dog', 'sheep', 'dog fur']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - suppord fact predict = ['dog-good', 'sheep-animal order']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - correspond target = ['even toed ungulate', 'human']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - test id = 1390, question = Where does the place in this image can be found in?, img = COCO_val2014_000000015559.jpg\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - real suppord fact in dataset=['snow', 'at location', 'street'], real answer = snow\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - normal model predict = ['mountainous area', 'ski slope', 'park', 'beach', 'mountain', 'hotel room', 'airport', 'lake', 'sandy', 'park space']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict = ['ski slope', 'beach', 'bathroom', 'toilet', 'mountainous area', 'park', 'mountain', 'hotel room', 'airport', 'lake']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict relation = ['at location', 'used for', 'has a', 'has property', 'belong to', 'related to', 'specific', 'surface', 'capable of', 'expensive', 'part of', 'long', 'animal family', 'small', 'animal order']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict fact = ['sandy', 'hotel', 'skiiers']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - suppord fact predict = ['sandy-has property', 'hotel-at location', 'skiiers-at location']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - correspond target = ['ski slope', 'beach', 'toilet', 'bathroom']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - test id = 2645, question = What is the dangerous animal in the image?, img = ILSVRC2012_test_00000037.JPEG\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - real suppord fact in dataset=['snake', 'capable of', 'be dangerous'], real answer = snake\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - normal model predict = ['snake', 'strawberry', 'green', 'orange', 'desert', 'blue', 'big', 'lizard', 'white', 'sweet and juicy']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict = ['green', 'desert', 'banana', 'wild', 'poisonous', 'warm place', 'zoo', 'no leg', 'snake', 'strawberry']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict relation = ['belong to', 'related to', 'is a', 'has property', 'has a', 'important', 'animal order', 'specific', 'animal class', 'part of', 'at location', 'used for', 'animal family', 'common', 'dangerous']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict fact = ['snake', 'frog', 'monkey']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - suppord fact predict = ['snake-has property', 'monkey-at location', 'snake-at location', 'frog-at location', 'frog-has property', 'snake-has a', 'monkey-related to']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - correspond target = ['desert', 'wild', 'no leg', 'zoo', 'warm place', 'green', 'banana', 'poisonous']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - test id = 2804, question = What is likely to be found in this place?, img = COCO_val2014_000000115776.jpg\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - real suppord fact in dataset=['coffee', 'at location', 'coffee shop'], real answer = coffee\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - normal model predict = ['cake', 'food', 'fork', 'cook food', 'prepare food', 'eat', 'kitchen table', 'cheese', 'kitchen', 'spoon']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict = ['kitchen table', 'kitchen', 'large container', 'wine', 'sleep away from home', 'sleep', 'temporary residence', 'cake', 'food', 'fork']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict relation = ['at location', 'used for', 'related to', 'belong to', 'has a', 'animal order', 'specific', 'part of', 'receives action', 'good', 'animal class', 'animal family', 'great', 'important', 'is a']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict fact = ['hotel room', 'restaurant kitchen', 'restaurant']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - suppord fact predict = ['hotel room-used for', 'restaurant kitchen-at location', 'restaurant-at location']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - correspond target = ['kitchen table', 'sleep', 'kitchen', 'wine', 'temporary residence', 'large container', 'sleep away from home']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - test id = 2146, question = Which object in this image is collected by arctophiles?, img = COCO_val2014_000000119802.jpg\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - real suppord fact in dataset=['arctophile', 'related to', 'teddy bear'], real answer = teddy bear\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - normal model predict = ['child', 'toddler', 'toys', 'flowers', 'baby bed', 'baby', 'pillows', 'furniture', 'rugby ball', 'teddy bear']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict = ['kite', 'cat', 'violin', 'child', 'toddler', 'toys', 'flowers', 'baby bed', 'baby', 'pillows']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict relation = ['has property', 'created by', 'used for', 'belong to', 'receives action', 'related to', 'desires', 'is a', 'at location', 'part of', 'has a', 'capable of', 'protected', 'specific', 'visible']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict fact = ['violinist', 'lists by country', 'live entity']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - suppord fact predict = ['live entity-is a', 'lists by country-belong to', 'violinist-related to']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - correspond target = ['kite', 'cat', 'violin']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - test id = 121, question = Which object is gererating light in this image?, img = ILSVRC2012_test_00002967.JPEG\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - real suppord fact in dataset=['lamp', 'used for', 'generate light'], real answer = lamp\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - normal model predict = ['computer', 'laptop', 'cell phone', 'bottle', 'mouse', 'printer', 'ipod', 'phone', 'desk', 'monitor']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict = ['computer', 'desk', 'home office', 'wine', 'laptop', 'cell phone', 'bottle', 'mouse', 'printer', 'ipod']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict relation = ['related to', 'used for', 'has property', 'is a', 'belong to', 'has a', 'at location', 'good', 'capable of', 'important', 'part of', 'common', 'specific', 'easy', 'great']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict fact = ['mean office in home', 'alcohol in it', 'in office']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - suppord fact predict = ['alcohol in it-has a', 'mean office in home-capable of', 'in office-at location']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - correspond target = ['home office', 'wine', 'computer', 'desk']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - test id = 2306, question = Which fruit here is neither orange nor lemon?, img = ILSVRC2012_test_00021198.JPEG\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - real suppord fact in dataset=['apple', 'is a', 'not orange nor be they lemon'], real answer = apple\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - normal model predict = ['lemon', 'orange', 'pineapple', 'carrot', 'tomato', 'apple', 'mustard', 'bell pepper', 'banana', 'cucumber']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict = ['lemon', 'carrot', 'sweet and juicy', 'vitamin c', 'seed', 'nail', 'kite', 'orange', 'pineapple', 'tomato']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict relation = ['is a', 'part of', 'has property', 'green', 'has a', 'acidic', 'red', 'created by', 'related to', 'sweet', 'acid', 'small', 'cool', 'popular', 'common']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - our model predict fact = ['orange vegetable', 'lime', 'orange']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - suppord fact predict = ['orange-is a', 'orange vegetable-is a', 'orange-has property', 'orange vegetable-related to', 'orange-has a', 'lime-related to', 'orange-acid']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - correspond target = ['vitamin c', 'seed', 'lemon', 'carrot', 'kite', 'sweet and juicy', 'nail']\n",
      "INFO - 08/13/22 23:30:53 - 0:01:11 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████▌               | 57/89 [00:39<00:20,  1.56it/s]INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - test id = 1083, question = What is the food on the left called?, img = COCO_val2014_000000100083.jpg\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - real suppord fact in dataset=['hamburger', 'is a', 'food'], real answer = hamburger\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - normal model predict = ['bread', 'cut', 'lemon', 'ice', 'doughnut', 'bagel', 'green', 'carrot', 'toast bread', 'flour']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict = ['banana', 'orange', 'donut', 'pretzel', 'vegetable', 'fig', 'lettuce', 'salad', 'fruit', 'pizza']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict relation = ['belong to', 'related to', 'is a', 'has a', 'part of', 'at location', 'used for', 'animal order', 'receives action', 'has property', 'specific', 'important', 'capable of', 'good', 'animal class']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict fact = ['finger food', 'cow food', 'food']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - suppord fact predict = ['food-is a', 'finger food-is a', 'food-belong to']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - correspond target = ['fig', 'salad', 'orange', 'lettuce', 'banana', 'pizza', 'pretzel', 'donut', 'vegetable', 'fruit']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - test id = 2802, question = Which fast food in this image contains meat?, img = COCO_val2014_000000134223.jpg\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - real suppord fact in dataset=['hotdog', 'belong to', 'fast food'], real answer = hotdog\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - normal model predict = ['bagel', 'pizza', 'sandwich', 'hamburger', 'salad', 'cheese', 'chocolate', 'strawberry', 'bread', 'hot dog']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict = ['cow', 'nail', 'knife', 'bagel', 'pizza', 'sandwich', 'hamburger', 'salad', 'cheese', 'chocolate']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict relation = ['related to', 'is a', 'has a', 'belong to', 'used for', 'has property', 'part of', 'created by', 'specific', 'animal order', 'common', 'important', 'small', 'social', 'independent']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict fact = ['meat', 'eat meat', 'cut meat with']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - suppord fact predict = ['meat-related to', 'cut meat with-used for', 'meat-belong to']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - correspond target = ['nail', 'knife', 'cow']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - test id = 2593, question = What is the four legged object in this image?, img = ILSVRC2012_test_00002108.JPEG\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - real suppord fact in dataset=['antelope', 'has a', 'four leg'], real answer = antelope\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - normal model predict = ['frisbee', 'soccer ball', 'animal', 'human', 'ball', 'baseball bat', 'baseball', 'baseball field', 'golf ball', 'rugby ball']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict = ['frisbee', 'soccer ball', 'baseball', 'tennis ball', 'basketball', 'orange', 'apple', 'animal', 'human', 'ball']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict relation = ['has property', 'related to', 'at location', 'animal family', 'used for', 'animal order', 'is a', 'animal class', 'protected', 'has a', 'safe', 'part of', 'specific', 'common', 'animal kingdom']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict fact = ['round', 'round and white', 'round and orange']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - suppord fact predict = ['round-is a', 'round and white-has property', 'round and orange-has property', 'round-has property', 'round-related to']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - correspond target = ['apple', 'basketball', 'orange', 'frisbee', 'soccer ball', 'tennis ball', 'baseball']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - test id = 2650, question = What thing does the place shown in this image have as a part?, img = COCO_val2014_000000145651.jpg\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - real suppord fact in dataset=['bedroom', 'has a', 'bed'], real answer = bed\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - normal model predict = ['ice', 'bed', 'bedroom', 'water', 'sink', 'bathroom', 'cold and wet', 'hot room', 'snow', 'cold']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict = ['wall', 'window', 'lamp', 'couch', 'furniture', 'house', 'chair', 'person', 'human', 'ice']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict relation = ['part of', 'has a', 'used for', 'related to', 'at location', 'large', 'small', 'receives action', 'animal family', 'social', 'animal order', 'specific', 'capable of', 'independent', 'is a']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict fact = ['room', 'hospital room', 'light room']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - suppord fact predict = ['hospital room-at location', 'room-at location', 'room-has a', 'light room-used for']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - correspond target = ['wall', 'house', 'furniture', 'window', 'couch', 'lamp', 'chair', 'person', 'human']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - test id = 1104, question = What medical instrument does the boy have?, img = ILSVRC2012_test_00040213.JPEG\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - real suppord fact in dataset=['stethoscope', 'is a', 'medical instrument'], real answer = stethoscope\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - normal model predict = ['metal', 'scissors', 'tie', 'toilet paper', 'wash machine', 'hair', 'toothbrush', 'stripe', 'fork', 'use toilet']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict = ['hair', 'fork', 'cut', 'pare apple', 'animal', 'human', 'herd sheep', 'metal', 'scissors', 'tie']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict relation = ['at location', 'used for', 'is a', 'has property', 'related to', 'receives action', 'has a', 'belong to', 'part of', 'capable of', 'animal order', 'created by', 'specific', 'good', 'animal class']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict fact = ['knife', 'knife mate', 'dog']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - suppord fact predict = ['dog-used for', 'dog-good', 'knife mate-related to', 'dog-has a', 'dog-belong to', 'knife-used for']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - correspond target = ['animal', 'herd sheep', 'hair', 'fork', 'pare apple', 'human', 'cut']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - test id = 188, question = What is the device in the image used for>, img = COCO_val2014_000000101862.jpg\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - real suppord fact in dataset=['controller', 'used for', 'control tv'], real answer = control tv\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - normal model predict = ['fight fire', 'listen to music', 'toast bread', 'bread', 'cut', 'plane to land on', 'play music', 'prepare food', 'work', 'control']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict = ['listen to music', 'work', 'pen', 'computer', 'keyboard', 'apple', 'monitor', 'desk', 'tall build', 'fight fire']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict relation = ['used for', 'related to', 'capable of', 'belong to', 'effective', 'specific', 'at location', 'good', 'receives action', 'animal order', 'easy', 'high', 'important', 'fast', 'efficient']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict fact = ['ipod', 'office', 'in office']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - suppord fact predict = ['office-used for', 'ipod-belong to', 'office-at location', 'in office-at location', 'ipod-used for']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - correspond target = ['pen', 'apple', 'desk', 'tall build', 'computer', 'monitor', 'keyboard', 'work', 'listen to music']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - test id = 1852, question = What are the people driving?, img = COCO_val2014_000000136833.jpg\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - real suppord fact in dataset=['motorcycle', 'belong to', 'transport'], real answer = motorcycle\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - normal model predict = ['car', 'store boat', 'boat', 'park space', 'furniture', 'travel in car', 'furniture store', 'vehicle', 'protect person from sun and rain', 'water']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict = ['kite', 'throw', 'elephant', 'hammer', 'axe', 'car', 'store boat', 'boat', 'park space', 'furniture']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict relation = ['at location', 'used for', 'related to', 'is a', 'has property', 'animal order', 'receives action', 'has a', 'animal family', 'belong to', 'animal class', 'capable of', 'part of', 'specific', 'surface']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict fact = ['person', 'hurt person', 'drive by person']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - suppord fact predict = ['drive by person-has property', 'hurt person-capable of', 'person-has property', 'person-capable of', 'hurt person-used for']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - correspond target = ['axe', 'throw', 'elephant', 'kite', 'hammer']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - test id = 227, question = Which object in this image is related to lawsuit?, img = COCO_val2014_000000101948.jpg\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - real suppord fact in dataset=['suit', 'related to', 'lawsuit'], real answer = suit\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - normal model predict = ['knife', 'bow tie', 'tie', 'crutch', 'hand', 'flute', 'bow', 'scissors', 'phone', 'cell phone']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict = ['scissors', 'trumpet', 'trombone', 'knife', 'bow tie', 'tie', 'crutch', 'hand', 'flute', 'bow']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict relation = ['related to', 'belong to', 'specific', 'used for', 'important', 'common', 'at location', 'part of', 'social', 'capable of', 'accurate', 'prevalent', 'has property', 'animal order', 'is a']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict fact = ['cornett', 'sew', 'tromboner']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - suppord fact predict = ['sew-belong to', 'cornett-related to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - correspond target = ['trombone', 'scissors', 'trumpet']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - test id = 2526, question = Which object in this image is a sour yellow fruit?, img = ILSVRC2012_test_00049151.JPEG\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - real suppord fact in dataset=['lemon', 'is a', 'sour yellow fruit'], real answer = lemon\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - normal model predict = ['lemon', 'strawberry', 'orange', 'pineapple', 'apple', 'banana', 'fruit', 'pomegranate', 'carrot', 'chocolate']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict = ['strawberry', 'banana', 'lemon', 'orange', 'pineapple', 'apple', 'fruit', 'pomegranate', 'carrot', 'chocolate']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict relation = ['belong to', 'is a', 'related to', 'visible', 'cool', 'important', 'has property', 'has a', 'part of', 'specific', 'created by', 'easy', 'used for', 'safe', 'good']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict fact = ['sweet yellow fruit', 'sweet red fruit', 'yellow fruit']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - suppord fact predict = ['sweet red fruit-is a', 'sweet yellow fruit-is a', 'yellow fruit-is a']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - correspond target = ['banana', 'strawberry']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - test id = 231, question = Which object in this image can be used for melody?, img = ILSVRC2012_test_00050462.JPEG\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - real suppord fact in dataset=['harp', 'used for', 'melody'], real answer = harp\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - normal model predict = ['bicycle', 'motorcycle', 'ride', 'mountain', 'motorbike', 'guitar', 'tree', 'basket', 'luggage', 'harp']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict = ['bicycle', 'motorcycle', 'horse', 'computer', 'couch', 'ride', 'mountain', 'motorbike', 'guitar', 'tree']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict relation = ['used for', 'related to', 'belong to', 'capable of', 'specific', 'receives action', 'desires', 'accurate', 'at location', 'important', 'animal order', 'has property', 'is a', 'common', 'active']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - our model predict fact = ['ride', 'cyberdating', 'laze']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - suppord fact predict = ['ride-related to', 'laze-used for', 'cyberdating-related to', 'ride-used for']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - correspond target = ['horse', 'computer', 'motorcycle', 'couch', 'bicycle']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:12 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████               | 58/89 [00:39<00:20,  1.53it/s]INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - test id = 332, question = What object in this image has straps?, img = ILSVRC2012_test_00000449.JPEG\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - real suppord fact in dataset=['backpack', 'related to', 'trap'], real answer = backpack\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - normal model predict = ['skateboard', 'bicycle', 'shirt', 'surfboard', 'tie', 'bow tie', 'neck brace', 'snowboard', 'corkscrew', 'crutch']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict = ['shirt', 'jacket', 'skateboard', 'bicycle', 'surfboard', 'tie', 'bow tie', 'neck brace', 'snowboard', 'corkscrew']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict relation = ['has a', 'related to', 'has property', 'part of', 'receives action', 'is a', 'specific', 'used for', 'belong to', 'animal order', 'at location', 'social', 'common', 'desires', 'capable of']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict fact = ['zipper', 'sleeve', 'collar']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - suppord fact predict = ['collar-related to', 'sleeve-part of', 'zipper-has a']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - correspond target = ['jacket', 'shirt']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - test id = 377, question = What is the container in this image, img = ILSVRC2012_test_00049153.JPEG\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - real suppord fact in dataset=['pencil box', 'belong to', 'container'], real answer = pencil box\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - normal model predict = ['computer', 'laptop', 'keyboard', 'pen', 'mouse', 'desk', 'home office', 'printer', 'pencil box', 'glass']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict = ['computer', 'keyboard', 'pen', 'desk', 'home office', 'work', 'window', 'monitor', 'tall build', 'laptop']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict relation = ['used for', 'related to', 'is a', 'at location', 'belong to', 'has a', 'has property', 'capable of', 'part of', 'good', 'specific', 'receives action', 'important', 'expensive', 'easy']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict fact = ['office', 'in office', 'mean office in home']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - suppord fact predict = ['office-used for', 'office-has a', 'office-at location', 'in office-at location', 'mean office in home-capable of']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - correspond target = ['pen', 'desk', 'tall build', 'monitor', 'computer', 'window', 'home office', 'keyboard', 'work']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - test id = 2724, question = What can be served here?, img = COCO_val2014_000000000802.jpg\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - real suppord fact in dataset=['kitchenette', 'used for', 'breakfast'], real answer = breakfast\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - normal model predict = ['oven', 'knife in drawer', 'kitchen utensil', 'cooking', 'cup', 'toilet paper', 'stove', 'use toilet', 'wash', 'wash machine']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict = ['oven', 'knife in drawer', 'kitchen utensil', 'cooking', 'cup', 'toilet paper', 'stove', 'rice cooker', 'microwave', 'cook food']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict relation = ['at location', 'used for', 'related to', 'belong to', 'is a', 'has property', 'has a', 'part of', 'receives action', 'created by', 'capable of', 'specific', 'animal order', 'good', 'common']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict fact = ['kitchen', 'cook roast', 'cook']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - suppord fact predict = ['kitchen-at location', 'cook-used for', 'kitchen-used for', 'cook roast-used for', 'kitchen-belong to']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - correspond target = ['kitchen utensil', 'oven', 'toilet paper', 'knife in drawer', 'microwave', 'cup', 'cooking', 'rice cooker', 'stove', 'cook food']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - test id = 559, question = Whether the laptop in the image is cheaper or more expensive than a apple mac?, img = COCO_val2014_000000116405.jpg\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - real suppord fact in dataset=['window desktop laptop', 'cheap', 'cheap'], real answer = cheap\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - normal model predict = ['laptop', 'cheap', 'keyboard', 'buy and sell', 'expensive', 'ram', 'apple', 'ambition', 'ipod', 'unhealthy']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict = ['laptop', 'cheap', 'keyboard', 'buy and sell', 'expensive', 'ram', 'apple', 'ambition', 'ipod', 'unhealthy']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict relation = ['cheap', 'expensive', 'popular', 'small', 'convenient', 'used for', 'large', 'transportable', 'green', 'compact', 'solar', 'red', 'low', 'easy', 'light']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict fact = ['desktop', 'apple', 'tablet pc']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - suppord fact predict = ['desktop-popular', 'tablet pc-small', 'desktop-compact', 'desktop-expensive', 'desktop-convenient', 'desktop-transportable']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - correspond target = ['laptop']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - test id = 2378, question = What toy can be found in the image?, img = COCO_val2014_000000118432.jpg\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - real suppord fact in dataset=['kite', 'is a', 'toy'], real answer = kite\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - normal model predict = ['beach', 'kite', 'butterfly', 'surf board', 'tennis ball', 'swimming', 'sand', 'tennis racket', 'bird', 'person']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict = ['tennis racket', 'golf ball', 'surfboard', 'racket', 'fly', 'stop sign', 'rugby ball', 'ski', 'airport', 'bicycle']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict relation = ['at location', 'has a', 'used for', 'capable of', 'part of', 'is a', 'animal family', 'has property', 'animal order', 'good', 'belong to', 'human', 'great', 'convenient', 'related to']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict fact = ['traffic sign', 'sports equipment', 'airplane']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - suppord fact predict = ['airplane-used for', 'airplane-at location', 'traffic sign-belong to', 'sports equipment-belong to']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - correspond target = ['golf ball', 'fly', 'rugby ball', 'ski', 'stop sign', 'surfboard', 'bicycle', 'tennis racket', 'racket', 'airport']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - test id = 2766, question = How would you describe the place in this image?, img = COCO_val2014_000000016931.jpg\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - real suppord fact in dataset=['snow', 'has property', 'cold'], real answer = cold\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - normal model predict = ['car', 'stop sign', 'road', 'your house', 'train', 'railroad track', 'house', 'police', 'travel in car', 'street']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict = ['car', 'stop sign', 'two', 'person', 'road', 'your house', 'train', 'railroad track', 'house', 'police']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict relation = ['related to', 'at location', 'belong to', 'has a', 'is a', 'specific', 'has property', 'animal order', 'stable', 'capable of', 'receives action', 'created by', 'safe', 'used for', 'animal family']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict fact = ['village', 'traffic sign', 'motorcycle']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - suppord fact predict = ['traffic sign-belong to', 'village-at location', 'motorcycle-stable', 'motorcycle-has a']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - correspond target = ['stop sign', 'two', 'person', 'car']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - test id = 474, question = which object can we find in this place shown in the image, img = COCO_val2014_000000105448.jpg\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - real suppord fact in dataset=['boy', 'at location', 'playground'], real answer = boy\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - normal model predict = ['person', 'snake', 'child', 'make person happy', 'eat', 'car', 'grass', 'tennis ball', 'throw', 'horse']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict = ['person', 'car', 'tree', 'animal', 'squirrel', 'skunk', 'travel', 'mushroom', 'transport', 'snake']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict relation = ['at location', 'capable of', 'belong to', 'used for', 'human', 'visible', 'active', 'primitive', 'animal order', 'blind', 'convenient', 'part of', 'surface', 'specific', 'accurate']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict fact = ['village', 'forest', 'road']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - suppord fact predict = ['road-at location', 'village-at location', 'forest-part of', 'forest-at location', 'road-used for']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - correspond target = ['tree', 'animal', 'mushroom', 'transport', 'squirrel', 'skunk', 'person', 'car', 'travel']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:54 - 0:01:13 - test id = 2400, question = Which object in this image is likely to be most cool?, img = COCO_val2014_000000019447.jpg\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - real suppord fact in dataset=['water', 'has property', 'cool'], real answer = water\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - normal model predict = ['giraffe', 'zebra', 'hippopotamus', 'long necked', 'snake', 'lizard', 'camel', 'turtle', 'wall', 'stripe']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict = ['butterfly', 'jellyfish', 'ocean', 'giraffe', 'zebra', 'hippopotamus', 'long necked', 'snake', 'lizard', 'camel']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict relation = ['has property', 'capable of', 'related to', 'is a', 'has a', 'important', 'dangerous', 'desires', 'visible', 'at location', 'high', 'used for', 'specific', 'long', 'part of']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict fact = ['beautiful', 'very deep', 'most ocean']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - suppord fact predict = ['very deep-has property', 'most ocean-at location', 'beautiful-has property']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - correspond target = ['ocean', 'jellyfish', 'butterfly']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - test id = 1157, question = What does the place in the image can be used for?, img = COCO_val2014_000000024845.jpg\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - real suppord fact in dataset=['bathroom', 'used for', 'wash your hand'], real answer = wash your hand\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - normal model predict = ['sleep', 'wash', 'sleep away from home', 'cooking', 'preventing from getting wet', 'cold and wet', 'prepare food', 'kitchenette', 'work for day without water', 'living room']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict = ['wash', 'cooking', 'prepare food', 'couch', 'breakfast', 'hotel room', 'human', 'house', 'furniture', 'wall']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict relation = ['used for', 'capable of', 'related to', 'belong to', 'receives action', 'part of', 'at location', 'animal order', 'specific', 'has a', 'good', 'effective', 'high', 'is a', 'great']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - our model predict fact = ['kitchenette', 'shower', 'room']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - suppord fact predict = ['kitchenette-used for', 'room-at location', 'kitchenette-at location', 'room-has a', 'shower-used for']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - correspond target = ['wall', 'prepare food', 'house', 'furniture', 'couch', 'cooking', 'hotel room', 'wash', 'human', 'breakfast']\n",
      "INFO - 08/13/22 23:30:54 - 0:01:13 - #################################################################################\n",
      " 66%|████████████████████████████▌              | 59/89 [00:40<00:21,  1.41it/s]INFO - 08/13/22 23:30:55 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - test id = 952, question = What is the fungus in the image?, img = COCO_val2014_000000140664.jpg\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - real suppord fact in dataset=['mushroom', 'is a', 'fungus'], real answer = mushroom\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - normal model predict = ['vegetable', 'broccoli', 'cheese', 'meat', 'fork', 'tomato', 'lemon', 'cucumber', 'artichoke', 'salad']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict = ['vegetable', 'fork', 'salad', 'lettuce', 'fruit', 'orange', 'fig', 'pizza', 'banana', 'hamburger']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict relation = ['is a', 'related to', 'easy', 'used for', 'belong to', 'at location', 'part of', 'good', 'important', 'has property', 'has a', 'animal order', 'animal class', 'animal family', 'great']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict fact = ['kitchen utensil', 'hold food', 'food']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - suppord fact predict = ['hold food-used for', 'food-is a', 'kitchen utensil-is a', 'food-belong to']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - correspond target = ['fig', 'fruit', 'salad', 'orange', 'lettuce', 'banana', 'pizza', 'vegetable', 'fork', 'hamburger']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - test id = 1238, question = Which object in this image is a barrier against people and the elephant?, img = COCO_val2014_000000017282.jpg\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - real suppord fact in dataset=['fence', 'is a', 'barrier against person or animal'], real answer = fence\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - normal model predict = ['elephant', 'hippopotamus', 'giraffe', 'camel', 'monkey', 'bear', 'horse', 'cow', 'zoo', 'whale']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict = ['elephant', 'horse', 'bicycle', 'hippopotamus', 'giraffe', 'camel', 'monkey', 'bear', 'cow', 'zoo']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict relation = ['is a', 'has property', 'has a', 'fast', 'tall', 'easy', 'slow', 'belong to', 'capable of', 'small', 'convenient', 'visible', 'long', 'related to', 'cool']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict fact = ['big gray animal with trunk', 'large animal', 'popular form of transportation especially among child environmentalist and asian']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - suppord fact predict = ['big gray animal with trunk-is a', 'popular form of transportation especially among child environmentalist and asian-is a', 'large animal-is a']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - correspond target = ['elephant', 'horse', 'bicycle']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - test id = 2004, question = Which little animal on the left of the image can be used to make soup?, img = COCO_val2014_000000146099.jpg\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - real suppord fact in dataset=['soup', 'related to', 'chicken'], real answer = chicken\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - normal model predict = ['fry bread', 'chicken', 'bread', 'spoon', 'sandwich', 'oven', 'toast bread', 'meat', 'rice cooker', 'cheese']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict = ['spoon', 'bowl', 'person', 'fry bread', 'chicken', 'bread', 'sandwich', 'oven', 'toast bread', 'meat']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict relation = ['capable of', 'used for', 'related to', 'is a', 'high', 'has a', 'effective', 'specific', 'accurate', 'long', 'efficient', 'has property', 'surface', 'part of', 'common']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict fact = ['serve soup', 'eat soup', 'eat vegetable']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - suppord fact predict = ['serve soup-related to', 'eat soup-used for', 'eat vegetable-capable of']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - correspond target = ['bowl', 'person', 'spoon']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - test id = 292, question = Which object in this image is a type of food?, img = COCO_val2014_000000131841.jpg\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - real suppord fact in dataset=['bread', 'is a', 'type of food'], real answer = bread\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - normal model predict = ['sandwich', 'bread', 'toast bread', 'fry bread', 'bagel', 'doughnut', 'donut', 'hamburger', 'cake', 'fork']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict = ['donut', 'hamburger', 'cake', 'fork', 'pretzel', 'salad', 'pizza', 'fruit', 'apple', 'vegetable']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict relation = ['is a', 'belong to', 'related to', 'has a', 'important', 'at location', 'used for', 'part of', 'capable of', 'good', 'has property', 'specific', 'cool', 'receives action', 'animal class']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict fact = ['food', 'eat food', 'stock food']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - suppord fact predict = ['food-related to', 'food-is a', 'eat food-related to', 'food-belong to', 'eat food-used for']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - correspond target = ['cake', 'apple', 'fruit', 'salad', 'pizza', 'pretzel', 'donut', 'vegetable', 'fork', 'hamburger']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - test id = 2663, question = What are the people travelling with in this image?, img = COCO_val2014_000000110330.jpg\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - real suppord fact in dataset=['bus', 'related to', 'travel'], real answer = bus\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - normal model predict = ['bus', 'cheap', 'taxi', 'food', 'tourist', 'bakery', 'railroad track', 'apartment', 'wash', 'truck']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict = ['handbag', 'bus', 'cheap', 'taxi', 'food', 'tourist', 'bakery', 'railroad track', 'apartment', 'wash']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict relation = ['is a', 'has property', 'animal order', 'has a', 'at location', 'used for', 'related to', 'animal family', 'animal class', 'fast', 'part of', 'good', 'common', 'animal kingdom', 'capable of']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict fact = ['child', 'woman', 'youth']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - suppord fact predict = ['woman-used for']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - correspond target = ['handbag']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - test id = 283, question = which object in this image can we used for eating soup, img = COCO_val2014_000000101456.jpg\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - real suppord fact in dataset=['bowl', 'used for', 'eat soup'], real answer = bowl\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - normal model predict = ['fork', 'spoon', 'bowl', 'cheese', 'cake', 'salad', 'basket', 'fry bread', 'plate', 'rice cooker']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict = ['fork', 'cake', 'bread', 'cat', 'banana', 'apple', 'person', 'hot dog', 'spoon', 'bowl']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict relation = ['related to', 'used for', 'belong to', 'capable of', 'specific', 'desires', 'part of', 'important', 'at location', 'has property', 'has a', 'accurate', 'receives action', 'animal order', 'good']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict fact = ['eat', 'eat fish', 'eat food']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - suppord fact predict = ['eat fish-desires', 'eat-used for', 'eat-has a', 'eat food-capable of', 'eat food-related to', 'eat fish-capable of', 'eat food-used for']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - correspond target = ['cake', 'apple', 'cat', 'hot dog', 'bread', 'banana', 'person', 'fork']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - test id = 2366, question = What is the shape of the sign?, img = COCO_val2014_000000110369.jpg\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - real suppord fact in dataset=['stop sign', 'is a', 'octogon'], real answer = octogon\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - normal model predict = ['stop sign', 'traffic light', 'car', 'road', 'railroad track', 'drink', 'move', 'driving', 'taxi', 'build']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict = ['stop sign', 'fire hydrant', 'two', 'traffic light', 'car', 'road', 'railroad track', 'drink', 'move', 'driving']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict relation = ['related to', 'at location', 'is a', 'belong to', 'animal order', 'has property', 'part of', 'used for', 'capable of', 'has a', 'animal family', 'receives action', 'specific', 'animal class', 'important']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - our model predict fact = ['motorcycle', 'firefighter', 'traffic sign']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - suppord fact predict = ['traffic sign-belong to', 'firefighter-related to', 'motorcycle-has a']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - correspond target = ['stop sign', 'two', 'fire hydrant']\n",
      "INFO - 08/13/22 23:30:55 - 0:01:14 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████▉              | 60/89 [00:41<00:22,  1.30it/s]INFO - 08/13/22 23:30:56 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - test id = 1392, question = Which object in this image pertain to the category Woodworking?, img = ILSVRC2012_test_00002135.JPEG\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - real suppord fact in dataset=['sofa', 'belong to', 'woodworking'], real answer = sofa\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - normal model predict = ['couch', 'sofa', 'pillows', 'monitor', 'bed', 'bedroom', 'baby bed', 'sleep', 'tv', 'furniture']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict = ['monitor', 'dining table', 'chair', 'desk', 'cabinets', 'cabinet', 'keyboard', 'cup', 'couch', 'sofa']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict relation = ['belong to', 'desires', 'related to', 'loyal', 'animal order', 'capable of', 'animal kingdom', 'animal phylum', 'is a', 'part of', 'important', 'trustworthy', 'human', 'at location', 'specific']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict fact = ['furniture', 'output', 'cupboard']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - suppord fact predict = ['output-related to', 'cupboard-at location', 'furniture-is a', 'furniture-related to', 'furniture-belong to', 'output-belong to']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - correspond target = ['desk', 'monitor', 'keyboard', 'cup', 'chair', 'cabinets', 'cabinet', 'dining table']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - test id = 1010, question = Which object in this image is related to pedalling?, img = COCO_val2014_000000020342.jpg\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - real suppord fact in dataset=['pedal', 'related to', 'bicycle'], real answer = bicycle\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - normal model predict = ['bicycle', 'unicycle', 'traffic light', 'cut', 'crutch', 'street', 'guitar', 'space to run and play', 'light', 'axe']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict = ['station', 'trombone', 'elephant', 'bicycle', 'unicycle', 'traffic light', 'cut', 'crutch', 'street', 'guitar']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict relation = ['related to', 'belong to', 'specific', 'used for', 'important', 'common', 'part of', 'has property', 'animal order', 'at location', 'social', 'is a', 'capable of', 'accurate', 'prevalent']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict fact = ['superstation', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - suppord fact predict = ['superstation-related to', 'therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - correspond target = ['trombone', 'elephant', 'station']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - test id = 336, question = what can you often find in the place shown in this picture, img = ILSVRC2012_test_00028847.JPEG\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - real suppord fact in dataset=['light', 'part of', 'kitchen'], real answer = light\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - normal model predict = ['oven', 'cup', 'wash machine', 'toilet paper', 'kitchen utensil', 'wash', 'cooking', 'flour', 'knife in drawer', 'kitchen']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict = ['oven', 'cup', 'toilet paper', 'kitchen utensil', 'cooking', 'knife in drawer', 'rice cooker', 'stove', 'cheese', 'cook food']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict relation = ['at location', 'used for', 'part of', 'has property', 'animal order', 'has a', 'receives action', 'specific', 'related to', 'convenient', 'created by', 'belong to', 'surface', 'cheap', 'capable of']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict fact = ['kitchen', 'kitchen utensil', 'restaurant kitchen']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - suppord fact predict = ['kitchen-at location', 'kitchen-belong to', 'kitchen-used for']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - correspond target = ['kitchen utensil', 'oven', 'toilet paper', 'knife in drawer', 'cup', 'cooking', 'rice cooker', 'stove', 'cheese', 'cook food']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - test id = 1645, question = Which object in this image is capable of holding water, img = ILSVRC2012_test_00002967.JPEG\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - real suppord fact in dataset=['bottle', 'capable of', 'hold water'], real answer = bottle\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - normal model predict = ['computer', 'person', 'cat', 'head', 'home office', 'desk', 'hand', 'monkey', 'make person happy', 'box']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict = ['person', 'monkey', 'horse', 'computer', 'cat', 'head', 'home office', 'desk', 'hand', 'make person happy']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict relation = ['capable of', 'used for', 'efficient', 'high', 'stable', 'effective', 'intelligent', 'powerful', 'accurate', 'transportable', 'reliable', 'fast', 'active', 'visible', 'part of']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict fact = ['blow that candle out', 'rest stand up', 'groom each other']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - suppord fact predict = ['blow that candle out-capable of', 'groom each other-capable of', 'rest stand up-capable of']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - correspond target = ['monkey', 'person', 'horse']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - test id = 622, question = which object in this picture can connect with an ibook, img = ILSVRC2012_test_00060109.JPEG\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - real suppord fact in dataset=['ibook', 'related to', 'laptop'], real answer = laptop\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - normal model predict = ['printer', 'listen to music', 'ipod', 'toaster', 'keyboard', 'bus', 'box', 'drum', 'drive screw', 'station']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict = ['dog', 'person', 'printer', 'listen to music', 'ipod', 'toaster', 'keyboard', 'bus', 'box', 'drum']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict relation = ['related to', 'used for', 'capable of', 'has property', 'at location', 'has a', 'specific', 'part of', 'is a', 'important', 'belong to', 'good', 'common', 'desires', 'accurate']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict fact = ['follow it master', 'reason with another person', 'listen to music with earphone']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - suppord fact predict = ['listen to music with earphone-capable of', 'reason with another person-capable of', 'follow it master-capable of']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - correspond target = ['person', 'dog']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - #################################################################################\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - test id = 732, question = Which object is used for banging out rhythms in this image?, img = ILSVRC2012_test_00022927.JPEG\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - real suppord fact in dataset=['drum', 'used for', 'bang out rhythm'], real answer = drum\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - normal model predict = ['golf ball', 'snowboard', 'car', 'skateboard', 'bicycle', 'dumbbell', 'hair spray', 'surfboard', 'corkscrew', 'bottle']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict = ['motorcycle', 'bus', 'golf ball', 'snowboard', 'car', 'skateboard', 'bicycle', 'dumbbell', 'hair spray', 'surfboard']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict relation = ['used for', 'related to', 'capable of', 'is a', 'belong to', 'popular', 'easy', 'light', 'powerful', 'effective', 'specific', 'cool', 'fast', 'visible', 'flexible']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - our model predict fact = ['go from place to place', 'page in them', 'ink in it']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - suppord fact predict = ['go from place to place-used for']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - correspond target = ['bus', 'motorcycle']\n",
      "INFO - 08/13/22 23:30:56 - 0:01:14 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 69%|█████████████████████████████▍             | 61/89 [00:42<00:20,  1.38it/s]INFO - 08/13/22 23:30:57 - 0:01:15 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - test id = 1888, question = Which object in this image has a paw, img = ILSVRC2012_test_00038016.JPEG\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - real suppord fact in dataset=['dog', 'has a', 'paw'], real answer = dog\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - normal model predict = ['dog', 'elephant', 'teddy bear', 'sheep', 'monkey', 'hippopotamus', 'giraffe', 'bear', 'ram', 'ipod']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict = ['elephant', 'airplane', 'bicycle', 'car', 'snake', 'skateboard', 'cart', 'dog', 'teddy bear', 'sheep']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict relation = ['has a', 'is a', 'part of', 'related to', 'capable of', 'light', 'frequent', 'specific', 'small', 'large', 'at location', 'blind', 'common', 'good', 'great']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict fact = ['bmx', 'india', 'wheel']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - suppord fact predict = ['wheel-part of', 'india-at location', 'wheel-related to', 'bmx-related to', 'wheel-has a']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - correspond target = ['airplane', 'skateboard', 'bicycle', 'elephant', 'car', 'snake', 'cart']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - test id = 1026, question = Which thing in this image is playing game?, img = ILSVRC2012_test_00029467.JPEG\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - real suppord fact in dataset=['person', 'desires', 'play game'], real answer = person\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - normal model predict = ['wii', 'racket', 'violin', 'guitar', 'piano', 'accordion', 'racquet', 'tennis racket', 'basketball', 'soccer ball']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict = ['wii', 'computer', 'laptop', 'kite', 'racket', 'violin', 'guitar', 'piano', 'accordion', 'racquet']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict relation = ['belong to', 'is a', 'loyal', 'important', 'easy', 'fast', 'related to', 'popular', 'used for', 'trustworthy', 'convenient', 'part of', 'comfortable', 'good', 'active']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict fact = ['play game', 'video game', 'video game console']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - suppord fact predict = ['video game-belong to', 'play game-used for', 'video game console-belong to', 'video game-related to']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - correspond target = ['wii', 'kite', 'laptop', 'computer']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - test id = 709, question = What do you need in your hand if you want to fly this thing?, img = COCO_val2014_000000004688.jpg\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - real suppord fact in dataset=['kite', 'related to', 'string'], real answer = kite\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - normal model predict = ['grass', 'throw', 'ski slope', 'helmet', 'bird', 'fence', 'entertain yourself on windy day', 'snow', 'use twice day', 'squirrel']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict = ['person', 'computer', 'grass', 'throw', 'ski slope', 'helmet', 'bird', 'fence', 'entertain yourself on windy day', 'snow']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict relation = ['related to', 'used for', 'at location', 'desires', 'specific', 'capable of', 'receives action', 'belong to', 'animal order', 'accurate', 'important', 'human', 'hot', 'surface', 'has a']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict fact = ['fortune to smile on them', 'help person', 'make human life easy']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - suppord fact predict = ['make human life easy-used for', 'fortune to smile on them-desires', 'help person-capable of']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - correspond target = ['computer', 'person']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - test id = 839, question = What can be found in this place?, img = ILSVRC2012_test_00007959.JPEG\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - real suppord fact in dataset=['rice cooker', 'at location', 'kitchen'], real answer = rice cooker\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - normal model predict = ['knife in drawer', 'kitchen utensil', 'toilet paper', 'use toilet', 'cup', 'toilet', 'large container', 'toilet seat', 'shelf', 'metal']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict = ['knife in drawer', 'kitchen utensil', 'toilet paper', 'cup', 'large container', 'kitchen table', 'cooking', 'oven', 'microwave', 'house']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict relation = ['at location', 'part of', 'used for', 'has a', 'receives action', 'related to', 'animal order', 'specific', 'animal family', 'social', 'frequent', 'belong to', 'created by', 'human', 'great']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict fact = ['kitchen', 'room', 'restaurant kitchen']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - suppord fact predict = ['kitchen-at location', 'kitchen-used for', 'restaurant kitchen-at location', 'room-at location', 'kitchen-belong to']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - correspond target = ['kitchen table', 'kitchen utensil', 'oven', 'toilet paper', 'knife in drawer', 'house', 'microwave', 'cup', 'cooking', 'large container']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - test id = 388, question = What in this image is made by cooking?, img = COCO_val2014_000000007107.jpg\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - real suppord fact in dataset=['donut', 'belong to', 'cooking'], real answer = donut\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - normal model predict = ['donut', 'doughnut', 'bread', 'cake', 'toast bread', 'bakery', 'sandwich', 'chocolate', 'fry bread', 'bagel']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict = ['oven', 'cheese', 'stove', 'kitchen', 'microwave', 'donut', 'doughnut', 'bread', 'cake', 'toast bread']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict relation = ['used for', 'receives action', 'has property', 'created by', 'related to', 'belong to', 'capable of', 'at location', 'part of', 'effective', 'specific', 'protected', 'animal order', 'desires', 'is a']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict fact = ['cook', 'cook meal', 'cook dinner']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - suppord fact predict = ['cook meal-used for', 'cook dinner-used for', 'cook-used for']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - correspond target = ['oven', 'kitchen', 'microwave', 'stove', 'cheese']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - test id = 2198, question = Which object in this image is favored by geeks?, img = COCO_val2014_000000124911.jpg\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - real suppord fact in dataset=['geek', 'related to', 'computer'], real answer = computer\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - normal model predict = ['computer', 'desk', 'couch', 'bed', 'laptop', 'pillows', 'dining table', 'chair', 'glass', 'sofa']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict = ['piano', 'trumpet', 'violin', 'computer', 'desk', 'couch', 'bed', 'laptop', 'pillows', 'dining table']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict relation = ['has property', 'related to', 'created by', 'used for', 'belong to', 'receives action', 'specific', 'desires', 'part of', 'social', 'protected', 'green', 'firm', 'at location', 'popular']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict fact = ['violinist', 'musician', 'pianist']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - suppord fact predict = ['musician-related to', 'violinist-related to', 'pianist-related to']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - correspond target = ['violin', 'piano', 'trumpet']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:57 - 0:01:15 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - test id = 1805, question = What can maul you to death?, img = COCO_val2014_000000008401.jpg\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - real suppord fact in dataset=['bear', 'is a', 'dangerous animal'], real answer = bear\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - normal model predict = ['animal', 'carnivora', 'tick', 'bear', 'human', 'ant', 'zoo', 'herd sheep', 'mammal', 'even toed ungulate']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict = ['elephant', 'throw', 'computer', 'hammer', 'axe', 'kite', 'animal', 'carnivora', 'tick', 'bear']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict relation = ['capable of', 'related to', 'used for', 'at location', 'has a', 'is a', 'animal order', 'desires', 'specific', 'has property', 'receives action', 'accurate', 'human', 'important', 'belong to']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict fact = ['person', 'help person', 'hurt person']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - suppord fact predict = ['hurt person-capable of', 'person-has property', 'person-capable of', 'hurt person-used for', 'help person-capable of']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - correspond target = ['axe', 'throw', 'computer', 'elephant', 'kite', 'hammer']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - test id = 1854, question = Which object in this image belongs to the class Bromeliaceae cultivar?, img = ILSVRC2012_test_00047632.JPEG\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - real suppord fact in dataset=['pineapple', 'belong to', 'bromeliaceae cultivar'], real answer = pineapple\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - normal model predict = ['fruit', 'banana', 'strawberry', 'pineapple', 'basket', 'fig', 'vegetable', 'donut', 'potted plant', 'pomegranate']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict = ['fruit', 'banana', 'strawberry', 'pineapple', 'basket', 'fig', 'vegetable', 'donut', 'potted plant', 'pomegranate']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict relation = ['belong to', 'desires', 'is a', 'related to', 'animal order', 'animal kingdom', 'animal phylum', 'at location', 'animal class', 'important', 'specific', 'animal family', 'sensible', 'human', 'trustworthy']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - our model predict fact = ['study archeology', 'developmental biology', 'leave on their branch']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - suppord fact predict = ['developmental biology-belong to']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - correspond target = ['fruit']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:15 - #################################################################################\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:42<00:19,  1.41it/s]INFO - 08/13/22 23:30:57 - 0:01:16 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - test id = 113, question = Which thing in this image can be found in your shoes?, img = COCO_val2014_000000022118.jpg\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - real suppord fact in dataset=['sand', 'at location', 'your shoe'], real answer = sand\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - normal model predict = ['sand', 'person', 'kite', 'ray', 'sandy', 'surf board', 'beach', 'frisbee', 'umbrella', 'chess board']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict = ['person', 'sunglasses', 'handbag', 'bow tie', 'short', 'shirt', 'sand', 'kite', 'ray', 'sandy']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict relation = ['at location', 'belong to', 'related to', 'desires', 'used for', 'specific', 'has property', 'receives action', 'visible', 'protected', 'animal order', 'created by', 'primitive', 'social', 'active']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict fact = ['clothing', 'fashion', 'comfortable shoe']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - suppord fact predict = ['clothing-belong to', 'comfortable shoe-desires', 'fashion-belong to']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - correspond target = ['handbag', 'short', 'bow tie', 'person', 'sunglasses', 'shirt']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - test id = 2011, question = What does this dog have?, img = COCO_val2014_000000145815.jpg\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - real suppord fact in dataset=['this dog', 'has a', 'frisbee'], real answer = frisbee\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - normal model predict = ['ski', 'ski slope', 'snowboard', 'dog', 'hair', 'mountain', 'rabbit', 'skiiers', 'snow', 'bear']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict = ['dog', 'hair', 'cat', 'animal', 'human', 'herd sheep', 'kitten', 'mouse', 'any place where person live', 'person']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict relation = ['has a', 'belong to', 'has property', 'related to', 'used for', 'at location', 'is a', 'receives action', 'desires', 'animal order', 'independent', 'part of', 'good', 'capable of', 'specific']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict fact = ['dog', 'cat', 'pet cat']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - suppord fact predict = ['dog-used for', 'dog-independent', 'cat-independent', 'dog-good', 'cat-at location', 'dog-has a', 'pet cat-desires', 'dog-belong to', 'cat-is a', 'cat-capable of', 'cat-belong to']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - correspond target = ['cat', 'animal', 'dog', 'herd sheep', 'hair', 'person', 'human', 'mouse', 'kitten', 'any place where person live']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - test id = 593, question = Which object in this image is similar to a tortoise?, img = ILSVRC2012_test_00011888.JPEG\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - real suppord fact in dataset=['turtle', 'has property', 'similar to tortoise'], real answer = turtle\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - normal model predict = ['turtle', 'elephant', 'lizard', 'giraffe', 'frog', 'hippopotamus', 'zebra', 'jellyfish', 'dolphin', 'whale']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict = ['shell', 'cat', 'feather', 'airplane', 'kite', 'low', 'turtle', 'elephant', 'lizard', 'giraffe']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict relation = ['related to', 'is a', 'capable of', 'has a', 'belong to', 'used for', 'has property', 'blind', 'important', 'desires', 'specific', 'part of', 'big', 'common', 'long']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict fact = ['bird', 'turtle', 'chase bird']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - suppord fact predict = ['chase bird-desires', 'turtle-has a', 'bird-related to', 'bird-has a', 'turtle-has property', 'bird-is a']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - correspond target = ['airplane', 'cat', 'feather', 'shell', 'low', 'kite']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - test id = 978, question = Which object in this image is related to music, img = ILSVRC2012_test_00053657.JPEG\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - real suppord fact in dataset=['violin', 'related to', 'music'], real answer = violin\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - normal model predict = ['cello', 'violin', 'guitar', 'piano', 'drum', 'like violin but large', 'flute', 'bow', 'metronome', 'scissors']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict = ['guitar', 'scissors', 'wood', 'cello', 'violin', 'piano', 'drum', 'like violin but large', 'flute', 'bow']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict relation = ['related to', 'specific', 'used for', 'belong to', 'important', 'common', 'part of', 'at location', 'social', 'animal order', 'accurate', 'prevalent', 'frequent', 'has a', 'capable of']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict fact = ['luthier', 'pearwood', 'sew']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - suppord fact predict = ['sew-belong to', 'luthier-related to', 'pearwood-related to']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - correspond target = ['guitar', 'scissors', 'wood']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - test id = 2716, question = Where does the animal in the middle of the image can be found in?, img = COCO_val2014_000000119581.jpg\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - real suppord fact in dataset=['cat', 'at location', 'any place where person live'], real answer = any place where person live\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - normal model predict = ['dog', 'hot dog', 'bed', 'hotel room', 'mountainous area', 'zoo', 'africa', 'hot room', 'bathroom', 'bedroom']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict = ['zoo', 'animal', 'cat', 'human', 'hair', 'herd sheep', 'dog', 'hot dog', 'bed', 'hotel room']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict relation = ['at location', 'capable of', 'has a', 'is a', 'used for', 'part of', 'has property', 'belong to', 'active', 'human', 'animal family', 'great', 'visible', 'surface', 'good']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict fact = ['monkey', 'kitten', 'dog']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - suppord fact predict = ['dog-used for', 'dog-good', 'dog-has a', 'dog-belong to', 'kitten-has a', 'monkey-at location']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - correspond target = ['cat', 'animal', 'herd sheep', 'zoo', 'hair', 'human']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - test id = 2579, question = what kind of transportation is cheeper than the object in the middle of this image, img = COCO_val2014_000000102056.jpg\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - real suppord fact in dataset=['bus', 'cheap', 'taxi'], real answer = taxi\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - normal model predict = ['bus', 'taxi', 'train', 'truck', 'car', 'food', 'donut', 'road', 'train station', 'transport']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict = ['bus', 'train', 'flight', 'cheap', 'bicycle', 'motorcycle', 'station', 'airplane', 'taxi', 'truck']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict relation = ['cheap', 'is a', 'fast', 'at location', 'animal family', 'animal class', 'safe', 'animal order', 'animal kingdom', 'belong to', 'good', 'small', 'important', 'easy', 'convenient']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict fact = ['car', 'automobile', 'train']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - suppord fact predict = ['train-at location', 'car-safe', 'train-fast', 'automobile-safe', 'automobile-small', 'train-cheap', 'car-fast', 'car-small', 'train-convenient']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - correspond target = ['airplane', 'bus', 'cheap', 'motorcycle', 'bicycle', 'station', 'train', 'flight']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - #################################################################################\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - test id = 543, question = What seen here may be placed in a cargo bin?, img = COCO_val2014_000000112022.jpg\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - real suppord fact in dataset=['cargo bin', 'related to', 'luggage'], real answer = luggage\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - normal model predict = ['luggage', 'car', 'skateboard', 'bicycle', 'taxi', 'bottle', 'ride', 'handbag', 'gift shop', 'bus']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict = ['train', 'airplane', 'luggage', 'car', 'skateboard', 'bicycle', 'taxi', 'bottle', 'ride', 'handbag']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict relation = ['used for', 'is a', 'at location', 'has a', 'capable of', 'belong to', 'receives action', 'part of', 'good', 'convenient', 'animal order', 'cool', 'great', 'fast', 'surface']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - our model predict fact = ['cargo bin', 'carry freight or cargo', 'carry freight']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - suppord fact predict = ['carry freight or cargo-used for', 'carry freight-capable of']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - correspond target = ['train', 'airplane']\n",
      "INFO - 08/13/22 23:30:57 - 0:01:16 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████▍            | 63/89 [00:43<00:19,  1.35it/s]INFO - 08/13/22 23:30:58 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - test id = 1621, question = What is the class of the animal presented in this image?, img = ILSVRC2012_test_00017099.JPEG\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - real suppord fact in dataset=['nail', 'animal class', 'gastropoda'], real answer = gastropoda\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - normal model predict = ['donut', 'doughnut', 'nail', 'fig', 'chocolate', 'cake', 'bakery', 'strawberry', 'fruit', 'pretzel']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict = ['green', 'mammal', 'carnivora', 'wild', 'donut', 'doughnut', 'nail', 'fig', 'chocolate', 'cake']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict relation = ['has property', 'is a', 'related to', 'belong to', 'has a', 'animal class', 'animal family', 'animal order', 'safe', 'animal kingdom', 'at location', 'common', 'important', 'light', 'fast']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict fact = ['frog', 'otter', 'fox']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - suppord fact predict = ['otter-animal order', 'fox-animal class', 'otter-animal class', 'frog-at location', 'frog-has property', 'fox-animal order']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - correspond target = ['wild', 'green', 'mammal', 'carnivora']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - test id = 2477, question = what does the object held in the man's hand has, img = ILSVRC2012_test_00024564.JPEG\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - real suppord fact in dataset=['guitar', 'has a', 'string'], real answer = string\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - normal model predict = ['guitar', 'violin', 'cello', 'harmonica', 'trumpet', 'piano', 'trombone', 'banjo', 'flute', 'saxophone']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict = ['kite', 'tennis ball', 'dog', 'guitar', 'violin', 'cello', 'harmonica', 'trumpet', 'piano', 'trombone']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict relation = ['at location', 'related to', 'used for', 'capable of', 'has a', 'part of', 'belong to', 'is a', 'good', 'specific', 'animal order', 'receives action', 'important', 'accurate', 'great']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict fact = ['shake hand', \"child's hand\", 'hit with racket']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - suppord fact predict = [\"child's hand-at location\", 'hit with racket-used for', 'shake hand-capable of']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - correspond target = ['kite', 'tennis ball', 'dog']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - test id = 2183, question = What is the place in this image usually used for?, img = ILSVRC2012_test_00004006.JPEG\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - real suppord fact in dataset=['market', 'used for', 'buy and sell'], real answer = buy and sell\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - normal model predict = ['travel', 'travel in car', 'sleep away from home', 'space to run and play', 'travel across water', 'protect person from sun and rain', 'entertain yourself on windy day', 'any place where person live', 'play music', 'buy and sell']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict = ['travel', 'work', 'transport', 'car', 'tall build', 'cat', 'computer', 'pen', 'window', 'monitor']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict relation = ['used for', 'capable of', 'receives action', 'has property', 'effective', 'at location', 'animal order', 'high', 'good', 'is a', 'part of', 'efficient', 'has a', 'fast', 'animal class']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict fact = ['office', 'purr', 'road']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - suppord fact predict = ['road-at location', 'office-used for', 'office-has a', 'office-at location', 'purr-capable of', 'road-used for']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - correspond target = ['pen', 'cat', 'tall build', 'computer', 'transport', 'monitor', 'window', 'work', 'car', 'travel']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - test id = 2552, question = Which object in this image is related to raster graphics?, img = ILSVRC2012_test_00055834.JPEG\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - real suppord fact in dataset=['raster graphic', 'related to', 'monitor'], real answer = monitor\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - normal model predict = ['computer', 'monitor', 'mouse', 'printer', 'laptop', 'desk', 'ipod', 'keyboard', 'wall', 'cell phone']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict = ['computer', 'laptop', 'wii', 'monitor', 'mouse', 'printer', 'desk', 'ipod', 'keyboard', 'wall']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict relation = ['related to', 'belong to', 'specific', 'used for', 'important', 'common', 'social', 'part of', 'animal order', 'prevalent', 'desires', 'at location', 'is a', 'has property', 'accurate']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict fact = ['video game', 'desktop', 'desktop computer']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - suppord fact predict = ['video game-belong to', 'desktop-prevalent', 'video game-related to', 'desktop-related to']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - correspond target = ['wii', 'laptop', 'computer']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - test id = 688, question = What stuffed animal is seen here?, img = COCO_val2014_000000108484.jpg\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - real suppord fact in dataset=['teddy bear', 'is a', 'stuff animal'], real answer = teddy bear\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - normal model predict = ['dog', 'rabbit', 'giraffe', 'teddy bear', 'cat', 'hot dog', 'dog poop', 'monkey', 'animal', 'bear']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict = ['dog', 'cat', 'animal', 'elephant', 'herd sheep', 'horse', 'human', 'hair', 'person', 'rabbit']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict relation = ['is a', 'belong to', 'has a', 'related to', 'at location', 'has property', 'part of', 'used for', 'important', 'capable of', 'good', 'receives action', 'cool', 'independent', 'created by']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict fact = ['dog', 'pet animal', 'big animal']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - suppord fact predict = ['dog-used for', 'dog-good', 'dog-independent', 'big animal-is a', 'dog-has a', 'dog-belong to', 'pet animal-related to', 'pet animal-has a']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - correspond target = ['cat', 'animal', 'horse', 'dog', 'herd sheep', 'hair', 'elephant', 'person', 'human']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - test id = 553, question = what can we find in the place shown in this image, img = COCO_val2014_000000120747.jpg\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - real suppord fact in dataset=['human', 'at location', 'room'], real answer = human\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - normal model predict = ['cup', 'house', 'furniture', 'kitchen table', 'kitchen', 'monitor', 'your house', 'wall', 'chair', 'dining table']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict = ['house', 'furniture', 'wall', 'chair', 'couch', 'toilet paper', 'toilet seat', 'wash', 'use toilet', 'clean your tooth in']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict relation = ['at location', 'used for', 'part of', 'has a', 'related to', 'animal order', 'belong to', 'receives action', 'specific', 'animal family', 'created by', 'capable of', 'social', 'convenient', 'active']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict fact = ['room', 'living room', 'bathroom']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - suppord fact predict = ['bathroom-used for', 'room-at location', 'bathroom-at location', 'room-has a']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - correspond target = ['wall', 'use toilet', 'toilet paper', 'house', 'furniture', 'couch', 'chair', 'toilet seat', 'wash', 'clean your tooth in']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - test id = 2372, question = Which animal in this image like nuts, img = COCO_val2014_000000015070.jpg\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - real suppord fact in dataset=['squirrel', 'desires', 'nut'], real answer = squirrel\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - normal model predict = ['cat', 'dog', 'kitten', 'rabbit', 'squirrel', 'monkey', 'skunk', 'otter', 'apple', 'dog poop']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict = ['cat', 'dog', 'kitten', 'animal', 'mouse', 'hair', 'human', 'person', 'herd sheep', 'rabbit']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict relation = ['desires', 'capable of', 'related to', 'has a', 'is a', 'specific', 'part of', 'has property', 'used for', 'long', 'important', 'belong to', 'independent', 'good', 'human']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict fact = ['cat', 'dog', 'pet cat']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - suppord fact predict = ['dog-used for', 'dog-independent', 'cat-independent', 'dog-good', 'pet cat-desires', 'dog-has a', 'cat-long', 'dog-belong to', 'cat-is a', 'cat-capable of', 'cat-belong to']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - correspond target = ['cat', 'animal', 'dog', 'herd sheep', 'hair', 'mouse', 'person', 'kitten', 'human']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - test id = 929, question = Which game of physical skill is shown here?, img = ILSVRC2012_test_00020186.JPEG\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - real suppord fact in dataset=['ping pong', 'belong to', 'games of physical skill'], real answer = ping pong\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - normal model predict = ['tennis ball', 'baseball', 'golf ball', 'computer', 'basketball', 'volleyball', 'soccer ball', 'frisbee', 'ball', 'wii']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict = ['baseball', 'golf ball', 'volleyball', 'tennis racket', 'rugby ball', 'balance beam', 'racket', 'skateboard', 'punching bag', 'bicycle']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict relation = ['is a', 'belong to', 'capable of', 'important', 'used for', 'part of', 'easy', 'has property', 'has a', 'fast', 'sweet', 'good', 'common', 'popular', 'tough']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - our model predict fact = ['sport game', 'team sport', 'sports equipment']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - suppord fact predict = ['sport game-is a', 'team sport-is a', 'sports equipment-belong to']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - correspond target = ['golf ball', 'balance beam', 'rugby ball', 'skateboard', 'tennis racket', 'bicycle', 'volleyball', 'racket', 'baseball', 'punching bag']\n",
      "INFO - 08/13/22 23:30:58 - 0:01:17 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████▉            | 64/89 [00:44<00:19,  1.26it/s]INFO - 08/13/22 23:30:59 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - test id = 447, question = What is the place in this image used for moving?, img = COCO_val2014_000000123555.jpg\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - real suppord fact in dataset=['road', 'used for', 'travel'], real answer = road\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - normal model predict = ['car', 'driving', 'traffic light', 'road', 'bicycle', 'travel in car', 'bus', 'vehicle', 'ride', 'street']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict = ['car', 'traffic light', 'travel', 'transport', 'turtle', 'driving', 'road', 'bicycle', 'travel in car', 'bus']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict relation = ['used for', 'related to', 'capable of', 'belong to', 'specific', 'important', 'easy', 'accurate', 'effective', 'at location', 'receives action', 'animal order', 'good', 'efficient', 'common']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict fact = ['road', 'road traffic control', 'slow mover']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - suppord fact predict = ['road-at location', 'slow mover-related to', 'road-used for', 'road traffic control-belong to']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - correspond target = ['traffic light', 'turtle', 'transport', 'car', 'travel']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - test id = 1249, question = Which object in this image is an animal?, img = ILSVRC2012_test_00002108.JPEG\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - real suppord fact in dataset=['antelope', 'belong to', 'animal'], real answer = antelope\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - normal model predict = ['sheep', 'frisbee', 'rabbit', 'horse', 'dog', 'teddy bear', 'cow', 'giraffe', 'zebra', 'herd sheep']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict = ['sheep', 'horse', 'dog', 'cow', 'giraffe', 'zebra', 'squirrel', 'frog', 'camel', 'person']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict relation = ['is a', 'belong to', 'used for', 'has property', 'has a', 'related to', 'cool', 'easy', 'safe', 'animal class', 'part of', 'convenient', 'popular', 'dangerous', 'at location']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict fact = ['animal', 'pet animal', 'woolly animal']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - suppord fact predict = ['animal-related to', 'animal-is a', 'pet animal-related to', 'woolly animal-related to', 'pet animal-has a', 'animal-belong to']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - correspond target = ['horse', 'dog', 'camel', 'zebra', 'sheep', 'squirrel', 'frog', 'giraffe', 'person', 'cow']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - test id = 116, question = Which object in this image is gritty?, img = COCO_val2014_000000022118.jpg\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - real suppord fact in dataset=['sand', 'has property', 'gritty'], real answer = sand\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - normal model predict = ['sand', 'beach', 'sandy', 'surf board', 'frisbee', 'water', 'clock', 'lot of sand', 'ray', 'golf ball']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict = ['tennis ball', 'skateboard', 'child', 'motorcycle', 'sand', 'beach', 'sandy', 'surf board', 'frisbee', 'water']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict relation = ['has property', 'belong to', 'related to', 'is a', 'has a', 'desires', 'protected', 'important', 'created by', 'receives action', 'specific', 'strong', 'visible', 'at location', 'firm']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict fact = ['hollow', 'subculture', 'boardsport']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - suppord fact predict = ['subculture-belong to', 'hollow-has property', 'boardsport-belong to']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - correspond target = ['motorcycle', 'tennis ball', 'child', 'skateboard']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - test id = 2330, question = What objects in this image are inspirational, img = ILSVRC2012_test_00035105.JPEG\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - real suppord fact in dataset=['forest road', 'has property', 'inspirational'], real answer = forest road\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - normal model predict = ['stop sign', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car', 'bus', 'person']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict = ['stop sign', 'horse', 'tv', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict relation = ['capable of', 'is a', 'has property', 'receives action', 'has a', 'used for', 'related to', 'part of', 'desires', 'at location', 'belong to', 'created by', 'specific', 'good', 'animal order']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict fact = ['traffic sign', 'clop', 'advertise']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - suppord fact predict = ['advertise-used for', 'traffic sign-belong to', 'clop-related to']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - correspond target = ['stop sign', 'tv', 'horse']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - test id = 59, question = Which object in this image is related to whey?, img = COCO_val2014_000000114108.jpg\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - real suppord fact in dataset=['whey', 'related to', 'cheese'], real answer = cheese\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - normal model predict = ['pizza', 'cheese', 'knife', 'salad', 'plate', 'italian', 'bread', 'cake', 'lobster', 'knife in drawer']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict = ['pizza', 'mushroom', 'pomegranate', 'cheese', 'knife', 'salad', 'plate', 'italian', 'bread', 'cake']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict relation = ['related to', 'belong to', 'specific', 'important', 'part of', 'used for', 'common', 'at location', 'animal order', 'social', 'has property', 'accurate', 'prevalent', 'capable of', 'is a']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict fact = ['italy', 'toadstool', 'grenadine']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - suppord fact predict = ['toadstool-related to', 'italy-belong to', 'grenadine-related to']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - correspond target = ['pizza', 'mushroom', 'pomegranate']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - test id = 1193, question = which kind of fruit in this image is smaller than watermellon, img = COCO_val2014_000000019167.jpg\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - real suppord fact in dataset=['watermelon', 'big', 'orange'], real answer = orange\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - normal model predict = ['strawberry', 'fruit', 'banana', 'chocolate', 'orange', 'apple', 'lemon', 'pineapple', 'donut', 'vegetable']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict = ['strawberry', 'apple', 'lemon', 'pineapple', 'pomegranate', 'fruit', 'banana', 'chocolate', 'orange', 'donut']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict relation = ['small', 'big', 'large', 'popular', 'green', 'sweet', 'is a', 'red', 'fat', 'long', 'colorful', 'warm', 'cheap', 'healthy', 'soft']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict fact = ['fruit', 'grape juice', 'cherry']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - suppord fact predict = ['fruit-is a']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - correspond target = ['apple', 'strawberry', 'pineapple', 'pomegranate', 'lemon']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - test id = 1509, question = Which object in this image can used for protecting people, img = COCO_val2014_000000016730.jpg\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - real suppord fact in dataset=['dog', 'used for', 'safty'], real answer = dog\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - normal model predict = ['sink', 'toothbrush', 'suitcase', 'fence', 'wall', 'blanket', 'refrigerator', 'shelf', 'bottle', 'bed']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict = ['suitcase', 'helmet', 'hat', 'sink', 'toothbrush', 'fence', 'wall', 'blanket', 'refrigerator', 'shelf']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict relation = ['used for', 'related to', 'capable of', 'specific', 'belong to', 'effective', 'accurate', 'efficient', 'easy', 'receives action', 'important', 'is a', 'has property', 'good', 'part of']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict fact = ['protect your head', 'carry your clothe', 'protect head']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - suppord fact predict = ['carry your clothe-used for', 'protect your head-used for', 'protect head-used for']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - correspond target = ['suitcase', 'hat', 'helmet']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:30:59 - 0:01:17 - #################################################################################\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - test id = 2592, question = Which object in this image is an animal?, img = ILSVRC2012_test_00002108.JPEG\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - real suppord fact in dataset=['antelope', 'belong to', 'animal'], real answer = antelope\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - normal model predict = ['sheep', 'frisbee', 'rabbit', 'horse', 'dog', 'teddy bear', 'cow', 'giraffe', 'zebra', 'herd sheep']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict = ['sheep', 'horse', 'dog', 'cow', 'giraffe', 'zebra', 'squirrel', 'frog', 'camel', 'person']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict relation = ['is a', 'belong to', 'used for', 'has property', 'has a', 'related to', 'cool', 'easy', 'safe', 'animal class', 'part of', 'convenient', 'popular', 'dangerous', 'at location']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - our model predict fact = ['animal', 'pet animal', 'woolly animal']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - suppord fact predict = ['animal-related to', 'animal-is a', 'pet animal-related to', 'woolly animal-related to', 'pet animal-has a', 'animal-belong to']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - correspond target = ['horse', 'dog', 'camel', 'zebra', 'sheep', 'squirrel', 'frog', 'giraffe', 'person', 'cow']\n",
      "INFO - 08/13/22 23:30:59 - 0:01:17 - #################################################################################\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:45<00:17,  1.36it/s]INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 1181, question = What in this image is related to settee?, img = ILSVRC2012_test_00002135.JPEG\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['settee', 'related to', 'sofa'], real answer = sofa\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['couch', 'sofa', 'bed', 'bedroom', 'pillows', 'sleep', 'baby bed', 'dining table', 'furniture', 'monitor']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['ray', 'elephant', 'trombone', 'couch', 'sofa', 'bed', 'bedroom', 'pillows', 'sleep', 'baby bed']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['related to', 'specific', 'belong to', 'used for', 'important', 'part of', 'common', 'animal order', 'social', 'at location', 'capable of', 'accurate', 'receives action', 'prevalent', 'frequent']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['batoidea', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['batoidea-belong to', 'therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['trombone', 'ray', 'elephant']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 1619, question = What is the tool in the image used in forestry occupations?, img = ILSVRC2012_test_00010774.JPEG\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['axe', 'belong to', 'forestry occupations'], real answer = axe\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['hammer', 'screwdriver', 'scissors', 'ruler', 'hand', 'knife', 'axe', 'corkscrew', 'mouth', 'bow']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['hammer', 'snake', 'elephant', 'screwdriver', 'scissors', 'ruler', 'hand', 'knife', 'axe', 'corkscrew']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['used for', 'belong to', 'at location', 'related to', 'has property', 'capable of', 'receives action', 'is a', 'specific', 'easy', 'convenient', 'has a', 'important', 'fast', 'animal order']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['pound in nail', 'knock', 'india']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['knock-related to', 'pound in nail-used for', 'india-at location']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['elephant', 'snake', 'hammer']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 391, question = Which object in this image is related to clop?, img = COCO_val2014_000000140542.jpg\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['clop', 'related to', 'horse'], real answer = horse\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['horse', 'cow', 'cattle', 'sheep', 'wood', 'herd sheep', 'wooden', 'camel', 'dog', 'fence']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['cow', 'camel', 'desert', 'hump', 'work for day without water', 'horse', 'cattle', 'sheep', 'wood', 'herd sheep']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['related to', 'specific', 'belong to', 'important', 'used for', 'common', 'social', 'at location', 'animal order', 'part of', 'accurate', 'capable of', 'frequent', 'prevalent', 'is a']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['dromedary', 'cattle', 'camel']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['cattle-belong to', 'camel-at location', 'camel-capable of', 'dromedary-related to', 'camel-related to', 'cattle-related to']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['desert', 'camel', 'work for day without water', 'hump', 'cow']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 521, question = What can be found in this place?, img = COCO_val2014_000000119961.jpg\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['cow', 'at location', 'pasture'], real answer = cow\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['horse', 'cow', 'dog poop', 'camel', 'animal', 'dog', 'sheep', 'herd sheep', 'cattle', 'lot of sand']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['house', 'build', 'hammer', 'cat', 'horse', 'cow', 'dog poop', 'camel', 'animal', 'dog']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['at location', 'has a', 'used for', 'related to', 'is a', 'part of', 'capable of', 'specific', 'has property', 'animal order', 'receives action', 'animal family', 'belong to', 'social', 'human']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['place', 'construction site', 'suburb']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['place-belong to', 'place-at location', 'construction site-at location', 'suburb-at location']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['house', 'cat', 'build', 'hammer']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 177, question = Which food in this image is full of vitamin C, img = COCO_val2014_000000016161.jpg\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['orange', 'has property', 'full of vitamin c'], real answer = orange\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['banana', 'apple', 'orange', 'lemon', 'chocolate', 'pare apple', 'pineapple', 'carrot', 'cake', 'sweet and juicy']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['banana', 'apple', 'orange', 'lemon', 'chocolate', 'pare apple', 'pineapple', 'carrot', 'cake', 'sweet and juicy']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['has property', 'related to', 'is a', 'has a', 'used for', 'acid', 'good', 'at location', 'common', 'light', 'acidic', 'belong to', 'specific', 'animal family', 'receives action']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['vitamin pill', 'source of potassium', 'potassium']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['potassium-has a', 'source of potassium-has property', 'vitamin pill-good']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['banana', 'apple']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 2126, question = Which object is easier than guitar in this image?, img = ILSVRC2012_test_00027147.JPEG\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['drum', 'easy', 'guitar'], real answer = drum\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['drum', 'guitar', 'bottle', 'person', 'saxophone', 'track', 'piano', 'metronome', 'your house', 'metal']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['trombone', 'violin', 'drum', 'guitar', 'bottle', 'person', 'saxophone', 'track', 'piano', 'metronome']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['is a', 'used for', 'capable of', 'fast', 'strong', 'easy', 'sweet', 'tall', 'related to', 'belong to', 'powerful', 'convenient', 'safe', 'common', 'soft']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['cello', 'instrument use to make music', 'violin']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['cello-related to', 'instrument use to make music-is a']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['trombone', 'violin']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 909, question = Which object in this image might require a boarding pass?, img = COCO_val2014_000000006789.jpg\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['train', 'capable of', 'require board pass'], real answer = train\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['traffic light', 'bus', 'railroad track', 'road', 'train', 'driving', 'car', 'ride', 'track', 'light']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['bus', 'person', 'dog', 'traffic light', 'railroad track', 'road', 'train', 'driving', 'car', 'ride']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['related to', 'capable of', 'has a', 'part of', 'is a', 'specific', 'belong to', 'used for', 'has property', 'common', 'visible', 'important', 'receives action', 'animal order', 'large']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['board train', 'train to catch', 'travel between bus stop']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['board train-capable of', 'train to catch-receives action', 'travel between bus stop-used for']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['bus', 'person', 'dog']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 988, question = which object in this image belongs to the category 'aerospace'?, img = COCO_val2014_000000100404.jpg\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['airplane', 'belong to', 'aerospace'], real answer = airplane\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['grass', 'kite', 'coast', 'rain', 'protect person from sun and rain', 'desert', 'horse', 'sand', 'jellyfish', 'sea']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['whale', 'grass', 'kite', 'coast', 'rain', 'protect person from sun and rain', 'desert', 'horse', 'sand', 'jellyfish']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['belong to', 'related to', 'desires', 'trustworthy', 'specific', 'loyal', 'important', 'animal phylum', 'animal kingdom', 'is a', 'animal order', 'sensible', 'protected', 'capable of', 'visible']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['ocean', 'marine mammal', 'in ocean']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['marine mammal-belong to', 'marine mammal-is a']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['whale']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:45<00:15,  1.45it/s]INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 2277, question = what's shown in the image?, img = ILSVRC2012_test_00002135.JPEG\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['sofa', 'at location', 'house'], real answer = sofa\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['couch', 'sofa', 'bedroom', 'monitor', 'bed', 'tv', 'pillows', 'chair', 'baby bed', 'furniture']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['couch', 'chair', 'furniture', 'wall', 'house', 'park space', 'human', 'person', 'sofa', 'bedroom']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['part of', 'is a', 'has a', 'at location', 'related to', 'used for', 'capable of', 'good', 'belong to', 'has property', 'animal order', 'receives action', 'important', 'great', 'fast']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['living room', 'room', 'dorm room']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['room-at location', 'room-has a', 'room-important']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['wall', 'house', 'furniture', 'couch', 'park space', 'chair', 'person', 'human']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 61, question = Which animal in this image belongs to the category Herpetology?, img = ILSVRC2012_test_00002980.JPEG\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['turtle', 'belong to', 'herpetology'], real answer = turtle\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['turtle', 'zebra', 'giraffe', 'lizard', 'frog', 'elephant', 'armadillo', 'baby', 'bird', 'desert']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['elephant', 'monkey', 'trombone', 'turtle', 'zebra', 'giraffe', 'lizard', 'frog', 'armadillo', 'baby']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['belong to', 'desires', 'is a', 'animal kingdom', 'loyal', 'animal phylum', 'related to', 'trustworthy', 'animal order', 'protected', 'sensible', 'visible', 'capable of', 'comfortable', 'human']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['primate', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['primate-is a', 'therapsida-belong to', 'tromboner-related to', 'primate-related to']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['trombone', 'monkey', 'elephant']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 1726, question = What thing shown is related to a lower jaw?, img = COCO_val2014_000000125291.jpg\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['low jaw', 'related to', 'mouth'], real answer = mouth\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['dog', 'wall', 'cat', 'hair', 'dog poop', 'sofa', 'bed', 'fence', 'animal', 'grass']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['clock', 'zoo', 'ruler', 'banana', 'dog', 'wall', 'cat', 'hair', 'dog poop', 'sofa']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['related to', 'belong to', 'specific', 'used for', 'capable of', 'important', 'good', 'is a', 'common', 'at location', 'accurate', 'part of', 'has a', 'easy', 'animal order']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['measuring instrument', 'measurement', 'monkey']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['monkey-related to', 'measuring instrument-belong to', 'monkey-at location', 'measurement-related to']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['banana', 'clock', 'zoo', 'ruler']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 1974, question = Which object in this image is a fish?, img = ILSVRC2012_test_00000980.JPEG\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['ray', 'belong to', 'fish by classification'], real answer = ray\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['ray', 'jellyfish', 'turtle', 'frog', 'lizard', 'snake', 'armadillo', 'fish', 'ant', 'lobster']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['jellyfish', 'goldfish', 'boat', 'cat', 'swim', 'ray', 'turtle', 'frog', 'lizard', 'snake']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['is a', 'belong to', 'related to', 'has a', 'part of', 'used for', 'cool', 'capable of', 'sweet', 'visible', 'important', 'easy', 'good', 'stable', 'common']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['not fish', 'fish', 'eat fish']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['fish-capable of', 'not fish-is a', 'eat fish-capable of', 'fish-related to', 'fish-belong to']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['jellyfish', 'cat', 'swim', 'boat', 'goldfish']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 2067, question = What in this image reminds you of the Roquefort?, img = COCO_val2014_000000020608.jpg\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['roquefort', 'related to', 'sheep'], real answer = sheep\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['grass', 'dog', 'dog poop', 'eat', 'park', 'cow', 'horse', 'cat', 'sheep', 'herd sheep']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['camel', 'giraffe', 'person', 'bread', 'grass', 'dog', 'dog poop', 'eat', 'park', 'cow']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['related to', 'used for', 'is a', 'belong to', 'at location', 'capable of', 'specific', 'has a', 'has property', 'important', 'part of', 'animal order', 'receives action', 'desires', 'accurate']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['truth', 'ruminant', 'pure truth']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['ruminant-is a', 'pure truth-desires', 'truth-important']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['bread', 'camel', 'giraffe', 'person']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 1059, question = What in this image belongs to the category Conservation and restoration?, img = ILSVRC2012_test_00002135.JPEG\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['sofa', 'belong to', 'conservation and restoration'], real answer = sofa\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['couch', 'sofa', 'bedroom', 'bed', 'monitor', 'sleep', 'pillows', 'baby bed', 'furniture', 'tv']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['child', 'person', 'couch', 'sofa', 'bedroom', 'bed', 'monitor', 'sleep', 'pillows', 'baby bed']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['belong to', 'desires', 'loyal', 'animal kingdom', 'animal phylum', 'animal order', 'trustworthy', 'is a', 'comfortable', 'protected', 'animal class', 'animal family', 'related to', 'human', 'sensible']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['family', 'follow it master', 'work refrigerator']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['work refrigerator-desires', 'family-belong to']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['person', 'child']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 2082, question = What is the another name of the electrical appliance on the left., img = COCO_val2014_000000107516.jpg\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['fridge', 'related to', 'refrigerator'], real answer = fridge\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['sink', 'lamp', 'mirror', 'cabinet', 'glass', 'light', 'monitor', 'button', 'bathroom', 'control']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['toaster', 'microwave', 'bedroom', 'sink', 'lamp', 'mirror', 'cabinet', 'glass', 'light', 'monitor']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['belong to', 'is a', 'part of', 'used for', 'at location', 'related to', 'receives action', 'animal order', 'animal class', 'specific', 'has property', 'animal family', 'has a', 'capable of', 'animal kingdom']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['your house', 'home appliances', 'electric appliance']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['home appliances-belong to', 'your house-at location', 'electric appliance-related to']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['microwave', 'bedroom', 'toaster']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 2745, question = Which electronic device can be found in this place?, img = ILSVRC2012_test_00024563.JPEG\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['printer', 'at location', 'home office'], real answer = printer\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['computer', 'spaceship', 'cell phone', 'bus', 'keyboard', 'truck', 'transport', 'beam', 'piano', 'printer']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['computer', 'keyboard', 'furniture', 'spaceship', 'cell phone', 'bus', 'truck', 'transport', 'beam', 'piano']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['at location', 'used for', 'belong to', 'has a', 'is a', 'visible', 'capable of', 'convenient', 'blind', 'primitive', 'part of', 'specific', 'frequent', 'surface', 'crowded']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['program', 'run program', 'housing']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['program-used for', 'housing-belong to', 'run program-capable of']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['keyboard', 'computer', 'furniture']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 599, question = What kind of roll can one see here?, img = ILSVRC2012_test_00002238.JPEG\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['bagel', 'is a', 'roll'], real answer = bagel\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['doughnut', 'flour', 'donut', 'shell', 'pretzel', 'bread', 'fry bread', 'plate', 'peel', 'cheese']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['donut', 'pretzel', 'fig', 'cup', 'fruit', 'vegetable', 'banana', 'broccoli', 'refrigerator', 'hotdog']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['belong to', 'is a', 'used for', 'related to', 'at location', 'important', 'has a', 'good', 'capable of', 'animal order', 'specific', 'receives action', 'common', 'easy', 'accurate']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['drink out of', 'eat food off plate', 'food and drink']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['food and drink-belong to', 'drink out of-used for']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['hotdog', 'fig', 'refrigerator', 'banana', 'broccoli', 'cup', 'pretzel', 'donut', 'vegetable', 'fruit']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - test id = 2335, question = What objects in this image are inspirational, img = ILSVRC2012_test_00035105.JPEG\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - real suppord fact in dataset=['forest road', 'has property', 'inspirational'], real answer = forest road\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - normal model predict = ['stop sign', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car', 'bus', 'person']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict = ['stop sign', 'horse', 'tv', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict relation = ['capable of', 'is a', 'has property', 'receives action', 'has a', 'used for', 'related to', 'part of', 'desires', 'at location', 'belong to', 'created by', 'specific', 'good', 'animal order']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - our model predict fact = ['traffic sign', 'clop', 'advertise']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - suppord fact predict = ['advertise-used for', 'traffic sign-belong to', 'clop-related to']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - correspond target = ['stop sign', 'tv', 'horse']\n",
      "INFO - 08/13/22 23:31:00 - 0:01:18 - #################################################################################\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:46<00:14,  1.49it/s]INFO - 08/13/22 23:31:01 - 0:01:19 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - test id = 2223, question = Which object in this image belongs to the class of Brassica?, img = COCO_val2014_000000121016.jpg\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - real suppord fact in dataset=['broccoli', 'belong to', 'brassica'], real answer = broccoli\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - normal model predict = ['broccoli', 'fork', 'meat', 'vegetable', 'cheese', 'zucchini', 'lettuce', 'cook food', 'spoon', 'chicken']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict = ['fork', 'meat', 'oven', 'kitchen', 'broccoli', 'vegetable', 'cheese', 'zucchini', 'lettuce', 'cook food']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict relation = ['belong to', 'is a', 'desires', 'easy', 'at location', 'animal kingdom', 'important', 'sensible', 'convenient', 'animal class', 'animal order', 'used for', 'related to', 'trustworthy', 'has property']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict fact = ['hold food', 'prepare food', 'sugar cure']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - suppord fact predict = ['hold food-used for', 'sugar cure-easy', 'prepare food-used for']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - correspond target = ['oven', 'kitchen', 'fork', 'meat']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - test id = 2178, question = Where could one sit and rest in this image?, img = COCO_val2014_000000140908.jpg\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - real suppord fact in dataset=['bench', 'used for', 'sit and rest'], real answer = bench\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - normal model predict = ['park', 'house', 'beach', 'mountain', 'police', 'your house', 'zoo', 'ski slope', 'apartment', 'mountainous area']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict = ['chair', 'track', 'park', 'house', 'beach', 'mountain', 'police', 'your house', 'zoo', 'ski slope']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict relation = ['at location', 'is a', 'capable of', 'has a', 'has property', 'used for', 'tall', 'related to', 'visible', 'stable', 'belong to', 'desires', 'fast', 'safe', 'convenient']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict fact = ['place to sit', 'comfortable to sit in', 'streets and roads']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - suppord fact predict = ['streets and roads-belong to', 'comfortable to sit in-has property', 'place to sit-is a']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - correspond target = ['track', 'chair']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:01 - 0:01:19 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - test id = 2340, question = what thing in this image can be used for reserving liquid, img = ILSVRC2012_test_00020499.JPEG\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - real suppord fact in dataset=['bottle', 'is a', 'fluid reservoir'], real answer = bottle\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - normal model predict = ['basket', 'vase', 'plate', 'bowl', 'shelf', 'oven', 'bird', 'sink', 'wood', 'shell']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict = ['spoon', 'computer', 'person', 'basket', 'vase', 'plate', 'bowl', 'shelf', 'oven', 'bird']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict relation = ['used for', 'capable of', 'related to', 'receives action', 'belong to', 'part of', 'specific', 'has property', 'is a', 'animal order', 'effective', 'good', 'created by', 'accurate', 'important']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict fact = ['make list', 'stir', 'send email']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - suppord fact predict = ['make list-capable of', 'stir-used for', 'send email-used for']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - correspond target = ['computer', 'person', 'spoon']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - test id = 1214, question = What thing does the animal in this image have as a part?, img = COCO_val2014_000000010822.jpg\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - real suppord fact in dataset=['zebra', 'has a', 'stripe'], real answer = stripe\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - normal model predict = ['zebra', 'stripe', 'blue', 'long necked', 'cloud', 'bikini', 'giraffe', 'jazz blue', 'camel', 'ocean']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict = ['long necked', 'africa', 'animal', 'giraffidae', 'tree', 'skunk', 'even toed ungulate', 'dog', 'zoo', 'squirrel']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict relation = ['has a', 'part of', 'is a', 'related to', 'animal family', 'animal order', 'large', 'receives action', 'small', 'has property', 'capable of', 'social', 'used for', 'animal kingdom', 'at location']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict fact = ['giraffe', 'wolf', 'forest']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - suppord fact predict = ['giraffe-animal family', 'giraffe-animal order', 'giraffe-receives action', 'wolf-related to', 'forest-part of', 'forest-at location', 'giraffe-has property', 'giraffe-at location']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - correspond target = ['giraffidae', 'tree', 'animal', 'dog', 'zoo', 'squirrel', 'skunk', 'even toed ungulate', 'long necked', 'africa']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - test id = 141, question = What property does the place in this image have?, img = ILSVRC2012_test_00009893.JPEG\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - real suppord fact in dataset=['kitchenette', 'has property', 'usually small'], real answer = kitchenette\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - normal model predict = ['hot room', 'laundromat', 'house', 'pleasant', 'hotel room', 'microwave', 'sound control room', 'smooth', 'clean your tooth in', 'your house']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict = ['clean your tooth in', 'sink', 'wash', 'sleep away from home', 'wash your hand', 'toilet paper', 'temporary residence', 'use toilet', 'toilet', 'work']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict relation = ['has property', 'has a', 'at location', 'used for', 'created by', 'animal family', 'firm', 'animal order', 'protected', 'belong to', 'receives action', 'animal class', 'related to', 'part of', 'animal phylum']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict fact = ['office', 'hotel room', 'bathroom']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - suppord fact predict = ['hotel room-used for', 'office-used for', 'bathroom-at location', 'bathroom-has a', 'bathroom-part of', 'bathroom-used for']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - correspond target = ['toilet', 'use toilet', 'toilet paper', 'sink', 'wash your hand', 'temporary residence', 'work', 'sleep away from home', 'wash', 'clean your tooth in']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - test id = 1058, question = What is the significant property of the animal in this image, img = ILSVRC2012_test_00003143.JPEG\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - real suppord fact in dataset=['nail', 'has property', 'low'], real answer = low\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - normal model predict = ['nail', 'snake', 'bird', 'tick', 'lizard', 'dragonfly', 'bee', 'ant', 'shell', 'armadillo']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict = ['zoo', 'green', 'wild', 'long necked', 'even toed ungulate', 'giraffidae', 'africa', 'extremely high blood pressure', 'chordata', 'nail']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict relation = ['has property', 'animal kingdom', 'animal class', 'animal family', 'is a', 'animal order', 'belong to', 'animal phylum', 'at location', 'protected', 'green', 'safe', 'receives action', 'has a', 'important']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - our model predict fact = ['frog', 'giraffe', 'monkey']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - suppord fact predict = ['giraffe-animal family', 'giraffe-animal order', 'giraffe-receives action', 'monkey-at location', 'giraffe-has property', 'giraffe-has a', 'giraffe-animal phylum', 'frog-at location', 'giraffe-at location', 'frog-has property']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - correspond target = ['chordata', 'giraffidae', 'extremely high blood pressure', 'wild', 'zoo', 'green', 'even toed ungulate', 'long necked', 'africa']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:19 - #################################################################################\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:46<00:13,  1.59it/s]INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - test id = 2251, question = Which object in this image belongs to the category winter equipment?, img = COCO_val2014_000000005032.jpg\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - real suppord fact in dataset=['skateboard', 'belong to', 'skateboarding equipment'], real answer = skateboard\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - normal model predict = ['snowboard', 'ski', 'ski slope', 'snowmobile', 'snow', 'surfboard', 'skateboard', 'bicycle', 'skiiers', 'kite']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict = ['ski', 'fire hydrant', 'tennis racket', 'computer', 'snowboard', 'ski slope', 'snowmobile', 'snow', 'surfboard', 'skateboard']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict relation = ['belong to', 'desires', 'is a', 'loyal', 'animal phylum', 'animal kingdom', 'related to', 'animal order', 'trustworthy', 'comfortable', 'at location', 'capable of', 'sensible', 'visible', 'animal class']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict fact = ['skiing equipment', 'firefighting equipment', 'equipment']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - suppord fact predict = ['equipment-belong to', 'firefighting equipment-belong to', 'skiing equipment-belong to']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - correspond target = ['tennis racket', 'ski', 'computer', 'fire hydrant']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - test id = 1098, question = which object in this image is not  good than honesty?, img = ILSVRC2012_test_00057322.JPEG\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - real suppord fact in dataset=['honesty', 'good', 'book'], real answer = book\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - normal model predict = ['computer', 'laptop', 'desk', 'pen', 'keyboard', 'printer', 'ram', 'home office', 'chair', 'pencil box']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict = ['laptop', 'ipod', 'computer', 'desk', 'pen', 'keyboard', 'printer', 'ram', 'home office', 'chair']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict relation = ['good', 'efficient', 'prevalent', 'low', 'reliable', 'cheap', 'effective', 'dependable', 'important', 'high', 'expensive', 'convenient', 'easy', 'frequent', 'popular']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict fact = ['walkman', 'desktop', 'cyberdating']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - suppord fact predict = ['desktop-popular', 'desktop-efficient', 'desktop-prevalent', 'walkman-good', 'desktop-expensive', 'desktop-convenient']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - correspond target = ['ipod', 'laptop']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - test id = 26, question = What is the object in the middle used for?, img = COCO_val2014_000000130438.jpg\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - real suppord fact in dataset=['hot dog', 'used for', 'eat'], real answer = eat\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - normal model predict = ['eat', 'prepare food', 'cut', 'bread', 'food', 'bagel', 'cook food', 'toast bread', 'fry bread', 'hot dog']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict = ['cut', 'pare apple', 'eat', 'prepare food', 'bread', 'food', 'bagel', 'cook food', 'toast bread', 'fry bread']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict relation = ['used for', 'capable of', 'at location', 'belong to', 'good', 'has property', 'is a', 'receives action', 'effective', 'safe', 'easy', 'important', 'animal order', 'high', 'great']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict fact = ['round cake', 'doughnut', 'knife']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - suppord fact predict = ['knife-used for']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - correspond target = ['pare apple', 'cut']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - test id = 2315, question = Which metal object in this image has less surface area than a screw?, img = ILSVRC2012_test_00008274.JPEG\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - real suppord fact in dataset=['screw', 'surface', 'nail'], real answer = nail\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - normal model predict = ['screwdriver', 'clock', 'ruler', 'corkscrew', 'drive screw', 'scissors', 'knife', 'power drill', 'airplane', 'plunger']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict = ['screwdriver', 'clock', 'ruler', 'corkscrew', 'drive screw', 'scissors', 'knife', 'power drill', 'airplane', 'plunger']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict relation = ['part of', 'has a', 'large', 'small', 'capable of', 'light', 'important', 'at location', 'frequent', 'heavy', 'social', 'related to', 'visible', 'stable', 'high']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict fact = ['screw', 'insert screw', 'turn screw']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - suppord fact predict = ['turn screw-capable of']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - correspond target = ['screwdriver']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - test id = 2707, question = What thing in this image is likely to be found in a hole, img = ILSVRC2012_test_00029408.JPEG\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - real suppord fact in dataset=['snake', 'at location', 'hole'], real answer = snake\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - normal model predict = ['snake', 'lizard', 'frog', 'armadillo', 'zebra', 'desert', 'ant', 'giraffe', 'turtle', 'monkey']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict = ['dog', 'house', 'snake', 'lizard', 'frog', 'armadillo', 'zebra', 'desert', 'ant', 'giraffe']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict relation = ['at location', 'used for', 'capable of', 'belong to', 'has a', 'part of', 'good', 'great', 'active', 'receives action', 'convenient', 'animal order', 'specific', 'human', 'animal family']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict fact = ['petshop', 'neighborhood', 'sandbar']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - suppord fact predict = ['petshop-at location', 'neighborhood-at location']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - correspond target = ['house', 'dog']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - test id = 376, question = Which object in this image is related to colour?, img = COCO_val2014_000000008876.jpg\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - real suppord fact in dataset=['wine', 'related to', 'colour'], real answer = wine\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - normal model predict = ['bottle', 'wine', 'wine glass', 'scissors', 'knife', 'ruler', 'drink', 'beer', 'fruit', 'axe']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict = ['scissors', 'elephant', 'trombone', 'bottle', 'wine', 'wine glass', 'knife', 'ruler', 'drink', 'beer']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict relation = ['related to', 'belong to', 'specific', 'used for', 'important', 'common', 'at location', 'part of', 'animal order', 'social', 'is a', 'has property', 'prevalent', 'has a', 'accurate']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict fact = ['sew', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - suppord fact predict = ['sew-belong to', 'therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - correspond target = ['trombone', 'scissors', 'elephant']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - test id = 96, question = What is the dog lying on in the image?, img = ILSVRC2012_test_00011808.JPEG\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - real suppord fact in dataset=['sofa', 'used for', 'lie on'], real answer = sofa\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - normal model predict = ['dog', 'donut', 'cat', 'human', 'hair', 'doughnut', 'mouse', 'hot dog', 'dog poop', 'kitten']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict = ['dog', 'cat', 'human', 'animal', 'goldfish', 'herd sheep', 'ant', 'donut', 'hair', 'doughnut']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict relation = ['related to', 'animal order', 'good', 'is a', 'used for', 'important', 'at location', 'part of', 'animal class', 'capable of', 'specific', 'great', 'human', 'belong to', 'fast']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict fact = ['dog', 'pet', 'pet cat']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - suppord fact predict = ['dog-used for', 'pet-is a', 'dog-good', 'pet-belong to', 'pet-used for', 'dog-belong to', 'pet-related to']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - correspond target = ['cat', 'animal', 'dog', 'ant', 'herd sheep', 'goldfish', 'human']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - test id = 2287, question = What place is shown in this image?, img = ILSVRC2012_test_00004714.JPEG\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - real suppord fact in dataset=['railroad track', 'at location', 'train station'], real answer = train station\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - normal model predict = ['airport', 'flight', 'airplane', 'land plane', 'runway', 'land airplane', 'plane', 'train station', 'railroad track', 'train']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict = ['airport', 'land plane', 'land airplane', 'plane', 'railroad track', 'plane to land on', 'station', 'flight', 'airplane', 'runway']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict relation = ['at location', 'is a', 'used for', 'related to', 'has property', 'has a', 'belong to', 'part of', 'cheap', 'common', 'fast', 'specific', 'important', 'convenient', 'easy']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict fact = ['runway', 'at train station', 'superstation']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - suppord fact predict = ['superstation-related to', 'at train station-at location', 'runway-at location', 'runway-used for']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - correspond target = ['railroad track', 'land airplane', 'plane', 'station', 'plane to land on', 'airport', 'land plane']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - test id = 1197, question = What is the animal in this image that is larger than a person?, img = COCO_val2014_000000112349.jpg\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - real suppord fact in dataset=['horse', 'has property', 'large than person'], real answer = horse\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - normal model predict = ['horse', 'bench', 'bicycle', 'motorcycle', 'cow', 'elephant', 'motorbike', 'big', 'ride', 'camel']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict = ['bench', 'car', 'kite', 'throw', 'horse', 'bicycle', 'motorcycle', 'cow', 'elephant', 'motorbike']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict relation = ['is a', 'small', 'capable of', 'has a', 'big', 'part of', 'large', 'important', 'related to', 'independent', 'good', 'long', 'high', 'great', 'common']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - our model predict fact = ['person', 'seat person', 'large than person']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - suppord fact predict = ['seat person-capable of', 'person-capable of']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - correspond target = ['kite', 'throw', 'bench', 'car']\n",
      "INFO - 08/13/22 23:31:01 - 0:01:20 - #################################################################################\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:47<00:12,  1.60it/s]INFO - 08/13/22 23:31:02 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - test id = 2772, question = what object in this image is a stuffed animal?, img = COCO_val2014_000000009262.jpg\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - real suppord fact in dataset=['teddy bear', 'is a', 'stuff animal'], real answer = teddy bear\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - normal model predict = ['teddy bear', 'cat', 'pizza', 'cake', 'bear', 'cheese', 'chocolate', 'fork', 'doughnut', 'donut']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict = ['cat', 'giraffe', 'sheep', 'armadillo', 'squirrel', 'elephant', 'cow', 'zebra', 'jellyfish', 'frog']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict relation = ['is a', 'has a', 'belong to', 'related to', 'has property', 'independent', 'part of', 'cool', 'animal class', 'created by', 'used for', 'good', 'small', 'blind', 'sweet']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict fact = ['cute smart furry animal', 'animal', 'woolly animal']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - suppord fact predict = ['cute smart furry animal-is a', 'animal-related to', 'animal-is a', 'woolly animal-related to', 'animal-belong to']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - correspond target = ['jellyfish', 'cat', 'armadillo', 'zebra', 'sheep', 'squirrel', 'frog', 'giraffe', 'elephant', 'cow']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - test id = 2303, question = Which object in this image is similar to minicomputer?, img = ILSVRC2012_test_00010098.JPEG\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - real suppord fact in dataset=['minicomputer', 'related to', 'computer'], real answer = computer\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - normal model predict = ['keyboard', 'computer', 'mouse', 'laptop', 'cell phone', 'pen', 'phone', 'hand', 'desk', 'pencil box']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict = ['cell phone', 'button', 'keyboard', 'computer', 'mouse', 'laptop', 'pen', 'phone', 'hand', 'desk']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict relation = ['related to', 'specific', 'used for', 'important', 'is a', 'common', 'part of', 'has property', 'has a', 'prevalent', 'social', 'good', 'capable of', 'belong to', 'at location']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict fact = ['m', 'call mobile phone', 'cell phone']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - suppord fact predict = ['cell phone-part of', 'm-related to', 'call mobile phone-is a']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - correspond target = ['button', 'cell phone']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - test id = 1447, question = What is this cake for?, img = COCO_val2014_000000123810.jpg\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - real suppord fact in dataset=['cake', 'related to', 'wedding'], real answer = wedding\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - normal model predict = ['cooking', 'kitchen', 'prepare food', 'cook food', 'kitchen utensil', 'cake', 'dishes', 'bread', 'eat', 'sleep away from home']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict = ['cooking', 'kitchen', 'cook food', 'kitchen utensil', 'cake', 'house', 'cheese', 'cup', 'flour', 'knife in drawer']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict relation = ['used for', 'has property', 'related to', 'belong to', 'capable of', 'at location', 'is a', 'easy', 'good', 'convenient', 'fast', 'safe', 'specific', 'effective', 'has a']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict fact = ['cake', 'kitchen', 'birthday dessert']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - suppord fact predict = ['kitchen-at location', 'kitchen-used for', 'cake-at location', 'cake-related to', 'birthday dessert-related to', 'kitchen-belong to']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - correspond target = ['cake', 'flour', 'kitchen utensil', 'kitchen', 'knife in drawer', 'house', 'cup', 'cooking', 'cheese', 'cook food']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:02 - 0:01:20 - test id = 2114, question = which object in this image can say 'I love you'?, img = ILSVRC2012_test_00044361.JPEG\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - real suppord fact in dataset=['person', 'capable of', 'say i love you'], real answer = person\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - normal model predict = ['person', 'horse', 'grass', 'make person happy', 'snake', 'dog', 'any place where person live', 'thing', 'dog poop', 'throw']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict = ['dog', 'computer', 'person', 'horse', 'grass', 'make person happy', 'snake', 'any place where person live', 'thing', 'dog poop']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict relation = ['capable of', 'related to', 'used for', 'desires', 'belong to', 'specific', 'at location', 'important', 'accurate', 'human', 'intelligent', 'visible', 'blind', 'common', 'is a']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict fact = [\"call man's best friend\", \"man's best friend\", 'help person']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - suppord fact predict = [\"call man's best friend-is a\", \"man's best friend-is a\", 'help person-capable of']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - correspond target = ['computer', 'dog']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - test id = 1327, question = Which animal in this image is also used to travel?, img = COCO_val2014_000000102672.jpg\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - real suppord fact in dataset=['horse', 'has property', 'use for travel'], real answer = horse\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - normal model predict = ['horse', 'elephant', 'camel', 'giraffe', 'canvas', 'cow', 'wooden', 'wood', 'motorcycle', 'luggage']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict = ['motorcycle', 'luggage', 'bicycle', 'bus', 'airplane', 'road', 'horse', 'elephant', 'camel', 'giraffe']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict relation = ['related to', 'used for', 'belong to', 'capable of', 'has property', 'specific', 'receives action', 'is a', 'at location', 'desires', 'part of', 'important', 'has a', 'accurate', 'visible']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict fact = ['travel', 'travel long distance', 'travel short distance']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - suppord fact predict = ['travel-used for', 'travel short distance-used for', 'travel long distance-used for', 'travel-related to']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - correspond target = ['airplane', 'bus', 'motorcycle', 'bicycle', 'luggage', 'road']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - test id = 389, question = Which object in this image belongs to the category of Constructions?, img = ILSVRC2012_test_00022897.JPEG\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - real suppord fact in dataset=['build', 'belong to', 'construction'], real answer = build\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - normal model predict = ['cow', 'horse', 'sheep', 'camel', 'cattle', 'herd sheep', 'cart', 'heifer', 'bicycle', 'animal']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict = ['cow', 'camel', 'giraffe', 'even toed ungulate', 'mammal', 'bovidae', 'horse', 'sheep', 'cattle', 'herd sheep']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict relation = ['belong to', 'desires', 'animal kingdom', 'animal phylum', 'loyal', 'is a', 'animal order', 'comfortable', 'animal family', 'animal class', 'trustworthy', 'capable of', 'human', 'sensible', 'small']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict fact = ['cattle', 'ruminant', 'sheep']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - suppord fact predict = ['cattle-belong to', 'cattle-animal family', 'sheep-animal order', 'ruminant-is a', 'cattle-animal class']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - correspond target = ['bovidae', 'camel', 'even toed ungulate', 'giraffe', 'cow', 'mammal']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - #################################################################################\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - test id = 1979, question = Why are they wearing helmet?, img = COCO_val2014_000000108094.jpg\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - real suppord fact in dataset=['helmet', 'related to', 'safety'], real answer = safety\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - normal model predict = ['helmet', 'sunglasses', 'suit', 'jacket', 'shirt', 'stripe', 'hat', 'canvas', 'feather', 'dumbbell']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict = ['person', 'dog', 'helmet', 'sunglasses', 'suit', 'jacket', 'shirt', 'stripe', 'hat', 'canvas']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict relation = ['related to', 'is a', 'has a', 'has property', 'belong to', 'used for', 'capable of', 'receives action', 'at location', 'desires', 'part of', 'specific', 'small', 'created by', 'long']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - our model predict fact = ['wear sweater', 'wear collar', 'wear hat']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - suppord fact predict = ['wear collar-capable of', 'wear sweater-capable of', 'wear hat-capable of']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - correspond target = ['person', 'dog']\n",
      "INFO - 08/13/22 23:31:02 - 0:01:20 - #################################################################################\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:48<00:13,  1.46it/s]INFO - 08/13/22 23:31:03 - 0:01:21 - #################################################################################\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - test id = 1389, question = Where does the place in this image can be found in?, img = COCO_val2014_000000015559.jpg\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - real suppord fact in dataset=['snow', 'at location', 'street'], real answer = snow\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - normal model predict = ['mountainous area', 'ski slope', 'park', 'beach', 'mountain', 'hotel room', 'airport', 'lake', 'sandy', 'park space']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - our model predict = ['ski slope', 'beach', 'bathroom', 'toilet', 'mountainous area', 'park', 'mountain', 'hotel room', 'airport', 'lake']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - our model predict relation = ['at location', 'used for', 'has a', 'has property', 'belong to', 'related to', 'specific', 'surface', 'capable of', 'expensive', 'part of', 'long', 'animal family', 'small', 'animal order']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - our model predict fact = ['sandy', 'hotel', 'skiiers']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - suppord fact predict = ['sandy-has property', 'hotel-at location', 'skiiers-at location']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - correspond target = ['ski slope', 'beach', 'toilet', 'bathroom']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - #################################################################################\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - #################################################################################\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - test id = 690, question = Tell me the name of the toy in this image?, img = COCO_val2014_000000108484.jpg\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - real suppord fact in dataset=['teddy bear', 'belong to', 'toy'], real answer = teddy bear\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - normal model predict = ['toys', 'pretzel', 'toy', 'teddy bear', 'human', 'mouse', 'strawberry', 'chocolate', 'unicycle', 'corkscrew']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - our model predict = ['human', 'wii', 'animal', 'hair', 'cat', 'toys', 'pretzel', 'toy', 'teddy bear', 'mouse']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - our model predict relation = ['is a', 'belong to', 'related to', 'part of', 'has a', 'good', 'animal order', 'animal family', 'safe', 'animal class', 'important', 'at location', 'animal kingdom', 'independent', 'healthy']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - our model predict fact = ['dog', 'game system', 'home video game consoles']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - suppord fact predict = ['dog-good', 'game system-is a', 'dog-independent', 'dog-has a', 'dog-belong to', 'home video game consoles-belong to']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - correspond target = ['cat', 'animal', 'wii', 'hair', 'human']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - #################################################################################\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - #################################################################################\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - test id = 2156, question = How is wedding feeling?, img = COCO_val2014_000000123810.jpg\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - real suppord fact in dataset=['wedding', 'has property', 'romantic'], real answer = romantic\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - normal model predict = ['bedroom', 'kitchen table', 'white', 'bed', 'sink', 'dining table', 'sofa', 'kitchen', 'cup', 'bathroom']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - our model predict = ['person', 'dog', 'bedroom', 'kitchen table', 'white', 'bed', 'sink', 'dining table', 'sofa', 'kitchen']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - our model predict relation = ['has property', 'related to', 'used for', 'at location', 'belong to', 'is a', 'receives action', 'has a', 'specific', 'animal order', 'desires', 'part of', 'animal class', 'surface', 'important']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - our model predict fact = ['feel happy', 'feel', 'nice friend']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - suppord fact predict = ['feel-has a', 'nice friend-is a']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - correspond target = ['person', 'dog']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:03 - 0:01:21 - #################################################################################\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - test id = 512, question = Which object has a long nose, img = COCO_val2014_000000001869.jpg\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - real suppord fact in dataset=['elephant', 'has a', 'long nose call trunk'], real answer = elephant\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - normal model predict = ['elephant', 'hippopotamus', 'camel', 'horse', 'giraffe', 'monkey', 'cow', 'antelope', 'zebra', 'whale']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - our model predict = ['giraffe', 'snake', 'banana', 'trombone', 'elephant', 'hippopotamus', 'camel', 'horse', 'monkey', 'cow']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - our model predict relation = ['has a', 'has property', 'is a', 'part of', 'related to', 'capable of', 'large', 'long', 'strong', 'light', 'social', 'common', 'high', 'frequent', 'low']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - our model predict fact = ['long neck', 'long', 'long neck animal']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - suppord fact predict = ['long-related to', 'long neck-has a', 'long neck-has property', 'long neck animal-has property']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - correspond target = ['trombone', 'giraffe', 'snake', 'banana']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - #################################################################################\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - #################################################################################\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - test id = 2364, question = What percussion instrument is seen here?, img = ILSVRC2012_test_00003337.JPEG\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - real suppord fact in dataset=['maraca', 'belong to', 'percussion instruments by tradition'], real answer = maraca\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - normal model predict = ['banjo', 'harmonica', 'baseball bat', 'baseball', 'soccer ball', 'baseball glove', 'tennis ball', 'ball', 'harp', 'guitar']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - our model predict = ['banjo', 'harmonica', 'harp', 'guitar', 'violin', 'drum', 'accordion', 'trombone', 'saxophone', 'french horn']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - our model predict relation = ['is a', 'belong to', 'has property', 'receives action', 'has a', 'used for', 'important', 'good', 'at location', 'related to', 'safe', 'animal class', 'cool', 'part of', 'easy']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - our model predict fact = ['musical string instrument', 'string musical instrument', 'musical instrument']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - suppord fact predict = ['musical string instrument-is a', 'musical instrument-belong to', 'musical instrument-related to', 'string musical instrument-is a', 'musical instrument-is a']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - correspond target = ['harp', 'accordion', 'french horn', 'banjo', 'drum', 'violin', 'saxophone', 'guitar', 'trombone', 'harmonica']\n",
      "INFO - 08/13/22 23:31:03 - 0:01:21 - #################################################################################\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:49<00:12,  1.41it/s]INFO - 08/13/22 23:31:04 - 0:01:22 - #################################################################################\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - test id = 1323, question = Which object in this image is used for playing songs?, img = ILSVRC2012_test_00029629.JPEG\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - real suppord fact in dataset=['banjo', 'used for', 'play song'], real answer = banjo\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - normal model predict = ['guitar', 'banjo', 'drum', 'saxophone', 'harmonica', 'violin', 'piano', 'cello', 'trombone', 'harp']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - our model predict = ['guitar', 'saxophone', 'harmonica', 'piano', 'cello', 'trombone', 'harp', 'trumpet', 'tennis ball', 'racquet']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - our model predict relation = ['used for', 'related to', 'belong to', 'effective', 'specific', 'efficient', 'easy', 'common', 'popular', 'has property', 'convenient', 'good', 'accurate', 'receives action', 'important']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - our model predict fact = ['play', 'play tune', 'play music']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - suppord fact predict = ['play-related to', 'play tune-used for', 'play music-used for', 'play-used for']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - correspond target = ['racquet', 'piano', 'harp', 'cello', 'saxophone', 'trumpet', 'guitar', 'trombone', 'tennis ball', 'harmonica']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - #################################################################################\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - #################################################################################\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - test id = 1952, question = Which object in this image is used for playing rugby?, img = ILSVRC2012_test_00011383.JPEG\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - real suppord fact in dataset=['rugby ball', 'used for', 'play rugby'], real answer = rugby ball\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - normal model predict = ['tennis ball', 'soccer ball', 'golf ball', 'ball', 'frisbee', 'rugby ball', 'tennis racket', 'baseball glove', 'volleyball', 'tennis']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - our model predict = ['tennis ball', 'tennis racket', 'baseball', 'racket', 'soccer ball', 'golf ball', 'ball', 'frisbee', 'rugby ball', 'baseball glove']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - our model predict relation = ['used for', 'related to', 'specific', 'effective', 'popular', 'efficient', 'easy', 'common', 'has property', 'belong to', 'convenient', 'light', 'accurate', 'expensive', 'hot']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - our model predict fact = ['play tennis', 'play tennis with', 'play outside']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - suppord fact predict = ['play tennis with-used for', 'play tennis-used for', 'play outside-has property']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - correspond target = ['tennis racket', 'racket', 'tennis ball', 'baseball']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - #################################################################################\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - #################################################################################\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - test id = 2007, question = What is the place in this image used for?, img = COCO_val2014_000000011727.jpg\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - real suppord fact in dataset=['bathroom', 'used for', 'clean your tooth in'], real answer = clean your tooth in\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - normal model predict = ['pee', 'wash', 'swim', 'sleep', 'preventing from getting wet', 'laundromat', 'sleep away from home', 'toilet', 'cold and wet', 'sink']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - our model predict = ['pee', 'wash', 'cooking', 'prepare food', 'hotel room', 'breakfast', 'house', 'plunger', 'swim', 'sleep']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - our model predict relation = ['used for', 'belong to', 'capable of', 'related to', 'effective', 'good', 'receives action', 'part of', 'great', 'specific', 'easy', 'at location', 'popular', 'important', 'animal order']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - our model predict fact = ['kitchenette', 'shower', 'toilet']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - suppord fact predict = ['toilet-used for', 'kitchenette-used for', 'kitchenette-at location', 'shower-used for']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - correspond target = ['prepare food', 'house', 'hotel room', 'plunger', 'cooking', 'pee', 'wash', 'breakfast']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - #################################################################################\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - #################################################################################\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - test id = 1174, question = which kind of consumer goods can we find in this image, img = COCO_val2014_000000149783.jpg\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - real suppord fact in dataset=['laptop', 'belong to', 'consumer goods'], real answer = laptop\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - normal model predict = ['computer', 'keyboard', 'printer', 'laptop', 'mouse', 'monitor', 'desk', 'pen', 'modern device', 'home office']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - our model predict = ['computer', 'keyboard', 'printer', 'monitor', 'desk', 'pen', 'window', 'work', 'your house', 'tall build']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - our model predict relation = ['belong to', 'at location', 'is a', 'related to', 'used for', 'has property', 'has a', 'desires', 'part of', 'capable of', 'receives action', 'important', 'blind', 'specific', 'animal order']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - our model predict fact = ['home office', 'office', 'save information']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - suppord fact predict = ['home office-at location', 'save information-capable of', 'office-used for', 'office-has a', 'office-at location']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - correspond target = ['pen', 'desk', 'your house', 'tall build', 'monitor', 'computer', 'window', 'keyboard', 'printer', 'work']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:04 - 0:01:22 - #################################################################################\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - test id = 2087, question = Why people need these stuffs?, img = COCO_val2014_000000108408.jpg\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - real suppord fact in dataset=['suitcase', 'related to', 'travel'], real answer = travel\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - normal model predict = ['two', 'luggage', 'any place where person live', 'travel in car', 'small', 'four', 'use twice day', 'child', 'hat with a wide brim', 'kept as pets']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - our model predict = ['elephant', 'throw', 'human', 'computer', 'kite', 'two', 'luggage', 'any place where person live', 'travel in car', 'small']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - our model predict relation = ['used for', 'at location', 'belong to', 'good', 'related to', 'has a', 'capable of', 'receives action', 'has property', 'great', 'specific', 'fast', 'effective', 'is a', 'animal order']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - our model predict fact = ['person', 'child', 'help person']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - suppord fact predict = ['person-has property', 'person-capable of', 'help person-capable of', 'child-belong to']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - correspond target = ['throw', 'computer', 'elephant', 'kite', 'human']\n",
      "INFO - 08/13/22 23:31:04 - 0:01:22 - #################################################################################\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:49<00:12,  1.35it/s]INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - test id = 2292, question = Which object in this image contains a lot of vitamin c?, img = ILSVRC2012_test_00014097.JPEG\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - real suppord fact in dataset=['strawberry', 'has property', 'rich in vitamin c'], real answer = strawberry\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - normal model predict = ['apple', 'orange', 'strawberry', 'lemon', 'pomegranate', 'fruit', 'pineapple', 'pare apple', 'fig', 'cucumber']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict = ['apple', 'orange', 'strawberry', 'lemon', 'pomegranate', 'fruit', 'pineapple', 'pare apple', 'fig', 'cucumber']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict relation = ['has property', 'is a', 'has a', 'related to', 'acidic', 'animal family', 'good', 'light', 'acid', 'animal class', 'common', 'popular', 'belong to', 'blind', 'social']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict fact = ['vitamin c', 'full of vitamin c', 'fruit rich in vitamin c']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - suppord fact predict = ['vitamin c-has a', 'fruit rich in vitamin c-is a', 'full of vitamin c-has property']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - correspond target = ['apple', 'orange']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - test id = 463, question = What can maul you to death?, img = COCO_val2014_000000008401.jpg\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - real suppord fact in dataset=['bear', 'is a', 'dangerous animal'], real answer = bear\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - normal model predict = ['animal', 'carnivora', 'tick', 'bear', 'human', 'ant', 'zoo', 'herd sheep', 'mammal', 'even toed ungulate']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict = ['elephant', 'throw', 'computer', 'hammer', 'axe', 'kite', 'animal', 'carnivora', 'tick', 'bear']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict relation = ['capable of', 'related to', 'used for', 'at location', 'has a', 'is a', 'animal order', 'desires', 'specific', 'has property', 'receives action', 'accurate', 'human', 'important', 'belong to']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict fact = ['person', 'help person', 'hurt person']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - suppord fact predict = ['hurt person-capable of', 'person-has property', 'person-capable of', 'hurt person-used for', 'help person-capable of']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - correspond target = ['axe', 'throw', 'computer', 'elephant', 'kite', 'hammer']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - test id = 1552, question = what thing is more stable than the vehicle shown in this image?, img = COCO_val2014_000000015596.jpg\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - real suppord fact in dataset=['motorcycle', 'stable', 'car'], real answer = car\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - normal model predict = ['motorcycle', 'car', 'motorbike', 'vehicle', 'snowmobile', 'baseball', 'baseball bat', 'police', 'racing', 'travel in car']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict = ['motorcycle', 'motorbike', 'truck', 'bicycle', 'train', 'airplane', 'bus', 'laptop', 'car', 'vehicle']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict relation = ['safe', 'fast', 'tough', 'cheap', 'stable', 'soft', 'high', 'expensive', 'impassable', 'popular', 'convenient', 'warm', 'comfortable', 'dangerous', 'dense']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict fact = ['car', 'vehicle', 'stop car']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - suppord fact predict = ['car-high', 'car-dangerous', 'car-safe', 'car-popular', 'car-fast', 'car-stable', 'car-expensive']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - correspond target = ['airplane', 'bus', 'laptop', 'truck', 'motorcycle', 'bicycle', 'train', 'motorbike']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - test id = 2703, question = Which object in this image might be used in snocross?, img = ILSVRC2012_test_00026134.JPEG\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - real suppord fact in dataset=['snocross', 'related to', 'snowmobile'], real answer = snowmobile\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - normal model predict = ['snowmobile', 'motorcycle', 'car', 'motorbike', 'truck', 'boat', 'airplane', 'train', 'vehicle', 'travel in car']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict = ['ski', 'ride', 'dog', 'snowboard', 'dog poop', 'vend stand', 'cold and wet', 'smooth', 'slippery', 'space to run and play']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict relation = ['related to', 'used for', 'at location', 'belong to', 'receives action', 'capable of', 'specific', 'desires', 'has a', 'has property', 'surface', 'visible', 'part of', 'important', 'active']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict fact = ['snow', 'amusement park', 'park']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - suppord fact predict = ['park-at location', 'snow-belong to', 'snow-used for', 'amusement park-has a', 'snow-has property']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - correspond target = ['smooth', 'dog poop', 'dog', 'slippery', 'ski', 'cold and wet', 'space to run and play', 'vend stand', 'ride', 'snowboard']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:50<00:12,  1.29it/s]INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - test id = 1081, question = Which instrument in the foreground can be found in weird al's video, img = ILSVRC2012_test_00022018.JPEG\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - real suppord fact in dataset=['accordion', 'at location', \"weird al's video\"], real answer = accordion\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - normal model predict = ['accordion', 'violin', 'piano', 'harmonica', 'guitar', 'flute', 'banjo', 'cello', 'clarinet', 'saxophone']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict = ['guitar', 'banjo', 'harp', 'kite', 'tennis racket', 'accordion', 'violin', 'piano', 'harmonica', 'flute']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict relation = ['at location', 'belong to', 'related to', 'receives action', 'used for', 'has property', 'specific', 'visible', 'animal order', 'has a', 'desires', 'animal class', 'protected', 'surface', 'animal family']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict fact = ['string instrumetn', 'string instrumetnt', 'string']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - suppord fact predict = ['string-has a', 'string-related to']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - correspond target = ['harp', 'guitar', 'banjo', 'tennis racket', 'kite']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - test id = 2039, question = Which word is normaly used to describe the animal in the image?, img = COCO_val2014_000000108338.jpg\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - real suppord fact in dataset=['elephant', 'has property', 'big'], real answer = big\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - normal model predict = ['elephant', 'car', 'cow', 'snake', 'human', 'person', 'house', 'tree', 'travel in car', 'hippopotamus']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict = ['elephant', 'cow', 'giraffe', 'camel', 'animal', 'zebra', 'frog', 'sheep', 'horse', 'whale']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict relation = ['used for', 'has property', 'belong to', 'is a', 'related to', 'desires', 'at location', 'has a', 'capable of', 'animal order', 'long', 'specific', 'safe', 'tall', 'common']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict fact = ['horse', 'farm animal', 'animal']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - suppord fact predict = ['farm animal-related to', 'farm animal-is a', 'horse-related to', 'animal-related to', 'animal-is a', 'horse-tall', 'horse-belong to', 'animal-belong to']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - correspond target = ['animal', 'horse', 'whale', 'camel', 'zebra', 'sheep', 'frog', 'elephant', 'giraffe', 'cow']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - test id = 258, question = What absorbs less solar heat than the place shown in the image, img = ILSVRC2012_test_00000912.JPEG\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - real suppord fact in dataset=['parking lot', 'solar', 'grass'], real answer = grass\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - normal model predict = ['car', 'travel in car', 'truck', 'boat', 'taxi', 'bakery', 'railroad track', 'plane to land on', 'big', 'eat']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict = ['truck', 'train', 'driving', 'window', 'bus', 'motorcycle', 'bicycle', 'computer', 'laptop', 'desk']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict relation = ['cheap', 'fast', 'expensive', 'low', 'used for', 'high', 'efficient', 'good', 'effective', 'at location', 'frequent', 'common', 'convenient', 'capable of', 'reliable']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict fact = ['hospital room', 'car', 'in office']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - suppord fact predict = ['car-high', 'car-used for', 'car-efficient', 'hospital room-at location', 'in office-at location', 'car-fast', 'car-expensive']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - correspond target = ['driving', 'desk', 'bus', 'laptop', 'window', 'truck', 'computer', 'motorcycle', 'bicycle', 'train']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - test id = 560, question = which object in this picture shows similar property as reishi, img = ILSVRC2012_test_00010194.JPEG\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - real suppord fact in dataset=['reishi', 'related to', 'mushroom'], real answer = mushroom\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - normal model predict = ['banana', 'carrot', 'pineapple', 'lemon', 'green', 'orange', 'snake', 'strawberry', 'fruit', 'poisonous']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict = ['banana', 'trombone', 'carrot', 'pineapple', 'lemon', 'green', 'orange', 'snake', 'strawberry', 'fruit']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict relation = ['has property', 'related to', 'belong to', 'has a', 'part of', 'at location', 'used for', 'created by', 'specific', 'common', 'important', 'animal order', 'is a', 'animal class', 'protected']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict fact = ['potassium', 'peelable', 'tromboner']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - suppord fact predict = ['tromboner-related to', 'peelable-has property', 'potassium-has a']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - correspond target = ['banana', 'trombone']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - test id = 611, question = Which object in this image is legless?, img = ILSVRC2012_test_00000165.JPEG\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - real suppord fact in dataset=['snake', 'related to', 'legless'], real answer = snake\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - normal model predict = ['snake', 'lizard', 'frog', 'armadillo', 'turtle', 'ant', 'bird', 'jellyfish', 'monkey', 'dragonfly']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict = ['elephant', 'clock', 'crutch', 'flute', 'trombone', 'snake', 'lizard', 'frog', 'armadillo', 'turtle']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict relation = ['is a', 'has property', 'related to', 'has a', 'part of', 'belong to', 'important', 'capable of', 'receives action', 'protected', 'used for', 'common', 'long', 'specific', 'safe']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict fact = ['tick', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - suppord fact predict = ['tick-related to', 'therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - correspond target = ['clock', 'elephant', 'crutch', 'trombone', 'flute']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - test id = 2129, question = Which object in this image is used for making a rhythm?, img = ILSVRC2012_test_00027147.JPEG\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - real suppord fact in dataset=['drum', 'used for', 'make rhythm'], real answer = drum\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - normal model predict = ['drum', 'guitar', 'wood', 'saxophone', 'luggage', 'wooden', 'trombone', 'suitcase', 'metal', 'camel']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict = ['person', 'chocolate', 'drum', 'guitar', 'wood', 'saxophone', 'luggage', 'wooden', 'trombone', 'suitcase']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict relation = ['used for', 'related to', 'easy', 'effective', 'specific', 'efficient', 'popular', 'accurate', 'hot', 'capable of', 'is a', 'belong to', 'flexible', 'transportable', 'convenient']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict fact = ['give money to charity', 'make someone happy', 'offer money to charity']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - suppord fact predict = ['offer money to charity-capable of', 'give money to charity-capable of', 'make someone happy-capable of']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - correspond target = ['chocolate', 'person']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - test id = 782, question = Which container is shown in this image ?, img = COCO_val2014_000000025286.jpg\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - real suppord fact in dataset=['vase', 'is a', 'container'], real answer = vase\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - normal model predict = ['flowers', 'fruit', 'kite', 'flower', 'pomegranate', 'airplane', 'mountain', 'vase', 'house', 'strawberry']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict = ['fruit', 'pomegranate', 'strawberry', 'lemon', 'pineapple', 'banana', 'orange', 'apple', 'flowers', 'kite']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict relation = ['related to', 'belong to', 'is a', 'has property', 'used for', 'has a', 'specific', 'at location', 'visible', 'created by', 'common', 'animal order', 'important', 'desires', 'capable of']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - our model predict fact = ['fruit', 'round fruit', 'piece of fruit']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - suppord fact predict = ['round fruit-related to', 'fruit-belong to', 'piece of fruit-is a', 'fruit-related to', 'fruit-specific', 'fruit-is a']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - correspond target = ['apple', 'strawberry', 'pineapple', 'pomegranate', 'orange', 'banana', 'lemon', 'fruit']\n",
      "INFO - 08/13/22 23:31:05 - 0:01:23 - #################################################################################\n",
      " 83%|███████████████████████████████████▊       | 74/89 [00:51<00:10,  1.37it/s]INFO - 08/13/22 23:31:06 - 0:01:24 - #################################################################################\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - test id = 2350, question = Which object in this image has a spine?, img = COCO_val2014_000000008708.jpg\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - real suppord fact in dataset=['book', 'has a', 'pine'], real answer = book\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - normal model predict = ['teddy bear', 'dog', 'bear', 'monkey', 'rabbit', 'cat', 'sheep', 'kitten', 'dog poop', 'giraffe']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - our model predict = ['dog', 'monkey', 'cat', 'giraffe', 'elephant', 'zebra', 'sofa', 'snake', 'person', 'horse']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - our model predict relation = ['has a', 'desires', 'related to', 'has property', 'is a', 'part of', 'specific', 'belong to', 'capable of', 'blind', 'social', 'long', 'human', 'used for', 'independent']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - our model predict fact = ['nose', 'leg', 'no leg']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - suppord fact predict = ['leg-part of', 'leg-has a', 'nose-part of', 'no leg-has a', 'nose-has a']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - correspond target = ['cat', 'sofa', 'horse', 'dog', 'zebra', 'elephant', 'giraffe', 'person', 'monkey', 'snake']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - #################################################################################\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - #################################################################################\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - test id = 293, question = Which object in this image is a type of food?, img = COCO_val2014_000000131841.jpg\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - real suppord fact in dataset=['bread', 'is a', 'type of food'], real answer = bread\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - normal model predict = ['sandwich', 'bread', 'toast bread', 'fry bread', 'bagel', 'doughnut', 'donut', 'hamburger', 'cake', 'fork']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - our model predict = ['donut', 'hamburger', 'cake', 'fork', 'pretzel', 'salad', 'pizza', 'fruit', 'apple', 'vegetable']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - our model predict relation = ['is a', 'belong to', 'related to', 'has a', 'important', 'at location', 'used for', 'part of', 'capable of', 'good', 'has property', 'specific', 'cool', 'receives action', 'animal class']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - our model predict fact = ['food', 'eat food', 'stock food']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - suppord fact predict = ['food-related to', 'food-is a', 'eat food-related to', 'food-belong to', 'eat food-used for']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - correspond target = ['cake', 'apple', 'fruit', 'salad', 'pizza', 'pretzel', 'donut', 'vegetable', 'fork', 'hamburger']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - #################################################################################\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - #################################################################################\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - test id = 2112, question = Which object in this image belongs to a computer?, img = COCO_val2014_000000113126.jpg\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - real suppord fact in dataset=['mouse', 'belong to', 'computing'], real answer = mouse\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - normal model predict = ['screwdriver', 'laptop', 'ruler', 'hammer', 'ram', 'power drill', 'pen', 'keyboard', 'drive screw', 'person']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - our model predict = ['laptop', 'ram', 'keyboard', 'person', 'desk', 'monitor', 'screwdriver', 'ruler', 'hammer', 'power drill']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - our model predict relation = ['belong to', 'is a', 'related to', 'has a', 'used for', 'desires', 'convenient', 'capable of', 'easy', 'at location', 'part of', 'blind', 'visible', 'specific', 'important']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - our model predict fact = ['computer', 'use computer', 'desktop computer']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - suppord fact predict = ['computer-has a', 'desktop computer-convenient', 'computer-related to', 'computer-belong to', 'computer-part of', 'use computer-capable of', 'computer-is a']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - correspond target = ['ram', 'desk', 'monitor', 'laptop', 'keyboard', 'person']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - #################################################################################\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - #################################################################################\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - test id = 519, question = what is the place in this image used for?, img = COCO_val2014_000000108548.jpg\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - real suppord fact in dataset=['bathroom', 'used for', 'wash your hand'], real answer = wash your hand\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - normal model predict = ['sleep away from home', 'sit outside', 'prepare food', 'eat', 'sit down on', 'sleep', 'travel', 'entertain yourself on windy day', 'wash', 'preventing from getting wet']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - our model predict = ['sleep away from home', 'prepare food', 'sleep', 'cooking', 'breakfast', 'human', 'park space', 'temporary residence', 'house', 'hotel room']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - our model predict relation = ['used for', 'related to', 'capable of', 'specific', 'receives action', 'belong to', 'effective', 'has property', 'high', 'part of', 'at location', 'animal order', 'good', 'important', 'common']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - our model predict fact = ['kitchenette', 'hotel room', 'room']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - suppord fact predict = ['hotel room-used for', 'kitchenette-used for', 'room-important', 'room-at location', 'kitchenette-at location']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - correspond target = ['prepare food', 'sleep', 'house', 'hotel room', 'park space', 'cooking', 'temporary residence', 'sleep away from home', 'human', 'breakfast']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - #################################################################################\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - #################################################################################\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - test id = 2408, question = Which food in this image is Mexican?, img = ILSVRC2012_test_00044153.JPEG\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - real suppord fact in dataset=['burrito', 'belong to', 'culture of mexico'], real answer = burrito\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - normal model predict = ['pizza', 'salad', 'sandwich', 'hamburger', 'cheese', 'bagel', 'tomato', 'burrito', 'bread', 'zucchini']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - our model predict = ['pizza', 'hot dog', 'maraca', 'salad', 'sandwich', 'hamburger', 'cheese', 'bagel', 'tomato', 'burrito']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - our model predict relation = ['belong to', 'related to', 'has property', 'is a', 'created by', 'important', 'protected', 'independent', 'popular', 'firm', 'common', 'part of', 'animal class', 'clean', 'visible']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - our model predict fact = ['latin american', 'italian society', 'traditional american food']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - suppord fact predict = ['latin american-related to', 'traditional american food-is a', 'italian society-belong to']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - correspond target = ['hot dog', 'maraca', 'pizza']\n",
      "INFO - 08/13/22 23:31:06 - 0:01:24 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████▏      | 75/89 [00:52<00:10,  1.36it/s]INFO - 08/13/22 23:31:07 - 0:01:25 - #################################################################################\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - test id = 637, question = Which kind of indoor sports are they playing?, img = ILSVRC2012_test_00002577.JPEG\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - real suppord fact in dataset=['table tennis', 'belong to', 'ping pong ball'], real answer = ping pong ball\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - normal model predict = ['volleyball', 'basketball', 'tennis ball', 'tennis', 'play basketball', 'soccer ball', 'baseball', 'tennis racket', 'play tennis', 'rugby ball']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict = ['volleyball', 'basketball', 'tennis ball', 'baseball', 'racket', 'racquet', 'tennis', 'play basketball', 'soccer ball', 'tennis racket']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict relation = ['belong to', 'is a', 'has property', 'receives action', 'has a', 'used for', 'related to', 'desires', 'part of', 'at location', 'created by', 'popular', 'important', 'common', 'animal class']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict fact = ['ball games', 'play outside', 'olympic games']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - suppord fact predict = ['olympic games-belong to', 'play outside-has property', 'ball games-belong to']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - correspond target = ['racquet', 'basketball', 'volleyball', 'racket', 'tennis ball', 'baseball']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - #################################################################################\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - #################################################################################\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - test id = 2304, question = What is the animal in the image?, img = COCO_val2014_000000107481.jpg\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - real suppord fact in dataset=['giraffe', 'is a', 'animal'], real answer = giraffe\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - normal model predict = ['giraffe', 'zoo', 'africa', 'actinopterygii', 'giraffidae', 'gastropoda', 'bovidae', 'lizard', 'hippopotamus', 'mammal']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict = ['zoo', 'africa', 'giraffidae', 'animal', 'long necked', 'green', 'chordata', 'wild', 'even toed ungulate', 'big']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict relation = ['is a', 'has property', 'belong to', 'animal order', 'has a', 'at location', 'animal class', 'related to', 'animal family', 'animal phylum', 'animal kingdom', 'part of', 'common', 'created by', 'important']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict fact = ['giraffe', 'elephant', 'frog']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - suppord fact predict = ['giraffe-animal family', 'giraffe-animal order', 'giraffe-animal phylum', 'elephant-has property', 'giraffe-has property', 'frog-at location', 'giraffe-at location', 'elephant-belong to', 'frog-has property']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - correspond target = ['chordata', 'giraffidae', 'animal', 'wild', 'zoo', 'green', 'even toed ungulate', 'long necked', 'africa', 'big']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - #################################################################################\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - #################################################################################\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - test id = 610, question = Which object in this image can be found in grass?, img = ILSVRC2012_test_00000165.JPEG\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - real suppord fact in dataset=['snake', 'at location', 'outside in grass'], real answer = snake\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - normal model predict = ['snake', 'tree', 'bird', 'lizard', 'ant', 'frog', 'squirrel', 'skunk', 'poisonous', 'palm tree']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict = ['tree', 'grass', 'flowers', 'fig', 'soccer ball', 'broccoli', 'snake', 'bird', 'lizard', 'ant']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict relation = ['at location', 'used for', 'has a', 'related to', 'belong to', 'part of', 'is a', 'capable of', 'specific', 'receives action', 'animal order', 'human', 'has property', 'surface', 'active']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict fact = ['lawn', 'shade lawn', 'garden plants']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - suppord fact predict = ['lawn-at location', 'shade lawn-capable of', 'lawn-related to', 'garden plants-belong to']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - correspond target = ['grass', 'fig', 'tree', 'flowers', 'broccoli', 'soccer ball']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - #################################################################################\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - #################################################################################\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - test id = 1088, question = What object in this image appears 'happy'?, img = ILSVRC2012_test_00005014.JPEG\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - real suppord fact in dataset=['person', 'desires', 'happy time'], real answer = person\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - normal model predict = ['grass', 'horse', 'dog', 'dog poop', 'person', 'frisbee', 'crutch', 'cat', 'cow', 'sheep']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict = ['dog', 'cat', 'camel', 'zebra', 'giraffe', 'monkey', 'elephant', 'grass', 'horse', 'dog poop']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict relation = ['related to', 'specific', 'used for', 'belong to', 'at location', 'capable of', 'animal order', 'desires', 'has a', 'important', 'has property', 'common', 'accurate', 'social', 'is a']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict fact = ['nose', 'neck', 'hump']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - suppord fact predict = ['hump-related to', 'nose-has a', 'neck-related to']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - correspond target = ['cat', 'dog', 'camel', 'zebra', 'giraffe', 'elephant', 'monkey']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - #################################################################################\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - #################################################################################\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - test id = 92, question = What object in this image is used for shearing?, img = COCO_val2014_000000112128.jpg\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - real suppord fact in dataset=['sheep', 'used for', 'hear'], real answer = sheep\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - normal model predict = ['sheep', 'herd sheep', 'cattle', 'cow', 'dog', 'rabbit', 'dog poop', 'teddy bear', 'bear', 'animal']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict = ['cow', 'horse', 'heifer', 'mammal', 'grass', 'even toed ungulate', 'lamp', 'sheep', 'herd sheep', 'cattle']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict relation = ['used for', 'related to', 'belong to', 'specific', 'at location', 'animal order', 'capable of', 'receives action', 'important', 'accurate', 'common', 'animal class', 'effective', 'has property', 'part of']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict fact = ['cattle', 'pasture', 'sheep']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - suppord fact predict = ['cattle-belong to', 'sheep-animal order', 'cattle-animal class', 'sheep-related to', 'pasture-at location', 'cattle-related to']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - correspond target = ['grass', 'horse', 'cow', 'even toed ungulate', 'lamp', 'heifer', 'mammal']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - #################################################################################\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - #################################################################################\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - test id = 2527, question = Whether this thing is faster or slower than a car?, img = COCO_val2014_000000144251.jpg\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - real suppord fact in dataset=['bus', 'slow', 'low'], real answer = low\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - normal model predict = ['cheap', 'ship', 'large ship', 'light', 'low', 'move', 'traffic light', 'bus', 'travel in car', 'train']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict = ['light', 'bus', 'train', 'truck', 'laptop', 'airplane', 'motorcycle', 'bicycle', 'cheap', 'ship']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict relation = ['fast', 'cheap', 'efficient', 'slow', 'expensive', 'easy', 'low', 'light', 'reliable', 'convenient', 'high', 'good', 'effective', 'blind', 'safe']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict fact = ['car', 'stop car', 'pull car']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - suppord fact predict = ['car-slow', 'car-light', 'car-high', 'car-safe', 'car-efficient', 'car-fast', 'car-expensive']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - correspond target = ['light', 'airplane', 'bus', 'laptop', 'truck', 'motorcycle', 'train', 'bicycle']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:07 - 0:01:25 - #################################################################################\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - test id = 1358, question = Which object in this image is used for cooking, img = COCO_val2014_000000000802.jpg\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - real suppord fact in dataset=['oven', 'used for', 'cook'], real answer = oven\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - normal model predict = ['microwave', 'bed', 'shelf', 'oven', 'knife in drawer', 'refrigerator', 'kitchen utensil', 'kitchenette', 'cooking', 'baby bed']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict = ['bed', 'couch', 'computer', 'microwave', 'shelf', 'oven', 'knife in drawer', 'refrigerator', 'kitchen utensil', 'kitchenette']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict relation = ['used for', 'related to', 'belong to', 'specific', 'effective', 'easy', 'efficient', 'important', 'accurate', 'common', 'good', 'popular', 'convenient', 'at location', 'great']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict fact = ['laze', 'nap', 'cyberdating']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - suppord fact predict = ['nap-used for', 'laze-used for', 'cyberdating-related to']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - correspond target = ['couch', 'computer', 'bed']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - #################################################################################\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - #################################################################################\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - test id = 852, question = What is the living being in the image?, img = COCO_val2014_000000013300.jpg\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - real suppord fact in dataset=['plant', 'is a', 'live be'], real answer = plant\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - normal model predict = ['strawberry', 'pomegranate', 'fruit', 'pineapple', 'fig', 'desert', 'cake', 'flowers', 'orange', 'banana']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict = ['mushroom', 'animal', 'tree', 'skunk', 'squirrel', 'elephant', 'giraffe', 'zebra', 'strawberry', 'pomegranate']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict relation = ['related to', 'at location', 'used for', 'has property', 'animal order', 'is a', 'belong to', 'has a', 'part of', 'specific', 'animal class', 'animal family', 'capable of', 'common', 'important']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - our model predict fact = ['herbivore', 'forest', 'living room']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - suppord fact predict = ['herbivore-is a', 'forest-part of', 'forest-at location', 'herbivore-belong to']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - correspond target = ['tree', 'animal', 'mushroom', 'zebra', 'squirrel', 'skunk', 'giraffe', 'elephant']\n",
      "INFO - 08/13/22 23:31:07 - 0:01:25 - #################################################################################\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:53<00:10,  1.23it/s]INFO - 08/13/22 23:31:08 - 0:01:26 - #################################################################################\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - test id = 2040, question = what kind can we see in this image, img = ILSVRC2012_test_00048805.JPEG\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - real suppord fact in dataset=['apple', 'belong to', 'fruit'], real answer = apple\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - normal model predict = ['fruit', 'orange', 'green', 'apple', 'peel', 'strawberry', 'vegetable', 'banana', 'flowers', 'lemon']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - our model predict = ['pleasant', 'shell', 'sandy', 'lot of sand', 'pretty girl', 'human', 'dog', 'tourist', 'romantic', 'seal']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - our model predict relation = ['at location', 'used for', 'belong to', 'related to', 'is a', 'has a', 'specific', 'has property', 'capable of', 'good', 'important', 'receives action', 'animal order', 'part of', 'common']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - our model predict fact = ['petshop', 'happyness', 'beach']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - suppord fact predict = ['beach-has a', 'beach-has property', 'beach-at location', 'petshop-at location']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - correspond target = ['tourist', 'pleasant', 'sandy', 'dog', 'shell', 'romantic', 'seal', 'lot of sand', 'human', 'pretty girl']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - #################################################################################\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - #################################################################################\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - test id = 623, question = What object belongs to art of Spain?, img = ILSVRC2012_test_00038723.JPEG\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - real suppord fact in dataset=['guitar', 'belong to', 'arts in spain'], real answer = guitar\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - normal model predict = ['guitar', 'drum', 'wine', 'bottle', 'bicycle', 'punching bag', 'racquet', 'harmonica', 'wine glass', 'banjo']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - our model predict = ['accordion', 'maraca', 'computer', 'guitar', 'drum', 'wine', 'bottle', 'bicycle', 'punching bag', 'racquet']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - our model predict relation = ['belong to', 'related to', 'capable of', 'is a', 'desires', 'at location', 'animal order', 'part of', 'animal phylum', 'important', 'animal kingdom', 'human', 'specific', 'animal class', 'trustworthy']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - our model predict fact = ['american inventions', 'music of switzerland', 'latin american']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - suppord fact predict = ['latin american-related to', 'american inventions-belong to', 'music of switzerland-belong to']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - correspond target = ['accordion', 'maraca', 'computer']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - #################################################################################\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - #################################################################################\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - test id = 1801, question = What can vibrate in this image?, img = COCO_val2014_000000112997.jpg\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - real suppord fact in dataset=['cell phone', 'capable of', 'vibrate'], real answer = cell phone\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - normal model predict = ['vend stand', 'cell phone', 'hammer', 'bottle', 'phone', 'hair spray', 'mouse', 'hand', 'printer', 'box']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - our model predict = ['mouse', 'keyboard', 'vend stand', 'cell phone', 'hammer', 'bottle', 'phone', 'hair spray', 'hand', 'printer']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - our model predict relation = ['used for', 'related to', 'capable of', 'has property', 'is a', 'at location', 'belong to', 'has a', 'specific', 'fast', 'good', 'common', 'important', 'easy', 'part of']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - our model predict fact = ['leave click', 'click', 'enter text']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - suppord fact predict = ['click-used for', 'leave click-related to', 'enter text-used for']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - correspond target = ['keyboard', 'mouse']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - #################################################################################\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - #################################################################################\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - test id = 792, question = What is the name of the vehicle in the middle of the image, img = COCO_val2014_000000103499.jpg\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - real suppord fact in dataset=['ride', 'related to', 'bicycle'], real answer = bicycle\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - normal model predict = ['rain', 'snow', 'build', 'cold', 'water', 'grass', 'drink', 'light', 'ice', 'cold and wet']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - our model predict = ['water', 'travel', 'fly', 'rain', 'snow', 'build', 'cold', 'grass', 'drink', 'light']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - our model predict relation = ['is a', 'animal class', 'animal order', 'belong to', 'animal kingdom', 'part of', 'animal family', 'important', 'animal phylum', 'has property', 'receives action', 'related to', 'human', 'common', 'used for']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - our model predict fact = ['airplane', 'plane', 'essential part of life']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - suppord fact predict = ['airplane-used for', 'essential part of life-is a']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - correspond target = ['water', 'fly', 'travel']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:26 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████▏     | 77/89 [00:53<00:09,  1.21it/s]INFO - 08/13/22 23:31:08 - 0:01:27 - #################################################################################\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - test id = 2491, question = which object in this image often has a living room, img = COCO_val2014_000000130419.jpg\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - real suppord fact in dataset=['live room', 'related to', 'house'], real answer = house\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - normal model predict = ['bicycle', 'bus', 'luggage', 'house', 'truck', 'suitcase', 'furniture', 'train station', 'train', 'car']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - our model predict = ['camel', 'sofa', 'bicycle', 'bus', 'luggage', 'house', 'truck', 'suitcase', 'furniture', 'train station']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - our model predict relation = ['has a', 'is a', 'related to', 'capable of', 'light', 'has property', 'blind', 'part of', 'strong', 'used for', 'big', 'long', 'frequent', 'specific', 'desires']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - our model predict fact = ['furniture that can support person', 'living arrangements', 'large mammal that live in dry area']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - suppord fact predict = ['large mammal that live in dry area-is a', 'furniture that can support person-is a']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - correspond target = ['camel', 'sofa']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - #################################################################################\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - #################################################################################\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - test id = 1939, question = What is the class of the animal in this image?, img = COCO_val2014_000000149832.jpg\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - real suppord fact in dataset=['cattle', 'animal class', 'mammal'], real answer = mammal\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - normal model predict = ['cow', 'horse', 'dog', 'camel', 'sheep', 'herd sheep', 'animal', 'grass', 'human', 'cattle']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - our model predict = ['horse', 'animal', 'grass', 'giraffidae', 'even toed ungulate', 'zoo', 'africa', 'extremely high blood pressure', 'stripe', 'long necked']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - our model predict relation = ['animal family', 'animal class', 'has property', 'is a', 'animal order', 'animal kingdom', 'at location', 'animal phylum', 'used for', 'safe', 'has a', 'common', 'related to', 'part of', 'green']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - our model predict fact = ['zebra', 'sheep', 'giraffe']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - suppord fact predict = ['giraffe-animal family', 'sheep-animal order', 'giraffe-animal order', 'zebra-is a', 'giraffe-has a', 'zebra-has a', 'zebra-animal kingdom', 'giraffe-has property', 'sheep-related to', 'giraffe-at location', 'zebra-at location']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - correspond target = ['giraffidae', 'grass', 'extremely high blood pressure', 'animal', 'horse', 'stripe', 'zoo', 'even toed ungulate', 'long necked', 'africa']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - #################################################################################\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - #################################################################################\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - test id = 907, question = Which object in this image is associated with slime?, img = ILSVRC2012_test_00003143.JPEG\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - real suppord fact in dataset=['lime', 'related to', 'nail'], real answer = nail\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - normal model predict = ['lizard', 'nail', 'butterfly', 'snake', 'ant', 'zebra', 'turtle', 'frog', 'dragonfly', 'bee']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - our model predict = ['butterfly', 'zebra', 'plant', 'lizard', 'nail', 'snake', 'ant', 'turtle', 'frog', 'dragonfly']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - our model predict relation = ['has property', 'is a', 'belong to', 'related to', 'has a', 'part of', 'at location', 'important', 'specific', 'used for', 'common', 'receives action', 'visible', 'desires', 'animal kingdom']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - our model predict fact = ['eukaryote', 'talk', 'lepidopteran']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - suppord fact predict = ['eukaryote-belong to', 'talk-related to', 'lepidopteran-is a']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - correspond target = ['zebra', 'plant', 'butterfly']\n",
      "INFO - 08/13/22 23:31:08 - 0:01:27 - #################################################################################\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - #################################################################################\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - test id = 847, question = What is used for hit in this image?, img = COCO_val2014_000000123964.jpg\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - real suppord fact in dataset=['baseball', 'used for', 'hit'], real answer = baseball\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - normal model predict = ['cow', 'dog', 'horse', 'cattle', 'sheep', 'animal', 'herd sheep', 'dog poop', 'human', 'transport person']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict = ['animal', 'herd sheep', 'human', 'turtle', 'cow', 'dog', 'horse', 'cattle', 'sheep', 'dog poop']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict relation = ['belong to', 'used for', 'good', 'important', 'related to', 'capable of', 'fast', 'easy', 'is a', 'specific', 'great', 'animal order', 'animal class', 'high', 'effective']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict fact = ['be pet', 'dog', 'graze in pasture']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - suppord fact predict = ['dog-used for', 'dog-good', 'dog-belong to', 'be pet-capable of']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - correspond target = ['turtle', 'herd sheep', 'animal', 'human']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - #################################################################################\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:54<00:08,  1.29it/s]INFO - 08/13/22 23:31:09 - 0:01:27 - #################################################################################\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - test id = 882, question = Which object in this image is like a hotplate?, img = COCO_val2014_000000136466.jpg\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - real suppord fact in dataset=['hotplate', 'related to', 'stove'], real answer = stove\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - normal model predict = ['microwave', 'toaster', 'station', 'oven', 'dishwasher', 'bus', 'train station', 'coffee', 'stove', 'wash machine']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict = ['microwave', 'station', 'luggage', 'toaster', 'oven', 'dishwasher', 'bus', 'train station', 'coffee', 'stove']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict relation = ['related to', 'is a', 'used for', 'has property', 'has a', 'part of', 'specific', 'important', 'at location', 'good', 'capable of', 'common', 'easy', 'accurate', 'belong to']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict fact = ['superstation', 'magnetron', 'bellhop']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - suppord fact predict = ['superstation-related to', 'bellhop-related to', 'magnetron-related to']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - correspond target = ['luggage', 'microwave', 'station']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - #################################################################################\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - #################################################################################\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - test id = 1990, question = Which object in this image has a long ear, img = ILSVRC2012_test_00002482.JPEG\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - real suppord fact in dataset=['rabbit', 'has a', 'long ear'], real answer = rabbit\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - normal model predict = ['dog', 'rabbit', 'monkey', 'cat', 'otter', 'dog poop', 'squirrel', 'sheep', 'skunk', 'frog']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict = ['snake', 'giraffe', 'banana', 'trombone', 'dog', 'rabbit', 'monkey', 'cat', 'otter', 'dog poop']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict relation = ['has a', 'related to', 'is a', 'part of', 'has property', 'capable of', 'long', 'social', 'specific', 'frequent', 'blind', 'strong', 'animal order', 'light', 'common']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict fact = ['long', 'long neck', 'long arm']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - suppord fact predict = ['long arm-related to', 'long neck-has a', 'long-related to', 'long neck-has property']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - correspond target = ['trombone', 'giraffe', 'snake', 'banana']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:09 - 0:01:27 - #################################################################################\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - test id = 742, question = Which animal in this image is able to carry goods?, img = COCO_val2014_000000109403.jpg\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - real suppord fact in dataset=['horse', 'capable of', 'carry rider'], real answer = horse\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - normal model predict = ['horse', 'hotdog', 'luggage', 'elephant', 'person', 'basket', 'handbag', 'cake', 'chicken', 'camel']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict = ['luggage', 'train', 'airplane', 'horse', 'hotdog', 'elephant', 'person', 'basket', 'handbag', 'cake']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict relation = ['capable of', 'used for', 'is a', 'has property', 'desires', 'has a', 'at location', 'high', 'accurate', 'related to', 'human', 'effective', 'efficient', 'visible', 'specific']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict fact = ['carry freight', 'carry freight or cargo', 'carry']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - suppord fact predict = ['carry freight or cargo-used for', 'carry freight-capable of', 'carry-used for']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - correspond target = ['luggage', 'train', 'airplane']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - #################################################################################\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - #################################################################################\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - test id = 2321, question = What is the place in this image used for?, img = COCO_val2014_000000101280.jpg\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - real suppord fact in dataset=['ocean', 'used for', 'swim'], real answer = swim\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - normal model predict = ['travel', 'travel across water', 'any place where person live', 'travel in car', 'mountainous area', 'protect person from sun and rain', 'entertain yourself on windy day', 'fun', 'life preserver', 'ocean']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict = ['sail boat', 'ski', 'cold and wet', 'smooth', 'slippery', 'snowboard', 'kite', 'cold', 'travel', 'travel across water']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict relation = ['used for', 'related to', 'capable of', 'effective', 'has property', 'at location', 'safe', 'high', 'efficient', 'receives action', 'light', 'specific', 'belong to', 'good', 'easy']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict fact = ['lake', 'snow', 'windy sky']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - suppord fact predict = ['snow-belong to', 'lake-used for', 'snow-used for', 'windy sky-at location', 'snow-has property']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - correspond target = ['smooth', 'slippery', 'ski', 'cold and wet', 'cold', 'kite', 'snowboard', 'sail boat']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - #################################################################################\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - #################################################################################\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - test id = 125, question = What is the instrument in the middle used for?, img = ILSVRC2012_test_00051302.JPEG\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - real suppord fact in dataset=['guitar', 'used for', 'music'], real answer = music\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - normal model predict = ['play music', 'play', 'work', 'space to run and play', 'fight fire', 'cut', 'sleep away from home', 'listen to music', 'buy and sell', 'music studio']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict = ['play music', 'bow', 'play', 'work', 'space to run and play', 'fight fire', 'cut', 'sleep away from home', 'listen to music', 'buy and sell']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict relation = ['used for', 'has property', 'is a', 'at location', 'capable of', 'fast', 'receives action', 'safe', 'belong to', 'convenient', 'effective', 'has a', 'popular', 'easy', 'good']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - our model predict fact = ['harp', 'accordion', 'violin']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - suppord fact predict = ['harp-used for', 'violin-receives action']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - correspond target = ['bow', 'play music']\n",
      "INFO - 08/13/22 23:31:09 - 0:01:27 - #################################################################################\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:55<00:07,  1.41it/s]INFO - 08/13/22 23:31:10 - 0:01:28 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - test id = 1600, question = Whether this animal runs slower or faster than horse?, img = ILSVRC2012_test_00000549.JPEG\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - real suppord fact in dataset=['camel', 'slow', 'low'], real answer = low\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - normal model predict = ['big', 'low', 'cow', 'move', 'wild', 'large ship', 'camel', 'tourist', 'lot of sand', 'herd sheep']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict = ['cow', 'elephant', 'car', 'big', 'low', 'move', 'wild', 'large ship', 'camel', 'tourist']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict relation = ['fast', 'slow', 'easy', 'light', 'stable', 'maneuverable', 'soft', 'comfortable', 'low', 'clean', 'safe', 'warm', 'convenient', 'long', 'efficient']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict fact = ['horse', 'horse driving', 'heavy than horse']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - suppord fact predict = ['horse-fast', 'horse-slow']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - correspond target = ['elephant', 'car', 'cow']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - test id = 129, question = Which object in this image has the property of fat, img = COCO_val2014_000000140963.jpg\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - real suppord fact in dataset=['hot dog', 'has property', 'fat'], real answer = hot dog\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - normal model predict = ['lobster', 'pizza', 'cheese', 'plate', 'bowl', 'beer', 'fork', 'bread', 'wine glass', 'restaurant']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict = ['lobster', 'bread', 'hair', 'pizza', 'cheese', 'plate', 'bowl', 'beer', 'fork', 'wine glass']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict relation = ['has property', 'created by', 'related to', 'has a', 'belong to', 'receives action', 'at location', 'protected', 'animal order', 'firm', 'animal class', 'solar', 'part of', 'animal kingdom', 'is a']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict fact = ['crab', 'follicle', 'flour']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - suppord fact predict = ['follicle-related to', 'crab-related to', 'flour-created by']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - correspond target = ['hair', 'bread', 'lobster']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - test id = 2022, question = Which object in this image are dangerous?, img = ILSVRC2012_test_00048011.JPEG\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - real suppord fact in dataset=['axe', 'has property', 'dangerous'], real answer = axe\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - normal model predict = ['hammer', 'scissors', 'screwdriver', 'corkscrew', 'knife', 'wood', 'chain saw', 'ruler', 'metal', 'axe']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict = ['snake', 'clock', 'person', 'flute', 'crutch', 'hammer', 'scissors', 'screwdriver', 'corkscrew', 'knife']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict relation = ['related to', 'used for', 'is a', 'has property', 'capable of', 'has a', 'belong to', 'part of', 'at location', 'specific', 'receives action', 'important', 'dangerous', 'desires', 'common']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict fact = ['be dangerous', 'tick', 'feel pain both physically and emotionally']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - suppord fact predict = ['tick-related to', 'feel pain both physically and emotionally-capable of', 'be dangerous-capable of']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - correspond target = ['clock', 'person', 'crutch', 'flute', 'snake']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - test id = 1487, question = What the cylinder object is used for?, img = ILSVRC2012_test_00059159.JPEG\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - real suppord fact in dataset=['cup', 'capable of', 'hold liquid'], real answer = cup\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - normal model predict = ['prepare food', 'drink', 'food', 'cook food', 'cooking', 'travel', 'wine', 'cut', 'toast bread', 'listen to music']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict = ['cut', 'listen to music', 'wine glass', 'apple', 'pare apple', 'prepare food', 'drink', 'food', 'cook food', 'cooking']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict relation = ['used for', 'capable of', 'receives action', 'is a', 'belong to', 'safe', 'effective', 'at location', 'good', 'has property', 'part of', 'high', 'efficient', 'fast', 'related to']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict fact = ['goblet', 'ipod', 'knife']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - suppord fact predict = ['knife-used for', 'ipod-used for', 'goblet-related to', 'ipod-belong to']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - correspond target = ['apple', 'wine glass', 'listen to music', 'pare apple', 'cut']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:10 - 0:01:28 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - test id = 1792, question = Which object in this image is related to plectrum?, img = ILSVRC2012_test_00001387.JPEG\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - real suppord fact in dataset=['plectrum', 'related to', 'guitar'], real answer = guitar\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - normal model predict = ['guitar', 'piano', 'flute', 'drum', 'cello', 'keyboard', 'harp', 'violin', 'knife', 'metronome']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict = ['trumpet', 'trombone', 'elephant', 'guitar', 'piano', 'flute', 'drum', 'cello', 'keyboard', 'harp']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict relation = ['related to', 'specific', 'belong to', 'used for', 'important', 'part of', 'common', 'social', 'at location', 'accurate', 'animal order', 'prevalent', 'capable of', 'frequent', 'trustworthy']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict fact = ['cornett', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - suppord fact predict = ['cornett-related to', 'therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - correspond target = ['trombone', 'elephant', 'trumpet']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - test id = 2095, question = Where you can find the object shown in this image?, img = ILSVRC2012_test_00045390.JPEG\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - real suppord fact in dataset=['close to tv', 'at location', 'tv'], real answer = close to tv\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - normal model predict = ['your house', 'house', 'bakery', 'airport', 'oven', 'laboratory', 'vend stand', 'city', 'kitchen', 'hotel room']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict = ['listen to music', 'ipod', 'apple', 'your house', 'house', 'bakery', 'airport', 'oven', 'laboratory', 'vend stand']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict relation = ['at location', 'belong to', 'used for', 'has property', 'related to', 'is a', 'has a', 'created by', 'specific', 'capable of', 'animal order', 'protected', 'visible', 'good', 'important']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - our model predict fact = ['ipod', 'itunes', 'portable media player']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - suppord fact predict = ['portable media player-belong to', 'itunes-belong to', 'ipod-used for', 'ipod-belong to']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - correspond target = ['apple', 'ipod', 'listen to music']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:28 - #################################################################################\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:55<00:06,  1.37it/s]INFO - 08/13/22 23:31:10 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - test id = 2245, question = Which object in this image is related to mitts?, img = ILSVRC2012_test_00059219.JPEG\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - real suppord fact in dataset=['mitt', 'related to', 'hand'], real answer = hand\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - normal model predict = ['trombone', 'saxophone', 'clarinet', 'crutch', 'trumpet', 'flute', 'violin', 'guitar', 'feather', 'sunglasses']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict = ['baseball glove', 'sheep', 'person', 'trombone', 'saxophone', 'clarinet', 'crutch', 'trumpet', 'flute', 'violin']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict relation = ['related to', 'specific', 'belong to', 'used for', 'important', 'common', 'part of', 'animal order', 'social', 'is a', 'at location', 'has property', 'has a', 'accurate', 'capable of']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict fact = ['fleece', 'glove', 'wear sweater']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - suppord fact predict = ['fleece-related to', 'wear sweater-capable of', 'glove-belong to', 'glove-is a']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - correspond target = ['sheep', 'baseball glove', 'person']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - test id = 1052, question = Which object in this image is related to delicious, img = COCO_val2014_000000136270.jpg\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - real suppord fact in dataset=['cake', 'related to', 'delicious'], real answer = cake\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - normal model predict = ['vase', 'knife', 'dishes', 'cake', 'spoon', 'dining table', 'bowl', 'flowers', 'kitchen table', 'knife in drawer']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict = ['butterfly', 'elephant', 'trombone', 'vase', 'knife', 'dishes', 'cake', 'spoon', 'dining table', 'bowl']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict relation = ['related to', 'belong to', 'specific', 'used for', 'important', 'common', 'part of', 'at location', 'animal order', 'is a', 'social', 'has property', 'accurate', 'has a', 'prevalent']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict fact = ['flutterby', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - suppord fact predict = ['flutterby-related to', 'therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - correspond target = ['trombone', 'elephant', 'butterfly']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - test id = 1736, question = Which object is related to sit, img = ILSVRC2012_test_00000499.JPEG\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - real suppord fact in dataset=['chair', 'related to', 'it'], real answer = chair\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - normal model predict = ['flute', 'cello', 'saxophone', 'violin', 'clarinet', 'piano', 'trombone', 'trumpet', 'harp', 'guitar']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict = ['trombone', 'guitar', 'elephant', 'flute', 'cello', 'saxophone', 'violin', 'clarinet', 'piano', 'trumpet']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict relation = ['related to', 'belong to', 'specific', 'part of', 'important', 'used for', 'at location', 'common', 'social', 'animal order', 'has a', 'is a', 'capable of', 'receives action', 'prevalent']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict fact = ['luthier', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - suppord fact predict = ['luthier-related to', 'therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - correspond target = ['guitar', 'trombone', 'elephant']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - test id = 1097, question = Which object in this image is sold, img = COCO_val2014_000000126429.jpg\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - real suppord fact in dataset=['wine', 'used for', 'sell'], real answer = wine\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - normal model predict = ['wine', 'wine glass', 'bottle', 'glass', 'beer', 'fruit', 'laboratory', 'drink', 'lipstick', 'corkscrew']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict = ['wood', 'banana', 'microwave', 'wine', 'wine glass', 'bottle', 'glass', 'beer', 'fruit', 'laboratory']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict relation = ['has property', 'is a', 'related to', 'belong to', 'has a', 'part of', 'at location', 'used for', 'important', 'good', 'receives action', 'created by', 'capable of', 'protected', 'common']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict fact = ['magnetron', 'pearwood', 'peelable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:10 - 0:01:29 - suppord fact predict = ['pearwood-related to', 'peelable-has property', 'magnetron-related to']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - correspond target = ['banana', 'microwave', 'wood']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - test id = 1842, question = What musical instrument can be found in this place?, img = ILSVRC2012_test_00015696.JPEG\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - real suppord fact in dataset=['metronome', 'at location', 'music studio'], real answer = metronome\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - normal model predict = ['violin', 'drum', 'cello', 'piano', 'guitar', 'like violin but large', 'music studio', 'train', 'music', 'play music']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict = ['violin', 'drum', 'guitar', 'trombone', 'harp', 'saxophone', 'harmonica', 'banjo', 'accordion', 'french horn']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict relation = ['at location', 'is a', 'has a', 'used for', 'part of', 'receives action', 'has property', 'belong to', 'related to', 'animal class', 'animal family', 'capable of', 'good', 'animal order', 'convenient']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict fact = ['musical instrument', 'musical string instrument', 'string musical instrument']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - suppord fact predict = ['musical string instrument-is a', 'musical instrument-belong to', 'musical instrument-related to', 'string musical instrument-is a', 'musical instrument-is a']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - correspond target = ['harp', 'accordion', 'french horn', 'banjo', 'drum', 'violin', 'saxophone', 'guitar', 'trombone', 'harmonica']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - test id = 42, question = What kind of vitamin does this breakfast contain?, img = COCO_val2014_000000135029.jpg\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - real suppord fact in dataset=['orange', 'has property', 'vitamin c'], real answer = vitamin c\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - normal model predict = ['orange', 'fruit', 'bread', 'wine', 'chocolate', 'white', 'flour', 'food', 'cheese', 'wine glass']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict = ['fruit', 'vegetable', 'fig', 'donut', 'banana', 'pretzel', 'broccoli', 'refrigerator', 'hot dog', 'hotdog']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict relation = ['has a', 'is a', 'has property', 'belong to', 'part of', 'receives action', 'at location', 'good', 'related to', 'used for', 'animal family', 'great', 'capable of', 'animal order', 'independent']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict fact = ['snack food', 'taste food', 'food and drink']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - suppord fact predict = ['food and drink-belong to', 'snack food-is a', 'snack food-belong to']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - correspond target = ['hotdog', 'fig', 'hot dog', 'refrigerator', 'banana', 'broccoli', 'pretzel', 'donut', 'vegetable', 'fruit']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - test id = 2620, question = Where you can usually find the sea life in this image, img = ILSVRC2012_test_00002915.JPEG\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - real suppord fact in dataset=['starfish', 'at location', 'beach'], real answer = beach\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - normal model predict = ['mountainous area', 'africa', 'zoo', 'coast', 'desert', 'tourist', 'laboratory', 'sandy', 'airport', 'park']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict = ['giraffe', 'dolphin', 'large ship', 'jellyfish', 'whale', 'seal', 'mountainous area', 'africa', 'zoo', 'coast']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict relation = ['at location', 'has property', 'used for', 'related to', 'has a', 'is a', 'belong to', 'visible', 'surface', 'capable of', 'specific', 'blind', 'protected', 'part of', 'important']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - our model predict fact = ['mammals by continent', 'sea lion', 'sea']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - suppord fact predict = ['mammals by continent-belong to', 'sea-at location']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - correspond target = ['jellyfish', 'whale', 'seal', 'large ship', 'giraffe', 'dolphin']\n",
      "INFO - 08/13/22 23:31:10 - 0:01:29 - #################################################################################\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:56<00:05,  1.47it/s]INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - test id = 2725, question = What in this image belongs to the category Developmental biology?, img = ILSVRC2012_test_00036186.JPEG\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - real suppord fact in dataset=['fruit', 'belong to', 'developmental biology'], real answer = fruit\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - normal model predict = ['fruit', 'flowers', 'child', 'basket', 'vegetable', 'potted plant', 'flower', 'strawberry', 'pomegranate', 'plant']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict = ['child', 'elephant', 'motorcycle', 'trombone', 'fruit', 'flowers', 'basket', 'vegetable', 'potted plant', 'flower']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict relation = ['belong to', 'desires', 'animal kingdom', 'animal phylum', 'animal order', 'is a', 'related to', 'loyal', 'trustworthy', 'animal family', 'animal class', 'important', 'protected', 'comfortable', 'sensible']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict fact = ['subculture', 'therapsida', 'tromboner']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - suppord fact predict = ['subculture-belong to', 'therapsida-belong to', 'tromboner-related to']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - correspond target = ['trombone', 'motorcycle', 'elephant', 'child']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - test id = 2558, question = What kind of water animal is in the image?, img = ILSVRC2012_test_00052304.JPEG\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - real suppord fact in dataset=['fish', 'related to', 'water animal'], real answer = fish\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - normal model predict = ['goldfish', 'fish', 'jellyfish', 'swimming', 'beach', 'dolphin', 'whale', 'swim', 'butterfly', 'lobster']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict = ['goldfish', 'low', 'shell', 'boat', 'fish', 'jellyfish', 'swimming', 'beach', 'dolphin', 'whale']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict relation = ['belong to', 'is a', 'related to', 'has a', 'has property', 'receives action', 'important', 'at location', 'common', 'good', 'animal order', 'specific', 'animal class', 'safe', 'part of']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict fact = ['turtle', 'shark', 'fish']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - suppord fact predict = ['fish-belong to', 'turtle-has a', 'turtle-has property', 'fish-related to']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - correspond target = ['low', 'boat', 'shell', 'goldfish']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - test id = 1906, question = What object in this image makes the situation dangerous for the woman?, img = COCO_val2014_000000144333.jpg\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - real suppord fact in dataset=['cell phone', 'has property', 'dangerous'], real answer = cell phone\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - normal model predict = ['bicycle', 'sunglasses', 'motorcycle', 'street', 'cat', 'gift shop', 'mountain', 'protect person from sun and rain', 'unicycle', 'skateboard']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict = ['handbag', 'dog', 'bread', 'bicycle', 'sunglasses', 'motorcycle', 'street', 'cat', 'gift shop', 'mountain']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict relation = ['used for', 'is a', 'related to', 'belong to', 'capable of', 'receives action', 'has property', 'has a', 'good', 'fast', 'part of', 'easy', 'important', 'at location', 'desires']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict fact = ['man', 'woman', 'truth']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - suppord fact predict = ['man-fast', 'woman-used for', 'truth-important']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - correspond target = ['dog', 'bread', 'handbag']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - test id = 2811, question = What object in this image can be used to transport a large number of people?, img = COCO_val2014_000000106508.jpg\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - real suppord fact in dataset=['bus', 'is a', 'form of mass transit'], real answer = bus\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - normal model predict = ['bus', 'taxi', 'train', 'train station', 'truck', 'ride', 'railroad track', 'transport', 'road', 'driving']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict = ['bicycle', 'bus', 'taxi', 'train', 'train station', 'truck', 'ride', 'railroad track', 'transport', 'road']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict relation = ['capable of', 'used for', 'has a', 'is a', 'related to', 'part of', 'belong to', 'fast', 'at location', 'receives action', 'good', 'animal order', 'blind', 'desires', 'great']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict fact = ['large than person', 'usually small', 'popular form of transportation especially among child environmentalist and asian']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - suppord fact predict = ['popular form of transportation especially among child environmentalist and asian-is a']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - correspond target = ['bicycle']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - test id = 1597, question = What is the object in the left side of this image used for?, img = COCO_val2014_000000138040.jpg\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - real suppord fact in dataset=['car', 'used for', 'driving'], real answer = driving\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - normal model predict = ['travel', 'travel in car', 'plane to land on', 'travel across water', 'space to run and play', 'prepare food', 'listen to music', 'sleep away from home', 'play music', 'transport']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict = ['travel', 'travel in car', 'transport', 'ski', 'car', 'plane to land on', 'travel across water', 'space to run and play', 'prepare food', 'listen to music']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict relation = ['used for', 'capable of', 'effective', 'good', 'efficient', 'high', 'at location', 'fast', 'great', 'safe', 'animal order', 'easy', 'popular', 'convenient', 'related to']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict fact = ['road', 'highway', 'snow']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - suppord fact predict = ['highway-used for', 'road-at location', 'snow-used for', 'road-used for']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - correspond target = ['travel in car', 'ski', 'transport', 'car', 'travel']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - test id = 1335, question = What object in this image is a type of mollusc?, img = ILSVRC2012_test_00000138.JPEG\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - real suppord fact in dataset=['nail', 'belong to', 'molluscs'], real answer = nail\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - normal model predict = ['screwdriver', 'baseball bat', 'corkscrew', 'baseball', 'bicycle', 'snake', 'hammer', 'cow', 'baseball glove', 'scissors']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict = ['camel', 'banana', 'tennis racket', 'giraffe', 'screwdriver', 'baseball bat', 'corkscrew', 'baseball', 'bicycle', 'snake']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict relation = ['belong to', 'related to', 'is a', 'at location', 'has property', 'has a', 'specific', 'important', 'desires', 'cool', 'used for', 'capable of', 'part of', 'receives action', 'visible']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict fact = ['racket', 'fiber', 'ruminant']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - suppord fact predict = ['ruminant-is a', 'fiber-belong to', 'racket-is a']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - correspond target = ['tennis racket', 'banana', 'camel', 'giraffe']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - test id = 67, question = Which object in this image is related to okapi?, img = COCO_val2014_000000012179.jpg\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - real suppord fact in dataset=['okapi', 'related to', 'giraffe'], real answer = giraffe\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - normal model predict = ['giraffe', 'hippopotamus', 'zebra', 'long necked', 'snake', 'lizard', 'tree', 'elephant', 'antelope', 'scissors']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict = ['long necked', 'zoo', 'animal', 'four', 'africa', 'even toed ungulate', 'banana', 'big', 'transport', 'giraffe']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict relation = ['related to', 'belong to', 'specific', 'important', 'used for', 'at location', 'common', 'animal order', 'social', 'part of', 'has property', 'prevalent', 'capable of', 'accurate', 'acid']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict fact = ['giraffe', 'elephant', 'monkey']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - suppord fact predict = ['elephant-related to', 'giraffe-animal order', 'elephant-has property', 'elephant-used for', 'giraffe-has property', 'giraffe-at location', 'elephant-belong to', 'monkey-at location', 'monkey-related to']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - correspond target = ['animal', 'transport', 'zoo', 'banana', 'four', 'even toed ungulate', 'long necked', 'africa', 'big']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - test id = 1753, question = Which object of this image has hair, img = COCO_val2014_000000104176.jpg\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - real suppord fact in dataset=['hair', 'part of', 'head'], real answer = head\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - normal model predict = ['bicycle', 'harmonica', 'guitar', 'green', 'hair', 'corkscrew', 'car', 'person', 'orange', 'screwdriver']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict = ['doughnut', 'pineapple', 'bicycle', 'harmonica', 'guitar', 'green', 'hair', 'corkscrew', 'car', 'person']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict relation = ['part of', 'has a', 'has property', 'related to', 'is a', 'used for', 'social', 'common', 'important', 'capable of', 'specific', 'at location', 'great', 'frequent', 'large']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict fact = ['metalworking', 'torus', 'prickley']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - suppord fact predict = ['torus-related to', 'prickley-is a']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - correspond target = ['doughnut', 'pineapple']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - test id = 2506, question = Which object in this image is related to cello?, img = ILSVRC2012_test_00053657.JPEG\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - real suppord fact in dataset=['cello', 'related to', 'violin'], real answer = violin\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - normal model predict = ['cello', 'violin', 'guitar', 'piano', 'drum', 'like violin but large', 'flute', 'bow', 'metronome', 'scissors']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict = ['guitar', 'scissors', 'wood', 'cello', 'violin', 'piano', 'drum', 'like violin but large', 'flute', 'bow']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict relation = ['related to', 'specific', 'used for', 'belong to', 'important', 'common', 'part of', 'at location', 'social', 'animal order', 'accurate', 'prevalent', 'frequent', 'has a', 'capable of']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict fact = ['luthier', 'pearwood', 'sew']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - suppord fact predict = ['sew-belong to', 'luthier-related to', 'pearwood-related to']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - correspond target = ['guitar', 'scissors', 'wood']\r\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - test id = 1257, question = Which object in this image is related to chopping, img = ILSVRC2012_test_00008415.JPEG\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - real suppord fact in dataset=['axe', 'related to', 'chop'], real answer = axe\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - normal model predict = ['grass', 'tree', 'knife', 'crutch', 'wood', 'bow tie', 'corkscrew', 'fence', 'scissors', 'root']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict = ['grass', 'sheep', 'sand', 'camel', 'skateboard', 'tree', 'knife', 'crutch', 'wood', 'bow tie']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict relation = ['related to', 'belong to', 'specific', 'important', 'used for', 'common', 'animal order', 'desires', 'at location', 'social', 'capable of', 'accurate', 'part of', 'prevalent', 'visible']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - our model predict fact = ['dromedary', 'mutton', 'grind']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - suppord fact predict = ['grind-at location', 'mutton-related to', 'grind-related to', 'dromedary-related to']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - correspond target = ['grass', 'camel', 'skateboard', 'sheep', 'sand']\n",
      "INFO - 08/13/22 23:31:11 - 0:01:29 - #################################################################################\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:57<00:04,  1.40it/s]INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - test id = 132, question = Which food in this images is round and has a whole in it?, img = ILSVRC2012_test_00017846.JPEG\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - real suppord fact in dataset=['bagel', 'is a', 'round with hole in them'], real answer = bagel\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - normal model predict = ['pizza', 'bagel', 'doughnut', 'donut', 'sandwich', 'chocolate', 'strawberry', 'hamburger', 'pretzel', 'mushroom']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict = ['apple', 'box', 'basketball', 'pizza', 'bagel', 'doughnut', 'donut', 'sandwich', 'chocolate', 'strawberry']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict relation = ['is a', 'at location', 'has a', 'has property', 'related to', 'part of', 'belong to', 'created by', 'independent', 'receives action', 'important', 'animal class', 'used for', 'specific', 'small']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict fact = ['put thing in', 'round and orange', 'sweet and mushy in pie']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - suppord fact predict = ['sweet and mushy in pie-has property', 'round and orange-has property', 'put thing in-used for']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - correspond target = ['box', 'apple', 'basketball']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - test id = 214, question = Which object in this image usually contains text?, img = COCO_val2014_000000008708.jpg\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - real suppord fact in dataset=['book', 'has a', 'text'], real answer = book\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - normal model predict = ['teddy bear', 'rabbit', 'bear', 'sheep', 'human', 'dog', 'monkey', 'baby bed', 'mouse', 'toys']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict = ['keyboard', 'bookshelf', 'monitor', 'teddy bear', 'rabbit', 'bear', 'sheep', 'human', 'dog', 'monkey']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict relation = ['has a', 'has property', 'desires', 'is a', 'related to', 'used for', 'belong to', 'specific', 'long', 'capable of', 'social', 'good', 'important', 'great', 'part of']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict fact = ['show text', 'enter text', 'contain book']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - suppord fact predict = ['show text-capable of', 'contain book-used for', 'enter text-used for']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - correspond target = ['keyboard', 'monitor', 'bookshelf']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - test id = 2166, question = What can I eat?, img = COCO_val2014_000000148957.jpg\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - real suppord fact in dataset=['donut', 'belong to', 'food'], real answer = donut\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - normal model predict = ['donut', 'doughnut', 'pretzel', 'chocolate', 'apple', 'cake', 'bakery', 'sandwich', 'orange', 'fruit']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict = ['apple', 'cake', 'bread', 'banana', 'fork', 'cat', 'hot dog', 'person', 'donut', 'doughnut']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict relation = ['related to', 'used for', 'is a', 'belong to', 'at location', 'has a', 'capable of', 'specific', 'receives action', 'animal order', 'good', 'part of', 'accurate', 'important', 'blind']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict fact = ['eat', 'eat food', 'eat cat food']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - suppord fact predict = ['eat-used for', 'eat-has a', 'eat food-capable of', 'eat food-related to', 'eat food-used for', 'eat cat food-capable of']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - correspond target = ['cake', 'apple', 'cat', 'hot dog', 'bread', 'banana', 'person', 'fork']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - test id = 2124, question = Which object in this image has a tail as a part of the body?, img = ILSVRC2012_test_00018396.JPEG\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - real suppord fact in dataset=['tail', 'part of', 'cat'], real answer = cat\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - normal model predict = ['cat', 'kitten', 'shirt', 'couch', 'dog', 'neck brace', 'hat', 'sofa', 'bed', 'blue']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict = ['person', 'giraffe', 'cat', 'kitten', 'shirt', 'couch', 'dog', 'neck brace', 'hat', 'sofa']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict relation = ['has property', 'has a', 'is a', 'capable of', 'part of', 'desires', 'receives action', 'animal class', 'clean', 'good', 'human', 'animal family', 'at location', 'surface', 'animal kingdom']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict fact = ['muscle in their body', 'cover your upper body', 'bone in their neck']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - suppord fact predict = ['muscle in their body-has a', 'bone in their neck-has a']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - correspond target = ['giraffe', 'person']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - test id = 1924, question = Which vegetable in this image is to cook?, img = COCO_val2014_000000013991.jpg\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - real suppord fact in dataset=['broccoli', 'is a', 'vegetable that person may cook'], real answer = broccoli\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - normal model predict = ['broccoli', 'tomato', 'salad', 'artichoke', 'zucchini', 'lettuce', 'cheese', 'chicken', 'carrot', 'cucumber']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict = ['cheese', 'oven', 'microwave', 'stove', 'kitchen', 'broccoli', 'tomato', 'salad', 'artichoke', 'zucchini']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict relation = ['is a', 'has property', 'created by', 'capable of', 'easy', 'related to', 'convenient', 'receives action', 'used for', 'part of', 'safe', 'accurate', 'sweet', 'important', 'protected']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict fact = ['cook', 'cook meal', 'cook roast']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - suppord fact predict = ['cook meal-used for', 'cook-used for', 'cook roast-used for']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - correspond target = ['oven', 'kitchen', 'microwave', 'stove', 'cheese']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - test id = 2664, question = Which object in this image is a pet for people?, img = COCO_val2014_000000127477.jpg\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - real suppord fact in dataset=['cat', 'used for', 'pet'], real answer = cat\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - normal model predict = ['couch', 'cat', 'bed', 'pillows', 'baby bed', 'chair', 'sleep', 'sofa', 'dog', 'kitten']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict = ['dog', 'turtle', 'couch', 'cat', 'bed', 'pillows', 'baby bed', 'chair', 'sleep', 'sofa']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict relation = ['is a', 'used for', 'has a', 'related to', 'belong to', 'has property', 'easy', 'capable of', 'good', 'cool', 'convenient', 'fast', 'popular', 'important', 'common']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict fact = ['popular family pet', 'be loyal pet', 'be pet']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - suppord fact predict = ['popular family pet-is a', 'be loyal pet-capable of', 'be pet-capable of']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - correspond target = ['turtle', 'dog']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - test id = 179, question = Which food is the most related to lemon, img = COCO_val2014_000000016161.jpg\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - real suppord fact in dataset=['orange', 'related to', 'lemon'], real answer = orange\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - normal model predict = ['banana', 'fruit', 'apple', 'carrot', 'pineapple', 'orange', 'pare apple', 'lemon', 'cake', 'chocolate']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict = ['banana', 'nail', 'zoo', 'person', 'fruit', 'apple', 'carrot', 'pineapple', 'orange', 'pare apple']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict relation = ['related to', 'specific', 'used for', 'belong to', 'important', 'common', 'is a', 'at location', 'has property', 'acid', 'social', 'animal order', 'part of', 'good', 'has a']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict fact = ['monkey', 'rate', 'low']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - suppord fact predict = ['low-has property', 'rate-related to', 'monkey-at location', 'low-related to', 'monkey-related to']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - correspond target = ['banana', 'zoo', 'person', 'nail']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - test id = 1206, question = What is the family of the animal in this image?, img = COCO_val2014_000000104002.jpg\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - real suppord fact in dataset=['cattle', 'animal family', 'bovidae'], real answer = bovidae\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - normal model predict = ['cow', 'animal', 'grass', 'horse', 'human', 'giraffidae', 'actinopterygii', 'bovidae', 'gastropoda', 'herd sheep']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict = ['grass', 'even toed ungulate', 'mammal', 'dog', 'carnivora', 'chordata', 'lamp', 'cow', 'animal', 'horse']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict relation = ['animal family', 'animal class', 'animal order', 'animal kingdom', 'is a', 'animal phylum', 'has property', 'at location', 'part of', 'human', 'related to', 'has a', 'common', 'safe', 'green']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict fact = ['fox', 'sheep', 'wolf']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - suppord fact predict = ['sheep-animal order', 'fox-animal phylum', 'wolf-related to', 'fox-animal class', 'sheep-related to', 'fox-animal order']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - correspond target = ['chordata', 'grass', 'dog', 'even toed ungulate', 'lamp', 'mammal', 'carnivora']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - test id = 2147, question = where is this place?, img = COCO_val2014_000000119802.jpg\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - real suppord fact in dataset=['crossroad', 'at location', 'road'], real answer = road\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - normal model predict = ['house', 'beach', 'bathroom', 'kitchen', 'airport', 'police', 'park', 'road', 'bedroom', 'baby bed']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict = ['build', 'space to run and play', 'dog poop', 'dog', 'make person happy', 'frisbee', 'ride', 'vend stand', 'cat', 'house']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict relation = ['is a', 'has property', 'belong to', 'at location', 'related to', 'used for', 'capable of', 'has a', 'desires', 'important', 'part of', 'cool', 'good', 'specific', 'visible']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict fact = ['park', 'place', 'amusement park']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - suppord fact predict = ['park-at location', 'park-used for', 'amusement park-capable of', 'place-at location', 'amusement park-has a', 'place-belong to']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - correspond target = ['cat', 'dog poop', 'dog', 'frisbee', 'space to run and play', 'vend stand', 'make person happy', 'build', 'ride']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - test id = 499, question = What is on the back of the animal?, img = ILSVRC2012_test_00008993.JPEG\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - real suppord fact in dataset=['camel', 'related to', 'hump'], real answer = hump\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - normal model predict = ['car', 'tree', 'desert', 'camel', 'park', 'grass', 'even toed ungulate', 'elephant', 'snake', 'palm tree']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict = ['even toed ungulate', 'shell', 'carnivora', 'giraffidae', 'long necked', 'africa', 'low', 'mammal', 'chordata', 'extremely high blood pressure']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict relation = ['has a', 'animal order', 'animal class', 'animal family', 'is a', 'animal phylum', 'animal kingdom', 'fast', 'used for', 'part of', 'has property', 'receives action', 'small', 'human', 'large']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - our model predict fact = ['fox', 'turtle', 'giraffe']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - suppord fact predict = ['giraffe-animal family', 'giraffe-animal order', 'giraffe-receives action', 'turtle-has a', 'giraffe-has a', 'fox-animal phylum', 'giraffe-has property', 'fox-animal class', 'turtle-has property', 'giraffe-animal phylum', 'fox-animal order']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - correspond target = ['chordata', 'giraffidae', 'extremely high blood pressure', 'shell', 'low', 'even toed ungulate', 'long necked', 'africa', 'mammal', 'carnivora']\n",
      "INFO - 08/13/22 23:31:12 - 0:01:30 - #################################################################################\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:58<00:04,  1.34it/s]INFO - 08/13/22 23:31:13 - 0:01:31 - #################################################################################\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - test id = 1724, question = Which object in this image contains meat?, img = COCO_val2014_000000020465.jpg\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - real suppord fact in dataset=['hot dog', 'is a', 'meet product'], real answer = hot dog\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - normal model predict = ['hot dog', 'dog', 'hotdog', 'pizza', 'hamburger', 'sandwich', 'dog poop', 'bagel', 'hot room', 'chocolate']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict = ['cat', 'cow', 'person', 'knife', 'nail', 'hot dog', 'dog', 'hotdog', 'pizza', 'hamburger']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict relation = ['has a', 'is a', 'has property', 'related to', 'belong to', 'part of', 'capable of', 'used for', 'small', 'desires', 'created by', 'independent', 'large', 'social', 'specific']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict fact = ['meat', 'eat meat', 'cut meat with']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - suppord fact predict = ['meat-related to', 'cut meat with-used for', 'meat-belong to', 'eat meat-capable of']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - correspond target = ['cat', 'person', 'knife', 'cow', 'nail']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - #################################################################################\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - #################################################################################\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - test id = 705, question = Which object in this image has a crust, img = ILSVRC2012_test_00004362.JPEG\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - real suppord fact in dataset=['crust', 'part of', 'pizza'], real answer = pizza\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - normal model predict = ['bus', 'bicycle', 'truck', 'french horn', 'car', 'italian', 'clock', 'pizza', 'coffee', 'pavement']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict = ['microwave', 'laptop', 'tv', 'bus', 'bicycle', 'truck', 'french horn', 'car', 'italian', 'clock']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict relation = ['has a', 'related to', 'part of', 'is a', 'used for', 'specific', 'has property', 'common', 'social', 'capable of', 'important', 'frequent', 'low', 'light', 'animal order']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict fact = ['button', 'magnetron', 'touchpad']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - suppord fact predict = ['button-part of', 'touchpad-part of', 'magnetron-related to']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - correspond target = ['microwave', 'tv', 'laptop']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - #################################################################################\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - #################################################################################\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - test id = 2225, question = which object in this image like to eat nut, img = ILSVRC2012_test_00004200.JPEG\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - real suppord fact in dataset=['squirrel', 'related to', 'eat nut'], real answer = squirrel\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - normal model predict = ['monkey', 'squirrel', 'cat', 'elephant', 'otter', 'bird', 'animal', 'dog', 'frog', 'ant']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict = ['elephant', 'person', 'cake', 'hot dog', 'banana', 'bread', 'apple', 'toddler', 'monkey', 'squirrel']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict relation = ['desires', 'has a', 'capable of', 'related to', 'has property', 'belong to', 'is a', 'used for', 'long', 'blind', 'specific', 'human', 'important', 'animal order', 'good']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict fact = ['eat', 'eat banana', 'eat peanut']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - suppord fact predict = ['eat-used for', 'eat banana-capable of', 'eat-has a', 'eat peanut-desires']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - correspond target = ['cake', 'apple', 'toddler', 'bread', 'hot dog', 'banana', 'elephant', 'person']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - #################################################################################\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - #################################################################################\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - test id = 1008, question = Which object in this image is used for cooling things?, img = ILSVRC2012_test_00001244.JPEG\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - real suppord fact in dataset=['refrigerator', 'used for', 'cool thing'], real answer = refrigerator\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - normal model predict = ['sink', 'refrigerator', 'microwave', 'shelf', 'fridge', 'knife in drawer', 'bottle', 'wall', 'kitchen utensil', 'cup']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict = ['sink', 'jacket', 'refrigerator', 'microwave', 'shelf', 'fridge', 'knife in drawer', 'bottle', 'wall', 'kitchen utensil']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict relation = ['used for', 'related to', 'specific', 'effective', 'efficient', 'easy', 'convenient', 'accurate', 'frequent', 'hot', 'belong to', 'at location', 'common', 'expensive', 'popular']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict fact = ['rinse thing', 'keep warm', 'clean messy room']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - suppord fact predict = ['keep warm-used for', 'rinse thing-used for']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - correspond target = ['sink', 'jacket']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - #################################################################################\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - #################################################################################\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - test id = 2334, question = What objects in this image are inspirational, img = ILSVRC2012_test_00035105.JPEG\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - real suppord fact in dataset=['forest road', 'has property', 'inspirational'], real answer = forest road\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - normal model predict = ['stop sign', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car', 'bus', 'person']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict = ['stop sign', 'horse', 'tv', 'train', 'car', 'ride', 'road', 'railroad track', 'bicycle', 'travel in car']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict relation = ['capable of', 'is a', 'has property', 'receives action', 'has a', 'used for', 'related to', 'part of', 'desires', 'at location', 'belong to', 'created by', 'specific', 'good', 'animal order']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict fact = ['traffic sign', 'clop', 'advertise']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - suppord fact predict = ['advertise-used for', 'traffic sign-belong to', 'clop-related to']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - correspond target = ['stop sign', 'tv', 'horse']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:13 - 0:01:31 - #################################################################################\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - test id = 1218, question = What thing does the animal in this image have as a part?, img = COCO_val2014_000000010822.jpg\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - real suppord fact in dataset=['zebra', 'has a', 'stripe'], real answer = stripe\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - normal model predict = ['zebra', 'stripe', 'blue', 'long necked', 'cloud', 'bikini', 'giraffe', 'jazz blue', 'camel', 'ocean']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict = ['long necked', 'africa', 'animal', 'giraffidae', 'tree', 'skunk', 'even toed ungulate', 'dog', 'zoo', 'squirrel']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict relation = ['has a', 'part of', 'is a', 'related to', 'animal family', 'animal order', 'large', 'receives action', 'small', 'has property', 'capable of', 'social', 'used for', 'animal kingdom', 'at location']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - our model predict fact = ['giraffe', 'wolf', 'forest']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - suppord fact predict = ['giraffe-animal family', 'giraffe-animal order', 'giraffe-receives action', 'wolf-related to', 'forest-part of', 'forest-at location', 'giraffe-has property', 'giraffe-at location']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - correspond target = ['giraffidae', 'tree', 'animal', 'dog', 'zoo', 'squirrel', 'skunk', 'even toed ungulate', 'long necked', 'africa']\n",
      "INFO - 08/13/22 23:31:13 - 0:01:31 - #################################################################################\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:58<00:03,  1.32it/s]INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - test id = 891, question = Which object can you find in the sky in this image?, img = COCO_val2014_000000153865.jpg\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - real suppord fact in dataset=['kite', 'at location', 'sky'], real answer = kite\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - normal model predict = ['kite', 'beach', 'surfboard', 'butterfly', 'person', 'cake', 'jumping', 'make person happy', 'tennis ball', 'swimming']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict = ['airplane', 'kite', 'beach', 'surfboard', 'butterfly', 'person', 'cake', 'jumping', 'make person happy', 'tennis ball']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict relation = ['at location', 'capable of', 'has property', 'is a', 'has a', 'part of', 'belong to', 'protected', 'tall', 'safe', 'impassable', 'visible', 'convenient', 'small', 'used for']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict fact = ['fly in sky', 'in sky', 'vehicle that fly']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - suppord fact predict = ['in sky-at location', 'vehicle that fly-is a']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - correspond target = ['airplane']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - test id = 1250, question = Which object in this image is related to a springbok?, img = ILSVRC2012_test_00002108.JPEG\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - real suppord fact in dataset=['springbok', 'related to', 'antelope'], real answer = antelope\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - normal model predict = ['grass', 'horse', 'frisbee', 'sand', 'camel', 'sheep', 'cow', 'herd sheep', 'crutch', 'kite']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict = ['grass', 'sand', 'monkey', 'skateboard', 'horse', 'frisbee', 'camel', 'sheep', 'cow', 'herd sheep']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict relation = ['related to', 'specific', 'used for', 'belong to', 'important', 'capable of', 'part of', 'common', 'has property', 'at location', 'is a', 'has a', 'social', 'accurate', 'surface']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict fact = ['primate', 'spinifex', 'grind']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - suppord fact predict = ['primate-related to', 'spinifex-related to', 'primate-is a', 'grind-at location', 'grind-related to']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - correspond target = ['grass', 'monkey', 'skateboard', 'sand']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - test id = 2001, question = What is the place in this image used for?, img = COCO_val2014_000000011727.jpg\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - real suppord fact in dataset=['bathroom', 'used for', 'clean your tooth in'], real answer = clean your tooth in\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - normal model predict = ['pee', 'wash', 'swim', 'sleep', 'preventing from getting wet', 'laundromat', 'sleep away from home', 'toilet', 'cold and wet', 'sink']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict = ['pee', 'wash', 'cooking', 'prepare food', 'hotel room', 'breakfast', 'house', 'plunger', 'swim', 'sleep']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict relation = ['used for', 'belong to', 'capable of', 'related to', 'effective', 'good', 'receives action', 'part of', 'great', 'specific', 'easy', 'at location', 'popular', 'important', 'animal order']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict fact = ['kitchenette', 'shower', 'toilet']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - suppord fact predict = ['toilet-used for', 'kitchenette-used for', 'kitchenette-at location', 'shower-used for']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - correspond target = ['prepare food', 'house', 'hotel room', 'plunger', 'cooking', 'pee', 'wash', 'breakfast']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - test id = 2257, question = Which animal in this image is related to cattleman?, img = COCO_val2014_000000019157.jpg\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - real suppord fact in dataset=['cattleman', 'related to', 'cattle'], real answer = cattle\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - normal model predict = ['horse', 'cow', 'cattle', 'sheep', 'camel', 'dog', 'elephant', 'grass', 'tree', 'herd sheep']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict = ['cow', 'camel', 'horse', 'cattle', 'sheep', 'dog', 'elephant', 'grass', 'tree', 'herd sheep']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict relation = ['related to', 'specific', 'important', 'belong to', 'used for', 'capable of', 'common', 'part of', 'at location', 'accurate', 'social', 'is a', 'animal order', 'has a', 'frequent']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict fact = ['dromedary', 'cattle', 'rhino']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - suppord fact predict = ['cattle-belong to', 'cattle-related to', 'dromedary-related to']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - correspond target = ['camel', 'cow']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - test id = 1708, question = What might one find in this appliance?, img = ILSVRC2012_test_00002720.JPEG\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - real suppord fact in dataset=['bread', 'at location', 'toaster'], real answer = bread\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - normal model predict = ['toaster', 'oven', 'bakery', 'microwave', 'vend stand', 'kitchen utensil', 'clock', 'drive screw', 'fridge', 'screwdriver']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict = ['toaster', 'oven', 'microwave', 'kitchen utensil', 'refrigerator', 'knife in drawer', 'stove', 'rice cooker', 'house', 'cook food']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict relation = ['at location', 'belong to', 'used for', 'related to', 'has a', 'specific', 'capable of', 'animal order', 'part of', 'has property', 'good', 'receives action', 'is a', 'important', 'social']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict fact = ['appliance', 'kitchen', 'electric appliance']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - suppord fact predict = ['appliance-is a', 'kitchen-at location', 'kitchen-used for', 'electric appliance-related to']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - correspond target = ['kitchen utensil', 'oven', 'refrigerator', 'knife in drawer', 'house', 'microwave', 'toaster', 'rice cooker', 'stove', 'cook food']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - test id = 1673, question = what can be found in mall n this image, img = COCO_val2014_000000106392.jpg\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - real suppord fact in dataset=['fork', 'at location', 'mall'], real answer = fork\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - normal model predict = ['wash machine', 'oven', 'toaster', 'microwave', 'toilet paper', 'coffee', 'house', 'cup', 'sound control room', 'use toilet']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict = ['wash machine', 'oven', 'microwave', 'toilet paper', 'house', 'cup', 'kitchen utensil', 'cook food', 'rice cooker', 'knife in drawer']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict relation = ['at location', 'used for', 'has a', 'part of', 'animal order', 'receives action', 'related to', 'belong to', 'specific', 'social', 'animal family', 'frequent', 'animal class', 'good', 'crowded']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict fact = ['laundromat', 'kitchen', 'restaurant kitchen']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - suppord fact predict = ['laundromat-at location', 'kitchen-at location', 'kitchen-belong to', 'kitchen-used for']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - correspond target = ['kitchen utensil', 'oven', 'toilet paper', 'knife in drawer', 'house', 'microwave', 'wash machine', 'cup', 'rice cooker', 'cook food']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - test id = 157, question = Which fruit in this image is most similar to mandarin?, img = ILSVRC2012_test_00007382.JPEG\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - real suppord fact in dataset=['orange', 'related to', 'mandarin'], real answer = orange\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - normal model predict = ['strawberry', 'lemon', 'salad', 'tomato', 'pineapple', 'apple', 'cake', 'mushroom', 'cucumber', 'bell pepper']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict = ['hammer', 'strawberry', 'lemon', 'salad', 'tomato', 'pineapple', 'apple', 'cake', 'mushroom', 'cucumber']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict relation = ['related to', 'used for', 'specific', 'belong to', 'important', 'common', 'is a', 'prevalent', 'acid', 'dangerous', 'good', 'accurate', 'has property', 'effective', 'at location']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict fact = ['make joke', 'pound', 'sugar cure']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - suppord fact predict = ['pound-related to']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - correspond target = ['hammer']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - test id = 1503, question = What action do you need to play this game?, img = COCO_val2014_000000108130.jpg\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - real suppord fact in dataset=['frisbee', 'related to', 'throw'], real answer = throw\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - normal model predict = ['racket', 'racquet', 'tennis racket', 'baseball bat', 'shell', 'kite', 'tennis ball', 'frisbee', 'string', 'helmet']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict = ['racket', 'racquet', 'kite', 'tennis ball', 'wii', 'person', 'volleyball', 'computer', 'baseball', 'laptop']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict relation = ['belong to', 'used for', 'capable of', 'at location', 'related to', 'easy', 'important', 'good', 'convenient', 'has property', 'fast', 'specific', 'accurate', 'expensive', 'reliable']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict fact = ['ball games', 'video game', 'play game']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - suppord fact predict = ['play game-capable of', 'video game-related to', 'play game-used for', 'video game-belong to', 'ball games-belong to']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - correspond target = ['racquet', 'laptop', 'computer', 'wii', 'person', 'volleyball', 'racket', 'kite', 'tennis ball', 'baseball']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - test id = 2181, question = Which object in this image can be found in the movie 'Deliverance'?, img = ILSVRC2012_test_00000658.JPEG\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - real suppord fact in dataset=['banjo', 'at location', 'movie deliverance'], real answer = banjo\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - normal model predict = ['guitar', 'music studio', 'microphone', 'banjo', 'drum', 'music', 'harmonica', 'play music', 'playing', 'piano']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict = ['person', 'giraffe', 'helmet', 'guitar', 'music studio', 'microphone', 'banjo', 'drum', 'music', 'harmonica']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict relation = ['at location', 'related to', 'belong to', 'specific', 'used for', 'important', 'visible', 'animal order', 'capable of', 'desires', 'accurate', 'part of', 'human', 'social', 'common']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict fact = ['neck', 'nose', 'prevent head injury']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - suppord fact predict = ['prevent head injury-capable of', 'nose-part of', 'neck-related to']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - correspond target = ['giraffe', 'person', 'helmet']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - test id = 2642, question = Which object in this image belongs to the category information technology?, img = COCO_val2014_000000116252.jpg\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - real suppord fact in dataset=['computer', 'belong to', 'media technology'], real answer = computer\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - normal model predict = ['monitor', 'cell phone', 'computer', 'laptop', 'keyboard', 'phone', 'mouse', 'modern device', 'remote', 'ipod']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict = ['monitor', 'laptop', 'vehicle', 'cell phone', 'computer', 'keyboard', 'phone', 'mouse', 'modern device', 'remote']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict relation = ['belong to', 'is a', 'desires', 'animal phylum', 'animal kingdom', 'loyal', 'related to', 'trustworthy', 'animal order', 'protected', 'comfortable', 'sensible', 'important', 'animal class', 'animal family']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict fact = ['mobile technology', 'technology', 'digital technology']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - suppord fact predict = ['technology-belong to', 'mobile technology-belong to', 'digital technology-belong to']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - correspond target = ['vehicle', 'monitor', 'laptop']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:59<00:03,  1.29it/s]INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - test id = 2785, question = What is the object in the bottom left of this image used for?, img = COCO_val2014_000000102641.jpg\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - real suppord fact in dataset=['remote', 'used for', 'control tv'], real answer = control tv\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - normal model predict = ['travel', 'cut', 'travel in car', 'space to run and play', 'sleep away from home', 'play music', 'move', 'work', 'prepare food', 'fun']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict = ['listen to music', 'play', 'play game of baseball', 'play baseball on it', 'play baseball', 'apple', 'baseball', 'sheep', 'travel', 'cut']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict relation = ['used for', 'capable of', 'related to', 'belong to', 'specific', 'at location', 'effective', 'good', 'great', 'efficient', 'high', 'part of', 'expensive', 'animal order', 'important']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict fact = ['ipod', 'baseball field', 'baa']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - suppord fact predict = ['baseball field-used for', 'ipod-belong to', 'baa-related to', 'ipod-used for', 'baseball field-at location']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - correspond target = ['apple', 'play game of baseball', 'sheep', 'play baseball on it', 'play', 'play baseball', 'baseball', 'listen to music']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - test id = 2003, question = Which object in this image can be found in herpetarium?, img = ILSVRC2012_test_00000108.JPEG\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - real suppord fact in dataset=['snake', 'at location', 'herpetarium'], real answer = snake\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - normal model predict = ['snake', 'frog', 'lizard', 'turtle', 'monkey', 'hot dog', 'armadillo', 'cross river', 'big', 'bird']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict = ['dog', 'cat', 'zoo', 'tv', 'banana', 'snake', 'frog', 'lizard', 'turtle', 'monkey']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict relation = ['at location', 'used for', 'has a', 'capable of', 'belong to', 'part of', 'specific', 'visible', 'active', 'human', 'has property', 'surface', 'related to', 'animal family', 'animal order']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict fact = ['petshop', 'monkey', 'apartment']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - suppord fact predict = ['apartment-at location', 'petshop-at location', 'monkey-at location', 'monkey-related to']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - correspond target = ['cat', 'dog', 'zoo', 'banana', 'tv']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - test id = 961, question = which object in this image can help people move, img = ILSVRC2012_test_00023289.JPEG\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - real suppord fact in dataset=['car', 'is a', 'person mover'], real answer = car\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - normal model predict = ['bus', 'taxi', 'train', 'person', 'car', 'transport person', 'train station', 'truck', 'railroad track', 'stop sign']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict = ['airplane', 'computer', 'bus', 'taxi', 'train', 'person', 'car', 'transport person', 'train station', 'truck']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict relation = ['capable of', 'used for', 'related to', 'has a', 'is a', 'good', 'desires', 'accurate', 'great', 'fast', 'easy', 'specific', 'long', 'high', 'intelligent']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict fact = ['help person', 'transport person', 'bus stop']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - suppord fact predict = ['transport person-used for', 'help person-capable of']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - correspond target = ['airplane', 'computer']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - test id = 774, question = What is the metal thing is used for?, img = COCO_val2014_000000104568.jpg\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - real suppord fact in dataset=['oven', 'used for', 'cooking'], real answer = cooking\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - normal model predict = ['cut', 'banana', 'orange', 'fruit', 'rich in vitamin c', 'green', 'preventing from getting wet', 'peel', 'pomegranate', 'lemon']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict = ['cut', 'pare apple', 'teddy bear', 'kite', 'wii', 'frisbee', 'skateboard', 'banana', 'orange', 'fruit']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict relation = ['used for', 'related to', 'belong to', 'has property', 'good', 'effective', 'capable of', 'is a', 'easy', 'safe', 'specific', 'at location', 'efficient', 'expensive', 'receives action']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict fact = ['knife', 'toy', 'toys']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - suppord fact predict = ['toy-related to', 'toy-is a', 'knife-used for', 'toys-belong to', 'toy-belong to']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - correspond target = ['skateboard', 'frisbee', 'wii', 'teddy bear', 'kite', 'pare apple', 'cut']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - test id = 1442, question = Which animal in this image can be found in kansa?, img = ILSVRC2012_test_00000165.JPEG\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - real suppord fact in dataset=['snake', 'at location', 'kansa'], real answer = snake\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - normal model predict = ['snake', 'lizard', 'frog', 'bird', 'monkey', 'giraffe', 'butterfly', 'turtle', 'ant', 'armadillo']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict = ['dog', 'zoo', 'dog poop', 'banana', 'person', 'space to run and play', 'frisbee', 'vend stand', 'snake', 'lizard']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict relation = ['at location', 'used for', 'has a', 'capable of', 'part of', 'related to', 'belong to', 'is a', 'specific', 'human', 'receives action', 'small', 'animal order', 'active', 'surface']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict fact = ['park', 'village', 'monkey']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - suppord fact predict = ['park-at location', 'park-used for', 'village-at location', 'monkey-at location', 'monkey-related to']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - correspond target = ['dog poop', 'dog', 'zoo', 'frisbee', 'banana', 'space to run and play', 'vend stand', 'person']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - test id = 1668, question = Which computer can you see in this image?, img = ILSVRC2012_test_00016048.JPEG\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - real suppord fact in dataset=['laptop', 'belong to', 'computer'], real answer = laptop\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - normal model predict = ['computer', 'monitor', 'cell phone', 'printer', 'tv', 'ipod', 'control tv', 'camera', 'your house', 'toys']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict = ['computer', 'monitor', 'cell phone', 'ipod', 'keyboard', 'printer', 'tv', 'control tv', 'camera', 'your house']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict relation = ['belong to', 'is a', 'at location', 'has property', 'related to', 'capable of', 'used for', 'desires', 'has a', 'fast', 'important', 'blind', 'good', 'visible', 'long']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - our model predict fact = ['video', 'digital electronics', 'program']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - suppord fact predict = ['digital electronics-belong to', 'program-used for', 'video-belong to']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - correspond target = ['ipod', 'computer', 'cell phone', 'monitor', 'keyboard']\n",
      "INFO - 08/13/22 23:31:14 - 0:01:32 - #################################################################################\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [01:00<00:02,  1.40it/s]INFO - 08/13/22 23:31:15 - 0:01:33 - #################################################################################\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - test id = 327, question = What can be found in this place?, img = ILSVRC2012_test_00000352.JPEG\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - real suppord fact in dataset=['dolphin', 'at location', 'sea'], real answer = dolphin\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - normal model predict = ['boat', 'coast', 'wave', 'shore boat', 'sail boat', 'whale', 'sea', 'dolphin', 'surf board', 'raft']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict = ['boat', 'coast', 'wave', 'surf board', 'lot of sand', 'shell', 'pretty girl', 'blue', 'sand', 'swim']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict relation = ['at location', 'has a', 'used for', 'related to', 'part of', 'belong to', 'capable of', 'receives action', 'has property', 'specific', 'surface', 'animal order', 'human', 'is a', 'animal family']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict fact = ['ocean beach', 'ocean', 'beach']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - suppord fact predict = ['beach-at location', 'ocean-has a', 'ocean-at location', 'ocean-part of', 'ocean beach-used for', 'ocean-used for', 'ocean-has property', 'beach-has a']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - correspond target = ['sand', 'blue', 'coast', 'wave', 'boat', 'shell', 'swim', 'lot of sand', 'surf board', 'pretty girl']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - #################################################################################\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - #################################################################################\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - test id = 287, question = What is this place used for?, img = COCO_val2014_000000006864.jpg\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - real suppord fact in dataset=['airport', 'used for', 'airplane'], real answer = airplane\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - normal model predict = ['sleep away from home', 'sit outside', 'laundromat', 'sleep', 'travel', 'travel in car', 'entertain yourself on windy day', 'plane to land on', 'swimming', 'store boat']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict = ['travel', 'plane to land on', 'land plane', 'airport', 'land airplane', 'station', 'car', 'train', 'plane', 'sleep away from home']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict relation = ['used for', 'capable of', 'related to', 'belong to', 'effective', 'receives action', 'has property', 'at location', 'good', 'high', 'efficient', 'specific', 'easy', 'important', 'part of']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict fact = ['train', 'runway', 'train station']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - suppord fact predict = ['train station-related to', 'train-at location', 'train-used for', 'runway-at location', 'train-efficient', 'runway-used for']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - correspond target = ['land airplane', 'train', 'station', 'plane to land on', 'plane', 'car', 'travel', 'airport', 'land plane']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - #################################################################################\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - #################################################################################\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - test id = 2814, question = What object in this image can be used to transport a large number of people?, img = COCO_val2014_000000106508.jpg\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - real suppord fact in dataset=['bus', 'is a', 'form of mass transit'], real answer = bus\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - normal model predict = ['bus', 'taxi', 'train', 'train station', 'truck', 'ride', 'railroad track', 'transport', 'road', 'driving']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict = ['bicycle', 'bus', 'taxi', 'train', 'train station', 'truck', 'ride', 'railroad track', 'transport', 'road']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict relation = ['capable of', 'used for', 'has a', 'is a', 'related to', 'part of', 'belong to', 'fast', 'at location', 'receives action', 'good', 'animal order', 'blind', 'desires', 'great']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict fact = ['large than person', 'usually small', 'popular form of transportation especially among child environmentalist and asian']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - suppord fact predict = ['popular form of transportation especially among child environmentalist and asian-is a']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - correspond target = ['bicycle']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - #################################################################################\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - #################################################################################\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - test id = 2182, question = which object is bigger than an elephant, img = ILSVRC2012_test_00002435.JPEG\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - real suppord fact in dataset=['whale', 'big', 'elephant'], real answer = whale\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - normal model predict = ['sea', 'whale', 'shore boat', 'boat', 'ocean', 'sand', 'desert', 'big', 'fish', 'water']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict = ['life preserver', 'sea', 'whale', 'shore boat', 'boat', 'ocean', 'sand', 'desert', 'big', 'fish']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict relation = ['big', 'light', 'small', 'large', 'tall', 'compact', 'solar', 'popular', 'green', 'is a', 'has a', 'has property', 'colorful', 'expensive', 'impassable']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict fact = ['moby dick', 'dock', 'boat']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - suppord fact predict = ['boat-has a']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - correspond target = ['life preserver']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - #################################################################################\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - #################################################################################\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - test id = 151, question = What equipment in the image has a physical impact buffer?, img = COCO_val2014_000000004021.jpg\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - real suppord fact in dataset=['glove', 'is a', 'physical impact buff'], real answer = glove\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - normal model predict = ['baseball', 'baseball bat', 'baseball glove', 'baseball field', 'play baseball', 'play baseball on it', 'soccer ball', 'play game of baseball', 'golf ball', 'rugby ball']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict = ['baseball', 'tennis ball', 'tennis racket', 'basketball', 'frisbee', 'racket', 'volleyball', 'snowboard', 'snowmobile', 'baseball bat']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict relation = ['related to', 'has a', 'capable of', 'is a', 'belong to', 'part of', 'specific', 'used for', 'important', 'at location', 'common', 'good', 'long', 'has property', 'strong']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict fact = ['physical sport', 'spectator sport', 'sport']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - suppord fact predict = ['sport-belong to', 'sport-used for', 'sport-is a', 'spectator sport-is a', 'sport-related to', 'physical sport-is a']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - correspond target = ['basketball', 'snowmobile', 'frisbee', 'volleyball', 'tennis racket', 'racket', 'tennis ball', 'baseball', 'snowboard']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - #################################################################################\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - #################################################################################\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - test id = 1982, question = What object in this image is protective equipment?, img = COCO_val2014_000000100909.jpg\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - real suppord fact in dataset=['baseball glove', 'is a', 'protective garment'], real answer = baseball glove\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - normal model predict = ['helmet', 'kite', 'surfboard', 'sunglasses', 'bicycle', 'frisbee', 'snowboard', 'baseball glove', 'golfcart', 'baseball bat']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict = ['helmet', 'surfboard', 'snowboard', 'tennis racket', 'computer', 'kite', 'sunglasses', 'bicycle', 'frisbee', 'baseball glove']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict relation = ['belong to', 'is a', 'related to', 'receives action', 'capable of', 'used for', 'part of', 'has property', 'important', 'has a', 'at location', 'specific', 'desires', 'good', 'animal order']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - our model predict fact = ['protective gear', 'equipment', 'sport equipment']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - suppord fact predict = ['sport equipment-is a', 'equipment-belong to', 'protective gear-belong to']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - correspond target = ['computer', 'surfboard', 'helmet', 'tennis racket', 'snowboard']\n",
      "INFO - 08/13/22 23:31:15 - 0:01:33 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████████ | 87/89 [01:01<00:01,  1.32it/s]INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - test id = 2541, question = which object in this image is related to 'woolly animal'?, img = COCO_val2014_000000027438.jpg\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - real suppord fact in dataset=['sheep', 'related to', 'woolly animal'], real answer = sheep\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - normal model predict = ['sheep', 'herd sheep', 'cattle', 'cow', 'horse', 'grass', 'dog', 'animal', 'dog poop', 'elephant']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict = ['cow', 'horse', 'dog', 'elephant', 'antelope', 'camel', 'cat', 'giraffe', 'armadillo', 'zebra']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict relation = ['related to', 'specific', 'used for', 'belong to', 'important', 'animal order', 'common', 'social', 'frequent', 'accurate', 'prevalent', 'has a', 'at location', 'acid', 'part of']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict fact = ['animal', 'farm animal', 'pet animal']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - suppord fact predict = ['animal-related to', 'animal-belong to', 'farm animal-related to', 'pet animal-related to']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - correspond target = ['cat', 'horse', 'dog', 'armadillo', 'camel', 'antelope', 'zebra', 'elephant', 'giraffe', 'cow']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - test id = 768, question = Which object in this image is used in a bloody mary?, img = COCO_val2014_000000105014.jpg\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - real suppord fact in dataset=['bloody mary', 'related to', 'tomato'], real answer = tomato\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - normal model predict = ['spoon', 'bread', 'knife', 'apple', 'fry bread', 'bowl', 'carrot', 'fork', 'cake', 'kitchen utensil']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict = ['pizza', 'person', 'spoon', 'bread', 'knife', 'apple', 'fry bread', 'bowl', 'carrot', 'fork']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict relation = ['is a', 'used for', 'belong to', 'at location', 'easy', 'related to', 'good', 'convenient', 'capable of', 'has property', 'receives action', 'safe', 'has a', 'visible', 'accurate']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict fact = ['high in calorie', 'italy', 'believe in santa claus']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - suppord fact predict = ['italy-belong to', 'high in calorie-has property', 'believe in santa claus-capable of']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - correspond target = ['pizza', 'person']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - test id = 2566, question = which object in this image can be used without power, img = ILSVRC2012_test_00027426.JPEG\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - real suppord fact in dataset=['bowl', 'is a', 'non power device'], real answer = bowl\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - normal model predict = ['bowl', 'dishes', 'vase', 'spoon', 'cup', 'dining table', 'kitchen table', 'kitchen utensil', 'basket', 'sink']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict = ['chair', 'couch', 'cat', 'sofa', 'dog', 'bowl', 'dishes', 'vase', 'spoon', 'cup']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict relation = ['used for', 'related to', 'at location', 'belong to', 'has property', 'receives action', 'specific', 'capable of', 'good', 'accurate', 'is a', 'has a', 'effective', 'animal order', 'common']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict fact = ['it', 'please it master', 'wash itself']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - suppord fact predict = ['it-is a', 'please it master-capable of', 'it-used for', 'wash itself-capable of', 'it-related to', 'it-belong to']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - correspond target = ['cat', 'sofa', 'dog', 'couch', 'chair']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - test id = 2102, question = Which object in this image is used in spaghetti sauce?, img = ILSVRC2012_test_00056044.JPEG\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - real suppord fact in dataset=['spaghetti sauce', 'related to', 'tomato'], real answer = tomato\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - normal model predict = ['bagel', 'tomato', 'pizza', 'zucchini', 'sandwich', 'salad', 'cheese', 'apple', 'toast bread', 'cucumber']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict = ['pizza', 'bagel', 'tomato', 'zucchini', 'sandwich', 'salad', 'cheese', 'apple', 'toast bread', 'cucumber']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict relation = ['has property', 'created by', 'used for', 'receives action', 'is a', 'has a', 'green', 'red', 'popular', 'protected', 'small', 'compact', 'firm', 'high', 'belong to']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict fact = ['sauce', 'tomato sauce', 'dough tomato sauce and mozzarella cheese']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - suppord fact predict = ['dough tomato sauce and mozzarella cheese-created by']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - correspond target = ['pizza']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - test id = 1977, question = Which object in this image can be found in table, img = COCO_val2014_000000106392.jpg\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - real suppord fact in dataset=['bottle', 'at location', 'table'], real answer = bottle\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - normal model predict = ['tv', 'house', 'electric fan', 'train station', 'microwave', 'station', 'bus', 'computer', 'clock', 'sound control room']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict = ['tv', 'computer', 'cat', 'toilet', 'bathroom', 'house', 'electric fan', 'train station', 'microwave', 'station']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict relation = ['at location', 'used for', 'has a', 'belong to', 'related to', 'specific', 'part of', 'frequent', 'visible', 'social', 'animal order', 'human', 'surface', 'great', 'crowded']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict fact = ['apartment', 'cyberdating', 'hotel']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - suppord fact predict = ['hotel-at location', 'apartment-at location', 'cyberdating-related to']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - correspond target = ['toilet', 'cat', 'computer', 'bathroom', 'tv']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - test id = 2326, question = what object in this image can pout?, img = COCO_val2014_000000011567.jpg\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - real suppord fact in dataset=['person', 'capable of', 'pout'], real answer = person\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - normal model predict = ['tennis ball', 'tennis racket', 'tennis', 'golf ball', 'person', 'soccer ball', 'racket', 'ball', 'play tennis', 'rugby ball']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict = ['tennis ball', 'tennis racket', 'tennis', 'soccer ball', 'play tennis', 'rugby ball', 'racquet', 'volleyball', 'play basketball', 'tv']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict relation = ['capable of', 'used for', 'related to', 'desires', 'has property', 'belong to', 'receives action', 'at location', 'fast', 'has a', 'good', 'easy', 'important', 'is a', 'specific']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict fact = ['ball', 'advertise', 'court']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - suppord fact predict = ['ball-related to', 'court-used for', 'ball-is a', 'advertise-used for', 'ball-belong to']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - correspond target = ['tennis', 'rugby ball', 'play tennis', 'volleyball', 'tv', 'play basketball', 'tennis racket', 'racquet', 'tennis ball', 'soccer ball']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - test id = 2613, question = Where the food in the image is fried or not?, img = COCO_val2014_000000111024.jpg\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - real suppord fact in dataset=['doughnut', 'related to', 'fry bread'], real answer = fry bread\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - normal model predict = ['bread', 'cheese', 'pizza', 'strawberry', 'bakery', 'toast bread', 'fig', 'chocolate', 'doughnut', 'bagel']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict = ['bread', 'cheese', 'pizza', 'mushroom', 'unhealthy', 'hamburger', 'italian', 'oven', 'hot dog', 'fridge']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict relation = ['has property', 'related to', 'is a', 'belong to', 'receives action', 'has a', 'used for', 'at location', 'created by', 'good', 'light', 'protected', 'firm', 'specific', 'clean']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict fact = ['pizza', 'sandwich', 'pizza parlor']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - suppord fact predict = ['pizza-has a', 'sandwich-belong to', 'pizza parlor-related to', 'pizza-related to', 'pizza-has property', 'pizza-at location', 'sandwich-used for', 'sandwich-at location', 'pizza-belong to']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - correspond target = ['cheese', 'mushroom', 'oven', 'hot dog', 'bread', 'fridge', 'unhealthy', 'pizza', 'italian', 'hamburger']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - test id = 1894, question = What kinds of vehicle is presented in this image?, img = ILSVRC2012_test_00053584.JPEG\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - real suppord fact in dataset=['car', 'related to', 'vehicle'], real answer = car\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - normal model predict = ['dog', 'hot dog', 'dog poop', 'animal', 'food', 'cow', 'toys', 'cat', 'toy', 'rabbit']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict = ['cart', 'bicycle', 'truck', 'unicycle', 'train', 'motorcycle', 'airplane', 'bus', 'dog', 'hot dog']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict relation = ['is a', 'has property', 'has a', 'animal class', 'animal order', 'animal family', 'animal kingdom', 'part of', 'good', 'important', 'safe', 'created by', 'common', 'at location', 'fast']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - our model predict fact = ['vehicle', 'car', 'vehicle type']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - suppord fact predict = ['car-safe', 'vehicle type-is a', 'vehicle-is a', 'car-fast']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - correspond target = ['airplane', 'bus', 'truck', 'motorcycle', 'unicycle', 'train', 'bicycle', 'cart']\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################\n",
      "100%|███████████████████████████████████████████| 89/89 [01:02<00:00,  1.43it/s]\n",
      "self.min: 106.8627700805664\n",
      "self.max: 347.17523193359375\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - ####  acc1= 0.00, acc3= 0.00, acc10= 85.87\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################################################\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - ####  mrr= 0.6561, mr = 11.27\n",
      "INFO - 08/13/22 23:31:16 - 0:01:34 - #################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "# 联合测试\n",
    "\n",
    "%cd code\n",
    "!python3 joint_test.py --gpu_id 4 --exp_name fusion_prediction_exp --ZSL 0 --fusion_model SAN  --method_choice W2V --exp_id rel15_fact3data_3score_10  --batch_size 32 --data_choice 3 --top_rel 15 --top_fact 3 --soft_score 100  --mrr 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8078114d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-12T15:18:37.953634Z",
     "start_time": "2022-08-12T15:18:37.232359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os,torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7,8,9\"\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a04de387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-12T11:20:28.630944Z",
     "start_time": "2022-08-12T11:20:00.923697Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 08/12/22 19:20:04 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 08/12/22 19:20:04 - 0:00:00 - The experiment will be stored in dump/0812-mask_prediction/rel3_fact5data_3score_10\n",
      "                                     \n",
      "INFO - 08/12/22 19:20:04 - 0:00:00 - Running command: python joint_test_mask.py --gpu_id 4 --exp_name mask_prediction --ZSL 0 --exp_id rel3_fact5data_3score_10 --data_choice 3 --top_rel 10 --top_fact 10 --soft_score 0 --mrr 1\n",
      "\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 128\n",
      "batch_size 128\n",
      "begin test! ...\n",
      "loading model  ...\n",
      "Traceback (most recent call last):\n",
      "  File \"joint_test_mask.py\", line 408, in <module>\n",
      "    runner = Runner(cfg)\n",
      "  File \"joint_test_mask.py\", line 71, in __init__\n",
      "    self._load_model(self.fusion_model_ans, \"fusion\", \"answer\")\n",
      "  File \"joint_test_mask.py\", line 340, in _load_model\n",
      "    model.load_state_dict(torch.load(save_path))\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/torch/serialization.py\", line 584, in load\n",
      "    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/torch/serialization.py\", line 842, in _load\n",
      "    result = unpickler.load()\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/torch/serialization.py\", line 834, in persistent_load\n",
      "    load_tensor(data_type, size, key, _maybe_decode_ascii(location))\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/torch/serialization.py\", line 823, in load_tensor\n",
      "    loaded_storages[key] = restore_location(storage, location)\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/torch/serialization.py\", line 174, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/torch/serialization.py\", line 156, in _cuda_deserialize\n",
      "    return obj.cuda(device)\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/torch/_utils.py\", line 77, in _cuda\n",
      "    return new_type(self.size()).copy_(self, non_blocking)\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/torch/cuda/__init__.py\", line 480, in _lazy_new\n",
      "    return super(_CudaBase, cls).__new__(cls, *args, **kwargs)\n",
      "RuntimeError: CUDA error: out of memory\n"
     ]
    }
   ],
   "source": [
    "# 联合测试2\n",
    "%cd code\n",
    "!python joint_test_mask.py --gpu_id 4 --exp_name mask_prediction --ZSL 0 --exp_id rel3_fact5data_3score_10 --data_choice 3 --top_rel 10 --top_fact 10 --soft_score 0  --mrr 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1f6a50a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T10:45:06.084915Z",
     "start_time": "2022-04-16T10:40:00.851644Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "INFO - 04/16/22 18:40:02 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 04/16/22 18:40:02 - 0:00:00 - The experiment will be stored in dump/0416-joint_test_fact_surface/rel3_fact5data_3score_10\n",
      "                                     \n",
      "INFO - 04/16/22 18:40:02 - 0:00:00 - Running command: python joint_test_fact_surface.py --gpu_id 1 --exp_name joint_test_fact_surface --ZSL 0 --exp_id rel3_fact5data_3score_10 --data_choice 3 --top_rel 10 --top_fact 10 --soft_score 0 --mrr 1\n",
      "\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 128\n",
      "batch_size 128\n",
      "begin test! ...\n",
      "loading model  ...\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_answer_SAN_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_answer_MLP_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_relation_SAN_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_relation_MLP_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_fact_SAN_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_fact_MLP_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_fact_SAN_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_fact_MLP_3.pkl model done!\n",
      "use train data: 3\n",
      "batch_size 128\n",
      "use train data: 3\n",
      "batch_size 128\n",
      "use train data: 3\n",
      "batch_size 128\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]tensor([0.0470, 0.0473, 0.0467, 0.0451, 0.0450, 0.0458, 0.0442, 0.0441, 0.0454,\n",
      "        0.0456, 0.0455, 0.0451, 0.0452, 0.0438, 0.0442, 0.0442, 0.0448, 0.0456,\n",
      "        0.0449, 0.0442], device='cuda:1', dtype=torch.float64)\n",
      "tensor([0.0581, 0.0585, 0.0467, 0.0451, 0.0450, 0.0458, 0.0442, 0.0441, 0.0454,\n",
      "        0.0456, 0.0455, 0.0451, 0.0452, 0.0438, 0.0442, 0.0442, 0.0448, 0.0456,\n",
      "        0.0449, 0.0442], device='cuda:1', dtype=torch.float64)\n",
      "100%|███████████████████████████████████████████| 23/23 [04:40<00:00, 12.19s/it]\n",
      "self.min: 135.8485870361328\n",
      "self.max: 272.82403564453125\n",
      "INFO - 04/16/22 18:45:04 - 0:05:02 - #################################################################################################################\n",
      "INFO - 04/16/22 18:45:04 - 0:05:02 - ####  acc1= 54.34, acc3= 73.04, acc10= 86.75\n",
      "INFO - 04/16/22 18:45:04 - 0:05:02 - #################################################################################################################\n",
      "INFO - 04/16/22 18:45:04 - 0:05:02 - #################################################################################################################\n",
      "INFO - 04/16/22 18:45:04 - 0:05:02 - ####  mrr= 0.6567, mr = 10.60\n",
      "INFO - 04/16/22 18:45:04 - 0:05:02 - #################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "# 联合测试 FACR surface\n",
    "%cd code\n",
    "!python joint_test_fact_surface.py --gpu_id 1 --exp_name joint_test_fact_surface --ZSL 0 --exp_id rel3_fact5data_3score_10 --data_choice 3 --top_rel 10 --top_fact 10 --soft_score 0  --mrr 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "918dca3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T10:29:54.604933Z",
     "start_time": "2023-01-12T10:29:39.788745Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 01/12/23 18:29:43 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 01/12/23 18:29:43 - 0:00:00 - The experiment will be stored in dump/0112-knowledge_space/W2V\n",
      "                                     \n",
      "INFO - 01/12/23 18:29:43 - 0:00:00 - Running command: python main.py --gpu_id 8 --exp_name knowledge_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --save_model 1 --relation_map 1\n",
      "\n",
      "2023-01-12 18:29:45.069837: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-12 18:29:45.069907: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 87, in _path_is_mode_type\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 81, in _path_stat\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tensorboard/summary/_tf/__init__.cpython-37m-x86_64-linux-gnu.so'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 336, in <module>\n",
      "    writer = SummaryWriter(log_dir=os.path.join(logger_path, 'tensorboard'))\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/torch/utils/tensorboard/writer.py\", line 225, in __init__\n",
      "    self._get_file_writer()\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/torch/utils/tensorboard/writer.py\", line 256, in _get_file_writer\n",
      "    self.flush_secs, self.filename_suffix)\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/torch/utils/tensorboard/writer.py\", line 66, in __init__\n",
      "    log_dir, max_queue, flush_secs, filename_suffix)\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tensorboard/summary/writer/event_file_writer.py\", line 72, in __init__\n",
      "    tf.io.gfile.makedirs(logdir)\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tensorboard/lazy.py\", line 65, in __getattr__\n",
      "    return getattr(load_once(self), attr_name)\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tensorboard/lazy.py\", line 97, in wrapper\n",
      "    cache[arg] = f(arg)\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tensorboard/lazy.py\", line 50, in load_once\n",
      "    module = load_fn()\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tensorboard/compat/__init__.py\", line 45, in tf\n",
      "    import tensorflow\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tensorflow/__init__.py\", line 51, in <module>\n",
      "    from ._api.v2 import compat\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tensorflow/_api/v2/compat/__init__.py\", line 37, in <module>\n",
      "    from . import v1\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tensorflow/_api/v2/compat/v1/__init__.py\", line 30, in <module>\n",
      "    from . import compat\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\", line 38, in <module>\n",
      "    from . import v2\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py\", line 28, in <module>\n",
      "    from tensorflow._api.v2.compat.v2 import __internal__\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tensorflow/_api/v2/compat/v2/__init__.py\", line 33, in <module>\n",
      "    from . import compat\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py\", line 38, in <module>\n",
      "    from . import v2\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py\", line 327, in <module>\n",
      "    from tensorboard.summary._tf import summary\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 963, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 906, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1280, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1252, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1383, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 95, in _path_isfile\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 87, in _path_is_mode_type\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# ansewer空间训练\n",
    "!python main.py --gpu_id 8 --exp_name knowledge_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --save_model 1 --relation_map 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e56334c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T09:25:18.885636Z",
     "start_time": "2022-06-21T08:56:41.928675Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 06/21/22 16:56:43 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 06/21/22 16:56:43 - 0:00:00 - The experiment will be stored in dump/0621-object_space/W2V\n",
      "                                     \n",
      "INFO - 06/21/22 16:56:43 - 0:00:00 - Running command: python main_top100entity.py --gpu_id 0 --exp_name object_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --save_model 0 --fact_map 1\n",
      "\n",
      "2022-06-21 16:56:43.941295: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-21 16:56:43.941365: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 128\n",
      "batch_size 128\n",
      "fusion_model:\n",
      "SAN(\n",
      "  (w_emb): WordEmbedding(\n",
      "    (emb): Embedding(15422, 300, padding_idx=15421)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (text): Seq2SeqRNN(\n",
      "    (rnn): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (attention): SanAttention(\n",
      "    (v_conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (q_lin): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (x_conv): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(5120, 8192, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(8192, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "Answer Model:\n",
      "MLP(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "train E000: 100% 21/21 [00:24<00:00,  1.17s/it]\n",
      "INFO - 06/21/22 16:57:27 - 0:00:44 - Train Epoch 0: LOSS= 7.21789, lr= 0.000500, acc1= 36.42,acc3= 44.17,acc10= 47.47\n",
      "train E001: 100% 21/21 [00:11<00:00,  1.78it/s]\n",
      "INFO - 06/21/22 16:57:39 - 0:00:55 - Train Epoch 1: LOSS= 3.66695, lr= 0.000750, acc1= 84.15,acc3= 88.72,acc10= 90.75\n",
      "eval E001: 100% 23/23 [00:23<00:00,  1.02s/it]\n",
      "INFO - 06/21/22 16:58:02 - 0:01:19 - #################################################################################################################\n",
      "INFO - 06/21/22 16:58:02 - 0:01:19 - Test Epoch 1: LOSS= 3.60278, acc1= 84.09, acc3= 88.52, acc10= 89.87\n",
      "INFO - 06/21/22 16:58:02 - 0:01:19 - #################################################################################################################\n",
      "train E002: 100% 21/21 [00:12<00:00,  1.71it/s]\n",
      "INFO - 06/21/22 16:58:14 - 0:01:31 - Train Epoch 2: LOSS= 2.28185, lr= 0.001000, acc1= 93.71,acc3= 95.95,acc10= 96.82\n",
      "eval E002: 100% 23/23 [00:11<00:00,  1.99it/s]\n",
      "INFO - 06/21/22 16:58:26 - 0:01:43 - #################################################################################################################\n",
      "INFO - 06/21/22 16:58:26 - 0:01:43 - Test Epoch 2: LOSS= 3.28538, acc1= 85.65, acc3= 89.48, acc10= 90.83\n",
      "INFO - 06/21/22 16:58:26 - 0:01:43 - #################################################################################################################\n",
      "train E003: 100% 21/21 [00:09<00:00,  2.11it/s]\n",
      "INFO - 06/21/22 16:58:36 - 0:01:53 - Train Epoch 3: LOSS= 1.58987, lr= 0.001250, acc1= 97.53,acc3= 98.61,acc10= 99.06\n",
      "eval E003: 100% 23/23 [00:09<00:00,  2.42it/s]\n",
      "INFO - 06/21/22 16:58:45 - 0:02:02 - #################################################################################################################\n",
      "INFO - 06/21/22 16:58:45 - 0:02:02 - Test Epoch 3: LOSS= 3.62482, acc1= 86.08, acc3= 88.63, acc10= 90.15\n",
      "INFO - 06/21/22 16:58:45 - 0:02:02 - #################################################################################################################\n",
      "train E004: 100% 21/21 [00:10<00:00,  2.02it/s]\n",
      "INFO - 06/21/22 16:58:56 - 0:02:12 - Train Epoch 4: LOSS= 1.20002, lr= 0.001500, acc1= 98.88,acc3= 99.40,acc10= 99.59\n",
      "eval E004: 100% 23/23 [00:10<00:00,  2.25it/s]\n",
      "INFO - 06/21/22 16:59:06 - 0:02:23 - #################################################################################################################\n",
      "INFO - 06/21/22 16:59:06 - 0:02:23 - Test Epoch 4: LOSS= 3.75540, acc1= 85.16, acc3= 88.42, acc10= 90.12\n",
      "INFO - 06/21/22 16:59:06 - 0:02:23 - #################################################################################################################\n",
      "train E005: 100% 21/21 [00:10<00:00,  2.06it/s]\n",
      "INFO - 06/21/22 16:59:16 - 0:02:33 - Train Epoch 5: LOSS= 1.10598, lr= 0.001750, acc1= 99.48,acc3= 99.81,acc10= 99.89\n",
      "eval E005: 100% 23/23 [00:10<00:00,  2.28it/s]\n",
      "INFO - 06/21/22 16:59:26 - 0:02:43 - #################################################################################################################\n",
      "INFO - 06/21/22 16:59:26 - 0:02:43 - Test Epoch 5: LOSS= 3.90644, acc1= 85.87, acc3= 89.02, acc10= 90.26\n",
      "INFO - 06/21/22 16:59:26 - 0:02:43 - #################################################################################################################\n",
      "train E006: 100% 21/21 [00:10<00:00,  2.01it/s]\n",
      "INFO - 06/21/22 16:59:37 - 0:02:53 - Train Epoch 6: LOSS= 1.08373, lr= 0.002000, acc1= 99.21,acc3= 99.55,acc10= 99.74\n",
      "eval E006: 100% 23/23 [00:10<00:00,  2.14it/s]\n",
      "INFO - 06/21/22 16:59:47 - 0:03:04 - #################################################################################################################\n",
      "INFO - 06/21/22 16:59:47 - 0:03:04 - Test Epoch 6: LOSS= 4.36258, acc1= 84.45, acc3= 88.52, acc10= 89.76\n",
      "INFO - 06/21/22 16:59:47 - 0:03:04 - #################################################################################################################\n",
      "train E007: 100% 21/21 [00:10<00:00,  1.95it/s]\n",
      "INFO - 06/21/22 16:59:58 - 0:03:15 - Train Epoch 7: LOSS= 1.06888, lr= 0.002000, acc1= 99.63,acc3= 99.89,acc10= 99.93\n",
      "eval E007: 100% 23/23 [00:10<00:00,  2.20it/s]\n",
      "INFO - 06/21/22 17:00:09 - 0:03:25 - #################################################################################################################\n",
      "INFO - 06/21/22 17:00:09 - 0:03:25 - Test Epoch 7: LOSS= 4.63990, acc1= 82.68, acc3= 86.50, acc10= 87.64\n",
      "INFO - 06/21/22 17:00:09 - 0:03:25 - #################################################################################################################\n",
      "train E008: 100% 21/21 [00:10<00:00,  1.94it/s]\n",
      "INFO - 06/21/22 17:00:19 - 0:03:36 - Train Epoch 8: LOSS= 0.93892, lr= 0.002000, acc1= 99.55,acc3= 99.74,acc10= 99.78\n",
      "eval E008: 100% 23/23 [00:10<00:00,  2.25it/s]\n",
      "INFO - 06/21/22 17:00:30 - 0:03:46 - #################################################################################################################\n",
      "INFO - 06/21/22 17:00:30 - 0:03:46 - Test Epoch 8: LOSS= 4.76343, acc1= 83.03, acc3= 85.65, acc10= 87.25\n",
      "INFO - 06/21/22 17:00:30 - 0:03:46 - #################################################################################################################\n",
      "train E009: 100% 21/21 [00:12<00:00,  1.69it/s]\n",
      "INFO - 06/21/22 17:00:42 - 0:03:59 - Train Epoch 9: LOSS= 0.93883, lr= 0.002000, acc1= 99.59,acc3= 99.85,acc10= 99.93\n",
      "eval E009: 100% 23/23 [00:15<00:00,  1.46it/s]\n",
      "INFO - 06/21/22 17:00:58 - 0:04:15 - #################################################################################################################\n",
      "INFO - 06/21/22 17:00:58 - 0:04:15 - Test Epoch 9: LOSS= 5.30634, acc1= 84.31, acc3= 87.32, acc10= 89.16\n",
      "INFO - 06/21/22 17:00:58 - 0:04:15 - #################################################################################################################\n",
      "train E010: 100% 21/21 [00:15<00:00,  1.37it/s]\n",
      "INFO - 06/21/22 17:01:13 - 0:04:30 - Train Epoch 10: LOSS= 0.77716, lr= 0.002000, acc1= 99.74,acc3= 99.93,acc10= 99.96\n",
      "eval E010: 100% 23/23 [00:12<00:00,  1.91it/s]\n",
      "INFO - 06/21/22 17:01:25 - 0:04:42 - #################################################################################################################\n",
      "INFO - 06/21/22 17:01:25 - 0:04:42 - Test Epoch 10: LOSS= 5.35709, acc1= 85.12, acc3= 88.31, acc10= 89.48\n",
      "INFO - 06/21/22 17:01:25 - 0:04:42 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E011: 100% 21/21 [00:11<00:00,  1.90it/s]\n",
      "INFO - 06/21/22 17:01:36 - 0:04:53 - Train Epoch 11: LOSS= 0.78193, lr= 0.002000, acc1= 99.66,acc3= 99.89,acc10= 99.89\n",
      "eval E011: 100% 23/23 [00:10<00:00,  2.16it/s]\n",
      "INFO - 06/21/22 17:01:47 - 0:05:04 - #################################################################################################################\n",
      "INFO - 06/21/22 17:01:47 - 0:05:04 - Test Epoch 11: LOSS= 5.34087, acc1= 84.24, acc3= 87.28, acc10= 88.88\n",
      "INFO - 06/21/22 17:01:47 - 0:05:04 - #################################################################################################################\n",
      "train E012: 100% 21/21 [00:10<00:00,  1.96it/s]\n",
      "INFO - 06/21/22 17:01:58 - 0:05:14 - Train Epoch 12: LOSS= 0.71132, lr= 0.002000, acc1= 99.93,acc3= 99.93,acc10= 99.93\n",
      "eval E012: 100% 23/23 [00:10<00:00,  2.11it/s]\n",
      "INFO - 06/21/22 17:02:09 - 0:05:25 - #################################################################################################################\n",
      "INFO - 06/21/22 17:02:09 - 0:05:25 - Test Epoch 12: LOSS= 5.65732, acc1= 84.45, acc3= 87.35, acc10= 88.91\n",
      "INFO - 06/21/22 17:02:09 - 0:05:25 - #################################################################################################################\n",
      "train E013: 100% 21/21 [00:11<00:00,  1.77it/s]\n",
      "INFO - 06/21/22 17:02:20 - 0:05:37 - Train Epoch 13: LOSS= 0.70865, lr= 0.002000, acc1= 99.74,acc3= 99.93,acc10= 99.93\n",
      "eval E013: 100% 23/23 [00:12<00:00,  1.90it/s]\n",
      "INFO - 06/21/22 17:02:33 - 0:05:49 - #################################################################################################################\n",
      "INFO - 06/21/22 17:02:33 - 0:05:49 - Test Epoch 13: LOSS= 5.62011, acc1= 85.02, acc3= 88.03, acc10= 89.27\n",
      "INFO - 06/21/22 17:02:33 - 0:05:49 - #################################################################################################################\n",
      "train E014: 100% 21/21 [00:12<00:00,  1.65it/s]\n",
      "INFO - 06/21/22 17:02:45 - 0:06:02 - Train Epoch 14: LOSS= 0.51613, lr= 0.001400, acc1= 99.93,acc3= 99.96,acc10= 99.96\n",
      "eval E014: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
      "INFO - 06/21/22 17:02:57 - 0:06:14 - #################################################################################################################\n",
      "INFO - 06/21/22 17:02:57 - 0:06:14 - Test Epoch 14: LOSS= 5.29546, acc1= 85.30, acc3= 88.03, acc10= 89.27\n",
      "INFO - 06/21/22 17:02:57 - 0:06:14 - #################################################################################################################\n",
      "train E015: 100% 21/21 [00:12<00:00,  1.68it/s]\n",
      "INFO - 06/21/22 17:03:10 - 0:06:26 - Train Epoch 15: LOSS= 0.30909, lr= 0.001400, acc1= 99.93,acc3= 99.93,acc10= 99.96\n",
      "eval E015: 100% 23/23 [00:11<00:00,  1.94it/s]\n",
      "INFO - 06/21/22 17:03:21 - 0:06:38 - #################################################################################################################\n",
      "INFO - 06/21/22 17:03:21 - 0:06:38 - Test Epoch 15: LOSS= 5.21963, acc1= 85.02, acc3= 88.35, acc10= 89.44\n",
      "INFO - 06/21/22 17:03:21 - 0:06:38 - #################################################################################################################\n",
      "train E016: 100% 21/21 [00:12<00:00,  1.66it/s]\n",
      "INFO - 06/21/22 17:03:34 - 0:06:51 - Train Epoch 16: LOSS= 0.27299, lr= 0.001400, acc1= 99.93,acc3= 99.96,acc10= 100.00\n",
      "eval E016: 100% 23/23 [00:12<00:00,  1.92it/s]\n",
      "INFO - 06/21/22 17:03:46 - 0:07:03 - #################################################################################################################\n",
      "INFO - 06/21/22 17:03:46 - 0:07:03 - Test Epoch 16: LOSS= 5.62905, acc1= 85.76, acc3= 89.05, acc10= 90.15\n",
      "INFO - 06/21/22 17:03:46 - 0:07:03 - #################################################################################################################\n",
      "train E017: 100% 21/21 [00:12<00:00,  1.64it/s]\n",
      "INFO - 06/21/22 17:03:59 - 0:07:16 - Train Epoch 17: LOSS= 0.20616, lr= 0.000980, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E017: 100% 23/23 [00:12<00:00,  1.86it/s]\n",
      "INFO - 06/21/22 17:04:11 - 0:07:28 - #################################################################################################################\n",
      "INFO - 06/21/22 17:04:11 - 0:07:28 - Test Epoch 17: LOSS= 5.30311, acc1= 85.33, acc3= 88.45, acc10= 89.73\n",
      "INFO - 06/21/22 17:04:11 - 0:07:28 - #################################################################################################################\n",
      "train E018: 100% 21/21 [00:13<00:00,  1.58it/s]\n",
      "INFO - 06/21/22 17:04:24 - 0:07:41 - Train Epoch 18: LOSS= 0.16388, lr= 0.000980, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E018: 100% 23/23 [00:12<00:00,  1.85it/s]\n",
      "INFO - 06/21/22 17:04:37 - 0:07:54 - #################################################################################################################\n",
      "INFO - 06/21/22 17:04:37 - 0:07:54 - Test Epoch 18: LOSS= 5.22631, acc1= 85.83, acc3= 88.77, acc10= 90.01\n",
      "INFO - 06/21/22 17:04:37 - 0:07:54 - #################################################################################################################\n",
      "train E019: 100% 21/21 [00:12<00:00,  1.67it/s]\n",
      "INFO - 06/21/22 17:04:50 - 0:08:06 - Train Epoch 19: LOSS= 0.11194, lr= 0.000980, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E019: 100% 23/23 [00:13<00:00,  1.74it/s]\n",
      "INFO - 06/21/22 17:05:03 - 0:08:19 - #################################################################################################################\n",
      "INFO - 06/21/22 17:05:03 - 0:08:19 - Test Epoch 19: LOSS= 5.37493, acc1= 86.47, acc3= 89.20, acc10= 90.44\n",
      "INFO - 06/21/22 17:05:03 - 0:08:19 - #################################################################################################################\n",
      "train E020: 100% 21/21 [00:12<00:00,  1.63it/s]\n",
      "INFO - 06/21/22 17:05:16 - 0:08:32 - Train Epoch 20: LOSS= 0.10030, lr= 0.000686, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E020: 100% 23/23 [00:12<00:00,  1.80it/s]\n",
      "INFO - 06/21/22 17:05:28 - 0:08:45 - #################################################################################################################\n",
      "INFO - 06/21/22 17:05:28 - 0:08:45 - Test Epoch 20: LOSS= 5.47770, acc1= 86.79, acc3= 89.13, acc10= 90.47\n",
      "INFO - 06/21/22 17:05:28 - 0:08:45 - #################################################################################################################\n",
      "train E021: 100% 21/21 [00:12<00:00,  1.63it/s]\n",
      "INFO - 06/21/22 17:05:41 - 0:08:58 - Train Epoch 21: LOSS= 0.10106, lr= 0.000686, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E021: 100% 23/23 [00:12<00:00,  1.85it/s]\n",
      "INFO - 06/21/22 17:05:54 - 0:09:10 - #################################################################################################################\n",
      "INFO - 06/21/22 17:05:54 - 0:09:10 - Test Epoch 21: LOSS= 5.20007, acc1= 86.36, acc3= 89.27, acc10= 90.44\n",
      "INFO - 06/21/22 17:05:54 - 0:09:10 - #################################################################################################################\n",
      "train E022: 100% 21/21 [00:12<00:00,  1.67it/s]\n",
      "INFO - 06/21/22 17:06:06 - 0:09:23 - Train Epoch 22: LOSS= 0.08660, lr= 0.000686, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E022: 100% 23/23 [00:12<00:00,  1.78it/s]\n",
      "INFO - 06/21/22 17:06:19 - 0:09:36 - #################################################################################################################\n",
      "INFO - 06/21/22 17:06:19 - 0:09:36 - Test Epoch 22: LOSS= 5.10678, acc1= 86.57, acc3= 89.44, acc10= 90.47\n",
      "INFO - 06/21/22 17:06:19 - 0:09:36 - #################################################################################################################\n",
      "train E023: 100% 21/21 [00:12<00:00,  1.68it/s]\n",
      "INFO - 06/21/22 17:06:32 - 0:09:48 - Train Epoch 23: LOSS= 0.07421, lr= 0.000480, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E023: 100% 23/23 [00:11<00:00,  1.93it/s]\n",
      "INFO - 06/21/22 17:06:44 - 0:10:00 - #################################################################################################################\n",
      "INFO - 06/21/22 17:06:44 - 0:10:00 - Test Epoch 23: LOSS= 5.17295, acc1= 86.36, acc3= 89.27, acc10= 90.51\n",
      "INFO - 06/21/22 17:06:44 - 0:10:00 - #################################################################################################################\n",
      "train E024: 100% 21/21 [00:12<00:00,  1.67it/s]\n",
      "INFO - 06/21/22 17:06:56 - 0:10:13 - Train Epoch 24: LOSS= 0.05673, lr= 0.000480, acc1= 100.00,acc3= 100.00,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E024: 100% 23/23 [00:12<00:00,  1.89it/s]\n",
      "INFO - 06/21/22 17:07:08 - 0:10:25 - #################################################################################################################\n",
      "INFO - 06/21/22 17:07:08 - 0:10:25 - Test Epoch 24: LOSS= 5.26703, acc1= 86.47, acc3= 89.30, acc10= 90.47\n",
      "INFO - 06/21/22 17:07:08 - 0:10:25 - #################################################################################################################\n",
      "train E025: 100% 21/21 [00:13<00:00,  1.58it/s]\n",
      "INFO - 06/21/22 17:07:22 - 0:10:38 - Train Epoch 25: LOSS= 0.06911, lr= 0.000480, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E025: 100% 23/23 [00:12<00:00,  1.81it/s]\n",
      "INFO - 06/21/22 17:07:34 - 0:10:51 - #################################################################################################################\n",
      "INFO - 06/21/22 17:07:34 - 0:10:51 - Test Epoch 25: LOSS= 5.06917, acc1= 86.72, acc3= 89.30, acc10= 90.51\n",
      "INFO - 06/21/22 17:07:34 - 0:10:51 - #################################################################################################################\n",
      "train E026: 100% 21/21 [00:13<00:00,  1.60it/s]\n",
      "INFO - 06/21/22 17:07:48 - 0:11:04 - Train Epoch 26: LOSS= 0.06106, lr= 0.000336, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E026: 100% 23/23 [00:12<00:00,  1.89it/s]\n",
      "INFO - 06/21/22 17:08:00 - 0:11:16 - #################################################################################################################\n",
      "INFO - 06/21/22 17:08:00 - 0:11:16 - Test Epoch 26: LOSS= 5.09669, acc1= 86.82, acc3= 89.62, acc10= 90.51\n",
      "INFO - 06/21/22 17:08:00 - 0:11:16 - #################################################################################################################\n",
      "train E027: 100% 21/21 [00:12<00:00,  1.66it/s]\n",
      "INFO - 06/21/22 17:08:12 - 0:11:29 - Train Epoch 27: LOSS= 0.05672, lr= 0.000336, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E027: 100% 23/23 [00:12<00:00,  1.90it/s]\n",
      "INFO - 06/21/22 17:08:24 - 0:11:41 - #################################################################################################################\n",
      "INFO - 06/21/22 17:08:24 - 0:11:41 - Test Epoch 27: LOSS= 5.29172, acc1= 86.68, acc3= 89.30, acc10= 90.65\n",
      "INFO - 06/21/22 17:08:24 - 0:11:41 - #################################################################################################################\n",
      "train E028: 100% 21/21 [00:12<00:00,  1.64it/s]\n",
      "INFO - 06/21/22 17:08:37 - 0:11:54 - Train Epoch 28: LOSS= 0.06232, lr= 0.000336, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E028: 100% 23/23 [00:12<00:00,  1.85it/s]\n",
      "INFO - 06/21/22 17:08:50 - 0:12:06 - #################################################################################################################\n",
      "INFO - 06/21/22 17:08:50 - 0:12:06 - Test Epoch 28: LOSS= 5.30356, acc1= 86.79, acc3= 89.44, acc10= 90.33\n",
      "INFO - 06/21/22 17:08:50 - 0:12:06 - #################################################################################################################\n",
      "train E029: 100% 21/21 [00:17<00:00,  1.19it/s]\n",
      "INFO - 06/21/22 17:09:07 - 0:12:24 - Train Epoch 29: LOSS= 0.05317, lr= 0.000235, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E029: 100% 23/23 [00:16<00:00,  1.37it/s]\n",
      "INFO - 06/21/22 17:09:24 - 0:12:41 - #################################################################################################################\n",
      "INFO - 06/21/22 17:09:24 - 0:12:41 - Test Epoch 29: LOSS= 5.43097, acc1= 86.68, acc3= 89.27, acc10= 90.54\n",
      "INFO - 06/21/22 17:09:24 - 0:12:41 - #################################################################################################################\n",
      "train E030: 100% 21/21 [00:15<00:00,  1.38it/s]\n",
      "INFO - 06/21/22 17:09:39 - 0:12:56 - Train Epoch 30: LOSS= 0.05524, lr= 0.000235, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E030: 100% 23/23 [00:14<00:00,  1.64it/s]\n",
      "INFO - 06/21/22 17:09:54 - 0:13:10 - #################################################################################################################\n",
      "INFO - 06/21/22 17:09:54 - 0:13:10 - Test Epoch 30: LOSS= 5.21250, acc1= 86.79, acc3= 89.30, acc10= 90.58\n",
      "INFO - 06/21/22 17:09:54 - 0:13:10 - #################################################################################################################\n",
      "train E031: 100% 21/21 [00:13<00:00,  1.54it/s]\n",
      "INFO - 06/21/22 17:10:07 - 0:13:24 - Train Epoch 31: LOSS= 0.04257, lr= 0.000235, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E031: 100% 23/23 [00:12<00:00,  1.89it/s]\n",
      "INFO - 06/21/22 17:10:19 - 0:13:36 - #################################################################################################################\n",
      "INFO - 06/21/22 17:10:19 - 0:13:36 - Test Epoch 31: LOSS= 5.54642, acc1= 86.72, acc3= 89.48, acc10= 90.72\n",
      "INFO - 06/21/22 17:10:19 - 0:13:36 - #################################################################################################################\n",
      "train E032: 100% 21/21 [00:12<00:00,  1.63it/s]\n",
      "INFO - 06/21/22 17:10:32 - 0:13:49 - Train Epoch 32: LOSS= 0.04268, lr= 0.000165, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E032: 100% 23/23 [00:12<00:00,  1.83it/s]\n",
      "INFO - 06/21/22 17:10:45 - 0:14:02 - #################################################################################################################\n",
      "INFO - 06/21/22 17:10:45 - 0:14:02 - Test Epoch 32: LOSS= 5.36812, acc1= 86.82, acc3= 89.48, acc10= 90.68\n",
      "INFO - 06/21/22 17:10:45 - 0:14:02 - #################################################################################################################\n",
      "train E033: 100% 21/21 [00:12<00:00,  1.70it/s]\n",
      "INFO - 06/21/22 17:10:57 - 0:14:14 - Train Epoch 33: LOSS= 0.04482, lr= 0.000165, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E033: 100% 23/23 [00:12<00:00,  1.91it/s]\n",
      "INFO - 06/21/22 17:11:09 - 0:14:26 - #################################################################################################################\n",
      "INFO - 06/21/22 17:11:09 - 0:14:26 - Test Epoch 33: LOSS= 5.21359, acc1= 86.79, acc3= 89.41, acc10= 90.75\n",
      "INFO - 06/21/22 17:11:09 - 0:14:26 - #################################################################################################################\n",
      "train E034: 100% 21/21 [00:12<00:00,  1.62it/s]\n",
      "INFO - 06/21/22 17:11:22 - 0:14:39 - Train Epoch 34: LOSS= 0.04272, lr= 0.000165, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E034: 100% 23/23 [00:11<00:00,  1.93it/s]\n",
      "INFO - 06/21/22 17:11:34 - 0:14:51 - #################################################################################################################\n",
      "INFO - 06/21/22 17:11:34 - 0:14:51 - Test Epoch 34: LOSS= 5.37451, acc1= 86.79, acc3= 89.37, acc10= 90.75\n",
      "INFO - 06/21/22 17:11:34 - 0:14:51 - #################################################################################################################\n",
      "train E035: 100% 21/21 [00:12<00:00,  1.67it/s]\n",
      "INFO - 06/21/22 17:11:47 - 0:15:03 - Train Epoch 35: LOSS= 0.04136, lr= 0.000115, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E035: 100% 23/23 [00:13<00:00,  1.67it/s]\n",
      "INFO - 06/21/22 17:12:01 - 0:15:17 - #################################################################################################################\n",
      "INFO - 06/21/22 17:12:01 - 0:15:17 - Test Epoch 35: LOSS= 5.18571, acc1= 86.89, acc3= 89.44, acc10= 90.72\n",
      "INFO - 06/21/22 17:12:01 - 0:15:17 - #################################################################################################################\n",
      "train E036: 100% 21/21 [00:19<00:00,  1.09it/s]\n",
      "INFO - 06/21/22 17:12:20 - 0:15:36 - Train Epoch 36: LOSS= 0.03784, lr= 0.000115, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E036: 100% 23/23 [00:15<00:00,  1.44it/s]\n",
      "INFO - 06/21/22 17:12:36 - 0:15:52 - #################################################################################################################\n",
      "INFO - 06/21/22 17:12:36 - 0:15:52 - Test Epoch 36: LOSS= 5.34219, acc1= 87.00, acc3= 89.41, acc10= 90.65\n",
      "INFO - 06/21/22 17:12:36 - 0:15:52 - #################################################################################################################\n",
      "train E037: 100% 21/21 [00:15<00:00,  1.39it/s]\n",
      "INFO - 06/21/22 17:12:51 - 0:16:08 - Train Epoch 37: LOSS= 0.03977, lr= 0.000115, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E037: 100% 23/23 [00:12<00:00,  1.77it/s]\n",
      "INFO - 06/21/22 17:13:04 - 0:16:21 - #################################################################################################################\n",
      "INFO - 06/21/22 17:13:04 - 0:16:21 - Test Epoch 37: LOSS= 5.22870, acc1= 86.89, acc3= 89.51, acc10= 90.68\n",
      "INFO - 06/21/22 17:13:04 - 0:16:21 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E038: 100% 21/21 [00:12<00:00,  1.69it/s]\n",
      "INFO - 06/21/22 17:13:16 - 0:16:33 - Train Epoch 38: LOSS= 0.04407, lr= 0.000081, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E038: 100% 23/23 [00:12<00:00,  1.85it/s]\n",
      "INFO - 06/21/22 17:13:29 - 0:16:45 - #################################################################################################################\n",
      "INFO - 06/21/22 17:13:29 - 0:16:45 - Test Epoch 38: LOSS= 5.44761, acc1= 86.93, acc3= 89.48, acc10= 90.58\n",
      "INFO - 06/21/22 17:13:29 - 0:16:45 - #################################################################################################################\n",
      "train E039: 100% 21/21 [00:14<00:00,  1.45it/s]\n",
      "INFO - 06/21/22 17:13:43 - 0:17:00 - Train Epoch 39: LOSS= 0.04197, lr= 0.000081, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E039: 100% 23/23 [00:16<00:00,  1.38it/s]\n",
      "INFO - 06/21/22 17:14:00 - 0:17:17 - #################################################################################################################\n",
      "INFO - 06/21/22 17:14:00 - 0:17:17 - Test Epoch 39: LOSS= 5.44881, acc1= 86.96, acc3= 89.44, acc10= 90.51\n",
      "INFO - 06/21/22 17:14:00 - 0:17:17 - #################################################################################################################\n",
      "train E040: 100% 21/21 [00:17<00:00,  1.21it/s]\n",
      "INFO - 06/21/22 17:14:17 - 0:17:34 - Train Epoch 40: LOSS= 0.04926, lr= 0.000081, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E040: 100% 23/23 [00:17<00:00,  1.33it/s]\n",
      "INFO - 06/21/22 17:14:35 - 0:17:51 - #################################################################################################################\n",
      "INFO - 06/21/22 17:14:35 - 0:17:51 - Test Epoch 40: LOSS= 5.54566, acc1= 87.07, acc3= 89.44, acc10= 90.68\n",
      "INFO - 06/21/22 17:14:35 - 0:17:51 - #################################################################################################################\n",
      "train E041: 100% 21/21 [00:13<00:00,  1.57it/s]\n",
      "INFO - 06/21/22 17:14:48 - 0:18:05 - Train Epoch 41: LOSS= 0.03991, lr= 0.000056, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E041: 100% 23/23 [00:10<00:00,  2.20it/s]\n",
      "INFO - 06/21/22 17:14:58 - 0:18:15 - #################################################################################################################\n",
      "INFO - 06/21/22 17:14:58 - 0:18:15 - Test Epoch 41: LOSS= 5.15212, acc1= 87.14, acc3= 89.48, acc10= 90.65\n",
      "INFO - 06/21/22 17:14:58 - 0:18:15 - #################################################################################################################\n",
      "train E042: 100% 21/21 [00:11<00:00,  1.79it/s]\n",
      "INFO - 06/21/22 17:15:10 - 0:18:27 - Train Epoch 42: LOSS= 0.03822, lr= 0.000056, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E042: 100% 23/23 [00:12<00:00,  1.89it/s]\n",
      "INFO - 06/21/22 17:15:22 - 0:18:39 - #################################################################################################################\n",
      "INFO - 06/21/22 17:15:22 - 0:18:39 - Test Epoch 42: LOSS= 5.16830, acc1= 87.14, acc3= 89.48, acc10= 90.65\n",
      "INFO - 06/21/22 17:15:22 - 0:18:39 - #################################################################################################################\n",
      "train E043: 100% 21/21 [00:11<00:00,  1.75it/s]\n",
      "INFO - 06/21/22 17:15:34 - 0:18:51 - Train Epoch 43: LOSS= 0.04523, lr= 0.000056, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E043: 100% 23/23 [00:11<00:00,  2.01it/s]\n",
      "INFO - 06/21/22 17:15:46 - 0:19:03 - #################################################################################################################\n",
      "INFO - 06/21/22 17:15:46 - 0:19:03 - Test Epoch 43: LOSS= 5.28369, acc1= 87.00, acc3= 89.51, acc10= 90.61\n",
      "INFO - 06/21/22 17:15:46 - 0:19:03 - #################################################################################################################\n",
      "train E044: 100% 21/21 [00:12<00:00,  1.71it/s]\n",
      "INFO - 06/21/22 17:15:58 - 0:19:15 - Train Epoch 44: LOSS= 0.03775, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E044: 100% 23/23 [00:14<00:00,  1.60it/s]\n",
      "INFO - 06/21/22 17:16:12 - 0:19:29 - #################################################################################################################\n",
      "INFO - 06/21/22 17:16:12 - 0:19:29 - Test Epoch 44: LOSS= 5.14253, acc1= 87.00, acc3= 89.48, acc10= 90.68\n",
      "INFO - 06/21/22 17:16:12 - 0:19:29 - #################################################################################################################\n",
      "train E045: 100% 21/21 [00:12<00:00,  1.65it/s]\n",
      "INFO - 06/21/22 17:16:25 - 0:19:42 - Train Epoch 45: LOSS= 0.03414, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E045: 100% 23/23 [00:12<00:00,  1.87it/s]\n",
      "INFO - 06/21/22 17:16:38 - 0:19:54 - #################################################################################################################\n",
      "INFO - 06/21/22 17:16:38 - 0:19:54 - Test Epoch 45: LOSS= 5.19121, acc1= 87.04, acc3= 89.44, acc10= 90.68\n",
      "INFO - 06/21/22 17:16:38 - 0:19:54 - #################################################################################################################\n",
      "train E046: 100% 21/21 [00:11<00:00,  1.83it/s]\n",
      "INFO - 06/21/22 17:16:49 - 0:20:06 - Train Epoch 46: LOSS= 0.04107, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E046: 100% 23/23 [00:10<00:00,  2.24it/s]\n",
      "INFO - 06/21/22 17:16:59 - 0:20:16 - #################################################################################################################\n",
      "INFO - 06/21/22 17:16:59 - 0:20:16 - Test Epoch 46: LOSS= 5.26821, acc1= 87.07, acc3= 89.48, acc10= 90.75\n",
      "INFO - 06/21/22 17:16:59 - 0:20:16 - #################################################################################################################\n",
      "train E047: 100% 21/21 [00:10<00:00,  1.96it/s]\n",
      "INFO - 06/21/22 17:17:10 - 0:20:27 - Train Epoch 47: LOSS= 0.04394, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E047: 100% 23/23 [00:10<00:00,  2.25it/s]\n",
      "INFO - 06/21/22 17:17:20 - 0:20:37 - #################################################################################################################\n",
      "INFO - 06/21/22 17:17:20 - 0:20:37 - Test Epoch 47: LOSS= 5.33578, acc1= 87.00, acc3= 89.44, acc10= 90.72\n",
      "INFO - 06/21/22 17:17:20 - 0:20:37 - #################################################################################################################\n",
      "train E048: 100% 21/21 [00:10<00:00,  2.00it/s]\n",
      "INFO - 06/21/22 17:17:31 - 0:20:47 - Train Epoch 48: LOSS= 0.04124, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E048: 100% 23/23 [00:10<00:00,  2.25it/s]\n",
      "INFO - 06/21/22 17:17:41 - 0:20:58 - #################################################################################################################\n",
      "INFO - 06/21/22 17:17:41 - 0:20:58 - Test Epoch 48: LOSS= 5.46425, acc1= 86.96, acc3= 89.37, acc10= 90.75\n",
      "INFO - 06/21/22 17:17:41 - 0:20:58 - #################################################################################################################\n",
      "train E049: 100% 21/21 [00:14<00:00,  1.45it/s]\n",
      "INFO - 06/21/22 17:17:55 - 0:21:12 - Train Epoch 49: LOSS= 0.04012, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E049: 100% 23/23 [00:13<00:00,  1.71it/s]\n",
      "INFO - 06/21/22 17:18:09 - 0:21:26 - #################################################################################################################\n",
      "INFO - 06/21/22 17:18:09 - 0:21:26 - Test Epoch 49: LOSS= 5.18927, acc1= 87.00, acc3= 89.41, acc10= 90.72\n",
      "INFO - 06/21/22 17:18:09 - 0:21:26 - #################################################################################################################\n",
      "train E050: 100% 21/21 [00:15<00:00,  1.38it/s]\n",
      "INFO - 06/21/22 17:18:24 - 0:21:41 - Train Epoch 50: LOSS= 0.03732, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E050: 100% 23/23 [00:12<00:00,  1.82it/s]\n",
      "INFO - 06/21/22 17:18:37 - 0:21:53 - #################################################################################################################\n",
      "INFO - 06/21/22 17:18:37 - 0:21:53 - Test Epoch 50: LOSS= 5.44372, acc1= 86.96, acc3= 89.41, acc10= 90.68\n",
      "INFO - 06/21/22 17:18:37 - 0:21:53 - #################################################################################################################\n",
      "train E051: 100% 21/21 [00:12<00:00,  1.67it/s]\n",
      "INFO - 06/21/22 17:18:49 - 0:22:06 - Train Epoch 51: LOSS= 0.03545, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E051: 100% 23/23 [00:09<00:00,  2.32it/s]\n",
      "INFO - 06/21/22 17:18:59 - 0:22:16 - #################################################################################################################\n",
      "INFO - 06/21/22 17:18:59 - 0:22:16 - Test Epoch 51: LOSS= 5.21311, acc1= 87.04, acc3= 89.44, acc10= 90.68\n",
      "INFO - 06/21/22 17:18:59 - 0:22:16 - #################################################################################################################\n",
      "train E052: 100% 21/21 [00:10<00:00,  2.03it/s]\n",
      "INFO - 06/21/22 17:19:10 - 0:22:26 - Train Epoch 52: LOSS= 0.03771, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E052: 100% 23/23 [00:09<00:00,  2.31it/s]\n",
      "INFO - 06/21/22 17:19:20 - 0:22:36 - #################################################################################################################\n",
      "INFO - 06/21/22 17:19:20 - 0:22:36 - Test Epoch 52: LOSS= 5.44694, acc1= 87.04, acc3= 89.55, acc10= 90.68\n",
      "INFO - 06/21/22 17:19:20 - 0:22:36 - #################################################################################################################\n",
      "train E053: 100% 21/21 [00:10<00:00,  2.00it/s]\n",
      "INFO - 06/21/22 17:19:30 - 0:22:47 - Train Epoch 53: LOSS= 0.03774, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E053: 100% 23/23 [00:09<00:00,  2.41it/s]\n",
      "INFO - 06/21/22 17:19:40 - 0:22:56 - #################################################################################################################\n",
      "INFO - 06/21/22 17:19:40 - 0:22:56 - Test Epoch 53: LOSS= 5.31605, acc1= 87.04, acc3= 89.55, acc10= 90.68\n",
      "INFO - 06/21/22 17:19:40 - 0:22:56 - #################################################################################################################\n",
      "train E054: 100% 21/21 [00:10<00:00,  2.07it/s]\n",
      "INFO - 06/21/22 17:19:50 - 0:23:06 - Train Epoch 54: LOSS= 0.03897, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E054: 100% 23/23 [00:09<00:00,  2.42it/s]\n",
      "INFO - 06/21/22 17:19:59 - 0:23:16 - #################################################################################################################\n",
      "INFO - 06/21/22 17:19:59 - 0:23:16 - Test Epoch 54: LOSS= 5.23670, acc1= 87.04, acc3= 89.44, acc10= 90.68\n",
      "INFO - 06/21/22 17:19:59 - 0:23:16 - #################################################################################################################\n",
      "train E055: 100% 21/21 [00:10<00:00,  2.08it/s]\n",
      "INFO - 06/21/22 17:20:09 - 0:23:26 - Train Epoch 55: LOSS= 0.03983, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E055: 100% 23/23 [00:09<00:00,  2.40it/s]\n",
      "INFO - 06/21/22 17:20:19 - 0:23:36 - #################################################################################################################\n",
      "INFO - 06/21/22 17:20:19 - 0:23:36 - Test Epoch 55: LOSS= 5.38900, acc1= 86.96, acc3= 89.51, acc10= 90.58\n",
      "INFO - 06/21/22 17:20:19 - 0:23:36 - #################################################################################################################\n",
      "train E056: 100% 21/21 [00:10<00:00,  2.08it/s]\n",
      "INFO - 06/21/22 17:20:29 - 0:23:46 - Train Epoch 56: LOSS= 0.03487, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E056: 100% 23/23 [00:09<00:00,  2.45it/s]\n",
      "INFO - 06/21/22 17:20:38 - 0:23:55 - #################################################################################################################\n",
      "INFO - 06/21/22 17:20:38 - 0:23:55 - Test Epoch 56: LOSS= 5.22793, acc1= 87.04, acc3= 89.51, acc10= 90.61\n",
      "INFO - 06/21/22 17:20:38 - 0:23:55 - #################################################################################################################\n",
      "train E057: 100% 21/21 [00:09<00:00,  2.11it/s]\n",
      "INFO - 06/21/22 17:20:48 - 0:24:05 - Train Epoch 57: LOSS= 0.03711, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E057: 100% 23/23 [00:09<00:00,  2.43it/s]\n",
      "INFO - 06/21/22 17:20:58 - 0:24:15 - #################################################################################################################\n",
      "INFO - 06/21/22 17:20:58 - 0:24:15 - Test Epoch 57: LOSS= 5.27329, acc1= 87.00, acc3= 89.41, acc10= 90.54\n",
      "INFO - 06/21/22 17:20:58 - 0:24:15 - #################################################################################################################\n",
      "train E058: 100% 21/21 [00:10<00:00,  2.08it/s]\n",
      "INFO - 06/21/22 17:21:08 - 0:24:25 - Train Epoch 58: LOSS= 0.03692, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E058: 100% 23/23 [00:09<00:00,  2.41it/s]\n",
      "INFO - 06/21/22 17:21:17 - 0:24:34 - #################################################################################################################\n",
      "INFO - 06/21/22 17:21:17 - 0:24:34 - Test Epoch 58: LOSS= 5.54217, acc1= 87.07, acc3= 89.41, acc10= 90.54\n",
      "INFO - 06/21/22 17:21:17 - 0:24:34 - #################################################################################################################\n",
      "train E059: 100% 21/21 [00:10<00:00,  2.09it/s]\n",
      "INFO - 06/21/22 17:21:28 - 0:24:44 - Train Epoch 59: LOSS= 0.03608, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E059: 100% 23/23 [00:09<00:00,  2.40it/s]\n",
      "INFO - 06/21/22 17:21:37 - 0:24:54 - #################################################################################################################\n",
      "INFO - 06/21/22 17:21:37 - 0:24:54 - Test Epoch 59: LOSS= 5.50022, acc1= 87.04, acc3= 89.41, acc10= 90.47\n",
      "INFO - 06/21/22 17:21:37 - 0:24:54 - #################################################################################################################\n",
      "train E060: 100% 21/21 [00:10<00:00,  2.09it/s]\n",
      "INFO - 06/21/22 17:21:47 - 0:25:04 - Train Epoch 60: LOSS= 0.03968, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E060: 100% 23/23 [00:09<00:00,  2.41it/s]\n",
      "INFO - 06/21/22 17:21:57 - 0:25:13 - #################################################################################################################\n",
      "INFO - 06/21/22 17:21:57 - 0:25:13 - Test Epoch 60: LOSS= 5.38102, acc1= 86.96, acc3= 89.59, acc10= 90.51\n",
      "INFO - 06/21/22 17:21:57 - 0:25:13 - #################################################################################################################\n",
      "train E061: 100% 21/21 [00:10<00:00,  2.08it/s]\n",
      "INFO - 06/21/22 17:22:07 - 0:25:24 - Train Epoch 61: LOSS= 0.03659, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E061: 100% 23/23 [00:09<00:00,  2.40it/s]\n",
      "INFO - 06/21/22 17:22:16 - 0:25:33 - #################################################################################################################\n",
      "INFO - 06/21/22 17:22:16 - 0:25:33 - Test Epoch 61: LOSS= 5.12360, acc1= 86.96, acc3= 89.55, acc10= 90.54\n",
      "INFO - 06/21/22 17:22:16 - 0:25:33 - #################################################################################################################\n",
      "train E062: 100% 21/21 [00:10<00:00,  2.09it/s]\n",
      "INFO - 06/21/22 17:22:27 - 0:25:43 - Train Epoch 62: LOSS= 0.03678, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E062: 100% 23/23 [00:09<00:00,  2.42it/s]\n",
      "INFO - 06/21/22 17:22:36 - 0:25:53 - #################################################################################################################\n",
      "INFO - 06/21/22 17:22:36 - 0:25:53 - Test Epoch 62: LOSS= 5.25521, acc1= 86.86, acc3= 89.59, acc10= 90.54\n",
      "INFO - 06/21/22 17:22:36 - 0:25:53 - #################################################################################################################\n",
      "train E063: 100% 21/21 [00:10<00:00,  2.09it/s]\n",
      "INFO - 06/21/22 17:22:46 - 0:26:03 - Train Epoch 63: LOSS= 0.03652, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E063: 100% 23/23 [00:09<00:00,  2.37it/s]\n",
      "INFO - 06/21/22 17:22:56 - 0:26:13 - #################################################################################################################\n",
      "INFO - 06/21/22 17:22:56 - 0:26:13 - Test Epoch 63: LOSS= 5.35671, acc1= 86.89, acc3= 89.59, acc10= 90.54\n",
      "INFO - 06/21/22 17:22:56 - 0:26:13 - #################################################################################################################\n",
      "train E064: 100% 21/21 [00:10<00:00,  2.06it/s]\n",
      "INFO - 06/21/22 17:23:06 - 0:26:23 - Train Epoch 64: LOSS= 0.03351, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E064: 100% 23/23 [00:09<00:00,  2.41it/s]\n",
      "INFO - 06/21/22 17:23:16 - 0:26:32 - #################################################################################################################\n",
      "INFO - 06/21/22 17:23:16 - 0:26:32 - Test Epoch 64: LOSS= 5.37473, acc1= 86.93, acc3= 89.55, acc10= 90.54\n",
      "INFO - 06/21/22 17:23:16 - 0:26:32 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E065: 100% 21/21 [00:09<00:00,  2.10it/s]\n",
      "INFO - 06/21/22 17:23:26 - 0:26:42 - Train Epoch 65: LOSS= 0.04293, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E065: 100% 23/23 [00:09<00:00,  2.40it/s]\n",
      "INFO - 06/21/22 17:23:35 - 0:26:52 - #################################################################################################################\n",
      "INFO - 06/21/22 17:23:35 - 0:26:52 - Test Epoch 65: LOSS= 5.13538, acc1= 86.96, acc3= 89.55, acc10= 90.58\n",
      "INFO - 06/21/22 17:23:35 - 0:26:52 - #################################################################################################################\n",
      "train E066: 100% 21/21 [00:10<00:00,  2.10it/s]\n",
      "INFO - 06/21/22 17:23:45 - 0:27:02 - Train Epoch 66: LOSS= 0.03496, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E066: 100% 23/23 [00:09<00:00,  2.43it/s]\n",
      "INFO - 06/21/22 17:23:55 - 0:27:11 - #################################################################################################################\n",
      "INFO - 06/21/22 17:23:55 - 0:27:11 - Test Epoch 66: LOSS= 5.32330, acc1= 86.96, acc3= 89.62, acc10= 90.51\n",
      "INFO - 06/21/22 17:23:55 - 0:27:11 - #################################################################################################################\n",
      "train E067: 100% 21/21 [00:10<00:00,  2.10it/s]\n",
      "INFO - 06/21/22 17:24:05 - 0:27:21 - Train Epoch 67: LOSS= 0.02972, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E067: 100% 23/23 [00:09<00:00,  2.40it/s]\n",
      "INFO - 06/21/22 17:24:14 - 0:27:31 - #################################################################################################################\n",
      "INFO - 06/21/22 17:24:14 - 0:27:31 - Test Epoch 67: LOSS= 5.11618, acc1= 86.93, acc3= 89.62, acc10= 90.51\n",
      "INFO - 06/21/22 17:24:14 - 0:27:31 - #################################################################################################################\n",
      "train E068: 100% 21/21 [00:10<00:00,  2.03it/s]\n",
      "INFO - 06/21/22 17:24:25 - 0:27:41 - Train Epoch 68: LOSS= 0.03079, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E068: 100% 23/23 [00:11<00:00,  2.04it/s]\n",
      "INFO - 06/21/22 17:24:36 - 0:27:53 - #################################################################################################################\n",
      "INFO - 06/21/22 17:24:36 - 0:27:53 - Test Epoch 68: LOSS= 5.19214, acc1= 86.96, acc3= 89.62, acc10= 90.51\n",
      "INFO - 06/21/22 17:24:36 - 0:27:53 - #################################################################################################################\n",
      "train E069: 100% 21/21 [00:10<00:00,  1.98it/s]\n",
      "INFO - 06/21/22 17:24:46 - 0:28:03 - Train Epoch 69: LOSS= 0.03989, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E069: 100% 23/23 [00:09<00:00,  2.35it/s]\n",
      "INFO - 06/21/22 17:24:56 - 0:28:13 - #################################################################################################################\n",
      "INFO - 06/21/22 17:24:56 - 0:28:13 - Test Epoch 69: LOSS= 5.36611, acc1= 86.96, acc3= 89.59, acc10= 90.51\n",
      "INFO - 06/21/22 17:24:56 - 0:28:13 - #################################################################################################################\n",
      "train E070: 100% 21/21 [00:10<00:00,  2.03it/s]\n",
      "INFO - 06/21/22 17:25:07 - 0:28:23 - Train Epoch 70: LOSS= 0.04116, lr= 0.000040, acc1= 100.00,acc3= 100.00,acc10= 100.00\n",
      "eval E070: 100% 23/23 [00:09<00:00,  2.31it/s]\n",
      "INFO - 06/21/22 17:25:16 - 0:28:33 - #################################################################################################################\n",
      "INFO - 06/21/22 17:25:16 - 0:28:33 - Test Epoch 70: LOSS= 5.14158, acc1= 86.96, acc3= 89.59, acc10= 90.54\n",
      "INFO - 06/21/22 17:25:16 - 0:28:33 - #################################################################################################################\n",
      "INFO - 06/21/22 17:25:16 - 0:28:33 - best performance =  87.07, 89.44, 90.68. best epoch = 40, correspond_loss= 5.5457\n",
      "Traceback (most recent call last):\n",
      "  File \"main_top100entity.py\", line 349, in <module>\n",
      "    logger.info(f\" fusion_model_path = {runner.fusion_model_path}\")\n",
      "AttributeError: 'Runner' object has no attribute 'fusion_model_path'\n"
     ]
    }
   ],
   "source": [
    "# object空间训练\n",
    "!python main_top100entity.py --gpu_id 0 --exp_name object_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V  --save_model 0 --fact_map 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "774e8f55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T07:30:02.476146Z",
     "start_time": "2022-07-09T07:29:34.287175Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 07/09/22 15:29:35 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 07/09/22 15:29:35 - 0:00:00 - The experiment will be stored in dump/0709-fact_surface_space/W2V\n",
      "                                     \n",
      "INFO - 07/09/22 15:29:35 - 0:00:00 - Running command: python main.py --gpu_id 2 --exp_name fact_surface_space --exp_id W2V --fusion_model SAN --data_choice 5 --method_choice W2V --save_model 1 --fact_surface_map 1\n",
      "\n",
      "2022-07-09 15:29:36.045564: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-09 15:29:36.045622: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 5\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 341, in <module>\n",
      "    runner = Runner(cfg)\n",
      "  File \"main.py\", line 40, in __init__\n",
      "    self.train_loader = fvqa.get_loader(args, self.word2vec, train=True)\n",
      "  File \"/ws/code/ZS-F-VQA/code/data/fvqa.py\", line 31, in get_loader\n",
      "    file_path=filepath\n",
      "  File \"/ws/code/ZS-F-VQA/code/data/fvqa.py\", line 76, in __init__\n",
      "    self.questions, self.answer_indices = self._qa_id_represent(cache_filepath)\n",
      "  File \"/ws/code/ZS-F-VQA/code/data/fvqa.py\", line 127, in _qa_id_represent\n",
      "    questions = list(prepare_questions(self.qa_json))  # 问题词列表的列表\n",
      "  File \"/ws/code/ZS-F-VQA/code/data/fvqa.py\", line 188, in prepare_questions\n",
      "    yield nltk.word_tokenize(process_punctuation(question))  # 得到一个词的list，例如['I', 'LOVE', 'YOU']\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/nltk/tokenize/__init__.py\", line 131, in word_tokenize\n",
      "    token for sent in sentences for token in _treebank_word_tokenizer.tokenize(sent)\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/nltk/tokenize/__init__.py\", line 131, in <listcomp>\n",
      "    token for sent in sentences for token in _treebank_word_tokenizer.tokenize(sent)\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/nltk/tokenize/destructive.py\", line 111, in tokenize\n",
      "    text = regexp.sub(substitution, text)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# fact-surface空间训练\n",
    "!python main.py --gpu_id 3 --exp_name fact_test --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --save_model 1  --fact_surface_map 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5075509f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:52:22.901918Z",
     "start_time": "2022-04-29T07:29:23.741816Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 04/29/22 15:29:28 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 04/29/22 15:29:28 - 0:00:00 - The experiment will be stored in dump/0429-semantic_space/W2V\n",
      "                                     \n",
      "INFO - 04/29/22 15:29:28 - 0:00:00 - Running command: python main_relation.py --gpu_id 1 --exp_name semantic_space --exp_id W2V --fusion_model MLPQ --data_choice 3 --method_choice W2V --save_model 0 --relation_map 1\n",
      "\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 128\n",
      "batch_size 128\n",
      "fusion_model:\n",
      "MLPQ(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      "  (w_emb): WordEmbedding(\n",
      "    (emb): Embedding(15422, 300, padding_idx=15421)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (text): Seq2SeqRNN(\n",
      "    (rnn): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  )\n",
      ")\n",
      "Answer Model:\n",
      "MLP(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "train E000: 100% 21/21 [00:28<00:00,  1.35s/it]\n",
      "INFO - 04/29/22 15:30:27 - 0:00:58 - Train Epoch 0: LOSS= 6.35631, lr= 0.000500, acc1= 16.90,acc3= 37.17,acc10= 73.02\n",
      "train E001: 100% 21/21 [00:15<00:00,  1.40it/s]\n",
      "INFO - 04/29/22 15:30:42 - 0:01:13 - Train Epoch 1: LOSS= 2.48297, lr= 0.000750, acc1= 43.31,acc3= 66.65,acc10= 90.15\n",
      "eval E001: 100% 23/23 [00:28<00:00,  1.25s/it]\n",
      "INFO - 04/29/22 15:31:11 - 0:01:42 - #################################################################################################################\n",
      "INFO - 04/29/22 15:31:11 - 0:01:42 - Test Epoch 1: LOSS= 1.71435, acc1= 56.46, acc3= 78.14, acc10= 94.62\n",
      "INFO - 04/29/22 15:31:11 - 0:01:42 - #################################################################################################################\n",
      "train E002: 100% 21/21 [00:18<00:00,  1.12it/s]\n",
      "INFO - 04/29/22 15:31:29 - 0:02:01 - Train Epoch 2: LOSS= 1.71764, lr= 0.001000, acc1= 53.35,acc3= 76.36,acc10= 94.42\n",
      "eval E002: 100% 23/23 [00:20<00:00,  1.12it/s]\n",
      "INFO - 04/29/22 15:31:50 - 0:02:21 - #################################################################################################################\n",
      "INFO - 04/29/22 15:31:50 - 0:02:21 - Test Epoch 2: LOSS= 1.56624, acc1= 59.62, acc3= 80.02, acc10= 95.36\n",
      "INFO - 04/29/22 15:31:50 - 0:02:21 - #################################################################################################################\n",
      "train E003: 100% 21/21 [00:17<00:00,  1.17it/s]\n",
      "INFO - 04/29/22 15:32:08 - 0:02:39 - Train Epoch 3: LOSS= 1.39156, lr= 0.001250, acc1= 62.12,acc3= 82.69,acc10= 96.14\n",
      "eval E003: 100% 23/23 [00:13<00:00,  1.71it/s]\n",
      "INFO - 04/29/22 15:32:21 - 0:02:53 - #################################################################################################################\n",
      "INFO - 04/29/22 15:32:21 - 0:02:53 - Test Epoch 3: LOSS= 1.42786, acc1= 63.80, acc3= 82.89, acc10= 96.10\n",
      "INFO - 04/29/22 15:32:21 - 0:02:53 - #################################################################################################################\n",
      "train E004: 100% 21/21 [00:12<00:00,  1.66it/s]\n",
      "INFO - 04/29/22 15:32:34 - 0:03:05 - Train Epoch 4: LOSS= 1.29026, lr= 0.001500, acc1= 62.80,acc3= 85.05,acc10= 97.23\n",
      "eval E004: 100% 23/23 [00:12<00:00,  1.91it/s]\n",
      "INFO - 04/29/22 15:32:46 - 0:03:17 - #################################################################################################################\n",
      "INFO - 04/29/22 15:32:46 - 0:03:17 - Test Epoch 4: LOSS= 1.66508, acc1= 60.64, acc3= 79.45, acc10= 94.05\n",
      "INFO - 04/29/22 15:32:46 - 0:03:17 - #################################################################################################################\n",
      "train E005: 100% 21/21 [00:12<00:00,  1.74it/s]\n",
      "INFO - 04/29/22 15:32:58 - 0:03:29 - Train Epoch 5: LOSS= 1.31369, lr= 0.001750, acc1= 65.01,acc3= 84.79,acc10= 97.26\n",
      "eval E005: 100% 23/23 [00:11<00:00,  2.03it/s]\n",
      "INFO - 04/29/22 15:33:09 - 0:03:41 - #################################################################################################################\n",
      "INFO - 04/29/22 15:33:09 - 0:03:41 - Test Epoch 5: LOSS= 1.39585, acc1= 62.84, acc3= 82.68, acc10= 96.07\n",
      "INFO - 04/29/22 15:33:09 - 0:03:41 - #################################################################################################################\n",
      "train E006: 100% 21/21 [00:11<00:00,  1.80it/s]\n",
      "INFO - 04/29/22 15:33:21 - 0:03:52 - Train Epoch 6: LOSS= 1.19349, lr= 0.002000, acc1= 66.69,acc3= 87.60,acc10= 98.05\n",
      "eval E006: 100% 23/23 [00:11<00:00,  1.93it/s]\n",
      "INFO - 04/29/22 15:33:33 - 0:04:04 - #################################################################################################################\n",
      "INFO - 04/29/22 15:33:33 - 0:04:04 - Test Epoch 6: LOSS= 1.76841, acc1= 66.10, acc3= 82.82, acc10= 96.39\n",
      "INFO - 04/29/22 15:33:33 - 0:04:04 - #################################################################################################################\n",
      "train E007: 100% 21/21 [00:11<00:00,  1.79it/s]\n",
      "INFO - 04/29/22 15:33:45 - 0:04:16 - Train Epoch 7: LOSS= 1.18711, lr= 0.002000, acc1= 68.00,acc3= 88.50,acc10= 98.16\n",
      "eval E007: 100% 23/23 [00:11<00:00,  1.95it/s]\n",
      "INFO - 04/29/22 15:33:56 - 0:04:28 - #################################################################################################################\n",
      "INFO - 04/29/22 15:33:56 - 0:04:28 - Test Epoch 7: LOSS= 1.71688, acc1= 63.27, acc3= 83.39, acc10= 96.07\n",
      "INFO - 04/29/22 15:33:56 - 0:04:28 - #################################################################################################################\n",
      "train E008: 100% 21/21 [00:11<00:00,  1.79it/s]\n",
      "INFO - 04/29/22 15:34:08 - 0:04:40 - Train Epoch 8: LOSS= 1.06810, lr= 0.002000, acc1= 71.00,acc3= 89.73,acc10= 98.69\n",
      "eval E008: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
      "INFO - 04/29/22 15:34:20 - 0:04:51 - #################################################################################################################\n",
      "INFO - 04/29/22 15:34:20 - 0:04:51 - Test Epoch 8: LOSS= 1.73473, acc1= 63.34, acc3= 82.89, acc10= 95.32\n",
      "INFO - 04/29/22 15:34:20 - 0:04:51 - #################################################################################################################\n",
      "train E009: 100% 21/21 [00:11<00:00,  1.83it/s]\n",
      "INFO - 04/29/22 15:34:31 - 0:05:03 - Train Epoch 9: LOSS= 0.93370, lr= 0.002000, acc1= 72.16,acc3= 91.64,acc10= 99.10\n",
      "eval E009: 100% 23/23 [00:11<00:00,  2.01it/s]\n",
      "INFO - 04/29/22 15:34:43 - 0:05:14 - #################################################################################################################\n",
      "INFO - 04/29/22 15:34:43 - 0:05:14 - Test Epoch 9: LOSS= 1.60724, acc1= 61.64, acc3= 83.56, acc10= 96.25\n",
      "INFO - 04/29/22 15:34:43 - 0:05:14 - #################################################################################################################\n",
      "train E010: 100% 21/21 [00:11<00:00,  1.81it/s]\n",
      "INFO - 04/29/22 15:34:54 - 0:05:26 - Train Epoch 10: LOSS= 0.75892, lr= 0.002000, acc1= 76.47,acc3= 93.63,acc10= 99.51\n",
      "eval E010: 100% 23/23 [00:12<00:00,  1.85it/s]\n",
      "INFO - 04/29/22 15:35:07 - 0:05:38 - #################################################################################################################\n",
      "INFO - 04/29/22 15:35:07 - 0:05:38 - Test Epoch 10: LOSS= 1.60286, acc1= 66.56, acc3= 85.62, acc10= 96.85\n",
      "INFO - 04/29/22 15:35:07 - 0:05:38 - #################################################################################################################\n",
      "train E011: 100% 21/21 [00:11<00:00,  1.83it/s]\n",
      "INFO - 04/29/22 15:35:18 - 0:05:50 - Train Epoch 11: LOSS= 0.75427, lr= 0.002000, acc1= 76.73,acc3= 93.63,acc10= 99.51\n",
      "eval E011: 100% 23/23 [00:11<00:00,  2.00it/s]\n",
      "INFO - 04/29/22 15:35:30 - 0:06:01 - #################################################################################################################\n",
      "INFO - 04/29/22 15:35:30 - 0:06:01 - Test Epoch 11: LOSS= 1.77868, acc1= 63.27, acc3= 84.27, acc10= 96.92\n",
      "INFO - 04/29/22 15:35:30 - 0:06:01 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E012: 100% 21/21 [00:11<00:00,  1.81it/s]\n",
      "INFO - 04/29/22 15:35:41 - 0:06:13 - Train Epoch 12: LOSS= 0.67287, lr= 0.002000, acc1= 78.27,acc3= 95.58,acc10= 99.78\n",
      "eval E012: 100% 23/23 [00:11<00:00,  1.99it/s]\n",
      "INFO - 04/29/22 15:35:53 - 0:06:25 - #################################################################################################################\n",
      "INFO - 04/29/22 15:35:53 - 0:06:25 - Test Epoch 12: LOSS= 1.60042, acc1= 67.41, acc3= 85.80, acc10= 96.81\n",
      "INFO - 04/29/22 15:35:53 - 0:06:25 - #################################################################################################################\n",
      "train E013: 100% 21/21 [00:11<00:00,  1.81it/s]\n",
      "INFO - 04/29/22 15:36:05 - 0:06:36 - Train Epoch 13: LOSS= 0.65423, lr= 0.002000, acc1= 79.69,acc3= 94.90,acc10= 99.78\n",
      "eval E013: 100% 23/23 [00:11<00:00,  1.92it/s]\n",
      "INFO - 04/29/22 15:36:17 - 0:06:48 - #################################################################################################################\n",
      "INFO - 04/29/22 15:36:17 - 0:06:48 - Test Epoch 13: LOSS= 1.74784, acc1= 66.14, acc3= 84.34, acc10= 96.39\n",
      "INFO - 04/29/22 15:36:17 - 0:06:48 - #################################################################################################################\n",
      "train E014: 100% 21/21 [00:11<00:00,  1.78it/s]\n",
      "INFO - 04/29/22 15:36:28 - 0:07:00 - Train Epoch 14: LOSS= 0.56693, lr= 0.001400, acc1= 81.83,acc3= 96.29,acc10= 99.78\n",
      "eval E014: 100% 23/23 [00:12<00:00,  1.89it/s]\n",
      "INFO - 04/29/22 15:36:41 - 0:07:12 - #################################################################################################################\n",
      "INFO - 04/29/22 15:36:41 - 0:07:12 - Test Epoch 14: LOSS= 1.62839, acc1= 66.67, acc3= 85.30, acc10= 96.78\n",
      "INFO - 04/29/22 15:36:41 - 0:07:12 - #################################################################################################################\n",
      "train E015: 100% 21/21 [00:11<00:00,  1.80it/s]\n",
      "INFO - 04/29/22 15:36:52 - 0:07:24 - Train Epoch 15: LOSS= 0.45038, lr= 0.001400, acc1= 85.50,acc3= 97.53,acc10= 100.00\n",
      "eval E015: 100% 23/23 [00:11<00:00,  1.94it/s]\n",
      "INFO - 04/29/22 15:37:04 - 0:07:36 - #################################################################################################################\n",
      "INFO - 04/29/22 15:37:04 - 0:07:36 - Test Epoch 15: LOSS= 1.67350, acc1= 67.55, acc3= 86.82, acc10= 96.42\n",
      "INFO - 04/29/22 15:37:04 - 0:07:36 - #################################################################################################################\n",
      "train E016: 100% 21/21 [00:11<00:00,  1.82it/s]\n",
      "INFO - 04/29/22 15:37:16 - 0:07:47 - Train Epoch 16: LOSS= 0.45669, lr= 0.001400, acc1= 85.76,acc3= 98.01,acc10= 99.89\n",
      "eval E016: 100% 23/23 [00:11<00:00,  2.02it/s]\n",
      "INFO - 04/29/22 15:37:27 - 0:07:59 - #################################################################################################################\n",
      "INFO - 04/29/22 15:37:27 - 0:07:59 - Test Epoch 16: LOSS= 1.64546, acc1= 66.63, acc3= 85.48, acc10= 97.06\n",
      "INFO - 04/29/22 15:37:27 - 0:07:59 - #################################################################################################################\n",
      "train E017: 100% 21/21 [00:11<00:00,  1.88it/s]\n",
      "INFO - 04/29/22 15:37:38 - 0:08:10 - Train Epoch 17: LOSS= 0.38323, lr= 0.000980, acc1= 87.52,acc3= 98.50,acc10= 99.96\n",
      "eval E017: 100% 23/23 [00:11<00:00,  1.97it/s]\n",
      "INFO - 04/29/22 15:37:50 - 0:08:22 - #################################################################################################################\n",
      "INFO - 04/29/22 15:37:50 - 0:08:22 - Test Epoch 17: LOSS= 1.69428, acc1= 68.33, acc3= 86.86, acc10= 96.95\n",
      "INFO - 04/29/22 15:37:50 - 0:08:22 - #################################################################################################################\n",
      "train E018: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 04/29/22 15:38:02 - 0:08:33 - Train Epoch 18: LOSS= 0.33026, lr= 0.000980, acc1= 89.13,acc3= 98.80,acc10= 100.00\n",
      "eval E018: 100% 23/23 [00:12<00:00,  1.91it/s]\n",
      "INFO - 04/29/22 15:38:14 - 0:08:45 - #################################################################################################################\n",
      "INFO - 04/29/22 15:38:14 - 0:08:45 - Test Epoch 18: LOSS= 1.70680, acc1= 67.06, acc3= 86.96, acc10= 96.74\n",
      "INFO - 04/29/22 15:38:14 - 0:08:45 - #################################################################################################################\n",
      "train E019: 100% 21/21 [00:11<00:00,  1.85it/s]\n",
      "INFO - 04/29/22 15:38:25 - 0:08:57 - Train Epoch 19: LOSS= 0.27091, lr= 0.000980, acc1= 90.97,acc3= 99.25,acc10= 100.00\n",
      "eval E019: 100% 23/23 [00:12<00:00,  1.87it/s]\n",
      "INFO - 04/29/22 15:38:38 - 0:09:09 - #################################################################################################################\n",
      "INFO - 04/29/22 15:38:38 - 0:09:09 - Test Epoch 19: LOSS= 1.70734, acc1= 67.55, acc3= 86.15, acc10= 96.92\n",
      "INFO - 04/29/22 15:38:38 - 0:09:09 - #################################################################################################################\n",
      "train E020: 100% 21/21 [00:11<00:00,  1.81it/s]\n",
      "INFO - 04/29/22 15:38:49 - 0:09:21 - Train Epoch 20: LOSS= 0.27492, lr= 0.000686, acc1= 90.90,acc3= 99.29,acc10= 100.00\n",
      "eval E020: 100% 23/23 [00:11<00:00,  1.94it/s]\n",
      "INFO - 04/29/22 15:39:01 - 0:09:33 - #################################################################################################################\n",
      "INFO - 04/29/22 15:39:01 - 0:09:33 - Test Epoch 20: LOSS= 1.90130, acc1= 69.15, acc3= 86.22, acc10= 97.02\n",
      "INFO - 04/29/22 15:39:01 - 0:09:33 - #################################################################################################################\n",
      "train E021: 100% 21/21 [00:11<00:00,  1.82it/s]\n",
      "INFO - 04/29/22 15:39:13 - 0:09:44 - Train Epoch 21: LOSS= 0.25147, lr= 0.000686, acc1= 91.46,acc3= 99.25,acc10= 100.00\n",
      "eval E021: 100% 23/23 [00:11<00:00,  1.99it/s]\n",
      "INFO - 04/29/22 15:39:24 - 0:09:56 - #################################################################################################################\n",
      "INFO - 04/29/22 15:39:24 - 0:09:56 - Test Epoch 21: LOSS= 1.81935, acc1= 68.58, acc3= 86.15, acc10= 97.06\n",
      "INFO - 04/29/22 15:39:24 - 0:09:56 - #################################################################################################################\n",
      "train E022: 100% 21/21 [00:11<00:00,  1.80it/s]\n",
      "INFO - 04/29/22 15:39:36 - 0:10:07 - Train Epoch 22: LOSS= 0.23821, lr= 0.000686, acc1= 92.02,acc3= 99.14,acc10= 99.96\n",
      "eval E022: 100% 23/23 [00:11<00:00,  1.94it/s]\n",
      "INFO - 04/29/22 15:39:48 - 0:10:19 - #################################################################################################################\n",
      "INFO - 04/29/22 15:39:48 - 0:10:19 - Test Epoch 22: LOSS= 2.01316, acc1= 68.61, acc3= 86.43, acc10= 96.95\n",
      "INFO - 04/29/22 15:39:48 - 0:10:19 - #################################################################################################################\n",
      "train E023: 100% 21/21 [00:11<00:00,  1.88it/s]\n",
      "INFO - 04/29/22 15:39:59 - 0:10:30 - Train Epoch 23: LOSS= 0.21531, lr= 0.000480, acc1= 92.28,acc3= 99.44,acc10= 99.96\n",
      "eval E023: 100% 23/23 [00:11<00:00,  2.00it/s]\n",
      "INFO - 04/29/22 15:40:10 - 0:10:42 - #################################################################################################################\n",
      "INFO - 04/29/22 15:40:10 - 0:10:42 - Test Epoch 23: LOSS= 1.93115, acc1= 69.11, acc3= 86.89, acc10= 96.88\n",
      "INFO - 04/29/22 15:40:10 - 0:10:42 - #################################################################################################################\n",
      "train E024: 100% 21/21 [00:11<00:00,  1.86it/s]\n",
      "INFO - 04/29/22 15:40:22 - 0:10:53 - Train Epoch 24: LOSS= 0.20024, lr= 0.000480, acc1= 92.77,acc3= 99.81,acc10= 100.00\n",
      "eval E024: 100% 23/23 [00:11<00:00,  2.03it/s]\n",
      "INFO - 04/29/22 15:40:33 - 0:11:05 - #################################################################################################################\n",
      "INFO - 04/29/22 15:40:33 - 0:11:05 - Test Epoch 24: LOSS= 1.96259, acc1= 68.01, acc3= 86.33, acc10= 97.13\n",
      "INFO - 04/29/22 15:40:33 - 0:11:05 - #################################################################################################################\n",
      "train E025: 100% 21/21 [00:11<00:00,  1.90it/s]\n",
      "INFO - 04/29/22 15:40:44 - 0:11:16 - Train Epoch 25: LOSS= 0.18544, lr= 0.000480, acc1= 94.08,acc3= 99.66,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E025: 100% 23/23 [00:11<00:00,  2.00it/s]\n",
      "INFO - 04/29/22 15:40:56 - 0:11:27 - #################################################################################################################\n",
      "INFO - 04/29/22 15:40:56 - 0:11:27 - Test Epoch 25: LOSS= 1.85352, acc1= 69.00, acc3= 87.35, acc10= 97.10\n",
      "INFO - 04/29/22 15:40:56 - 0:11:27 - #################################################################################################################\n",
      "train E026: 100% 21/21 [00:11<00:00,  1.79it/s]\n",
      "INFO - 04/29/22 15:41:07 - 0:11:39 - Train Epoch 26: LOSS= 0.19041, lr= 0.000336, acc1= 93.48,acc3= 99.78,acc10= 100.00\n",
      "eval E026: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
      "INFO - 04/29/22 15:41:19 - 0:11:51 - #################################################################################################################\n",
      "INFO - 04/29/22 15:41:19 - 0:11:51 - Test Epoch 26: LOSS= 1.94814, acc1= 68.86, acc3= 86.36, acc10= 97.02\n",
      "INFO - 04/29/22 15:41:19 - 0:11:51 - #################################################################################################################\n",
      "train E027: 100% 21/21 [00:11<00:00,  1.81it/s]\n",
      "INFO - 04/29/22 15:41:31 - 0:12:02 - Train Epoch 27: LOSS= 0.18652, lr= 0.000336, acc1= 93.52,acc3= 99.74,acc10= 100.00\n",
      "eval E027: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
      "INFO - 04/29/22 15:41:42 - 0:12:14 - #################################################################################################################\n",
      "INFO - 04/29/22 15:41:42 - 0:12:14 - Test Epoch 27: LOSS= 1.90832, acc1= 68.19, acc3= 86.40, acc10= 97.06\n",
      "INFO - 04/29/22 15:41:42 - 0:12:14 - #################################################################################################################\n",
      "train E028: 100% 21/21 [00:11<00:00,  1.89it/s]\n",
      "INFO - 04/29/22 15:41:53 - 0:12:25 - Train Epoch 28: LOSS= 0.17703, lr= 0.000336, acc1= 93.37,acc3= 99.89,acc10= 100.00\n",
      "eval E028: 100% 23/23 [00:11<00:00,  2.02it/s]\n",
      "INFO - 04/29/22 15:42:05 - 0:12:36 - #################################################################################################################\n",
      "INFO - 04/29/22 15:42:05 - 0:12:36 - Test Epoch 28: LOSS= 1.88987, acc1= 67.91, acc3= 86.72, acc10= 96.88\n",
      "INFO - 04/29/22 15:42:05 - 0:12:36 - #################################################################################################################\n",
      "train E029: 100% 21/21 [00:11<00:00,  1.85it/s]\n",
      "INFO - 04/29/22 15:42:16 - 0:12:48 - Train Epoch 29: LOSS= 0.17651, lr= 0.000235, acc1= 93.86,acc3= 99.78,acc10= 100.00\n",
      "eval E029: 100% 23/23 [00:11<00:00,  1.94it/s]\n",
      "INFO - 04/29/22 15:42:28 - 0:13:00 - #################################################################################################################\n",
      "INFO - 04/29/22 15:42:28 - 0:13:00 - Test Epoch 29: LOSS= 1.98704, acc1= 67.80, acc3= 86.72, acc10= 96.92\n",
      "INFO - 04/29/22 15:42:28 - 0:13:00 - #################################################################################################################\n",
      "train E030: 100% 21/21 [00:11<00:00,  1.81it/s]\n",
      "INFO - 04/29/22 15:42:40 - 0:13:11 - Train Epoch 30: LOSS= 0.15412, lr= 0.000235, acc1= 94.98,acc3= 99.70,acc10= 100.00\n",
      "eval E030: 100% 23/23 [00:12<00:00,  1.89it/s]\n",
      "INFO - 04/29/22 15:42:52 - 0:13:23 - #################################################################################################################\n",
      "INFO - 04/29/22 15:42:52 - 0:13:23 - Test Epoch 30: LOSS= 1.97756, acc1= 68.90, acc3= 86.33, acc10= 96.85\n",
      "INFO - 04/29/22 15:42:52 - 0:13:23 - #################################################################################################################\n",
      "train E031: 100% 21/21 [00:11<00:00,  1.85it/s]\n",
      "INFO - 04/29/22 15:43:03 - 0:13:35 - Train Epoch 31: LOSS= 0.14735, lr= 0.000235, acc1= 94.83,acc3= 99.85,acc10= 99.96\n",
      "eval E031: 100% 23/23 [00:11<00:00,  2.01it/s]\n",
      "INFO - 04/29/22 15:43:15 - 0:13:46 - #################################################################################################################\n",
      "INFO - 04/29/22 15:43:15 - 0:13:46 - Test Epoch 31: LOSS= 2.02672, acc1= 68.65, acc3= 86.68, acc10= 96.92\n",
      "INFO - 04/29/22 15:43:15 - 0:13:46 - #################################################################################################################\n",
      "train E032: 100% 21/21 [00:11<00:00,  1.84it/s]\n",
      "INFO - 04/29/22 15:43:26 - 0:13:58 - Train Epoch 32: LOSS= 0.13858, lr= 0.000165, acc1= 95.54,acc3= 99.93,acc10= 100.00\n",
      "eval E032: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
      "INFO - 04/29/22 15:43:38 - 0:14:09 - #################################################################################################################\n",
      "INFO - 04/29/22 15:43:38 - 0:14:09 - Test Epoch 32: LOSS= 2.01865, acc1= 68.15, acc3= 86.47, acc10= 96.95\n",
      "INFO - 04/29/22 15:43:38 - 0:14:09 - #################################################################################################################\n",
      "train E033: 100% 21/21 [00:11<00:00,  1.87it/s]\n",
      "INFO - 04/29/22 15:43:49 - 0:14:21 - Train Epoch 33: LOSS= 0.14932, lr= 0.000165, acc1= 95.09,acc3= 99.78,acc10= 100.00\n",
      "eval E033: 100% 23/23 [00:11<00:00,  1.97it/s]\n",
      "INFO - 04/29/22 15:44:01 - 0:14:32 - #################################################################################################################\n",
      "INFO - 04/29/22 15:44:01 - 0:14:32 - Test Epoch 33: LOSS= 1.96556, acc1= 68.47, acc3= 86.68, acc10= 97.02\n",
      "INFO - 04/29/22 15:44:01 - 0:14:32 - #################################################################################################################\n",
      "train E034: 100% 21/21 [00:11<00:00,  1.78it/s]\n",
      "INFO - 04/29/22 15:44:12 - 0:14:44 - Train Epoch 34: LOSS= 0.14051, lr= 0.000165, acc1= 95.13,acc3= 99.93,acc10= 100.00\n",
      "eval E034: 100% 23/23 [00:12<00:00,  1.90it/s]\n",
      "INFO - 04/29/22 15:44:25 - 0:14:56 - #################################################################################################################\n",
      "INFO - 04/29/22 15:44:25 - 0:14:56 - Test Epoch 34: LOSS= 1.98099, acc1= 68.19, acc3= 86.61, acc10= 96.99\n",
      "INFO - 04/29/22 15:44:25 - 0:14:56 - #################################################################################################################\n",
      "train E035: 100% 21/21 [00:11<00:00,  1.84it/s]\n",
      "INFO - 04/29/22 15:44:36 - 0:15:08 - Train Epoch 35: LOSS= 0.14048, lr= 0.000115, acc1= 95.17,acc3= 99.85,acc10= 100.00\n",
      "eval E035: 100% 23/23 [00:11<00:00,  2.01it/s]\n",
      "INFO - 04/29/22 15:44:47 - 0:15:19 - #################################################################################################################\n",
      "INFO - 04/29/22 15:44:47 - 0:15:19 - Test Epoch 35: LOSS= 2.14511, acc1= 68.37, acc3= 86.82, acc10= 96.95\n",
      "INFO - 04/29/22 15:44:47 - 0:15:19 - #################################################################################################################\n",
      "train E036: 100% 21/21 [00:11<00:00,  1.84it/s]\n",
      "INFO - 04/29/22 15:44:59 - 0:15:30 - Train Epoch 36: LOSS= 0.14749, lr= 0.000115, acc1= 95.20,acc3= 99.93,acc10= 100.00\n",
      "eval E036: 100% 23/23 [00:11<00:00,  2.00it/s]\n",
      "INFO - 04/29/22 15:45:10 - 0:15:42 - #################################################################################################################\n",
      "INFO - 04/29/22 15:45:10 - 0:15:42 - Test Epoch 36: LOSS= 2.03306, acc1= 68.23, acc3= 87.04, acc10= 97.06\n",
      "INFO - 04/29/22 15:45:10 - 0:15:42 - #################################################################################################################\n",
      "train E037: 100% 21/21 [00:11<00:00,  1.83it/s]\n",
      "INFO - 04/29/22 15:45:22 - 0:15:53 - Train Epoch 37: LOSS= 0.13920, lr= 0.000115, acc1= 95.09,acc3= 99.93,acc10= 100.00\n",
      "eval E037: 100% 23/23 [00:11<00:00,  2.03it/s]\n",
      "INFO - 04/29/22 15:45:33 - 0:16:05 - #################################################################################################################\n",
      "INFO - 04/29/22 15:45:33 - 0:16:05 - Test Epoch 37: LOSS= 2.11355, acc1= 67.94, acc3= 86.57, acc10= 96.85\n",
      "INFO - 04/29/22 15:45:33 - 0:16:05 - #################################################################################################################\n",
      "train E038: 100% 21/21 [00:11<00:00,  1.87it/s]\n",
      "INFO - 04/29/22 15:45:44 - 0:16:16 - Train Epoch 38: LOSS= 0.13437, lr= 0.000081, acc1= 95.54,acc3= 99.81,acc10= 100.00\n",
      "eval E038: 100% 23/23 [00:11<00:00,  2.07it/s]\n",
      "INFO - 04/29/22 15:45:56 - 0:16:27 - #################################################################################################################\n",
      "INFO - 04/29/22 15:45:56 - 0:16:27 - Test Epoch 38: LOSS= 2.02086, acc1= 68.26, acc3= 86.65, acc10= 96.81\n",
      "INFO - 04/29/22 15:45:56 - 0:16:27 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E039: 100% 21/21 [00:10<00:00,  1.92it/s]\n",
      "INFO - 04/29/22 15:46:06 - 0:16:38 - Train Epoch 39: LOSS= 0.13027, lr= 0.000081, acc1= 95.39,acc3= 99.89,acc10= 100.00\n",
      "eval E039: 100% 23/23 [00:10<00:00,  2.09it/s]\n",
      "INFO - 04/29/22 15:46:17 - 0:16:49 - #################################################################################################################\n",
      "INFO - 04/29/22 15:46:17 - 0:16:49 - Test Epoch 39: LOSS= 2.01363, acc1= 67.91, acc3= 86.57, acc10= 96.81\n",
      "INFO - 04/29/22 15:46:17 - 0:16:49 - #################################################################################################################\n",
      "train E040: 100% 21/21 [00:10<00:00,  1.94it/s]\n",
      "INFO - 04/29/22 15:46:28 - 0:17:00 - Train Epoch 40: LOSS= 0.13232, lr= 0.000081, acc1= 95.88,acc3= 99.96,acc10= 100.00\n",
      "eval E040: 100% 23/23 [00:10<00:00,  2.09it/s]\n",
      "INFO - 04/29/22 15:46:39 - 0:17:11 - #################################################################################################################\n",
      "INFO - 04/29/22 15:46:39 - 0:17:11 - Test Epoch 40: LOSS= 2.03791, acc1= 68.44, acc3= 86.68, acc10= 96.78\n",
      "INFO - 04/29/22 15:46:39 - 0:17:11 - #################################################################################################################\n",
      "train E041: 100% 21/21 [00:10<00:00,  1.93it/s]\n",
      "INFO - 04/29/22 15:46:50 - 0:17:22 - Train Epoch 41: LOSS= 0.12802, lr= 0.000056, acc1= 95.92,acc3= 99.81,acc10= 100.00\n",
      "eval E041: 100% 23/23 [00:11<00:00,  2.08it/s]\n",
      "INFO - 04/29/22 15:47:01 - 0:17:33 - #################################################################################################################\n",
      "INFO - 04/29/22 15:47:01 - 0:17:33 - Test Epoch 41: LOSS= 2.02251, acc1= 68.05, acc3= 86.79, acc10= 96.88\n",
      "INFO - 04/29/22 15:47:01 - 0:17:33 - #################################################################################################################\n",
      "train E042: 100% 21/21 [00:11<00:00,  1.91it/s]\n",
      "INFO - 04/29/22 15:47:12 - 0:17:44 - Train Epoch 42: LOSS= 0.13148, lr= 0.000056, acc1= 95.50,acc3= 99.85,acc10= 100.00\n",
      "eval E042: 100% 23/23 [00:11<00:00,  2.01it/s]\n",
      "INFO - 04/29/22 15:47:24 - 0:17:55 - #################################################################################################################\n",
      "INFO - 04/29/22 15:47:24 - 0:17:55 - Test Epoch 42: LOSS= 1.97253, acc1= 68.01, acc3= 86.82, acc10= 96.74\n",
      "INFO - 04/29/22 15:47:24 - 0:17:55 - #################################################################################################################\n",
      "train E043: 100% 21/21 [00:11<00:00,  1.86it/s]\n",
      "INFO - 04/29/22 15:47:35 - 0:18:07 - Train Epoch 43: LOSS= 0.12101, lr= 0.000056, acc1= 95.39,acc3= 99.85,acc10= 100.00\n",
      "eval E043: 100% 23/23 [00:11<00:00,  2.06it/s]\n",
      "INFO - 04/29/22 15:47:46 - 0:18:18 - #################################################################################################################\n",
      "INFO - 04/29/22 15:47:46 - 0:18:18 - Test Epoch 43: LOSS= 1.98528, acc1= 68.23, acc3= 86.86, acc10= 96.60\n",
      "INFO - 04/29/22 15:47:46 - 0:18:18 - #################################################################################################################\n",
      "train E044: 100% 21/21 [00:11<00:00,  1.86it/s]\n",
      "INFO - 04/29/22 15:47:57 - 0:18:29 - Train Epoch 44: LOSS= 0.12726, lr= 0.000040, acc1= 95.62,acc3= 99.89,acc10= 100.00\n",
      "eval E044: 100% 23/23 [00:10<00:00,  2.13it/s]\n",
      "INFO - 04/29/22 15:48:08 - 0:18:40 - #################################################################################################################\n",
      "INFO - 04/29/22 15:48:08 - 0:18:40 - Test Epoch 44: LOSS= 2.06028, acc1= 68.23, acc3= 86.86, acc10= 96.74\n",
      "INFO - 04/29/22 15:48:08 - 0:18:40 - #################################################################################################################\n",
      "train E045: 100% 21/21 [00:10<00:00,  1.93it/s]\n",
      "INFO - 04/29/22 15:48:19 - 0:18:51 - Train Epoch 45: LOSS= 0.12926, lr= 0.000040, acc1= 95.50,acc3= 99.85,acc10= 100.00\n",
      "eval E045: 100% 23/23 [00:10<00:00,  2.10it/s]\n",
      "INFO - 04/29/22 15:48:30 - 0:19:02 - #################################################################################################################\n",
      "INFO - 04/29/22 15:48:30 - 0:19:02 - Test Epoch 45: LOSS= 2.01762, acc1= 68.19, acc3= 86.79, acc10= 96.81\n",
      "INFO - 04/29/22 15:48:30 - 0:19:02 - #################################################################################################################\n",
      "train E046: 100% 21/21 [00:10<00:00,  1.92it/s]\n",
      "INFO - 04/29/22 15:48:41 - 0:19:13 - Train Epoch 46: LOSS= 0.12111, lr= 0.000040, acc1= 95.92,acc3= 99.89,acc10= 100.00\n",
      "eval E046: 100% 23/23 [00:11<00:00,  2.01it/s]\n",
      "INFO - 04/29/22 15:48:52 - 0:19:24 - #################################################################################################################\n",
      "INFO - 04/29/22 15:48:52 - 0:19:24 - Test Epoch 46: LOSS= 2.05070, acc1= 68.23, acc3= 86.75, acc10= 96.74\n",
      "INFO - 04/29/22 15:48:52 - 0:19:24 - #################################################################################################################\n",
      "train E047: 100% 21/21 [00:11<00:00,  1.87it/s]\n",
      "INFO - 04/29/22 15:49:04 - 0:19:35 - Train Epoch 47: LOSS= 0.12456, lr= 0.000040, acc1= 96.03,acc3= 99.85,acc10= 100.00\n",
      "eval E047: 100% 23/23 [00:11<00:00,  2.02it/s]\n",
      "INFO - 04/29/22 15:49:15 - 0:19:47 - #################################################################################################################\n",
      "INFO - 04/29/22 15:49:15 - 0:19:47 - Test Epoch 47: LOSS= 2.01482, acc1= 68.54, acc3= 86.65, acc10= 96.78\n",
      "INFO - 04/29/22 15:49:15 - 0:19:47 - #################################################################################################################\n",
      "train E048: 100% 21/21 [00:11<00:00,  1.87it/s]\n",
      "INFO - 04/29/22 15:49:26 - 0:19:58 - Train Epoch 48: LOSS= 0.11217, lr= 0.000040, acc1= 96.33,acc3= 99.81,acc10= 100.00\n",
      "eval E048: 100% 23/23 [00:11<00:00,  2.03it/s]\n",
      "INFO - 04/29/22 15:49:38 - 0:20:09 - #################################################################################################################\n",
      "INFO - 04/29/22 15:49:38 - 0:20:09 - Test Epoch 48: LOSS= 2.00796, acc1= 68.15, acc3= 86.86, acc10= 96.74\n",
      "INFO - 04/29/22 15:49:38 - 0:20:09 - #################################################################################################################\n",
      "train E049: 100% 21/21 [00:11<00:00,  1.89it/s]\n",
      "INFO - 04/29/22 15:49:49 - 0:20:20 - Train Epoch 49: LOSS= 0.12123, lr= 0.000040, acc1= 95.88,acc3= 99.81,acc10= 100.00\n",
      "eval E049: 100% 23/23 [00:11<00:00,  2.02it/s]\n",
      "INFO - 04/29/22 15:50:00 - 0:20:32 - #################################################################################################################\n",
      "INFO - 04/29/22 15:50:00 - 0:20:32 - Test Epoch 49: LOSS= 2.06181, acc1= 68.15, acc3= 86.75, acc10= 96.74\n",
      "INFO - 04/29/22 15:50:00 - 0:20:32 - #################################################################################################################\n",
      "train E050: 100% 21/21 [00:11<00:00,  1.75it/s]\n",
      "INFO - 04/29/22 15:50:12 - 0:20:44 - Train Epoch 50: LOSS= 0.11307, lr= 0.000040, acc1= 96.18,acc3= 99.85,acc10= 100.00\n",
      "eval E050: 100% 23/23 [00:12<00:00,  1.82it/s]\n",
      "INFO - 04/29/22 15:50:25 - 0:20:56 - #################################################################################################################\n",
      "INFO - 04/29/22 15:50:25 - 0:20:56 - Test Epoch 50: LOSS= 2.06695, acc1= 68.54, acc3= 86.86, acc10= 96.81\n",
      "INFO - 04/29/22 15:50:25 - 0:20:56 - #################################################################################################################\n",
      "train E051: 100% 21/21 [00:11<00:00,  1.78it/s]\n",
      "INFO - 04/29/22 15:50:37 - 0:21:08 - Train Epoch 51: LOSS= 0.11351, lr= 0.000040, acc1= 95.99,acc3= 99.81,acc10= 100.00\n",
      "eval E051: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
      "INFO - 04/29/22 15:50:48 - 0:21:20 - #################################################################################################################\n",
      "INFO - 04/29/22 15:50:48 - 0:21:20 - Test Epoch 51: LOSS= 2.02231, acc1= 68.44, acc3= 86.72, acc10= 96.88\n",
      "INFO - 04/29/22 15:50:48 - 0:21:20 - #################################################################################################################\n",
      "train E052: 100% 21/21 [00:11<00:00,  1.89it/s]\n",
      "INFO - 04/29/22 15:50:59 - 0:21:31 - Train Epoch 52: LOSS= 0.12494, lr= 0.000040, acc1= 95.77,acc3= 99.85,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E052: 100% 23/23 [00:11<00:00,  2.03it/s]\n",
      "INFO - 04/29/22 15:51:11 - 0:21:42 - #################################################################################################################\n",
      "INFO - 04/29/22 15:51:11 - 0:21:42 - Test Epoch 52: LOSS= 2.03254, acc1= 67.87, acc3= 86.86, acc10= 96.78\n",
      "INFO - 04/29/22 15:51:11 - 0:21:42 - #################################################################################################################\n",
      "train E053: 100% 21/21 [00:11<00:00,  1.85it/s]\n",
      "INFO - 04/29/22 15:51:22 - 0:21:54 - Train Epoch 53: LOSS= 0.11462, lr= 0.000040, acc1= 96.18,acc3= 99.93,acc10= 100.00\n",
      "eval E053: 100% 23/23 [00:11<00:00,  2.02it/s]\n",
      "INFO - 04/29/22 15:51:33 - 0:22:05 - #################################################################################################################\n",
      "INFO - 04/29/22 15:51:33 - 0:22:05 - Test Epoch 53: LOSS= 2.15742, acc1= 68.44, acc3= 86.61, acc10= 96.81\n",
      "INFO - 04/29/22 15:51:33 - 0:22:05 - #################################################################################################################\n",
      "train E054: 100% 21/21 [00:12<00:00,  1.72it/s]\n",
      "INFO - 04/29/22 15:51:46 - 0:22:17 - Train Epoch 54: LOSS= 0.11981, lr= 0.000040, acc1= 95.58,acc3= 99.85,acc10= 100.00\n",
      "eval E054: 100% 23/23 [00:12<00:00,  1.88it/s]\n",
      "INFO - 04/29/22 15:51:58 - 0:22:29 - #################################################################################################################\n",
      "INFO - 04/29/22 15:51:58 - 0:22:29 - Test Epoch 54: LOSS= 2.13513, acc1= 68.54, acc3= 86.61, acc10= 96.74\n",
      "INFO - 04/29/22 15:51:58 - 0:22:29 - #################################################################################################################\n",
      "train E055: 100% 21/21 [00:11<00:00,  1.85it/s]\n",
      "INFO - 04/29/22 15:52:09 - 0:22:41 - Train Epoch 55: LOSS= 0.11940, lr= 0.000040, acc1= 95.54,acc3= 99.85,acc10= 100.00\n",
      "eval E055: 100% 23/23 [00:11<00:00,  2.03it/s]\n",
      "INFO - 04/29/22 15:52:21 - 0:22:52 - #################################################################################################################\n",
      "INFO - 04/29/22 15:52:21 - 0:22:52 - Test Epoch 55: LOSS= 2.01233, acc1= 68.51, acc3= 86.50, acc10= 96.81\n",
      "INFO - 04/29/22 15:52:21 - 0:22:52 - #################################################################################################################\n",
      "INFO - 04/29/22 15:52:21 - 0:22:52 - best performance =  69.00, 87.35, 97.10. best epoch = 25, correspond_loss= 1.8535\n",
      "Traceback (most recent call last):\n",
      "  File \"main_relation.py\", line 353, in <module>\n",
      "    logger.info(f\" fusion_model_path = {runner.fusion_model_path}\")\n",
      "AttributeError: 'Runner' object has no attribute 'fusion_model_path'\n"
     ]
    }
   ],
   "source": [
    "#语义空间\n",
    "!python main_relation.py --gpu_id 1 --exp_name semantic_space --exp_id W2V --fusion_model MLPQ --data_choice 3 --method_choice W2V  --save_model 0 --relation_map 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "15b8c8a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T14:08:53.927387Z",
     "start_time": "2022-07-19T12:19:23.038249Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 07/19/22 20:19:25 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 07/19/22 20:19:25 - 0:00:00 - The experiment will be stored in dump/0719-answer_space/Lxmert\n",
      "                                     \n",
      "INFO - 07/19/22 20:19:25 - 0:00:00 - Running command: python main_lxmert.py --gpu_id 0 --exp_name answer_space --exp_id Lxmert --fusion_model LXMERT --data_choice 2 --method_choice W2V --batch_size 32 --save_model 1\n",
      "\n",
      "2022-07-19 20:19:25.253333: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-19 20:19:25.253413: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 2\n",
      "Start to load Faster-RCNN detected objects from /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/fvqa_obj36.tsv\n",
      "Loaded 3016 images in file /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/fvqa_obj36.tsv in 44 seconds.\n",
      "batch_size 32\n",
      "Start to load Faster-RCNN detected objects from /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/fvqa_obj36.tsv\n",
      "Loaded 3016 images in file /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/fvqa_obj36.tsv in 42 seconds.\n",
      "batch_size 32\n",
      "INFO - 07/19/22 20:21:07 - 0:01:42 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO - 07/19/22 20:21:08 - 0:01:43 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO - 07/19/22 20:21:08 - 0:01:43 - extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpedr0nu98\n",
      "INFO - 07/19/22 20:21:14 - 0:01:49 - Model config {\n",
      "                                       \"attention_probs_dropout_prob\": 0.1,\n",
      "                                       \"hidden_act\": \"gelu\",\n",
      "                                       \"hidden_dropout_prob\": 0.1,\n",
      "                                       \"hidden_size\": 768,\n",
      "                                       \"initializer_range\": 0.02,\n",
      "                                       \"intermediate_size\": 3072,\n",
      "                                       \"max_position_embeddings\": 512,\n",
      "                                       \"num_attention_heads\": 12,\n",
      "                                       \"num_hidden_layers\": 12,\n",
      "                                       \"type_vocab_size\": 2,\n",
      "                                       \"vocab_size\": 30522\n",
      "                                     }\n",
      "                                     \n",
      "LXRT encoder with 9 l_layers, 5 x_layers, and 5 r_layers.\n",
      "Load LXMERT pre-trained model from /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/model\n",
      "\n",
      "Weights in loaded but not in model:\n",
      "answer_head.logit_fc.0.bias\n",
      "answer_head.logit_fc.0.weight\n",
      "answer_head.logit_fc.2.bias\n",
      "answer_head.logit_fc.2.weight\n",
      "answer_head.logit_fc.3.bias\n",
      "answer_head.logit_fc.3.weight\n",
      "cls.predictions.bias\n",
      "cls.predictions.decoder.weight\n",
      "cls.predictions.transform.LayerNorm.bias\n",
      "cls.predictions.transform.LayerNorm.weight\n",
      "cls.predictions.transform.dense.bias\n",
      "cls.predictions.transform.dense.weight\n",
      "cls.seq_relationship.bias\n",
      "cls.seq_relationship.weight\n",
      "obj_predict_head.decoder_dict.attr.bias\n",
      "obj_predict_head.decoder_dict.attr.weight\n",
      "obj_predict_head.decoder_dict.feat.bias\n",
      "obj_predict_head.decoder_dict.feat.weight\n",
      "obj_predict_head.decoder_dict.obj.bias\n",
      "obj_predict_head.decoder_dict.obj.weight\n",
      "obj_predict_head.transform.LayerNorm.bias\n",
      "obj_predict_head.transform.LayerNorm.weight\n",
      "obj_predict_head.transform.dense.bias\n",
      "obj_predict_head.transform.dense.weight\n",
      "\n",
      "Weights in model but not in loaded:\n",
      "\n",
      "model.bert.embeddings.word_embeddings.weight:\tFalse\n",
      "model.bert.embeddings.position_embeddings.weight:\tFalse\n",
      "model.bert.embeddings.token_type_embeddings.weight:\tFalse\n",
      "model.bert.embeddings.LayerNorm.weight:\tFalse\n",
      "model.bert.embeddings.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.visn_fc.visn_fc.weight:\tFalse\n",
      "model.bert.encoder.visn_fc.visn_fc.bias:\tFalse\n",
      "model.bert.encoder.visn_fc.visn_layer_norm.weight:\tFalse\n",
      "model.bert.encoder.visn_fc.visn_layer_norm.bias:\tFalse\n",
      "model.bert.encoder.visn_fc.box_fc.weight:\tFalse\n",
      "model.bert.encoder.visn_fc.box_fc.bias:\tFalse\n",
      "model.bert.encoder.visn_fc.box_layer_norm.weight:\tFalse\n",
      "model.bert.encoder.visn_fc.box_layer_norm.bias:\tFalse\n",
      "model.bert.encoder.layer.0.attention.self.query.weight:\tFalse\n",
      "model.bert.encoder.layer.0.attention.self.query.bias:\tFalse\n",
      "model.bert.encoder.layer.0.attention.self.key.weight:\tFalse\n",
      "model.bert.encoder.layer.0.attention.self.key.bias:\tFalse\n",
      "model.bert.encoder.layer.0.attention.self.value.weight:\tFalse\n",
      "model.bert.encoder.layer.0.attention.self.value.bias:\tFalse\n",
      "model.bert.encoder.layer.0.attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.0.attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.0.attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.0.attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.0.intermediate.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.0.intermediate.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.0.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.0.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.0.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.0.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.1.attention.self.query.weight:\tFalse\n",
      "model.bert.encoder.layer.1.attention.self.query.bias:\tFalse\n",
      "model.bert.encoder.layer.1.attention.self.key.weight:\tFalse\n",
      "model.bert.encoder.layer.1.attention.self.key.bias:\tFalse\n",
      "model.bert.encoder.layer.1.attention.self.value.weight:\tFalse\n",
      "model.bert.encoder.layer.1.attention.self.value.bias:\tFalse\n",
      "model.bert.encoder.layer.1.attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.1.attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.1.attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.1.attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.1.intermediate.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.1.intermediate.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.1.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.1.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.1.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.1.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.2.attention.self.query.weight:\tFalse\n",
      "model.bert.encoder.layer.2.attention.self.query.bias:\tFalse\n",
      "model.bert.encoder.layer.2.attention.self.key.weight:\tFalse\n",
      "model.bert.encoder.layer.2.attention.self.key.bias:\tFalse\n",
      "model.bert.encoder.layer.2.attention.self.value.weight:\tFalse\n",
      "model.bert.encoder.layer.2.attention.self.value.bias:\tFalse\n",
      "model.bert.encoder.layer.2.attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.2.attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.2.attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.2.attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.2.intermediate.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.2.intermediate.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.2.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.2.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.2.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.2.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.3.attention.self.query.weight:\tFalse\n",
      "model.bert.encoder.layer.3.attention.self.query.bias:\tFalse\n",
      "model.bert.encoder.layer.3.attention.self.key.weight:\tFalse\n",
      "model.bert.encoder.layer.3.attention.self.key.bias:\tFalse\n",
      "model.bert.encoder.layer.3.attention.self.value.weight:\tFalse\n",
      "model.bert.encoder.layer.3.attention.self.value.bias:\tFalse\n",
      "model.bert.encoder.layer.3.attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.3.attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.3.attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.3.attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.3.intermediate.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.3.intermediate.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.3.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.3.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.3.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.3.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.4.attention.self.query.weight:\tFalse\n",
      "model.bert.encoder.layer.4.attention.self.query.bias:\tFalse\n",
      "model.bert.encoder.layer.4.attention.self.key.weight:\tFalse\n",
      "model.bert.encoder.layer.4.attention.self.key.bias:\tFalse\n",
      "model.bert.encoder.layer.4.attention.self.value.weight:\tFalse\n",
      "model.bert.encoder.layer.4.attention.self.value.bias:\tFalse\n",
      "model.bert.encoder.layer.4.attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.4.attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.4.attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.4.attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.4.intermediate.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.4.intermediate.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.4.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.4.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.4.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.4.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.5.attention.self.query.weight:\tFalse\n",
      "model.bert.encoder.layer.5.attention.self.query.bias:\tFalse\n",
      "model.bert.encoder.layer.5.attention.self.key.weight:\tFalse\n",
      "model.bert.encoder.layer.5.attention.self.key.bias:\tFalse\n",
      "model.bert.encoder.layer.5.attention.self.value.weight:\tFalse\n",
      "model.bert.encoder.layer.5.attention.self.value.bias:\tFalse\n",
      "model.bert.encoder.layer.5.attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.5.attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.5.attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.5.attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.5.intermediate.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.5.intermediate.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.5.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.5.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.5.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.5.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.6.attention.self.query.weight:\tFalse\n",
      "model.bert.encoder.layer.6.attention.self.query.bias:\tFalse\n",
      "model.bert.encoder.layer.6.attention.self.key.weight:\tFalse\n",
      "model.bert.encoder.layer.6.attention.self.key.bias:\tFalse\n",
      "model.bert.encoder.layer.6.attention.self.value.weight:\tFalse\n",
      "model.bert.encoder.layer.6.attention.self.value.bias:\tFalse\n",
      "model.bert.encoder.layer.6.attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.6.attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.6.attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.6.attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.6.intermediate.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.6.intermediate.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.6.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.6.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.6.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.6.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.7.attention.self.query.weight:\tFalse\n",
      "model.bert.encoder.layer.7.attention.self.query.bias:\tFalse\n",
      "model.bert.encoder.layer.7.attention.self.key.weight:\tFalse\n",
      "model.bert.encoder.layer.7.attention.self.key.bias:\tFalse\n",
      "model.bert.encoder.layer.7.attention.self.value.weight:\tFalse\n",
      "model.bert.encoder.layer.7.attention.self.value.bias:\tFalse\n",
      "model.bert.encoder.layer.7.attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.7.attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.7.attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.7.attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.7.intermediate.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.7.intermediate.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.7.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.7.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.7.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.7.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.8.attention.self.query.weight:\tFalse\n",
      "model.bert.encoder.layer.8.attention.self.query.bias:\tFalse\n",
      "model.bert.encoder.layer.8.attention.self.key.weight:\tFalse\n",
      "model.bert.encoder.layer.8.attention.self.key.bias:\tFalse\n",
      "model.bert.encoder.layer.8.attention.self.value.weight:\tFalse\n",
      "model.bert.encoder.layer.8.attention.self.value.bias:\tFalse\n",
      "model.bert.encoder.layer.8.attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.8.attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.8.attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.8.attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.layer.8.intermediate.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.8.intermediate.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.8.output.dense.weight:\tFalse\n",
      "model.bert.encoder.layer.8.output.dense.bias:\tFalse\n",
      "model.bert.encoder.layer.8.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.layer.8.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.visual_attention.att.query.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.visual_attention.att.query.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.visual_attention.att.key.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.visual_attention.att.key.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.visual_attention.att.value.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.visual_attention.att.value.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.visual_attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.visual_attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.visual_attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.visual_attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.lang_self_att.self.query.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.lang_self_att.self.query.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.lang_self_att.self.key.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.lang_self_att.self.key.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.lang_self_att.self.value.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.lang_self_att.self.value.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.lang_self_att.output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.lang_self_att.output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.lang_self_att.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.lang_self_att.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.visn_self_att.self.query.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.visn_self_att.self.query.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.visn_self_att.self.key.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.visn_self_att.self.key.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.visn_self_att.self.value.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.visn_self_att.self.value.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.visn_self_att.output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.visn_self_att.output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.visn_self_att.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.visn_self_att.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.lang_inter.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.lang_inter.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.lang_output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.lang_output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.lang_output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.lang_output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.visn_inter.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.visn_inter.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.visn_output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.visn_output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.0.visn_output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.0.visn_output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.visual_attention.att.query.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.visual_attention.att.query.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.visual_attention.att.key.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.visual_attention.att.key.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.visual_attention.att.value.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.visual_attention.att.value.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.visual_attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.visual_attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.visual_attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.visual_attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.lang_self_att.self.query.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.lang_self_att.self.query.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.lang_self_att.self.key.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.lang_self_att.self.key.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.lang_self_att.self.value.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.lang_self_att.self.value.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.lang_self_att.output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.lang_self_att.output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.lang_self_att.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.lang_self_att.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.visn_self_att.self.query.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.visn_self_att.self.query.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.visn_self_att.self.key.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.visn_self_att.self.key.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.visn_self_att.self.value.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.visn_self_att.self.value.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.visn_self_att.output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.visn_self_att.output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.visn_self_att.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.visn_self_att.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.lang_inter.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.lang_inter.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.lang_output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.lang_output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.lang_output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.lang_output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.visn_inter.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.visn_inter.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.visn_output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.visn_output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.1.visn_output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.1.visn_output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.visual_attention.att.query.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.visual_attention.att.query.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.visual_attention.att.key.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.visual_attention.att.key.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.visual_attention.att.value.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.visual_attention.att.value.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.visual_attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.visual_attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.visual_attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.visual_attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.lang_self_att.self.query.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.lang_self_att.self.query.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.lang_self_att.self.key.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.lang_self_att.self.key.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.lang_self_att.self.value.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.lang_self_att.self.value.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.lang_self_att.output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.lang_self_att.output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.lang_self_att.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.lang_self_att.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.visn_self_att.self.query.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.visn_self_att.self.query.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.visn_self_att.self.key.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.visn_self_att.self.key.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.visn_self_att.self.value.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.visn_self_att.self.value.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.visn_self_att.output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.visn_self_att.output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.visn_self_att.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.visn_self_att.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.lang_inter.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.lang_inter.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.lang_output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.lang_output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.lang_output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.lang_output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.visn_inter.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.visn_inter.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.visn_output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.visn_output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.2.visn_output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.2.visn_output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.visual_attention.att.query.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.visual_attention.att.query.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.visual_attention.att.key.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.visual_attention.att.key.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.visual_attention.att.value.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.visual_attention.att.value.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.visual_attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.visual_attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.visual_attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.visual_attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.lang_self_att.self.query.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.lang_self_att.self.query.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.lang_self_att.self.key.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.lang_self_att.self.key.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.lang_self_att.self.value.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.lang_self_att.self.value.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.lang_self_att.output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.lang_self_att.output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.lang_self_att.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.lang_self_att.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.visn_self_att.self.query.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.visn_self_att.self.query.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.visn_self_att.self.key.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.visn_self_att.self.key.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.visn_self_att.self.value.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.visn_self_att.self.value.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.visn_self_att.output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.visn_self_att.output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.visn_self_att.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.visn_self_att.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.lang_inter.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.lang_inter.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.lang_output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.lang_output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.lang_output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.lang_output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.visn_inter.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.visn_inter.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.visn_output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.visn_output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.3.visn_output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.3.visn_output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.visual_attention.att.query.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.visual_attention.att.query.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.visual_attention.att.key.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.visual_attention.att.key.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.visual_attention.att.value.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.visual_attention.att.value.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.visual_attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.visual_attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.visual_attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.visual_attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.lang_self_att.self.query.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.lang_self_att.self.query.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.lang_self_att.self.key.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.lang_self_att.self.key.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.lang_self_att.self.value.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.lang_self_att.self.value.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.lang_self_att.output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.lang_self_att.output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.lang_self_att.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.lang_self_att.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.visn_self_att.self.query.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.visn_self_att.self.query.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.visn_self_att.self.key.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.visn_self_att.self.key.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.visn_self_att.self.value.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.visn_self_att.self.value.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.visn_self_att.output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.visn_self_att.output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.visn_self_att.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.visn_self_att.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.lang_inter.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.lang_inter.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.lang_output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.lang_output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.lang_output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.lang_output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.visn_inter.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.visn_inter.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.visn_output.dense.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.visn_output.dense.bias:\tFalse\n",
      "model.bert.encoder.x_layers.4.visn_output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.x_layers.4.visn_output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.r_layers.0.attention.self.query.weight:\tFalse\n",
      "model.bert.encoder.r_layers.0.attention.self.query.bias:\tFalse\n",
      "model.bert.encoder.r_layers.0.attention.self.key.weight:\tFalse\n",
      "model.bert.encoder.r_layers.0.attention.self.key.bias:\tFalse\n",
      "model.bert.encoder.r_layers.0.attention.self.value.weight:\tFalse\n",
      "model.bert.encoder.r_layers.0.attention.self.value.bias:\tFalse\n",
      "model.bert.encoder.r_layers.0.attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.r_layers.0.attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.r_layers.0.attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.r_layers.0.attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.r_layers.0.intermediate.dense.weight:\tFalse\n",
      "model.bert.encoder.r_layers.0.intermediate.dense.bias:\tFalse\n",
      "model.bert.encoder.r_layers.0.output.dense.weight:\tFalse\n",
      "model.bert.encoder.r_layers.0.output.dense.bias:\tFalse\n",
      "model.bert.encoder.r_layers.0.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.r_layers.0.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.r_layers.1.attention.self.query.weight:\tFalse\n",
      "model.bert.encoder.r_layers.1.attention.self.query.bias:\tFalse\n",
      "model.bert.encoder.r_layers.1.attention.self.key.weight:\tFalse\n",
      "model.bert.encoder.r_layers.1.attention.self.key.bias:\tFalse\n",
      "model.bert.encoder.r_layers.1.attention.self.value.weight:\tFalse\n",
      "model.bert.encoder.r_layers.1.attention.self.value.bias:\tFalse\n",
      "model.bert.encoder.r_layers.1.attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.r_layers.1.attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.r_layers.1.attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.r_layers.1.attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.r_layers.1.intermediate.dense.weight:\tFalse\n",
      "model.bert.encoder.r_layers.1.intermediate.dense.bias:\tFalse\n",
      "model.bert.encoder.r_layers.1.output.dense.weight:\tFalse\n",
      "model.bert.encoder.r_layers.1.output.dense.bias:\tFalse\n",
      "model.bert.encoder.r_layers.1.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.r_layers.1.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.r_layers.2.attention.self.query.weight:\tFalse\n",
      "model.bert.encoder.r_layers.2.attention.self.query.bias:\tFalse\n",
      "model.bert.encoder.r_layers.2.attention.self.key.weight:\tFalse\n",
      "model.bert.encoder.r_layers.2.attention.self.key.bias:\tFalse\n",
      "model.bert.encoder.r_layers.2.attention.self.value.weight:\tFalse\n",
      "model.bert.encoder.r_layers.2.attention.self.value.bias:\tFalse\n",
      "model.bert.encoder.r_layers.2.attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.r_layers.2.attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.r_layers.2.attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.r_layers.2.attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.r_layers.2.intermediate.dense.weight:\tFalse\n",
      "model.bert.encoder.r_layers.2.intermediate.dense.bias:\tFalse\n",
      "model.bert.encoder.r_layers.2.output.dense.weight:\tFalse\n",
      "model.bert.encoder.r_layers.2.output.dense.bias:\tFalse\n",
      "model.bert.encoder.r_layers.2.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.r_layers.2.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.r_layers.3.attention.self.query.weight:\tFalse\n",
      "model.bert.encoder.r_layers.3.attention.self.query.bias:\tFalse\n",
      "model.bert.encoder.r_layers.3.attention.self.key.weight:\tFalse\n",
      "model.bert.encoder.r_layers.3.attention.self.key.bias:\tFalse\n",
      "model.bert.encoder.r_layers.3.attention.self.value.weight:\tFalse\n",
      "model.bert.encoder.r_layers.3.attention.self.value.bias:\tFalse\n",
      "model.bert.encoder.r_layers.3.attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.r_layers.3.attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.r_layers.3.attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.r_layers.3.attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.r_layers.3.intermediate.dense.weight:\tFalse\n",
      "model.bert.encoder.r_layers.3.intermediate.dense.bias:\tFalse\n",
      "model.bert.encoder.r_layers.3.output.dense.weight:\tFalse\n",
      "model.bert.encoder.r_layers.3.output.dense.bias:\tFalse\n",
      "model.bert.encoder.r_layers.3.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.r_layers.3.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.r_layers.4.attention.self.query.weight:\tFalse\n",
      "model.bert.encoder.r_layers.4.attention.self.query.bias:\tFalse\n",
      "model.bert.encoder.r_layers.4.attention.self.key.weight:\tFalse\n",
      "model.bert.encoder.r_layers.4.attention.self.key.bias:\tFalse\n",
      "model.bert.encoder.r_layers.4.attention.self.value.weight:\tFalse\n",
      "model.bert.encoder.r_layers.4.attention.self.value.bias:\tFalse\n",
      "model.bert.encoder.r_layers.4.attention.output.dense.weight:\tFalse\n",
      "model.bert.encoder.r_layers.4.attention.output.dense.bias:\tFalse\n",
      "model.bert.encoder.r_layers.4.attention.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.r_layers.4.attention.output.LayerNorm.bias:\tFalse\n",
      "model.bert.encoder.r_layers.4.intermediate.dense.weight:\tFalse\n",
      "model.bert.encoder.r_layers.4.intermediate.dense.bias:\tFalse\n",
      "model.bert.encoder.r_layers.4.output.dense.weight:\tFalse\n",
      "model.bert.encoder.r_layers.4.output.dense.bias:\tFalse\n",
      "model.bert.encoder.r_layers.4.output.LayerNorm.weight:\tFalse\n",
      "model.bert.encoder.r_layers.4.output.LayerNorm.bias:\tFalse\n",
      "model.bert.pooler.dense.weight:\tFalse\n",
      "model.bert.pooler.dense.bias:\tFalse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fusion_model:\r\n",
      "LXMERT(\r\n",
      "  (lxrt_encoder): LXRTEncoder(\r\n",
      "    (model): LXRTFeatureExtraction(\r\n",
      "      (bert): LXRTModel(\r\n",
      "        (embeddings): BertEmbeddings(\r\n",
      "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\r\n",
      "          (position_embeddings): Embedding(512, 768, padding_idx=0)\r\n",
      "          (token_type_embeddings): Embedding(2, 768, padding_idx=0)\r\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "        )\r\n",
      "        (encoder): LXRTEncoder(\r\n",
      "          (visn_fc): VisualFeatEncoder(\r\n",
      "            (visn_fc): Linear(in_features=2048, out_features=768, bias=True)\r\n",
      "            (visn_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "            (box_fc): Linear(in_features=4, out_features=768, bias=True)\r\n",
      "            (box_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "          (layer): ModuleList(\r\n",
      "            (0): BertLayer(\r\n",
      "              (attention): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (intermediate): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (1): BertLayer(\r\n",
      "              (attention): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (intermediate): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (2): BertLayer(\r\n",
      "              (attention): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (intermediate): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (3): BertLayer(\r\n",
      "              (attention): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (intermediate): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (4): BertLayer(\r\n",
      "              (attention): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (intermediate): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (5): BertLayer(\r\n",
      "              (attention): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (intermediate): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (6): BertLayer(\r\n",
      "              (attention): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (intermediate): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (7): BertLayer(\r\n",
      "              (attention): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (intermediate): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (8): BertLayer(\r\n",
      "              (attention): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (intermediate): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (x_layers): ModuleList(\r\n",
      "            (0): LXRTXLayer(\r\n",
      "              (visual_attention): BertCrossattLayer(\r\n",
      "                (att): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (lang_self_att): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (visn_self_att): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (lang_inter): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (lang_output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "              (visn_inter): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (visn_output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (1): LXRTXLayer(\r\n",
      "              (visual_attention): BertCrossattLayer(\r\n",
      "                (att): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (lang_self_att): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (visn_self_att): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (lang_inter): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (lang_output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "              (visn_inter): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (visn_output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (2): LXRTXLayer(\r\n",
      "              (visual_attention): BertCrossattLayer(\r\n",
      "                (att): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (lang_self_att): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (visn_self_att): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (lang_inter): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (lang_output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "              (visn_inter): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (visn_output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (3): LXRTXLayer(\r\n",
      "              (visual_attention): BertCrossattLayer(\r\n",
      "                (att): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (lang_self_att): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (visn_self_att): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (lang_inter): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (lang_output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "              (visn_inter): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (visn_output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (4): LXRTXLayer(\r\n",
      "              (visual_attention): BertCrossattLayer(\r\n",
      "                (att): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (lang_self_att): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (visn_self_att): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (lang_inter): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (lang_output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "              (visn_inter): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (visn_output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (r_layers): ModuleList(\r\n",
      "            (0): BertLayer(\r\n",
      "              (attention): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (intermediate): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (1): BertLayer(\r\n",
      "              (attention): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (intermediate): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (2): BertLayer(\r\n",
      "              (attention): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (intermediate): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (3): BertLayer(\r\n",
      "              (attention): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (intermediate): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (4): BertLayer(\r\n",
      "              (attention): BertSelfattLayer(\r\n",
      "                (self): BertAttention(\r\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "                (output): BertAttOutput(\r\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "                )\r\n",
      "              )\r\n",
      "              (intermediate): BertIntermediate(\r\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "              )\r\n",
      "              (output): BertOutput(\r\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\r\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (pooler): BertPooler(\r\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "          (activation): Tanh()\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (lstm): LSTM(768, 768, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\r\n",
      "  (dropout_r): Dropout(p=0.1, inplace=False)\r\n",
      "  (fc_rnn): Linear(in_features=1536, out_features=1024, bias=True)\r\n",
      "  (convs): ModuleList(\r\n",
      "    (0): Conv2d(1, 256, kernel_size=(2, 768), stride=(1, 1))\r\n",
      "    (1): Conv2d(1, 256, kernel_size=(3, 768), stride=(1, 1))\r\n",
      "    (2): Conv2d(1, 256, kernel_size=(4, 768), stride=(1, 1))\r\n",
      "  )\r\n",
      "  (dropout_c): Dropout(p=0.1, inplace=False)\r\n",
      "  (fc_cnn): Linear(in_features=768, out_features=1024, bias=True)\r\n",
      "  (fc): Linear(in_features=2048, out_features=1024, bias=True)\r\n",
      ")\r\n",
      "Answer Model:\r\n",
      "MLP(\r\n",
      "  (mlp): GroupMLP(\r\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\r\n",
      "    (drop): Dropout(p=0.0, inplace=False)\r\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\r\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\r\n",
      "  )\r\n",
      ")\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E000: 100% 86/86 [00:26<00:00,  3.28it/s]\n",
      "INFO - 07/19/22 20:21:56 - 0:02:32 - Train Epoch 0: LOSS= 3.74740, lr= 0.000500, acc1= 33.92,acc3= 48.03,acc10= 63.08\n",
      "train E001: 100% 86/86 [00:27<00:00,  3.16it/s]\n",
      "INFO - 07/19/22 20:22:24 - 0:02:59 - Train Epoch 1: LOSS= 2.09768, lr= 0.000750, acc1= 51.75,acc3= 71.02,acc10= 85.34\n",
      "eval E001: 100% 87/87 [00:22<00:00,  3.90it/s]\n",
      "INFO - 07/19/22 20:22:46 - 0:03:21 - #################################################################################################################\n",
      "INFO - 07/19/22 20:22:46 - 0:03:21 - Test Epoch 1: LOSS= 3.20884, acc1= 36.90, acc3= 54.72, acc10= 71.70\n",
      "INFO - 07/19/22 20:22:46 - 0:03:21 - #################################################################################################################\n",
      "train E002: 100% 86/86 [00:24<00:00,  3.49it/s]\n",
      "INFO - 07/19/22 20:23:11 - 0:03:46 - Train Epoch 2: LOSS= 1.96876, lr= 0.001000, acc1= 53.98,acc3= 73.54,acc10= 88.05\n",
      "eval E002: 100% 87/87 [00:21<00:00,  3.96it/s]\n",
      "INFO - 07/19/22 20:23:33 - 0:04:08 - #################################################################################################################\n",
      "INFO - 07/19/22 20:23:33 - 0:04:08 - Test Epoch 2: LOSS= 3.58038, acc1= 33.24, acc3= 52.47, acc10= 69.16\n",
      "INFO - 07/19/22 20:23:33 - 0:04:08 - #################################################################################################################\n",
      "train E003: 100% 86/86 [00:23<00:00,  3.59it/s]\n",
      "INFO - 07/19/22 20:23:57 - 0:04:32 - Train Epoch 3: LOSS= 1.89860, lr= 0.001250, acc1= 55.81,acc3= 75.51,acc10= 88.96\n",
      "eval E003: 100% 87/87 [00:20<00:00,  4.24it/s]\n",
      "INFO - 07/19/22 20:24:17 - 0:04:53 - #################################################################################################################\n",
      "INFO - 07/19/22 20:24:17 - 0:04:53 - Test Epoch 3: LOSS= 3.63555, acc1= 34.03, acc3= 51.09, acc10= 69.96\n",
      "INFO - 07/19/22 20:24:17 - 0:04:53 - #################################################################################################################\n",
      "train E004: 100% 86/86 [00:24<00:00,  3.49it/s]\n",
      "INFO - 07/19/22 20:24:42 - 0:05:18 - Train Epoch 4: LOSS= 1.88419, lr= 0.001500, acc1= 55.34,acc3= 75.44,acc10= 89.80\n",
      "eval E004: 100% 87/87 [00:23<00:00,  3.73it/s]\n",
      "INFO - 07/19/22 20:25:05 - 0:05:41 - #################################################################################################################\n",
      "INFO - 07/19/22 20:25:05 - 0:05:41 - Test Epoch 4: LOSS= 3.41783, acc1= 36.03, acc3= 54.10, acc10= 71.88\n",
      "INFO - 07/19/22 20:25:05 - 0:05:41 - #################################################################################################################\n",
      "train E005: 100% 86/86 [00:24<00:00,  3.47it/s]\n",
      "INFO - 07/19/22 20:25:30 - 0:06:06 - Train Epoch 5: LOSS= 1.83275, lr= 0.001750, acc1= 57.13,acc3= 76.13,acc10= 89.55\n",
      "eval E005: 100% 87/87 [00:22<00:00,  3.79it/s]\n",
      "INFO - 07/19/22 20:25:53 - 0:06:29 - #################################################################################################################\n",
      "INFO - 07/19/22 20:25:53 - 0:06:29 - Test Epoch 5: LOSS= 3.38171, acc1= 35.34, acc3= 53.63, acc10= 71.15\n",
      "INFO - 07/19/22 20:25:53 - 0:06:29 - #################################################################################################################\n",
      "train E006: 100% 86/86 [00:25<00:00,  3.32it/s]\n",
      "INFO - 07/19/22 20:26:19 - 0:06:55 - Train Epoch 6: LOSS= 1.78015, lr= 0.002000, acc1= 57.79,acc3= 78.14,acc10= 89.69\n",
      "eval E006: 100% 87/87 [00:21<00:00,  4.03it/s]\n",
      "INFO - 07/19/22 20:26:41 - 0:07:16 - #################################################################################################################\n",
      "INFO - 07/19/22 20:26:41 - 0:07:16 - Test Epoch 6: LOSS= 3.40789, acc1= 38.72, acc3= 54.79, acc10= 71.63\n",
      "INFO - 07/19/22 20:26:41 - 0:07:16 - #################################################################################################################\n",
      "train E007: 100% 86/86 [00:23<00:00,  3.69it/s]\n",
      "INFO - 07/19/22 20:27:04 - 0:07:40 - Train Epoch 7: LOSS= 1.59358, lr= 0.002000, acc1= 61.99,acc3= 80.37,acc10= 92.11\n",
      "eval E007: 100% 87/87 [00:21<00:00,  4.05it/s]\n",
      "INFO - 07/19/22 20:27:26 - 0:08:01 - #################################################################################################################\n",
      "INFO - 07/19/22 20:27:26 - 0:08:01 - Test Epoch 7: LOSS= 3.67861, acc1= 36.83, acc3= 55.52, acc10= 73.15\n",
      "INFO - 07/19/22 20:27:26 - 0:08:01 - #################################################################################################################\n",
      "train E008: 100% 86/86 [00:23<00:00,  3.62it/s]\n",
      "INFO - 07/19/22 20:27:50 - 0:08:25 - Train Epoch 8: LOSS= 1.49551, lr= 0.002000, acc1= 63.89,acc3= 82.20,acc10= 93.31\n",
      "eval E008: 100% 87/87 [00:20<00:00,  4.15it/s]\n",
      "INFO - 07/19/22 20:28:11 - 0:08:46 - #################################################################################################################\n",
      "INFO - 07/19/22 20:28:11 - 0:08:46 - Test Epoch 8: LOSS= 3.76029, acc1= 38.82, acc3= 57.11, acc10= 72.39\n",
      "INFO - 07/19/22 20:28:11 - 0:08:46 - #################################################################################################################\n",
      "train E009: 100% 86/86 [00:23<00:00,  3.70it/s]\n",
      "INFO - 07/19/22 20:28:34 - 0:09:10 - Train Epoch 9: LOSS= 1.38448, lr= 0.002000, acc1= 66.08,acc3= 84.21,acc10= 94.33\n",
      "eval E009: 100% 87/87 [00:21<00:00,  4.02it/s]\n",
      "INFO - 07/19/22 20:28:56 - 0:09:32 - #################################################################################################################\n",
      "INFO - 07/19/22 20:28:56 - 0:09:32 - Test Epoch 9: LOSS= 3.42908, acc1= 41.84, acc3= 59.54, acc10= 75.29\n",
      "INFO - 07/19/22 20:28:56 - 0:09:32 - #################################################################################################################\n",
      "train E010: 100% 86/86 [00:23<00:00,  3.62it/s]\n",
      "INFO - 07/19/22 20:29:20 - 0:09:56 - Train Epoch 10: LOSS= 1.29377, lr= 0.002000, acc1= 68.31,acc3= 85.89,acc10= 94.92\n",
      "eval E010: 100% 87/87 [00:20<00:00,  4.17it/s]\n",
      "INFO - 07/19/22 20:29:41 - 0:10:17 - #################################################################################################################\n",
      "INFO - 07/19/22 20:29:41 - 0:10:17 - Test Epoch 10: LOSS= 3.64304, acc1= 40.97, acc3= 58.16, acc10= 73.33\n",
      "INFO - 07/19/22 20:29:41 - 0:10:17 - #################################################################################################################\n",
      "train E011: 100% 86/86 [00:24<00:00,  3.53it/s]\n",
      "INFO - 07/19/22 20:30:05 - 0:10:41 - Train Epoch 11: LOSS= 1.11177, lr= 0.002000, acc1= 72.15,acc3= 88.23,acc10= 96.05\n",
      "eval E011: 100% 87/87 [00:23<00:00,  3.66it/s]\n",
      "INFO - 07/19/22 20:30:29 - 0:11:05 - #################################################################################################################\n",
      "INFO - 07/19/22 20:30:29 - 0:11:05 - Test Epoch 11: LOSS= 3.60657, acc1= 41.29, acc3= 57.04, acc10= 72.10\n",
      "INFO - 07/19/22 20:30:29 - 0:11:05 - #################################################################################################################\n",
      "train E012: 100% 86/86 [00:24<00:00,  3.57it/s]\n",
      "INFO - 07/19/22 20:30:53 - 0:11:29 - Train Epoch 12: LOSS= 1.03211, lr= 0.002000, acc1= 73.83,acc3= 89.88,acc10= 96.71\n",
      "eval E012: 100% 87/87 [00:20<00:00,  4.20it/s]\n",
      "INFO - 07/19/22 20:31:14 - 0:11:50 - #################################################################################################################\n",
      "INFO - 07/19/22 20:31:14 - 0:11:50 - Test Epoch 12: LOSS= 3.74688, acc1= 41.15, acc3= 58.35, acc10= 72.79\n",
      "INFO - 07/19/22 20:31:14 - 0:11:50 - #################################################################################################################\n",
      "train E013: 100% 86/86 [00:23<00:00,  3.72it/s]\n",
      "INFO - 07/19/22 20:31:37 - 0:12:13 - Train Epoch 13: LOSS= 0.90980, lr= 0.002000, acc1= 76.68,acc3= 91.63,acc10= 97.62\n",
      "eval E013: 100% 87/87 [00:21<00:00,  4.14it/s]\n",
      "INFO - 07/19/22 20:31:58 - 0:12:34 - #################################################################################################################\n",
      "INFO - 07/19/22 20:31:58 - 0:12:34 - Test Epoch 13: LOSS= 4.20318, acc1= 40.24, acc3= 56.97, acc10= 73.11\n",
      "INFO - 07/19/22 20:31:58 - 0:12:34 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E014: 100% 86/86 [00:21<00:00,  3.94it/s]\n",
      "INFO - 07/19/22 20:32:20 - 0:12:56 - Train Epoch 14: LOSS= 0.64722, lr= 0.001400, acc1= 82.60,acc3= 95.25,acc10= 98.83\n",
      "eval E014: 100% 87/87 [00:20<00:00,  4.19it/s]\n",
      "INFO - 07/19/22 20:32:41 - 0:13:16 - #################################################################################################################\n",
      "INFO - 07/19/22 20:32:41 - 0:13:16 - Test Epoch 14: LOSS= 3.71427, acc1= 43.65, acc3= 60.74, acc10= 77.07\n",
      "INFO - 07/19/22 20:32:41 - 0:13:16 - #################################################################################################################\n",
      "train E015: 100% 86/86 [00:23<00:00,  3.68it/s]\n",
      "INFO - 07/19/22 20:33:05 - 0:13:40 - Train Epoch 15: LOSS= 0.54868, lr= 0.001400, acc1= 84.98,acc3= 96.13,acc10= 99.05\n",
      "eval E015: 100% 87/87 [00:21<00:00,  3.99it/s]\n",
      "INFO - 07/19/22 20:33:26 - 0:14:02 - #################################################################################################################\n",
      "INFO - 07/19/22 20:33:26 - 0:14:02 - Test Epoch 15: LOSS= 4.08584, acc1= 44.19, acc3= 60.12, acc10= 74.71\n",
      "INFO - 07/19/22 20:33:26 - 0:14:02 - #################################################################################################################\n",
      "train E016: 100% 86/86 [00:24<00:00,  3.56it/s]\n",
      "INFO - 07/19/22 20:33:51 - 0:14:26 - Train Epoch 16: LOSS= 0.55311, lr= 0.001400, acc1= 84.80,acc3= 96.49,acc10= 99.12\n",
      "eval E016: 100% 87/87 [00:25<00:00,  3.48it/s]\n",
      "INFO - 07/19/22 20:34:16 - 0:14:51 - #################################################################################################################\n",
      "INFO - 07/19/22 20:34:16 - 0:14:51 - Test Epoch 16: LOSS= 4.28310, acc1= 42.42, acc3= 60.05, acc10= 77.00\n",
      "INFO - 07/19/22 20:34:16 - 0:14:51 - #################################################################################################################\n",
      "train E017: 100% 86/86 [00:25<00:00,  3.31it/s]\n",
      "INFO - 07/19/22 20:34:42 - 0:15:17 - Train Epoch 17: LOSS= 0.38617, lr= 0.000980, acc1= 89.22,acc3= 98.06,acc10= 99.49\n",
      "eval E017: 100% 87/87 [00:23<00:00,  3.68it/s]\n",
      "INFO - 07/19/22 20:35:05 - 0:15:41 - #################################################################################################################\n",
      "INFO - 07/19/22 20:35:05 - 0:15:41 - Test Epoch 17: LOSS= 4.25915, acc1= 45.50, acc3= 62.37, acc10= 77.29\n",
      "INFO - 07/19/22 20:35:05 - 0:15:41 - #################################################################################################################\n",
      "train E018: 100% 86/86 [00:23<00:00,  3.68it/s]\n",
      "INFO - 07/19/22 20:35:29 - 0:16:04 - Train Epoch 18: LOSS= 0.27352, lr= 0.000980, acc1= 91.92,acc3= 98.50,acc10= 99.82\n",
      "eval E018: 100% 87/87 [00:21<00:00,  4.10it/s]\n",
      "INFO - 07/19/22 20:35:50 - 0:16:26 - #################################################################################################################\n",
      "INFO - 07/19/22 20:35:50 - 0:16:26 - Test Epoch 18: LOSS= 4.21500, acc1= 45.72, acc3= 62.63, acc10= 77.21\n",
      "INFO - 07/19/22 20:35:50 - 0:16:26 - #################################################################################################################\n",
      "train E019: 100% 86/86 [00:23<00:00,  3.72it/s]\n",
      "INFO - 07/19/22 20:36:14 - 0:16:49 - Train Epoch 19: LOSS= 0.22065, lr= 0.000980, acc1= 93.20,acc3= 98.94,acc10= 99.89\n",
      "eval E019: 100% 87/87 [00:19<00:00,  4.51it/s]\n",
      "INFO - 07/19/22 20:36:33 - 0:17:08 - #################################################################################################################\n",
      "INFO - 07/19/22 20:36:33 - 0:17:08 - Test Epoch 19: LOSS= 4.28312, acc1= 44.34, acc3= 61.50, acc10= 77.14\n",
      "INFO - 07/19/22 20:36:33 - 0:17:08 - #################################################################################################################\n",
      "train E020: 100% 86/86 [00:22<00:00,  3.79it/s]\n",
      "INFO - 07/19/22 20:36:56 - 0:17:31 - Train Epoch 20: LOSS= 0.18955, lr= 0.000686, acc1= 94.12,acc3= 99.23,acc10= 100.00\n",
      "eval E020: 100% 87/87 [00:21<00:00,  4.01it/s]\n",
      "INFO - 07/19/22 20:37:17 - 0:17:53 - #################################################################################################################\n",
      "INFO - 07/19/22 20:37:17 - 0:17:53 - Test Epoch 20: LOSS= 4.71478, acc1= 45.65, acc3= 63.43, acc10= 77.25\n",
      "INFO - 07/19/22 20:37:17 - 0:17:53 - #################################################################################################################\n",
      "train E021: 100% 86/86 [00:22<00:00,  3.74it/s]\n",
      "INFO - 07/19/22 20:37:41 - 0:18:16 - Train Epoch 21: LOSS= 0.14671, lr= 0.000686, acc1= 95.43,acc3= 99.67,acc10= 99.96\n",
      "eval E021: 100% 87/87 [00:22<00:00,  3.86it/s]\n",
      "INFO - 07/19/22 20:38:03 - 0:18:39 - #################################################################################################################\n",
      "INFO - 07/19/22 20:38:03 - 0:18:39 - Test Epoch 21: LOSS= 4.59458, acc1= 45.36, acc3= 62.84, acc10= 77.87\n",
      "INFO - 07/19/22 20:38:03 - 0:18:39 - #################################################################################################################\n",
      "train E022: 100% 86/86 [00:24<00:00,  3.45it/s]\n",
      "INFO - 07/19/22 20:38:28 - 0:19:04 - Train Epoch 22: LOSS= 0.12131, lr= 0.000686, acc1= 96.27,acc3= 99.52,acc10= 100.00\n",
      "eval E022: 100% 87/87 [00:23<00:00,  3.71it/s]\n",
      "INFO - 07/19/22 20:38:52 - 0:19:27 - #################################################################################################################\n",
      "INFO - 07/19/22 20:38:52 - 0:19:27 - Test Epoch 22: LOSS= 4.55896, acc1= 45.79, acc3= 62.19, acc10= 77.10\n",
      "INFO - 07/19/22 20:38:52 - 0:19:27 - #################################################################################################################\n",
      "train E023: 100% 86/86 [00:25<00:00,  3.42it/s]\n",
      "INFO - 07/19/22 20:39:17 - 0:19:52 - Train Epoch 23: LOSS= 0.10473, lr= 0.000480, acc1= 96.67,acc3= 99.67,acc10= 99.96\n",
      "eval E023: 100% 87/87 [00:21<00:00,  4.01it/s]\n",
      "INFO - 07/19/22 20:39:38 - 0:20:14 - #################################################################################################################\n",
      "INFO - 07/19/22 20:39:38 - 0:20:14 - Test Epoch 23: LOSS= 4.74704, acc1= 46.04, acc3= 63.17, acc10= 77.76\n",
      "INFO - 07/19/22 20:39:38 - 0:20:14 - #################################################################################################################\n",
      "train E024: 100% 86/86 [00:23<00:00,  3.70it/s]\n",
      "INFO - 07/19/22 20:40:02 - 0:20:38 - Train Epoch 24: LOSS= 0.10237, lr= 0.000480, acc1= 96.53,acc3= 99.82,acc10= 99.96\n",
      "eval E024: 100% 87/87 [00:21<00:00,  4.12it/s]\n",
      "INFO - 07/19/22 20:40:23 - 0:20:59 - #################################################################################################################\n",
      "INFO - 07/19/22 20:40:23 - 0:20:59 - Test Epoch 24: LOSS= 4.85438, acc1= 45.54, acc3= 62.23, acc10= 77.07\n",
      "INFO - 07/19/22 20:40:23 - 0:20:59 - #################################################################################################################\n",
      "train E025: 100% 86/86 [00:22<00:00,  3.81it/s]\n",
      "INFO - 07/19/22 20:40:46 - 0:21:21 - Train Epoch 25: LOSS= 0.08432, lr= 0.000480, acc1= 97.55,acc3= 99.82,acc10= 100.00\n",
      "eval E025: 100% 87/87 [00:21<00:00,  4.05it/s]\n",
      "INFO - 07/19/22 20:41:07 - 0:21:43 - #################################################################################################################\n",
      "INFO - 07/19/22 20:41:07 - 0:21:43 - Test Epoch 25: LOSS= 4.95376, acc1= 45.32, acc3= 62.81, acc10= 76.92\n",
      "INFO - 07/19/22 20:41:07 - 0:21:43 - #################################################################################################################\n",
      "train E026: 100% 86/86 [00:23<00:00,  3.60it/s]\n",
      "INFO - 07/19/22 20:41:31 - 0:22:07 - Train Epoch 26: LOSS= 0.08126, lr= 0.000336, acc1= 97.48,acc3= 99.74,acc10= 99.96\n",
      "eval E026: 100% 87/87 [00:20<00:00,  4.20it/s]\n",
      "INFO - 07/19/22 20:41:52 - 0:22:27 - #################################################################################################################\n",
      "INFO - 07/19/22 20:41:52 - 0:22:27 - Test Epoch 26: LOSS= 4.99085, acc1= 46.08, acc3= 63.50, acc10= 77.50\n",
      "INFO - 07/19/22 20:41:52 - 0:22:27 - #################################################################################################################\n",
      "train E027: 100% 86/86 [00:24<00:00,  3.47it/s]\n",
      "INFO - 07/19/22 20:42:17 - 0:22:52 - Train Epoch 27: LOSS= 0.06858, lr= 0.000336, acc1= 97.95,acc3= 99.82,acc10= 99.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E027: 100% 87/87 [00:24<00:00,  3.60it/s]\n",
      "INFO - 07/19/22 20:42:41 - 0:23:16 - #################################################################################################################\n",
      "INFO - 07/19/22 20:42:41 - 0:23:16 - Test Epoch 27: LOSS= 4.90335, acc1= 46.81, acc3= 63.86, acc10= 77.98\n",
      "INFO - 07/19/22 20:42:41 - 0:23:16 - #################################################################################################################\n",
      "train E028: 100% 86/86 [00:23<00:00,  3.70it/s]\n",
      "INFO - 07/19/22 20:43:05 - 0:23:40 - Train Epoch 28: LOSS= 0.04868, lr= 0.000336, acc1= 98.32,acc3= 99.96,acc10= 100.00\n",
      "eval E028: 100% 87/87 [00:20<00:00,  4.20it/s]\n",
      "INFO - 07/19/22 20:43:25 - 0:24:01 - #################################################################################################################\n",
      "INFO - 07/19/22 20:43:25 - 0:24:01 - Test Epoch 28: LOSS= 5.19341, acc1= 46.34, acc3= 63.43, acc10= 77.58\n",
      "INFO - 07/19/22 20:43:25 - 0:24:01 - #################################################################################################################\n",
      "train E029: 100% 86/86 [00:23<00:00,  3.69it/s]\n",
      "INFO - 07/19/22 20:43:49 - 0:24:24 - Train Epoch 29: LOSS= 0.06072, lr= 0.000235, acc1= 97.88,acc3= 99.96,acc10= 100.00\n",
      "eval E029: 100% 87/87 [00:21<00:00,  4.13it/s]\n",
      "INFO - 07/19/22 20:44:10 - 0:24:45 - #################################################################################################################\n",
      "INFO - 07/19/22 20:44:10 - 0:24:45 - Test Epoch 29: LOSS= 5.16220, acc1= 45.54, acc3= 62.88, acc10= 76.81\n",
      "INFO - 07/19/22 20:44:10 - 0:24:45 - #################################################################################################################\n",
      "train E030: 100% 86/86 [00:23<00:00,  3.67it/s]\n",
      "INFO - 07/19/22 20:44:33 - 0:25:09 - Train Epoch 30: LOSS= 0.05538, lr= 0.000235, acc1= 98.21,acc3= 99.82,acc10= 99.96\n",
      "eval E030: 100% 87/87 [00:21<00:00,  4.10it/s]\n",
      "INFO - 07/19/22 20:44:54 - 0:25:30 - #################################################################################################################\n",
      "INFO - 07/19/22 20:44:54 - 0:25:30 - Test Epoch 30: LOSS= 5.20415, acc1= 46.15, acc3= 62.77, acc10= 77.36\n",
      "INFO - 07/19/22 20:44:54 - 0:25:30 - #################################################################################################################\n",
      "train E031: 100% 86/86 [00:23<00:00,  3.63it/s]\n",
      "INFO - 07/19/22 20:45:18 - 0:25:54 - Train Epoch 31: LOSS= 0.04259, lr= 0.000235, acc1= 98.65,acc3= 99.89,acc10= 100.00\n",
      "eval E031: 100% 87/87 [00:20<00:00,  4.15it/s]\n",
      "INFO - 07/19/22 20:45:39 - 0:26:15 - #################################################################################################################\n",
      "INFO - 07/19/22 20:45:39 - 0:26:15 - Test Epoch 31: LOSS= 5.52309, acc1= 45.72, acc3= 62.81, acc10= 76.92\n",
      "INFO - 07/19/22 20:45:39 - 0:26:15 - #################################################################################################################\n",
      "train E032: 100% 86/86 [00:24<00:00,  3.55it/s]\n",
      "INFO - 07/19/22 20:46:03 - 0:26:39 - Train Epoch 32: LOSS= 0.03491, lr= 0.000165, acc1= 98.57,acc3= 99.96,acc10= 100.00\n",
      "eval E032: 100% 87/87 [00:21<00:00,  4.05it/s]\n",
      "INFO - 07/19/22 20:46:25 - 0:27:00 - #################################################################################################################\n",
      "INFO - 07/19/22 20:46:25 - 0:27:00 - Test Epoch 32: LOSS= 5.47966, acc1= 46.04, acc3= 63.10, acc10= 77.50\n",
      "INFO - 07/19/22 20:46:25 - 0:27:00 - #################################################################################################################\n",
      "train E033: 100% 86/86 [00:22<00:00,  3.77it/s]\n",
      "INFO - 07/19/22 20:46:48 - 0:27:23 - Train Epoch 33: LOSS= 0.03190, lr= 0.000165, acc1= 98.98,acc3= 99.96,acc10= 100.00\n",
      "eval E033: 100% 87/87 [00:20<00:00,  4.17it/s]\n",
      "INFO - 07/19/22 20:47:09 - 0:27:44 - #################################################################################################################\n",
      "INFO - 07/19/22 20:47:09 - 0:27:44 - Test Epoch 33: LOSS= 5.52225, acc1= 45.79, acc3= 63.24, acc10= 77.54\n",
      "INFO - 07/19/22 20:47:09 - 0:27:44 - #################################################################################################################\n",
      "train E034: 100% 86/86 [00:23<00:00,  3.68it/s]\n",
      "INFO - 07/19/22 20:47:32 - 0:28:07 - Train Epoch 34: LOSS= 0.03665, lr= 0.000165, acc1= 98.46,acc3= 99.89,acc10= 100.00\n",
      "eval E034: 100% 87/87 [00:21<00:00,  4.07it/s]\n",
      "INFO - 07/19/22 20:47:53 - 0:28:29 - #################################################################################################################\n",
      "INFO - 07/19/22 20:47:53 - 0:28:29 - Test Epoch 34: LOSS= 5.62814, acc1= 46.12, acc3= 63.21, acc10= 77.98\n",
      "INFO - 07/19/22 20:47:53 - 0:28:29 - #################################################################################################################\n",
      "train E035: 100% 86/86 [00:23<00:00,  3.62it/s]\n",
      "INFO - 07/19/22 20:48:17 - 0:28:53 - Train Epoch 35: LOSS= 0.04003, lr= 0.000115, acc1= 98.65,acc3= 99.93,acc10= 100.00\n",
      "eval E035: 100% 87/87 [00:20<00:00,  4.20it/s]\n",
      "INFO - 07/19/22 20:48:38 - 0:29:13 - #################################################################################################################\n",
      "INFO - 07/19/22 20:48:38 - 0:29:13 - Test Epoch 35: LOSS= 5.57578, acc1= 46.19, acc3= 63.68, acc10= 77.69\n",
      "INFO - 07/19/22 20:48:38 - 0:29:13 - #################################################################################################################\n",
      "train E036: 100% 86/86 [00:23<00:00,  3.71it/s]\n",
      "INFO - 07/19/22 20:49:01 - 0:29:36 - Train Epoch 36: LOSS= 0.03266, lr= 0.000115, acc1= 98.61,acc3= 100.00,acc10= 100.00\n",
      "eval E036: 100% 87/87 [00:20<00:00,  4.20it/s]\n",
      "INFO - 07/19/22 20:49:22 - 0:29:57 - #################################################################################################################\n",
      "INFO - 07/19/22 20:49:22 - 0:29:57 - Test Epoch 36: LOSS= 5.60749, acc1= 46.44, acc3= 63.75, acc10= 77.87\n",
      "INFO - 07/19/22 20:49:22 - 0:29:57 - #################################################################################################################\n",
      "train E037: 100% 86/86 [00:24<00:00,  3.56it/s]\n",
      "INFO - 07/19/22 20:49:46 - 0:30:21 - Train Epoch 37: LOSS= 0.03398, lr= 0.000115, acc1= 98.68,acc3= 100.00,acc10= 100.00\n",
      "eval E037: 100% 87/87 [00:21<00:00,  4.13it/s]\n",
      "INFO - 07/19/22 20:50:07 - 0:30:42 - #################################################################################################################\n",
      "INFO - 07/19/22 20:50:07 - 0:30:42 - Test Epoch 37: LOSS= 5.53859, acc1= 46.48, acc3= 63.50, acc10= 78.01\n",
      "INFO - 07/19/22 20:50:07 - 0:30:42 - #################################################################################################################\n",
      "train E038: 100% 86/86 [00:25<00:00,  3.43it/s]\n",
      "INFO - 07/19/22 20:50:32 - 0:31:08 - Train Epoch 38: LOSS= 0.02805, lr= 0.000081, acc1= 98.76,acc3= 100.00,acc10= 100.00\n",
      "eval E038: 100% 87/87 [00:20<00:00,  4.27it/s]\n",
      "INFO - 07/19/22 20:50:52 - 0:31:28 - #################################################################################################################\n",
      "INFO - 07/19/22 20:50:52 - 0:31:28 - Test Epoch 38: LOSS= 5.61664, acc1= 46.70, acc3= 63.72, acc10= 77.98\n",
      "INFO - 07/19/22 20:50:52 - 0:31:28 - #################################################################################################################\n",
      "train E039: 100% 86/86 [00:22<00:00,  3.76it/s]\n",
      "INFO - 07/19/22 20:51:15 - 0:31:51 - Train Epoch 39: LOSS= 0.04029, lr= 0.000081, acc1= 98.61,acc3= 99.93,acc10= 100.00\n",
      "eval E039: 100% 87/87 [00:20<00:00,  4.25it/s]\n",
      "INFO - 07/19/22 20:51:36 - 0:32:11 - #################################################################################################################\n",
      "INFO - 07/19/22 20:51:36 - 0:32:11 - Test Epoch 39: LOSS= 5.49627, acc1= 46.44, acc3= 63.75, acc10= 77.87\n",
      "INFO - 07/19/22 20:51:36 - 0:32:11 - #################################################################################################################\n",
      "train E040: 100% 86/86 [00:23<00:00,  3.73it/s]\n",
      "INFO - 07/19/22 20:51:59 - 0:32:34 - Train Epoch 40: LOSS= 0.03029, lr= 0.000081, acc1= 98.94,acc3= 99.93,acc10= 100.00\n",
      "eval E040: 100% 87/87 [00:19<00:00,  4.37it/s]\n",
      "INFO - 07/19/22 20:52:19 - 0:32:54 - #################################################################################################################\n",
      "INFO - 07/19/22 20:52:19 - 0:32:54 - Test Epoch 40: LOSS= 5.62871, acc1= 46.81, acc3= 64.26, acc10= 78.01\n",
      "INFO - 07/19/22 20:52:19 - 0:32:54 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E041: 100% 86/86 [00:23<00:00,  3.70it/s]\n",
      "INFO - 07/19/22 20:52:42 - 0:33:18 - Train Epoch 41: LOSS= 0.02668, lr= 0.000056, acc1= 99.05,acc3= 100.00,acc10= 100.00\n",
      "eval E041: 100% 87/87 [00:21<00:00,  4.09it/s]\n",
      "INFO - 07/19/22 20:53:04 - 0:33:39 - #################################################################################################################\n",
      "INFO - 07/19/22 20:53:04 - 0:33:39 - Test Epoch 41: LOSS= 5.55862, acc1= 46.77, acc3= 64.15, acc10= 77.87\n",
      "INFO - 07/19/22 20:53:04 - 0:33:39 - #################################################################################################################\n",
      "train E042: 100% 86/86 [00:23<00:00,  3.62it/s]\n",
      "INFO - 07/19/22 20:53:27 - 0:34:03 - Train Epoch 42: LOSS= 0.02879, lr= 0.000056, acc1= 98.79,acc3= 100.00,acc10= 100.00\n",
      "eval E042: 100% 87/87 [00:21<00:00,  4.01it/s]\n",
      "INFO - 07/19/22 20:53:49 - 0:34:24 - #################################################################################################################\n",
      "INFO - 07/19/22 20:53:49 - 0:34:24 - Test Epoch 42: LOSS= 5.63317, acc1= 46.55, acc3= 64.37, acc10= 78.08\n",
      "INFO - 07/19/22 20:53:49 - 0:34:24 - #################################################################################################################\n",
      "train E043: 100% 86/86 [00:26<00:00,  3.23it/s]\n",
      "INFO - 07/19/22 20:54:16 - 0:34:51 - Train Epoch 43: LOSS= 0.03277, lr= 0.000056, acc1= 98.76,acc3= 99.93,acc10= 99.96\n",
      "eval E043: 100% 87/87 [00:23<00:00,  3.68it/s]\n",
      "INFO - 07/19/22 20:54:39 - 0:35:15 - #################################################################################################################\n",
      "INFO - 07/19/22 20:54:39 - 0:35:15 - Test Epoch 43: LOSS= 5.61361, acc1= 46.66, acc3= 64.19, acc10= 78.12\n",
      "INFO - 07/19/22 20:54:39 - 0:35:15 - #################################################################################################################\n",
      "train E044: 100% 86/86 [00:23<00:00,  3.65it/s]\n",
      "INFO - 07/19/22 20:55:03 - 0:35:38 - Train Epoch 44: LOSS= 0.02635, lr= 0.000040, acc1= 99.01,acc3= 100.00,acc10= 100.00\n",
      "eval E044: 100% 87/87 [00:20<00:00,  4.18it/s]\n",
      "INFO - 07/19/22 20:55:24 - 0:35:59 - #################################################################################################################\n",
      "INFO - 07/19/22 20:55:24 - 0:35:59 - Test Epoch 44: LOSS= 5.60310, acc1= 46.73, acc3= 64.30, acc10= 78.16\n",
      "INFO - 07/19/22 20:55:24 - 0:35:59 - #################################################################################################################\n",
      "train E045: 100% 86/86 [00:23<00:00,  3.64it/s]\n",
      "INFO - 07/19/22 20:55:47 - 0:36:23 - Train Epoch 45: LOSS= 0.02052, lr= 0.000040, acc1= 99.20,acc3= 100.00,acc10= 100.00\n",
      "eval E045: 100% 87/87 [00:20<00:00,  4.23it/s]\n",
      "INFO - 07/19/22 20:56:08 - 0:36:43 - #################################################################################################################\n",
      "INFO - 07/19/22 20:56:08 - 0:36:43 - Test Epoch 45: LOSS= 5.66186, acc1= 46.66, acc3= 64.15, acc10= 78.23\n",
      "INFO - 07/19/22 20:56:08 - 0:36:43 - #################################################################################################################\n",
      "train E046: 100% 86/86 [00:22<00:00,  3.84it/s]\n",
      "INFO - 07/19/22 20:56:30 - 0:37:06 - Train Epoch 46: LOSS= 0.02391, lr= 0.000040, acc1= 99.16,acc3= 99.96,acc10= 100.00\n",
      "eval E046: 100% 87/87 [00:20<00:00,  4.17it/s]\n",
      "INFO - 07/19/22 20:56:51 - 0:37:27 - #################################################################################################################\n",
      "INFO - 07/19/22 20:56:51 - 0:37:27 - Test Epoch 46: LOSS= 5.65995, acc1= 46.92, acc3= 64.01, acc10= 78.08\n",
      "INFO - 07/19/22 20:56:51 - 0:37:27 - #################################################################################################################\n",
      "train E047: 100% 86/86 [00:23<00:00,  3.61it/s]\n",
      "INFO - 07/19/22 20:57:15 - 0:37:50 - Train Epoch 47: LOSS= 0.03202, lr= 0.000040, acc1= 98.54,acc3= 100.00,acc10= 100.00\n",
      "eval E047: 100% 87/87 [00:21<00:00,  4.11it/s]\n",
      "INFO - 07/19/22 20:57:36 - 0:38:12 - #################################################################################################################\n",
      "INFO - 07/19/22 20:57:36 - 0:38:12 - Test Epoch 47: LOSS= 5.71041, acc1= 46.48, acc3= 64.01, acc10= 78.23\n",
      "INFO - 07/19/22 20:57:36 - 0:38:12 - #################################################################################################################\n",
      "train E048: 100% 86/86 [00:24<00:00,  3.47it/s]\n",
      "INFO - 07/19/22 20:58:01 - 0:38:36 - Train Epoch 48: LOSS= 0.02835, lr= 0.000040, acc1= 98.98,acc3= 100.00,acc10= 100.00\n",
      "eval E048: 100% 87/87 [00:22<00:00,  3.85it/s]\n",
      "INFO - 07/19/22 20:58:24 - 0:38:59 - #################################################################################################################\n",
      "INFO - 07/19/22 20:58:24 - 0:38:59 - Test Epoch 48: LOSS= 5.71803, acc1= 46.84, acc3= 64.11, acc10= 78.16\n",
      "INFO - 07/19/22 20:58:24 - 0:38:59 - #################################################################################################################\n",
      "train E049: 100% 86/86 [00:24<00:00,  3.53it/s]\n",
      "INFO - 07/19/22 20:58:48 - 0:39:23 - Train Epoch 49: LOSS= 0.02395, lr= 0.000040, acc1= 99.23,acc3= 100.00,acc10= 100.00\n",
      "eval E049: 100% 87/87 [00:20<00:00,  4.19it/s]\n",
      "INFO - 07/19/22 20:59:09 - 0:39:44 - #################################################################################################################\n",
      "INFO - 07/19/22 20:59:09 - 0:39:44 - Test Epoch 49: LOSS= 5.65569, acc1= 47.13, acc3= 64.08, acc10= 77.83\n",
      "INFO - 07/19/22 20:59:09 - 0:39:44 - #################################################################################################################\n",
      "train E050: 100% 86/86 [00:23<00:00,  3.72it/s]\n",
      "INFO - 07/19/22 20:59:32 - 0:40:07 - Train Epoch 50: LOSS= 0.02325, lr= 0.000040, acc1= 99.23,acc3= 100.00,acc10= 100.00\n",
      "eval E050: 100% 87/87 [00:21<00:00,  4.08it/s]\n",
      "INFO - 07/19/22 20:59:53 - 0:40:29 - #################################################################################################################\n",
      "INFO - 07/19/22 20:59:53 - 0:40:29 - Test Epoch 50: LOSS= 5.72698, acc1= 46.77, acc3= 64.15, acc10= 78.05\n",
      "INFO - 07/19/22 20:59:53 - 0:40:29 - #################################################################################################################\n",
      "train E051: 100% 86/86 [00:22<00:00,  3.74it/s]\n",
      "INFO - 07/19/22 21:00:16 - 0:40:52 - Train Epoch 51: LOSS= 0.01965, lr= 0.000040, acc1= 99.34,acc3= 100.00,acc10= 100.00\n",
      "eval E051: 100% 87/87 [00:20<00:00,  4.20it/s]\n",
      "INFO - 07/19/22 21:00:37 - 0:41:12 - #################################################################################################################\n",
      "INFO - 07/19/22 21:00:37 - 0:41:12 - Test Epoch 51: LOSS= 5.69523, acc1= 46.92, acc3= 63.79, acc10= 77.79\n",
      "INFO - 07/19/22 21:00:37 - 0:41:12 - #################################################################################################################\n",
      "train E052: 100% 86/86 [00:23<00:00,  3.68it/s]\n",
      "INFO - 07/19/22 21:01:00 - 0:41:36 - Train Epoch 52: LOSS= 0.01900, lr= 0.000040, acc1= 99.27,acc3= 100.00,acc10= 100.00\n",
      "eval E052: 100% 87/87 [00:20<00:00,  4.24it/s]\n",
      "INFO - 07/19/22 21:01:21 - 0:41:56 - #################################################################################################################\n",
      "INFO - 07/19/22 21:01:21 - 0:41:56 - Test Epoch 52: LOSS= 5.68121, acc1= 47.02, acc3= 64.19, acc10= 78.05\n",
      "INFO - 07/19/22 21:01:21 - 0:41:56 - #################################################################################################################\n",
      "train E053: 100% 86/86 [00:23<00:00,  3.63it/s]\n",
      "INFO - 07/19/22 21:01:45 - 0:42:20 - Train Epoch 53: LOSS= 0.02214, lr= 0.000040, acc1= 99.27,acc3= 100.00,acc10= 100.00\n",
      "eval E053: 100% 87/87 [00:21<00:00,  3.99it/s]\n",
      "INFO - 07/19/22 21:02:06 - 0:42:42 - #################################################################################################################\n",
      "INFO - 07/19/22 21:02:06 - 0:42:42 - Test Epoch 53: LOSS= 5.81285, acc1= 46.73, acc3= 64.22, acc10= 78.23\n",
      "INFO - 07/19/22 21:02:06 - 0:42:42 - #################################################################################################################\n",
      "train E054: 100% 86/86 [00:23<00:00,  3.72it/s]\n",
      "INFO - 07/19/22 21:02:29 - 0:43:05 - Train Epoch 54: LOSS= 0.02423, lr= 0.000040, acc1= 99.20,acc3= 99.96,acc10= 99.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E054: 100% 87/87 [00:21<00:00,  4.12it/s]\n",
      "INFO - 07/19/22 21:02:51 - 0:43:26 - #################################################################################################################\n",
      "INFO - 07/19/22 21:02:51 - 0:43:26 - Test Epoch 54: LOSS= 5.77199, acc1= 47.10, acc3= 64.11, acc10= 78.23\n",
      "INFO - 07/19/22 21:02:51 - 0:43:26 - #################################################################################################################\n",
      "train E055: 100% 86/86 [00:23<00:00,  3.72it/s]\n",
      "INFO - 07/19/22 21:03:14 - 0:43:50 - Train Epoch 55: LOSS= 0.02008, lr= 0.000040, acc1= 99.34,acc3= 99.96,acc10= 100.00\n",
      "eval E055: 100% 87/87 [00:21<00:00,  4.08it/s]\n",
      "INFO - 07/19/22 21:03:35 - 0:44:11 - #################################################################################################################\n",
      "INFO - 07/19/22 21:03:35 - 0:44:11 - Test Epoch 55: LOSS= 5.76647, acc1= 46.84, acc3= 63.93, acc10= 78.37\n",
      "INFO - 07/19/22 21:03:35 - 0:44:11 - #################################################################################################################\n",
      "train E056: 100% 86/86 [00:24<00:00,  3.58it/s]\n",
      "INFO - 07/19/22 21:03:59 - 0:44:35 - Train Epoch 56: LOSS= 0.02060, lr= 0.000040, acc1= 99.20,acc3= 100.00,acc10= 100.00\n",
      "eval E056: 100% 87/87 [00:22<00:00,  3.92it/s]\n",
      "INFO - 07/19/22 21:04:22 - 0:44:57 - #################################################################################################################\n",
      "INFO - 07/19/22 21:04:22 - 0:44:57 - Test Epoch 56: LOSS= 5.76026, acc1= 46.84, acc3= 64.01, acc10= 78.19\n",
      "INFO - 07/19/22 21:04:22 - 0:44:57 - #################################################################################################################\n",
      "train E057: 100% 86/86 [00:23<00:00,  3.65it/s]\n",
      "INFO - 07/19/22 21:04:45 - 0:45:21 - Train Epoch 57: LOSS= 0.02596, lr= 0.000040, acc1= 98.94,acc3= 100.00,acc10= 100.00\n",
      "eval E057: 100% 87/87 [00:22<00:00,  3.93it/s]\n",
      "INFO - 07/19/22 21:05:07 - 0:45:43 - #################################################################################################################\n",
      "INFO - 07/19/22 21:05:07 - 0:45:43 - Test Epoch 57: LOSS= 5.94367, acc1= 46.88, acc3= 64.22, acc10= 78.37\n",
      "INFO - 07/19/22 21:05:07 - 0:45:43 - #################################################################################################################\n",
      "train E058: 100% 86/86 [00:24<00:00,  3.49it/s]\n",
      "INFO - 07/19/22 21:05:32 - 0:46:07 - Train Epoch 58: LOSS= 0.02321, lr= 0.000040, acc1= 99.23,acc3= 99.93,acc10= 100.00\n",
      "eval E058: 100% 87/87 [00:22<00:00,  3.94it/s]\n",
      "INFO - 07/19/22 21:05:54 - 0:46:30 - #################################################################################################################\n",
      "INFO - 07/19/22 21:05:54 - 0:46:30 - Test Epoch 58: LOSS= 5.81944, acc1= 47.10, acc3= 64.26, acc10= 78.12\n",
      "INFO - 07/19/22 21:05:54 - 0:46:30 - #################################################################################################################\n",
      "train E059: 100% 86/86 [00:23<00:00,  3.67it/s]\n",
      "INFO - 07/19/22 21:06:18 - 0:46:53 - Train Epoch 59: LOSS= 0.02844, lr= 0.000040, acc1= 98.90,acc3= 100.00,acc10= 100.00\n",
      "eval E059: 100% 87/87 [00:21<00:00,  4.11it/s]\n",
      "INFO - 07/19/22 21:06:39 - 0:47:14 - #################################################################################################################\n",
      "INFO - 07/19/22 21:06:39 - 0:47:14 - Test Epoch 59: LOSS= 5.83100, acc1= 46.77, acc3= 63.90, acc10= 77.76\n",
      "INFO - 07/19/22 21:06:39 - 0:47:14 - #################################################################################################################\n",
      "train E060: 100% 86/86 [00:23<00:00,  3.73it/s]\n",
      "INFO - 07/19/22 21:07:02 - 0:47:37 - Train Epoch 60: LOSS= 0.02032, lr= 0.000040, acc1= 99.20,acc3= 100.00,acc10= 100.00\n",
      "eval E060: 100% 87/87 [00:21<00:00,  4.10it/s]\n",
      "INFO - 07/19/22 21:07:23 - 0:47:58 - #################################################################################################################\n",
      "INFO - 07/19/22 21:07:23 - 0:47:58 - Test Epoch 60: LOSS= 5.90163, acc1= 46.92, acc3= 64.04, acc10= 77.83\n",
      "INFO - 07/19/22 21:07:23 - 0:47:58 - #################################################################################################################\n",
      "train E061: 100% 86/86 [00:24<00:00,  3.46it/s]\n",
      "INFO - 07/19/22 21:07:48 - 0:48:23 - Train Epoch 61: LOSS= 0.02007, lr= 0.000040, acc1= 99.20,acc3= 100.00,acc10= 100.00\n",
      "eval E061: 100% 87/87 [00:26<00:00,  3.32it/s]\n",
      "INFO - 07/19/22 21:08:14 - 0:48:49 - #################################################################################################################\n",
      "INFO - 07/19/22 21:08:14 - 0:48:49 - Test Epoch 61: LOSS= 5.84367, acc1= 46.59, acc3= 64.15, acc10= 77.90\n",
      "INFO - 07/19/22 21:08:14 - 0:48:49 - #################################################################################################################\n",
      "train E062: 100% 86/86 [00:24<00:00,  3.54it/s]\n",
      "INFO - 07/19/22 21:08:38 - 0:49:14 - Train Epoch 62: LOSS= 0.02533, lr= 0.000040, acc1= 99.05,acc3= 99.96,acc10= 100.00\n",
      "eval E062: 100% 87/87 [00:22<00:00,  3.83it/s]\n",
      "INFO - 07/19/22 21:09:01 - 0:49:36 - #################################################################################################################\n",
      "INFO - 07/19/22 21:09:01 - 0:49:36 - Test Epoch 62: LOSS= 5.87486, acc1= 47.24, acc3= 64.26, acc10= 78.30\n",
      "INFO - 07/19/22 21:09:01 - 0:49:36 - #################################################################################################################\n",
      "train E063: 100% 86/86 [00:25<00:00,  3.41it/s]\n",
      "INFO - 07/19/22 21:09:27 - 0:50:02 - Train Epoch 63: LOSS= 0.03299, lr= 0.000040, acc1= 98.79,acc3= 99.96,acc10= 100.00\n",
      "eval E063: 100% 87/87 [00:22<00:00,  3.83it/s]\n",
      "INFO - 07/19/22 21:09:49 - 0:50:25 - #################################################################################################################\n",
      "INFO - 07/19/22 21:09:49 - 0:50:25 - Test Epoch 63: LOSS= 5.86611, acc1= 46.92, acc3= 63.97, acc10= 78.16\n",
      "INFO - 07/19/22 21:09:49 - 0:50:25 - #################################################################################################################\n",
      "train E064: 100% 86/86 [00:26<00:00,  3.30it/s]\n",
      "INFO - 07/19/22 21:10:15 - 0:50:51 - Train Epoch 64: LOSS= 0.02951, lr= 0.000040, acc1= 98.72,acc3= 100.00,acc10= 100.00\n",
      "eval E064: 100% 87/87 [00:22<00:00,  3.90it/s]\n",
      "INFO - 07/19/22 21:10:38 - 0:51:13 - #################################################################################################################\n",
      "INFO - 07/19/22 21:10:38 - 0:51:13 - Test Epoch 64: LOSS= 5.72916, acc1= 47.13, acc3= 63.64, acc10= 77.90\n",
      "INFO - 07/19/22 21:10:38 - 0:51:13 - #################################################################################################################\n",
      "train E065: 100% 86/86 [00:23<00:00,  3.68it/s]\n",
      "INFO - 07/19/22 21:11:01 - 0:51:37 - Train Epoch 65: LOSS= 0.03086, lr= 0.000040, acc1= 98.65,acc3= 100.00,acc10= 100.00\n",
      "eval E065: 100% 87/87 [00:21<00:00,  4.04it/s]\n",
      "INFO - 07/19/22 21:11:23 - 0:51:58 - #################################################################################################################\n",
      "INFO - 07/19/22 21:11:23 - 0:51:58 - Test Epoch 65: LOSS= 5.75406, acc1= 47.02, acc3= 63.86, acc10= 77.76\n",
      "INFO - 07/19/22 21:11:23 - 0:51:58 - #################################################################################################################\n",
      "train E066: 100% 86/86 [00:23<00:00,  3.64it/s]\n",
      "INFO - 07/19/22 21:11:46 - 0:52:22 - Train Epoch 66: LOSS= 0.01931, lr= 0.000040, acc1= 99.23,acc3= 100.00,acc10= 100.00\n",
      "eval E066: 100% 87/87 [00:20<00:00,  4.20it/s]\n",
      "INFO - 07/19/22 21:12:07 - 0:52:43 - #################################################################################################################\n",
      "INFO - 07/19/22 21:12:07 - 0:52:43 - Test Epoch 66: LOSS= 5.88382, acc1= 47.28, acc3= 63.64, acc10= 77.76\n",
      "INFO - 07/19/22 21:12:07 - 0:52:43 - #################################################################################################################\n",
      "train E067: 100% 86/86 [00:23<00:00,  3.61it/s]\n",
      "INFO - 07/19/22 21:12:31 - 0:53:06 - Train Epoch 67: LOSS= 0.02177, lr= 0.000040, acc1= 99.20,acc3= 100.00,acc10= 100.00\n",
      "eval E067: 100% 87/87 [00:22<00:00,  3.83it/s]\n",
      "INFO - 07/19/22 21:12:54 - 0:53:29 - #################################################################################################################\n",
      "INFO - 07/19/22 21:12:54 - 0:53:29 - Test Epoch 67: LOSS= 5.79740, acc1= 47.53, acc3= 63.68, acc10= 77.83\n",
      "INFO - 07/19/22 21:12:54 - 0:53:29 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E068: 100% 86/86 [00:25<00:00,  3.41it/s]\n",
      "INFO - 07/19/22 21:13:19 - 0:53:54 - Train Epoch 68: LOSS= 0.02647, lr= 0.000040, acc1= 98.98,acc3= 99.93,acc10= 99.96\n",
      "eval E068: 100% 87/87 [00:22<00:00,  3.88it/s]\n",
      "INFO - 07/19/22 21:13:41 - 0:54:17 - #################################################################################################################\n",
      "INFO - 07/19/22 21:13:41 - 0:54:17 - Test Epoch 68: LOSS= 5.79665, acc1= 47.17, acc3= 64.08, acc10= 78.05\n",
      "INFO - 07/19/22 21:13:41 - 0:54:17 - #################################################################################################################\n",
      "train E069: 100% 86/86 [00:27<00:00,  3.10it/s]\n",
      "INFO - 07/19/22 21:14:09 - 0:54:44 - Train Epoch 69: LOSS= 0.02638, lr= 0.000040, acc1= 98.87,acc3= 99.96,acc10= 100.00\n",
      "eval E069: 100% 87/87 [00:25<00:00,  3.37it/s]\n",
      "INFO - 07/19/22 21:14:35 - 0:55:10 - #################################################################################################################\n",
      "INFO - 07/19/22 21:14:35 - 0:55:10 - Test Epoch 69: LOSS= 5.92907, acc1= 47.10, acc3= 63.72, acc10= 77.90\n",
      "INFO - 07/19/22 21:14:35 - 0:55:10 - #################################################################################################################\n",
      "train E070: 100% 86/86 [00:23<00:00,  3.65it/s]\n",
      "INFO - 07/19/22 21:14:58 - 0:55:34 - Train Epoch 70: LOSS= 0.02248, lr= 0.000040, acc1= 99.09,acc3= 100.00,acc10= 100.00\n",
      "eval E070: 100% 87/87 [00:22<00:00,  3.90it/s]\n",
      "INFO - 07/19/22 21:15:21 - 0:55:56 - #################################################################################################################\n",
      "INFO - 07/19/22 21:15:21 - 0:55:56 - Test Epoch 70: LOSS= 5.85079, acc1= 46.95, acc3= 63.75, acc10= 77.90\n",
      "INFO - 07/19/22 21:15:21 - 0:55:56 - #################################################################################################################\n",
      "train E071: 100% 86/86 [00:24<00:00,  3.52it/s]\n",
      "INFO - 07/19/22 21:15:45 - 0:56:21 - Train Epoch 71: LOSS= 0.01586, lr= 0.000040, acc1= 99.34,acc3= 100.00,acc10= 100.00\n",
      "eval E071: 100% 87/87 [00:21<00:00,  4.11it/s]\n",
      "INFO - 07/19/22 21:16:06 - 0:56:42 - #################################################################################################################\n",
      "INFO - 07/19/22 21:16:06 - 0:56:42 - Test Epoch 71: LOSS= 5.86288, acc1= 47.35, acc3= 63.53, acc10= 77.90\n",
      "INFO - 07/19/22 21:16:06 - 0:56:42 - #################################################################################################################\n",
      "train E072: 100% 86/86 [00:24<00:00,  3.56it/s]\n",
      "INFO - 07/19/22 21:16:30 - 0:57:06 - Train Epoch 72: LOSS= 0.02353, lr= 0.000040, acc1= 99.09,acc3= 100.00,acc10= 100.00\n",
      "eval E072: 100% 87/87 [00:21<00:00,  3.97it/s]\n",
      "INFO - 07/19/22 21:16:52 - 0:57:28 - #################################################################################################################\n",
      "INFO - 07/19/22 21:16:52 - 0:57:28 - Test Epoch 72: LOSS= 6.05656, acc1= 47.06, acc3= 63.61, acc10= 77.90\n",
      "INFO - 07/19/22 21:16:52 - 0:57:28 - #################################################################################################################\n",
      "train E073: 100% 86/86 [00:23<00:00,  3.67it/s]\n",
      "INFO - 07/19/22 21:17:16 - 0:57:51 - Train Epoch 73: LOSS= 0.02480, lr= 0.000040, acc1= 99.01,acc3= 100.00,acc10= 100.00\n",
      "eval E073: 100% 87/87 [00:21<00:00,  4.03it/s]\n",
      "INFO - 07/19/22 21:17:37 - 0:58:13 - #################################################################################################################\n",
      "INFO - 07/19/22 21:17:37 - 0:58:13 - Test Epoch 73: LOSS= 5.84755, acc1= 47.31, acc3= 63.90, acc10= 78.01\n",
      "INFO - 07/19/22 21:17:37 - 0:58:13 - #################################################################################################################\n",
      "train E074: 100% 86/86 [00:24<00:00,  3.52it/s]\n",
      "INFO - 07/19/22 21:18:02 - 0:58:37 - Train Epoch 74: LOSS= 0.01718, lr= 0.000040, acc1= 99.27,acc3= 100.00,acc10= 100.00\n",
      "eval E074: 100% 87/87 [00:22<00:00,  3.95it/s]\n",
      "INFO - 07/19/22 21:18:24 - 0:58:59 - #################################################################################################################\n",
      "INFO - 07/19/22 21:18:24 - 0:58:59 - Test Epoch 74: LOSS= 5.98881, acc1= 47.17, acc3= 63.79, acc10= 78.01\n",
      "INFO - 07/19/22 21:18:24 - 0:58:59 - #################################################################################################################\n",
      "train E075: 100% 86/86 [00:25<00:00,  3.38it/s]\n",
      "INFO - 07/19/22 21:18:49 - 0:59:25 - Train Epoch 75: LOSS= 0.02701, lr= 0.000040, acc1= 99.09,acc3= 99.96,acc10= 100.00\n",
      "eval E075: 100% 87/87 [00:22<00:00,  3.93it/s]\n",
      "INFO - 07/19/22 21:19:12 - 0:59:47 - #################################################################################################################\n",
      "INFO - 07/19/22 21:19:12 - 0:59:47 - Test Epoch 75: LOSS= 5.90314, acc1= 46.73, acc3= 64.04, acc10= 78.05\n",
      "INFO - 07/19/22 21:19:12 - 0:59:47 - #################################################################################################################\n",
      "train E076: 100% 86/86 [00:24<00:00,  3.55it/s]\n",
      "INFO - 07/19/22 21:19:36 - 1:00:11 - Train Epoch 76: LOSS= 0.02061, lr= 0.000040, acc1= 99.31,acc3= 99.96,acc10= 100.00\n",
      "eval E076: 100% 87/87 [00:22<00:00,  3.85it/s]\n",
      "INFO - 07/19/22 21:19:58 - 1:00:34 - #################################################################################################################\n",
      "INFO - 07/19/22 21:19:58 - 1:00:34 - Test Epoch 76: LOSS= 5.90200, acc1= 46.81, acc3= 64.30, acc10= 78.19\n",
      "INFO - 07/19/22 21:19:58 - 1:00:34 - #################################################################################################################\n",
      "train E077: 100% 86/86 [00:27<00:00,  3.13it/s]\n",
      "INFO - 07/19/22 21:20:26 - 1:01:01 - Train Epoch 77: LOSS= 0.02004, lr= 0.000040, acc1= 99.16,acc3= 100.00,acc10= 100.00\n",
      "eval E077: 100% 87/87 [00:27<00:00,  3.17it/s]\n",
      "INFO - 07/19/22 21:20:53 - 1:01:29 - #################################################################################################################\n",
      "INFO - 07/19/22 21:20:53 - 1:01:29 - Test Epoch 77: LOSS= 5.93663, acc1= 46.88, acc3= 64.40, acc10= 78.30\n",
      "INFO - 07/19/22 21:20:53 - 1:01:29 - #################################################################################################################\n",
      "train E078: 100% 86/86 [00:24<00:00,  3.55it/s]\n",
      "INFO - 07/19/22 21:21:18 - 1:01:53 - Train Epoch 78: LOSS= 0.02053, lr= 0.000040, acc1= 99.31,acc3= 100.00,acc10= 100.00\n",
      "eval E078: 100% 87/87 [00:21<00:00,  3.99it/s]\n",
      "INFO - 07/19/22 21:21:39 - 1:02:15 - #################################################################################################################\n",
      "INFO - 07/19/22 21:21:39 - 1:02:15 - Test Epoch 78: LOSS= 5.92646, acc1= 47.35, acc3= 64.59, acc10= 78.30\n",
      "INFO - 07/19/22 21:21:39 - 1:02:15 - #################################################################################################################\n",
      "train E079: 100% 86/86 [00:23<00:00,  3.66it/s]\n",
      "INFO - 07/19/22 21:22:03 - 1:02:39 - Train Epoch 79: LOSS= 0.02070, lr= 0.000040, acc1= 99.12,acc3= 100.00,acc10= 100.00\n",
      "eval E079: 100% 87/87 [00:20<00:00,  4.22it/s]\n",
      "INFO - 07/19/22 21:22:24 - 1:02:59 - #################################################################################################################\n",
      "INFO - 07/19/22 21:22:24 - 1:02:59 - Test Epoch 79: LOSS= 6.00519, acc1= 47.06, acc3= 64.51, acc10= 78.45\n",
      "INFO - 07/19/22 21:22:24 - 1:02:59 - #################################################################################################################\n",
      "train E080: 100% 86/86 [00:22<00:00,  3.89it/s]\n",
      "INFO - 07/19/22 21:22:46 - 1:03:21 - Train Epoch 80: LOSS= 0.03119, lr= 0.000040, acc1= 98.87,acc3= 100.00,acc10= 100.00\n",
      "eval E080: 100% 87/87 [00:21<00:00,  4.05it/s]\n",
      "INFO - 07/19/22 21:23:07 - 1:03:43 - #################################################################################################################\n",
      "INFO - 07/19/22 21:23:07 - 1:03:43 - Test Epoch 80: LOSS= 5.97447, acc1= 47.13, acc3= 63.90, acc10= 78.01\n",
      "INFO - 07/19/22 21:23:07 - 1:03:43 - #################################################################################################################\n",
      "train E081: 100% 86/86 [00:23<00:00,  3.65it/s]\n",
      "INFO - 07/19/22 21:23:31 - 1:04:06 - Train Epoch 81: LOSS= 0.02221, lr= 0.000040, acc1= 99.27,acc3= 100.00,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E081: 100% 87/87 [00:21<00:00,  4.02it/s]\n",
      "INFO - 07/19/22 21:23:53 - 1:04:28 - #################################################################################################################\n",
      "INFO - 07/19/22 21:23:53 - 1:04:28 - Test Epoch 81: LOSS= 5.94726, acc1= 46.52, acc3= 63.86, acc10= 78.12\n",
      "INFO - 07/19/22 21:23:53 - 1:04:28 - #################################################################################################################\n",
      "train E082: 100% 86/86 [00:29<00:00,  2.89it/s]\n",
      "INFO - 07/19/22 21:24:22 - 1:04:58 - Train Epoch 82: LOSS= 0.02109, lr= 0.000040, acc1= 99.34,acc3= 100.00,acc10= 100.00\n",
      "eval E082: 100% 87/87 [00:27<00:00,  3.13it/s]\n",
      "INFO - 07/19/22 21:24:50 - 1:05:26 - #################################################################################################################\n",
      "INFO - 07/19/22 21:24:50 - 1:05:26 - Test Epoch 82: LOSS= 5.86396, acc1= 46.44, acc3= 63.97, acc10= 78.05\n",
      "INFO - 07/19/22 21:24:50 - 1:05:26 - #################################################################################################################\n",
      "train E083: 100% 86/86 [00:29<00:00,  2.88it/s]\n",
      "INFO - 07/19/22 21:25:20 - 1:05:55 - Train Epoch 83: LOSS= 0.01939, lr= 0.000040, acc1= 99.23,acc3= 99.96,acc10= 100.00\n",
      "eval E083: 100% 87/87 [00:24<00:00,  3.58it/s]\n",
      "INFO - 07/19/22 21:25:44 - 1:06:20 - #################################################################################################################\n",
      "INFO - 07/19/22 21:25:44 - 1:06:20 - Test Epoch 83: LOSS= 5.88282, acc1= 46.81, acc3= 64.15, acc10= 78.05\n",
      "INFO - 07/19/22 21:25:44 - 1:06:20 - #################################################################################################################\n",
      "train E084: 100% 86/86 [00:24<00:00,  3.44it/s]\n",
      "INFO - 07/19/22 21:26:09 - 1:06:45 - Train Epoch 84: LOSS= 0.02459, lr= 0.000040, acc1= 99.16,acc3= 99.93,acc10= 100.00\n",
      "eval E084: 100% 87/87 [00:22<00:00,  3.87it/s]\n",
      "INFO - 07/19/22 21:26:32 - 1:07:07 - #################################################################################################################\n",
      "INFO - 07/19/22 21:26:32 - 1:07:07 - Test Epoch 84: LOSS= 5.92621, acc1= 47.21, acc3= 64.55, acc10= 78.19\n",
      "INFO - 07/19/22 21:26:32 - 1:07:07 - #################################################################################################################\n",
      "train E085: 100% 86/86 [00:23<00:00,  3.64it/s]\n",
      "INFO - 07/19/22 21:26:55 - 1:07:31 - Train Epoch 85: LOSS= 0.02479, lr= 0.000040, acc1= 98.87,acc3= 99.93,acc10= 100.00\n",
      "eval E085: 100% 87/87 [00:20<00:00,  4.33it/s]\n",
      "INFO - 07/19/22 21:27:15 - 1:07:51 - #################################################################################################################\n",
      "INFO - 07/19/22 21:27:15 - 1:07:51 - Test Epoch 85: LOSS= 6.06761, acc1= 47.13, acc3= 64.70, acc10= 78.12\n",
      "INFO - 07/19/22 21:27:15 - 1:07:51 - #################################################################################################################\n",
      "train E086: 100% 86/86 [00:23<00:00,  3.68it/s]\n",
      "INFO - 07/19/22 21:27:39 - 1:08:14 - Train Epoch 86: LOSS= 0.01965, lr= 0.000040, acc1= 99.09,acc3= 100.00,acc10= 100.00\n",
      "eval E086: 100% 87/87 [00:21<00:00,  4.03it/s]\n",
      "INFO - 07/19/22 21:28:00 - 1:08:36 - #################################################################################################################\n",
      "INFO - 07/19/22 21:28:00 - 1:08:36 - Test Epoch 86: LOSS= 5.97896, acc1= 46.99, acc3= 64.70, acc10= 77.98\n",
      "INFO - 07/19/22 21:28:00 - 1:08:36 - #################################################################################################################\n",
      "train E087: 100% 86/86 [00:23<00:00,  3.62it/s]\n",
      "INFO - 07/19/22 21:28:24 - 1:09:00 - Train Epoch 87: LOSS= 0.01952, lr= 0.000040, acc1= 99.09,acc3= 100.00,acc10= 100.00\n",
      "eval E087: 100% 87/87 [00:24<00:00,  3.51it/s]\n",
      "INFO - 07/19/22 21:28:49 - 1:09:24 - #################################################################################################################\n",
      "INFO - 07/19/22 21:28:49 - 1:09:24 - Test Epoch 87: LOSS= 6.07081, acc1= 46.70, acc3= 64.62, acc10= 78.05\n",
      "INFO - 07/19/22 21:28:49 - 1:09:24 - #################################################################################################################\n",
      "train E088: 100% 86/86 [00:29<00:00,  2.93it/s]\n",
      "INFO - 07/19/22 21:29:18 - 1:09:54 - Train Epoch 88: LOSS= 0.02166, lr= 0.000040, acc1= 99.12,acc3= 100.00,acc10= 100.00\n",
      "eval E088: 100% 87/87 [00:27<00:00,  3.11it/s]\n",
      "INFO - 07/19/22 21:29:46 - 1:10:22 - #################################################################################################################\n",
      "INFO - 07/19/22 21:29:46 - 1:10:22 - Test Epoch 88: LOSS= 6.07135, acc1= 46.88, acc3= 64.55, acc10= 77.98\n",
      "INFO - 07/19/22 21:29:46 - 1:10:22 - #################################################################################################################\n",
      "train E089: 100% 86/86 [00:25<00:00,  3.38it/s]\n",
      "INFO - 07/19/22 21:30:12 - 1:10:47 - Train Epoch 89: LOSS= 0.02096, lr= 0.000040, acc1= 99.09,acc3= 100.00,acc10= 100.00\n",
      "eval E089: 100% 87/87 [00:24<00:00,  3.54it/s]\n",
      "INFO - 07/19/22 21:30:36 - 1:11:12 - #################################################################################################################\n",
      "INFO - 07/19/22 21:30:36 - 1:11:12 - Test Epoch 89: LOSS= 6.01805, acc1= 47.21, acc3= 64.22, acc10= 78.12\n",
      "INFO - 07/19/22 21:30:36 - 1:11:12 - #################################################################################################################\n",
      "train E090: 100% 86/86 [00:25<00:00,  3.42it/s]\n",
      "INFO - 07/19/22 21:31:01 - 1:11:37 - Train Epoch 90: LOSS= 0.02399, lr= 0.000040, acc1= 99.09,acc3= 100.00,acc10= 100.00\n",
      "eval E090: 100% 87/87 [00:22<00:00,  3.89it/s]\n",
      "INFO - 07/19/22 21:31:24 - 1:11:59 - #################################################################################################################\n",
      "INFO - 07/19/22 21:31:24 - 1:11:59 - Test Epoch 90: LOSS= 6.07256, acc1= 46.70, acc3= 63.86, acc10= 77.69\n",
      "INFO - 07/19/22 21:31:24 - 1:11:59 - #################################################################################################################\n",
      "train E091: 100% 86/86 [00:23<00:00,  3.68it/s]\n",
      "INFO - 07/19/22 21:31:47 - 1:12:23 - Train Epoch 91: LOSS= 0.01522, lr= 0.000040, acc1= 99.38,acc3= 100.00,acc10= 100.00\n",
      "eval E091: 100% 87/87 [00:22<00:00,  3.91it/s]\n",
      "INFO - 07/19/22 21:32:10 - 1:12:45 - #################################################################################################################\n",
      "INFO - 07/19/22 21:32:10 - 1:12:45 - Test Epoch 91: LOSS= 6.11158, acc1= 46.73, acc3= 63.93, acc10= 77.76\n",
      "INFO - 07/19/22 21:32:10 - 1:12:45 - #################################################################################################################\n",
      "train E092: 100% 86/86 [00:23<00:00,  3.71it/s]\n",
      "INFO - 07/19/22 21:32:33 - 1:13:08 - Train Epoch 92: LOSS= 0.01779, lr= 0.000040, acc1= 99.20,acc3= 100.00,acc10= 100.00\n",
      "eval E092: 100% 87/87 [00:20<00:00,  4.22it/s]\n",
      "INFO - 07/19/22 21:32:53 - 1:13:29 - #################################################################################################################\n",
      "INFO - 07/19/22 21:32:53 - 1:13:29 - Test Epoch 92: LOSS= 6.13214, acc1= 46.73, acc3= 63.79, acc10= 77.61\n",
      "INFO - 07/19/22 21:32:53 - 1:13:29 - #################################################################################################################\n",
      "train E093: 100% 86/86 [00:24<00:00,  3.46it/s]\n",
      "INFO - 07/19/22 21:33:18 - 1:13:54 - Train Epoch 93: LOSS= 0.01987, lr= 0.000040, acc1= 99.20,acc3= 99.96,acc10= 100.00\n",
      "eval E093: 100% 87/87 [00:24<00:00,  3.57it/s]\n",
      "INFO - 07/19/22 21:33:43 - 1:14:18 - #################################################################################################################\n",
      "INFO - 07/19/22 21:33:43 - 1:14:18 - Test Epoch 93: LOSS= 6.18255, acc1= 46.81, acc3= 63.79, acc10= 77.98\n",
      "INFO - 07/19/22 21:33:43 - 1:14:18 - #################################################################################################################\n",
      "train E094: 100% 86/86 [00:23<00:00,  3.66it/s]\n",
      "INFO - 07/19/22 21:34:06 - 1:14:42 - Train Epoch 94: LOSS= 0.02232, lr= 0.000040, acc1= 98.98,acc3= 100.00,acc10= 100.00\n",
      "eval E094: 100% 87/87 [00:22<00:00,  3.81it/s]\n",
      "INFO - 07/19/22 21:34:29 - 1:15:04 - #################################################################################################################\n",
      "INFO - 07/19/22 21:34:29 - 1:15:04 - Test Epoch 94: LOSS= 6.12076, acc1= 46.55, acc3= 64.26, acc10= 77.94\n",
      "INFO - 07/19/22 21:34:29 - 1:15:04 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E095: 100% 86/86 [00:24<00:00,  3.45it/s]\n",
      "INFO - 07/19/22 21:34:54 - 1:15:29 - Train Epoch 95: LOSS= 0.02320, lr= 0.000040, acc1= 98.90,acc3= 100.00,acc10= 100.00\n",
      "eval E095: 100% 87/87 [00:23<00:00,  3.70it/s]\n",
      "INFO - 07/19/22 21:35:17 - 1:15:53 - #################################################################################################################\n",
      "INFO - 07/19/22 21:35:17 - 1:15:53 - Test Epoch 95: LOSS= 6.20510, acc1= 46.52, acc3= 64.48, acc10= 77.87\n",
      "INFO - 07/19/22 21:35:17 - 1:15:53 - #################################################################################################################\n",
      "train E096: 100% 86/86 [00:22<00:00,  3.78it/s]\n",
      "INFO - 07/19/22 21:35:40 - 1:16:16 - Train Epoch 96: LOSS= 0.02139, lr= 0.000040, acc1= 99.09,acc3= 99.96,acc10= 100.00\n",
      "eval E096: 100% 87/87 [00:22<00:00,  3.93it/s]\n",
      "INFO - 07/19/22 21:36:02 - 1:16:38 - #################################################################################################################\n",
      "INFO - 07/19/22 21:36:02 - 1:16:38 - Test Epoch 96: LOSS= 6.11128, acc1= 46.66, acc3= 64.40, acc10= 77.94\n",
      "INFO - 07/19/22 21:36:02 - 1:16:38 - #################################################################################################################\n",
      "train E097: 100% 86/86 [00:24<00:00,  3.45it/s]\n",
      "INFO - 07/19/22 21:36:27 - 1:17:03 - Train Epoch 97: LOSS= 0.02013, lr= 0.000040, acc1= 99.09,acc3= 100.00,acc10= 100.00\n",
      "eval E097: 100% 87/87 [00:22<00:00,  3.85it/s]\n",
      "INFO - 07/19/22 21:36:50 - 1:17:25 - #################################################################################################################\n",
      "INFO - 07/19/22 21:36:50 - 1:17:25 - Test Epoch 97: LOSS= 6.06591, acc1= 46.55, acc3= 64.55, acc10= 78.01\n",
      "INFO - 07/19/22 21:36:50 - 1:17:25 - #################################################################################################################\n",
      "train E098: 100% 86/86 [00:25<00:00,  3.33it/s]\n",
      "INFO - 07/19/22 21:37:16 - 1:17:51 - Train Epoch 98: LOSS= 0.02021, lr= 0.000040, acc1= 99.20,acc3= 99.96,acc10= 100.00\n",
      "eval E098: 100% 87/87 [00:24<00:00,  3.56it/s]\n",
      "INFO - 07/19/22 21:37:40 - 1:18:16 - #################################################################################################################\n",
      "INFO - 07/19/22 21:37:40 - 1:18:16 - Test Epoch 98: LOSS= 6.03867, acc1= 46.99, acc3= 64.55, acc10= 78.01\n",
      "INFO - 07/19/22 21:37:40 - 1:18:16 - #################################################################################################################\n",
      "train E099: 100% 86/86 [00:26<00:00,  3.31it/s]\n",
      "INFO - 07/19/22 21:38:06 - 1:18:42 - Train Epoch 99: LOSS= 0.02720, lr= 0.000040, acc1= 98.87,acc3= 99.89,acc10= 99.96\n",
      "eval E099: 100% 87/87 [00:21<00:00,  4.04it/s]\n",
      "INFO - 07/19/22 21:38:28 - 1:19:03 - #################################################################################################################\n",
      "INFO - 07/19/22 21:38:28 - 1:19:03 - Test Epoch 99: LOSS= 6.08938, acc1= 46.88, acc3= 64.55, acc10= 77.98\n",
      "INFO - 07/19/22 21:38:28 - 1:19:03 - #################################################################################################################\n",
      "train E100: 100% 86/86 [00:23<00:00,  3.66it/s]\n",
      "INFO - 07/19/22 21:38:51 - 1:19:27 - Train Epoch 100: LOSS= 0.01908, lr= 0.000040, acc1= 99.16,acc3= 100.00,acc10= 100.00\n",
      "eval E100: 100% 87/87 [00:21<00:00,  4.09it/s]\n",
      "INFO - 07/19/22 21:39:12 - 1:19:48 - #################################################################################################################\n",
      "INFO - 07/19/22 21:39:12 - 1:19:48 - Test Epoch 100: LOSS= 6.14218, acc1= 47.10, acc3= 64.66, acc10= 77.87\n",
      "INFO - 07/19/22 21:39:12 - 1:19:48 - #################################################################################################################\n",
      "train E101: 100% 86/86 [00:22<00:00,  3.89it/s]\n",
      "INFO - 07/19/22 21:39:35 - 1:20:10 - Train Epoch 101: LOSS= 0.01613, lr= 0.000040, acc1= 99.42,acc3= 99.96,acc10= 99.96\n",
      "eval E101: 100% 87/87 [00:20<00:00,  4.34it/s]\n",
      "INFO - 07/19/22 21:39:55 - 1:20:30 - #################################################################################################################\n",
      "INFO - 07/19/22 21:39:55 - 1:20:30 - Test Epoch 101: LOSS= 6.05937, acc1= 47.79, acc3= 64.59, acc10= 78.16\n",
      "INFO - 07/19/22 21:39:55 - 1:20:30 - #################################################################################################################\n",
      "train E102: 100% 86/86 [00:23<00:00,  3.66it/s]\n",
      "INFO - 07/19/22 21:40:18 - 1:20:54 - Train Epoch 102: LOSS= 0.01586, lr= 0.000040, acc1= 99.38,acc3= 100.00,acc10= 100.00\n",
      "eval E102: 100% 87/87 [00:21<00:00,  4.01it/s]\n",
      "INFO - 07/19/22 21:40:40 - 1:21:16 - #################################################################################################################\n",
      "INFO - 07/19/22 21:40:40 - 1:21:16 - Test Epoch 102: LOSS= 6.11940, acc1= 47.24, acc3= 64.26, acc10= 78.16\n",
      "INFO - 07/19/22 21:40:40 - 1:21:16 - #################################################################################################################\n",
      "train E103: 100% 86/86 [00:25<00:00,  3.44it/s]\n",
      "INFO - 07/19/22 21:41:05 - 1:21:41 - Train Epoch 103: LOSS= 0.01778, lr= 0.000040, acc1= 99.23,acc3= 100.00,acc10= 100.00\n",
      "eval E103: 100% 87/87 [00:26<00:00,  3.34it/s]\n",
      "INFO - 07/19/22 21:41:31 - 1:22:07 - #################################################################################################################\n",
      "INFO - 07/19/22 21:41:31 - 1:22:07 - Test Epoch 103: LOSS= 6.37716, acc1= 47.35, acc3= 64.22, acc10= 77.98\n",
      "INFO - 07/19/22 21:41:31 - 1:22:07 - #################################################################################################################\n",
      "train E104: 100% 86/86 [00:27<00:00,  3.14it/s]\n",
      "INFO - 07/19/22 21:41:59 - 1:22:34 - Train Epoch 104: LOSS= 0.01371, lr= 0.000040, acc1= 99.42,acc3= 99.96,acc10= 100.00\n",
      "eval E104: 100% 87/87 [00:23<00:00,  3.68it/s]\n",
      "INFO - 07/19/22 21:42:22 - 1:22:58 - #################################################################################################################\n",
      "INFO - 07/19/22 21:42:22 - 1:22:58 - Test Epoch 104: LOSS= 6.35695, acc1= 47.42, acc3= 64.40, acc10= 78.30\n",
      "INFO - 07/19/22 21:42:22 - 1:22:58 - #################################################################################################################\n",
      "train E105: 100% 86/86 [00:24<00:00,  3.56it/s]\n",
      "INFO - 07/19/22 21:42:46 - 1:23:22 - Train Epoch 105: LOSS= 0.01640, lr= 0.000040, acc1= 99.20,acc3= 100.00,acc10= 100.00\n",
      "eval E105: 100% 87/87 [00:21<00:00,  4.10it/s]\n",
      "INFO - 07/19/22 21:43:08 - 1:23:43 - #################################################################################################################\n",
      "INFO - 07/19/22 21:43:08 - 1:23:43 - Test Epoch 105: LOSS= 6.33484, acc1= 47.24, acc3= 64.22, acc10= 78.37\n",
      "INFO - 07/19/22 21:43:08 - 1:23:43 - #################################################################################################################\n",
      "train E106: 100% 86/86 [00:22<00:00,  3.84it/s]\n",
      "INFO - 07/19/22 21:43:30 - 1:24:06 - Train Epoch 106: LOSS= 0.02576, lr= 0.000040, acc1= 99.16,acc3= 100.00,acc10= 100.00\n",
      "eval E106: 100% 87/87 [00:19<00:00,  4.52it/s]\n",
      "INFO - 07/19/22 21:43:49 - 1:24:25 - #################################################################################################################\n",
      "INFO - 07/19/22 21:43:49 - 1:24:25 - Test Epoch 106: LOSS= 6.21841, acc1= 47.42, acc3= 64.40, acc10= 78.23\n",
      "INFO - 07/19/22 21:43:49 - 1:24:25 - #################################################################################################################\n",
      "train E107: 100% 86/86 [00:21<00:00,  4.00it/s]\n",
      "INFO - 07/19/22 21:44:11 - 1:24:46 - Train Epoch 107: LOSS= 0.02538, lr= 0.000040, acc1= 99.12,acc3= 99.96,acc10= 100.00\n",
      "eval E107: 100% 87/87 [00:21<00:00,  4.04it/s]\n",
      "INFO - 07/19/22 21:44:32 - 1:25:08 - #################################################################################################################\n",
      "INFO - 07/19/22 21:44:32 - 1:25:08 - Test Epoch 107: LOSS= 6.16285, acc1= 47.57, acc3= 64.15, acc10= 78.30\n",
      "INFO - 07/19/22 21:44:32 - 1:25:08 - #################################################################################################################\n",
      "train E108: 100% 86/86 [00:25<00:00,  3.39it/s]\n",
      "INFO - 07/19/22 21:44:58 - 1:25:33 - Train Epoch 108: LOSS= 0.01545, lr= 0.000040, acc1= 99.27,acc3= 100.00,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E108: 100% 87/87 [00:24<00:00,  3.56it/s]\n",
      "INFO - 07/19/22 21:45:22 - 1:25:58 - #################################################################################################################\n",
      "INFO - 07/19/22 21:45:22 - 1:25:58 - Test Epoch 108: LOSS= 6.19665, acc1= 47.39, acc3= 64.44, acc10= 78.34\n",
      "INFO - 07/19/22 21:45:22 - 1:25:58 - #################################################################################################################\n",
      "train E109: 100% 86/86 [00:22<00:00,  3.75it/s]\n",
      "INFO - 07/19/22 21:45:45 - 1:26:21 - Train Epoch 109: LOSS= 0.02188, lr= 0.000040, acc1= 99.20,acc3= 99.93,acc10= 100.00\n",
      "eval E109: 100% 87/87 [00:21<00:00,  4.14it/s]\n",
      "INFO - 07/19/22 21:46:06 - 1:26:42 - #################################################################################################################\n",
      "INFO - 07/19/22 21:46:06 - 1:26:42 - Test Epoch 109: LOSS= 6.19921, acc1= 47.82, acc3= 64.37, acc10= 78.45\n",
      "INFO - 07/19/22 21:46:06 - 1:26:42 - #################################################################################################################\n",
      "train E110: 100% 86/86 [00:23<00:00,  3.72it/s]\n",
      "INFO - 07/19/22 21:46:29 - 1:27:05 - Train Epoch 110: LOSS= 0.01762, lr= 0.000040, acc1= 99.27,acc3= 100.00,acc10= 100.00\n",
      "eval E110: 100% 87/87 [00:21<00:00,  4.13it/s]\n",
      "INFO - 07/19/22 21:46:50 - 1:27:26 - #################################################################################################################\n",
      "INFO - 07/19/22 21:46:50 - 1:27:26 - Test Epoch 110: LOSS= 6.22796, acc1= 47.61, acc3= 64.44, acc10= 78.45\n",
      "INFO - 07/19/22 21:46:50 - 1:27:26 - #################################################################################################################\n",
      "train E111: 100% 86/86 [00:22<00:00,  3.85it/s]\n",
      "INFO - 07/19/22 21:47:13 - 1:27:48 - Train Epoch 111: LOSS= 0.01669, lr= 0.000040, acc1= 99.27,acc3= 100.00,acc10= 100.00\n",
      "eval E111: 100% 87/87 [00:19<00:00,  4.55it/s]\n",
      "INFO - 07/19/22 21:47:32 - 1:28:07 - #################################################################################################################\n",
      "INFO - 07/19/22 21:47:32 - 1:28:07 - Test Epoch 111: LOSS= 6.20305, acc1= 47.97, acc3= 64.48, acc10= 78.56\n",
      "INFO - 07/19/22 21:47:32 - 1:28:07 - #################################################################################################################\n",
      "train E112: 100% 86/86 [00:21<00:00,  3.94it/s]\n",
      "INFO - 07/19/22 21:47:54 - 1:28:29 - Train Epoch 112: LOSS= 0.01519, lr= 0.000040, acc1= 99.31,acc3= 99.96,acc10= 100.00\n",
      "eval E112: 100% 87/87 [00:19<00:00,  4.56it/s]\n",
      "INFO - 07/19/22 21:48:13 - 1:28:48 - #################################################################################################################\n",
      "INFO - 07/19/22 21:48:13 - 1:28:48 - Test Epoch 112: LOSS= 6.24810, acc1= 47.53, acc3= 64.22, acc10= 78.23\n",
      "INFO - 07/19/22 21:48:13 - 1:28:48 - #################################################################################################################\n",
      "train E113: 100% 86/86 [00:21<00:00,  3.95it/s]\n",
      "INFO - 07/19/22 21:48:35 - 1:29:10 - Train Epoch 113: LOSS= 0.01522, lr= 0.000040, acc1= 99.38,acc3= 100.00,acc10= 100.00\n",
      "eval E113: 100% 87/87 [00:21<00:00,  4.10it/s]\n",
      "INFO - 07/19/22 21:48:56 - 1:29:31 - #################################################################################################################\n",
      "INFO - 07/19/22 21:48:56 - 1:29:31 - Test Epoch 113: LOSS= 6.25545, acc1= 47.86, acc3= 64.55, acc10= 78.23\n",
      "INFO - 07/19/22 21:48:56 - 1:29:31 - #################################################################################################################\n",
      "train E114: 100% 86/86 [00:23<00:00,  3.72it/s]\n",
      "INFO - 07/19/22 21:49:19 - 1:29:55 - Train Epoch 114: LOSS= 0.01966, lr= 0.000040, acc1= 99.16,acc3= 99.96,acc10= 99.96\n",
      "eval E114: 100% 87/87 [00:21<00:00,  4.08it/s]\n",
      "INFO - 07/19/22 21:49:40 - 1:30:16 - #################################################################################################################\n",
      "INFO - 07/19/22 21:49:40 - 1:30:16 - Test Epoch 114: LOSS= 6.24297, acc1= 47.71, acc3= 64.40, acc10= 78.19\n",
      "INFO - 07/19/22 21:49:40 - 1:30:16 - #################################################################################################################\n",
      "train E115: 100% 86/86 [00:23<00:00,  3.74it/s]\n",
      "INFO - 07/19/22 21:50:03 - 1:30:39 - Train Epoch 115: LOSS= 0.01997, lr= 0.000040, acc1= 99.20,acc3= 99.96,acc10= 100.00\n",
      "eval E115: 100% 87/87 [00:21<00:00,  4.11it/s]\n",
      "INFO - 07/19/22 21:50:25 - 1:31:00 - #################################################################################################################\n",
      "INFO - 07/19/22 21:50:25 - 1:31:00 - Test Epoch 115: LOSS= 6.17637, acc1= 47.86, acc3= 64.37, acc10= 78.19\n",
      "INFO - 07/19/22 21:50:25 - 1:31:00 - #################################################################################################################\n",
      "train E116: 100% 86/86 [00:21<00:00,  3.93it/s]\n",
      "INFO - 07/19/22 21:50:47 - 1:31:22 - Train Epoch 116: LOSS= 0.02529, lr= 0.000040, acc1= 99.23,acc3= 100.00,acc10= 100.00\n",
      "eval E116: 100% 87/87 [00:19<00:00,  4.44it/s]\n",
      "INFO - 07/19/22 21:51:06 - 1:31:42 - #################################################################################################################\n",
      "INFO - 07/19/22 21:51:06 - 1:31:42 - Test Epoch 116: LOSS= 6.05421, acc1= 47.57, acc3= 64.40, acc10= 78.16\n",
      "INFO - 07/19/22 21:51:06 - 1:31:42 - #################################################################################################################\n",
      "train E117: 100% 86/86 [00:21<00:00,  4.05it/s]\n",
      "INFO - 07/19/22 21:51:27 - 1:32:03 - Train Epoch 117: LOSS= 0.01727, lr= 0.000040, acc1= 99.34,acc3= 100.00,acc10= 100.00\n",
      "eval E117: 100% 87/87 [00:18<00:00,  4.59it/s]\n",
      "INFO - 07/19/22 21:51:46 - 1:32:22 - #################################################################################################################\n",
      "INFO - 07/19/22 21:51:46 - 1:32:22 - Test Epoch 117: LOSS= 6.04706, acc1= 47.46, acc3= 64.01, acc10= 78.27\n",
      "INFO - 07/19/22 21:51:46 - 1:32:22 - #################################################################################################################\n",
      "train E118: 100% 86/86 [00:22<00:00,  3.82it/s]\n",
      "INFO - 07/19/22 21:52:09 - 1:32:44 - Train Epoch 118: LOSS= 0.01268, lr= 0.000040, acc1= 99.42,acc3= 100.00,acc10= 100.00\n",
      "eval E118: 100% 87/87 [00:20<00:00,  4.16it/s]\n",
      "INFO - 07/19/22 21:52:30 - 1:33:05 - #################################################################################################################\n",
      "INFO - 07/19/22 21:52:30 - 1:33:05 - Test Epoch 118: LOSS= 6.14486, acc1= 47.53, acc3= 64.04, acc10= 78.48\n",
      "INFO - 07/19/22 21:52:30 - 1:33:05 - #################################################################################################################\n",
      "train E119: 100% 86/86 [00:23<00:00,  3.63it/s]\n",
      "INFO - 07/19/22 21:52:54 - 1:33:29 - Train Epoch 119: LOSS= 0.01638, lr= 0.000040, acc1= 99.38,acc3= 100.00,acc10= 100.00\n",
      "eval E119: 100% 87/87 [00:21<00:00,  4.14it/s]\n",
      "INFO - 07/19/22 21:53:15 - 1:33:50 - #################################################################################################################\n",
      "INFO - 07/19/22 21:53:15 - 1:33:50 - Test Epoch 119: LOSS= 6.22723, acc1= 47.50, acc3= 63.57, acc10= 78.41\n",
      "INFO - 07/19/22 21:53:15 - 1:33:50 - #################################################################################################################\n",
      "train E120: 100% 86/86 [00:22<00:00,  3.78it/s]\n",
      "INFO - 07/19/22 21:53:37 - 1:34:13 - Train Epoch 120: LOSS= 0.01316, lr= 0.000040, acc1= 99.27,acc3= 100.00,acc10= 100.00\n",
      "eval E120: 100% 87/87 [00:19<00:00,  4.44it/s]\n",
      "INFO - 07/19/22 21:53:57 - 1:34:32 - #################################################################################################################\n",
      "INFO - 07/19/22 21:53:57 - 1:34:32 - Test Epoch 120: LOSS= 6.29242, acc1= 47.68, acc3= 63.35, acc10= 78.05\n",
      "INFO - 07/19/22 21:53:57 - 1:34:32 - #################################################################################################################\n",
      "train E121: 100% 86/86 [00:21<00:00,  3.99it/s]\n",
      "INFO - 07/19/22 21:54:18 - 1:34:54 - Train Epoch 121: LOSS= 0.01879, lr= 0.000040, acc1= 99.27,acc3= 100.00,acc10= 100.00\n",
      "eval E121: 100% 87/87 [00:19<00:00,  4.43it/s]\n",
      "INFO - 07/19/22 21:54:38 - 1:35:14 - #################################################################################################################\n",
      "INFO - 07/19/22 21:54:38 - 1:35:14 - Test Epoch 121: LOSS= 6.35673, acc1= 47.97, acc3= 63.86, acc10= 78.48\n",
      "INFO - 07/19/22 21:54:38 - 1:35:14 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E122: 100% 86/86 [00:21<00:00,  3.98it/s]\n",
      "INFO - 07/19/22 21:55:00 - 1:35:35 - Train Epoch 122: LOSS= 0.01376, lr= 0.000040, acc1= 99.27,acc3= 100.00,acc10= 100.00\n",
      "eval E122: 100% 87/87 [00:19<00:00,  4.36it/s]\n",
      "INFO - 07/19/22 21:55:20 - 1:35:55 - #################################################################################################################\n",
      "INFO - 07/19/22 21:55:20 - 1:35:55 - Test Epoch 122: LOSS= 6.28632, acc1= 47.64, acc3= 63.93, acc10= 78.05\n",
      "INFO - 07/19/22 21:55:20 - 1:35:55 - #################################################################################################################\n",
      "train E123: 100% 86/86 [00:23<00:00,  3.73it/s]\n",
      "INFO - 07/19/22 21:55:43 - 1:36:18 - Train Epoch 123: LOSS= 0.02141, lr= 0.000040, acc1= 99.23,acc3= 99.96,acc10= 100.00\n",
      "eval E123: 100% 87/87 [00:20<00:00,  4.31it/s]\n",
      "INFO - 07/19/22 21:56:03 - 1:36:38 - #################################################################################################################\n",
      "INFO - 07/19/22 21:56:03 - 1:36:38 - Test Epoch 123: LOSS= 6.24367, acc1= 47.50, acc3= 63.90, acc10= 77.83\n",
      "INFO - 07/19/22 21:56:03 - 1:36:38 - #################################################################################################################\n",
      "train E124: 100% 86/86 [00:22<00:00,  3.75it/s]\n",
      "INFO - 07/19/22 21:56:26 - 1:37:01 - Train Epoch 124: LOSS= 0.02268, lr= 0.000040, acc1= 99.23,acc3= 100.00,acc10= 100.00\n",
      "eval E124: 100% 87/87 [00:19<00:00,  4.38it/s]\n",
      "INFO - 07/19/22 21:56:46 - 1:37:21 - #################################################################################################################\n",
      "INFO - 07/19/22 21:56:46 - 1:37:21 - Test Epoch 124: LOSS= 6.28534, acc1= 47.02, acc3= 63.86, acc10= 77.94\n",
      "INFO - 07/19/22 21:56:46 - 1:37:21 - #################################################################################################################\n",
      "train E125: 100% 86/86 [00:22<00:00,  3.89it/s]\n",
      "INFO - 07/19/22 21:57:08 - 1:37:43 - Train Epoch 125: LOSS= 0.01560, lr= 0.000040, acc1= 99.34,acc3= 100.00,acc10= 100.00\n",
      "eval E125: 100% 87/87 [00:19<00:00,  4.49it/s]\n",
      "INFO - 07/19/22 21:57:27 - 1:38:03 - #################################################################################################################\n",
      "INFO - 07/19/22 21:57:27 - 1:38:03 - Test Epoch 125: LOSS= 6.28340, acc1= 47.28, acc3= 63.86, acc10= 77.90\n",
      "INFO - 07/19/22 21:57:27 - 1:38:03 - #################################################################################################################\n",
      "train E126: 100% 86/86 [00:21<00:00,  3.95it/s]\n",
      "INFO - 07/19/22 21:57:49 - 1:38:25 - Train Epoch 126: LOSS= 0.01515, lr= 0.000040, acc1= 99.20,acc3= 100.00,acc10= 100.00\n",
      "eval E126: 100% 87/87 [00:19<00:00,  4.52it/s]\n",
      "INFO - 07/19/22 21:58:08 - 1:38:44 - #################################################################################################################\n",
      "INFO - 07/19/22 21:58:08 - 1:38:44 - Test Epoch 126: LOSS= 6.30902, acc1= 47.31, acc3= 64.04, acc10= 78.16\n",
      "INFO - 07/19/22 21:58:08 - 1:38:44 - #################################################################################################################\n",
      "train E127: 100% 86/86 [00:22<00:00,  3.81it/s]\n",
      "INFO - 07/19/22 21:58:31 - 1:39:06 - Train Epoch 127: LOSS= 0.02012, lr= 0.000040, acc1= 99.20,acc3= 100.00,acc10= 100.00\n",
      "eval E127: 100% 87/87 [00:21<00:00,  4.13it/s]\n",
      "INFO - 07/19/22 21:58:52 - 1:39:27 - #################################################################################################################\n",
      "INFO - 07/19/22 21:58:52 - 1:39:27 - Test Epoch 127: LOSS= 6.21811, acc1= 47.21, acc3= 63.90, acc10= 78.27\n",
      "INFO - 07/19/22 21:58:52 - 1:39:27 - #################################################################################################################\n",
      "train E128: 100% 86/86 [00:23<00:00,  3.65it/s]\n",
      "INFO - 07/19/22 21:59:16 - 1:39:51 - Train Epoch 128: LOSS= 0.01493, lr= 0.000040, acc1= 99.34,acc3= 99.96,acc10= 100.00\n",
      "eval E128: 100% 87/87 [00:21<00:00,  4.10it/s]\n",
      "INFO - 07/19/22 21:59:37 - 1:40:12 - #################################################################################################################\n",
      "INFO - 07/19/22 21:59:37 - 1:40:12 - Test Epoch 128: LOSS= 6.29876, acc1= 47.28, acc3= 64.08, acc10= 78.45\n",
      "INFO - 07/19/22 21:59:37 - 1:40:12 - #################################################################################################################\n",
      "train E129: 100% 86/86 [00:22<00:00,  3.76it/s]\n",
      "INFO - 07/19/22 22:00:00 - 1:40:35 - Train Epoch 129: LOSS= 0.01259, lr= 0.000040, acc1= 99.45,acc3= 99.96,acc10= 100.00\n",
      "eval E129: 100% 87/87 [00:19<00:00,  4.49it/s]\n",
      "INFO - 07/19/22 22:00:19 - 1:40:55 - #################################################################################################################\n",
      "INFO - 07/19/22 22:00:19 - 1:40:55 - Test Epoch 129: LOSS= 6.36638, acc1= 47.10, acc3= 64.30, acc10= 78.27\n",
      "INFO - 07/19/22 22:00:19 - 1:40:55 - #################################################################################################################\n",
      "train E130: 100% 86/86 [00:21<00:00,  4.04it/s]\n",
      "INFO - 07/19/22 22:00:40 - 1:41:16 - Train Epoch 130: LOSS= 0.01656, lr= 0.000040, acc1= 99.31,acc3= 100.00,acc10= 100.00\n",
      "eval E130: 100% 87/87 [00:19<00:00,  4.57it/s]\n",
      "INFO - 07/19/22 22:00:59 - 1:41:35 - #################################################################################################################\n",
      "INFO - 07/19/22 22:00:59 - 1:41:35 - Test Epoch 130: LOSS= 6.44737, acc1= 47.21, acc3= 63.97, acc10= 77.90\n",
      "INFO - 07/19/22 22:00:59 - 1:41:35 - #################################################################################################################\n",
      "train E131: 100% 86/86 [00:21<00:00,  4.09it/s]\n",
      "INFO - 07/19/22 22:01:20 - 1:41:56 - Train Epoch 131: LOSS= 0.01965, lr= 0.000040, acc1= 99.20,acc3= 100.00,acc10= 100.00\n",
      "eval E131: 100% 87/87 [00:20<00:00,  4.33it/s]\n",
      "INFO - 07/19/22 22:01:41 - 1:42:16 - #################################################################################################################\n",
      "INFO - 07/19/22 22:01:41 - 1:42:16 - Test Epoch 131: LOSS= 6.23350, acc1= 48.00, acc3= 64.04, acc10= 77.87\n",
      "INFO - 07/19/22 22:01:41 - 1:42:16 - #################################################################################################################\n",
      "train E132: 100% 86/86 [00:22<00:00,  3.74it/s]\n",
      "INFO - 07/19/22 22:02:04 - 1:42:39 - Train Epoch 132: LOSS= 0.01543, lr= 0.000040, acc1= 99.27,acc3= 100.00,acc10= 100.00\n",
      "eval E132: 100% 87/87 [00:21<00:00,  4.10it/s]\n",
      "INFO - 07/19/22 22:02:25 - 1:43:00 - #################################################################################################################\n",
      "INFO - 07/19/22 22:02:25 - 1:43:00 - Test Epoch 132: LOSS= 6.29889, acc1= 47.50, acc3= 64.08, acc10= 78.01\n",
      "INFO - 07/19/22 22:02:25 - 1:43:00 - #################################################################################################################\n",
      "train E133: 100% 86/86 [00:23<00:00,  3.70it/s]\n",
      "INFO - 07/19/22 22:02:48 - 1:43:23 - Train Epoch 133: LOSS= 0.01911, lr= 0.000040, acc1= 99.09,acc3= 100.00,acc10= 100.00\n",
      "eval E133: 100% 87/87 [00:21<00:00,  4.03it/s]\n",
      "INFO - 07/19/22 22:03:10 - 1:43:45 - #################################################################################################################\n",
      "INFO - 07/19/22 22:03:10 - 1:43:45 - Test Epoch 133: LOSS= 6.26718, acc1= 47.24, acc3= 63.86, acc10= 77.94\n",
      "INFO - 07/19/22 22:03:10 - 1:43:45 - #################################################################################################################\n",
      "train E134: 100% 86/86 [00:22<00:00,  3.78it/s]\n",
      "INFO - 07/19/22 22:03:32 - 1:44:08 - Train Epoch 134: LOSS= 0.01776, lr= 0.000040, acc1= 99.05,acc3= 100.00,acc10= 100.00\n",
      "eval E134: 100% 87/87 [00:19<00:00,  4.50it/s]\n",
      "INFO - 07/19/22 22:03:52 - 1:44:27 - #################################################################################################################\n",
      "INFO - 07/19/22 22:03:52 - 1:44:27 - Test Epoch 134: LOSS= 6.21781, acc1= 47.31, acc3= 64.15, acc10= 78.08\n",
      "INFO - 07/19/22 22:03:52 - 1:44:27 - #################################################################################################################\n",
      "train E135: 100% 86/86 [00:21<00:00,  4.07it/s]\n",
      "INFO - 07/19/22 22:04:13 - 1:44:48 - Train Epoch 135: LOSS= 0.01850, lr= 0.000040, acc1= 99.16,acc3= 99.96,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E135: 100% 87/87 [00:19<00:00,  4.57it/s]\n",
      "INFO - 07/19/22 22:04:32 - 1:45:07 - #################################################################################################################\n",
      "INFO - 07/19/22 22:04:32 - 1:45:07 - Test Epoch 135: LOSS= 6.30505, acc1= 47.35, acc3= 64.40, acc10= 78.16\n",
      "INFO - 07/19/22 22:04:32 - 1:45:07 - #################################################################################################################\n",
      "train E136: 100% 86/86 [00:21<00:00,  4.08it/s]\n",
      "INFO - 07/19/22 22:04:53 - 1:45:28 - Train Epoch 136: LOSS= 0.02152, lr= 0.000040, acc1= 99.12,acc3= 100.00,acc10= 100.00\n",
      "eval E136: 100% 87/87 [00:20<00:00,  4.30it/s]\n",
      "INFO - 07/19/22 22:05:13 - 1:45:49 - #################################################################################################################\n",
      "INFO - 07/19/22 22:05:13 - 1:45:49 - Test Epoch 136: LOSS= 6.35034, acc1= 47.28, acc3= 64.40, acc10= 78.34\n",
      "INFO - 07/19/22 22:05:13 - 1:45:49 - #################################################################################################################\n",
      "train E137: 100% 86/86 [00:23<00:00,  3.72it/s]\n",
      "INFO - 07/19/22 22:05:36 - 1:46:12 - Train Epoch 137: LOSS= 0.01424, lr= 0.000040, acc1= 99.42,acc3= 100.00,acc10= 100.00\n",
      "eval E137: 100% 87/87 [00:20<00:00,  4.20it/s]\n",
      "INFO - 07/19/22 22:05:57 - 1:46:32 - #################################################################################################################\n",
      "INFO - 07/19/22 22:05:57 - 1:46:32 - Test Epoch 137: LOSS= 6.38706, acc1= 47.31, acc3= 64.40, acc10= 78.37\n",
      "INFO - 07/19/22 22:05:57 - 1:46:32 - #################################################################################################################\n",
      "train E138: 100% 86/86 [00:23<00:00,  3.71it/s]\n",
      "INFO - 07/19/22 22:06:20 - 1:46:56 - Train Epoch 138: LOSS= 0.01663, lr= 0.000040, acc1= 99.23,acc3= 100.00,acc10= 100.00\n",
      "eval E138: 100% 87/87 [00:21<00:00,  4.13it/s]\n",
      "INFO - 07/19/22 22:06:41 - 1:47:17 - #################################################################################################################\n",
      "INFO - 07/19/22 22:06:41 - 1:47:17 - Test Epoch 138: LOSS= 6.51571, acc1= 47.02, acc3= 64.22, acc10= 78.23\n",
      "INFO - 07/19/22 22:06:41 - 1:47:17 - #################################################################################################################\n",
      "train E139: 100% 86/86 [00:21<00:00,  4.07it/s]\n",
      "INFO - 07/19/22 22:07:02 - 1:47:38 - Train Epoch 139: LOSS= 0.01248, lr= 0.000040, acc1= 99.34,acc3= 100.00,acc10= 100.00\n",
      "eval E139: 100% 87/87 [00:19<00:00,  4.43it/s]\n",
      "INFO - 07/19/22 22:07:22 - 1:47:58 - #################################################################################################################\n",
      "INFO - 07/19/22 22:07:22 - 1:47:58 - Test Epoch 139: LOSS= 6.60175, acc1= 46.99, acc3= 64.22, acc10= 78.19\n",
      "INFO - 07/19/22 22:07:22 - 1:47:58 - #################################################################################################################\n",
      "train E140: 100% 86/86 [00:21<00:00,  3.95it/s]\n",
      "INFO - 07/19/22 22:07:44 - 1:48:19 - Train Epoch 140: LOSS= 0.01497, lr= 0.000040, acc1= 99.38,acc3= 100.00,acc10= 100.00\n",
      "eval E140: 100% 87/87 [00:18<00:00,  4.69it/s]\n",
      "INFO - 07/19/22 22:08:02 - 1:48:38 - #################################################################################################################\n",
      "INFO - 07/19/22 22:08:02 - 1:48:38 - Test Epoch 140: LOSS= 6.56399, acc1= 47.31, acc3= 63.82, acc10= 78.34\n",
      "INFO - 07/19/22 22:08:02 - 1:48:38 - #################################################################################################################\n",
      "train E141: 100% 86/86 [00:21<00:00,  3.96it/s]\n",
      "INFO - 07/19/22 22:08:24 - 1:49:00 - Train Epoch 141: LOSS= 0.01481, lr= 0.000040, acc1= 99.52,acc3= 100.00,acc10= 100.00\n",
      "eval E141: 100% 87/87 [00:20<00:00,  4.27it/s]\n",
      "INFO - 07/19/22 22:08:45 - 1:49:20 - #################################################################################################################\n",
      "INFO - 07/19/22 22:08:45 - 1:49:20 - Test Epoch 141: LOSS= 6.51417, acc1= 47.50, acc3= 64.04, acc10= 78.05\n",
      "INFO - 07/19/22 22:08:45 - 1:49:20 - #################################################################################################################\n",
      "INFO - 07/19/22 22:08:51 - 1:49:27 - best performance =  47.97, 64.48, 78.56. best epoch = 111, correspond_loss= 6.2031\n",
      "INFO - 07/19/22 22:08:51 - 1:49:27 -  fusion_model_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_answer_LXMERT_2.pkl\n",
      "INFO - 07/19/22 22:08:51 - 1:49:27 -  answer_net_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_answer_MLP_2.pkl\n"
     ]
    }
   ],
   "source": [
    "# object空间训练LXMERT\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=8 python main_lxmert.py --gpu_id 0 --exp_name answer_space --exp_id Lxmert --fusion_model LXMERT --data_choice 2 --method_choice W2V --batch_size 32  --save_model 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf411cf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-07-09T13:12:20.434Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 07/09/22 21:12:22 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 07/09/22 21:12:22 - 0:00:00 - The experiment will be stored in dump/0709-fact_space/W2V\n",
      "                                     \n",
      "INFO - 07/09/22 21:12:22 - 0:00:00 - Running command: python main_relation.py --gpu_id 2 --exp_name fact_space --exp_id W2V --fusion_model MLPQ --data_choice 5 --method_choice W2V --save_model 0 --fact_map 1\n",
      "\n",
      "2022-07-09 21:12:22.209208: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-09 21:12:22.209281: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 5\n",
      "batch_size 128\n",
      "batch_size 128\n",
      "fusion_model:\n",
      "MLPQ(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      "  (w_emb): WordEmbedding(\n",
      "    (emb): Embedding(15422, 300, padding_idx=15421)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (text): Seq2SeqRNN(\n",
      "    (rnn): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  )\n",
      ")\n",
      "Answer Model:\n",
      "MLP(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "train E000: 100% 432/432 [02:59<00:00,  2.40it/s]\n",
      "INFO - 07/09/22 21:15:59 - 0:03:38 - Train Epoch 0: LOSS= 3.28723, lr= 0.000500, acc1= 67.92,acc3= 73.32,acc10= 75.52\n",
      "train E001: 100% 432/432 [02:59<00:00,  2.41it/s]\n",
      "INFO - 07/09/22 21:18:59 - 0:06:37 - Train Epoch 1: LOSS= 1.59101, lr= 0.000750, acc1= 85.14,acc3= 87.46,acc10= 88.51\n",
      "eval E001: 100% 23/23 [00:19<00:00,  1.20it/s]\n",
      "INFO - 07/09/22 21:19:18 - 0:06:56 - #################################################################################################################\n",
      "INFO - 07/09/22 21:19:18 - 0:06:56 - Test Epoch 1: LOSS= 3.33045, acc1= 75.56, acc3= 78.82, acc10= 79.88\n",
      "INFO - 07/09/22 21:19:18 - 0:06:56 - #################################################################################################################\n",
      "train E002: 100% 432/432 [02:55<00:00,  2.46it/s]\n",
      "INFO - 07/09/22 21:22:13 - 0:09:52 - Train Epoch 2: LOSS= 1.33443, lr= 0.001000, acc1= 86.85,acc3= 88.58,acc10= 89.44\n",
      "eval E002: 100% 23/23 [00:08<00:00,  2.71it/s]\n",
      "INFO - 07/09/22 21:22:22 - 0:10:00 - #################################################################################################################\n",
      "INFO - 07/09/22 21:22:22 - 0:10:00 - Test Epoch 2: LOSS= 3.45134, acc1= 75.81, acc3= 78.96, acc10= 80.45\n",
      "INFO - 07/09/22 21:22:22 - 0:10:00 - #################################################################################################################\n",
      "train E003: 100% 432/432 [02:57<00:00,  2.43it/s]\n",
      "INFO - 07/09/22 21:25:20 - 0:12:58 - Train Epoch 3: LOSS= 1.26874, lr= 0.001250, acc1= 87.19,acc3= 88.87,acc10= 89.74\n",
      "eval E003: 100% 23/23 [00:08<00:00,  2.58it/s]\n",
      "INFO - 07/09/22 21:25:28 - 0:13:07 - #################################################################################################################\n",
      "INFO - 07/09/22 21:25:28 - 0:13:07 - Test Epoch 3: LOSS= 4.03382, acc1= 75.70, acc3= 78.71, acc10= 79.56\n",
      "INFO - 07/09/22 21:25:28 - 0:13:07 - #################################################################################################################\n",
      "train E004: 100% 432/432 [02:59<00:00,  2.41it/s]\n",
      "INFO - 07/09/22 21:28:28 - 0:16:06 - Train Epoch 4: LOSS= 1.25845, lr= 0.001500, acc1= 87.31,acc3= 88.91,acc10= 89.86\n",
      "eval E004: 100% 23/23 [00:08<00:00,  2.60it/s]\n",
      "INFO - 07/09/22 21:28:36 - 0:16:15 - #################################################################################################################\n",
      "INFO - 07/09/22 21:28:36 - 0:16:15 - Test Epoch 4: LOSS= 4.20279, acc1= 75.35, acc3= 78.14, acc10= 79.84\n",
      "INFO - 07/09/22 21:28:36 - 0:16:15 - #################################################################################################################\n",
      "train E005: 100% 432/432 [02:58<00:00,  2.42it/s]\n",
      "INFO - 07/09/22 21:31:35 - 0:19:14 - Train Epoch 5: LOSS= 1.28456, lr= 0.001750, acc1= 87.26,acc3= 88.91,acc10= 89.78\n",
      "eval E005: 100% 23/23 [00:08<00:00,  2.67it/s]\n",
      "INFO - 07/09/22 21:31:44 - 0:19:22 - #################################################################################################################\n",
      "INFO - 07/09/22 21:31:44 - 0:19:22 - Test Epoch 5: LOSS= 4.42535, acc1= 75.20, acc3= 78.21, acc10= 79.84\n",
      "INFO - 07/09/22 21:31:44 - 0:19:22 - #################################################################################################################\n",
      "train E006: 100% 432/432 [02:58<00:00,  2.41it/s]\n",
      "INFO - 07/09/22 21:34:43 - 0:22:21 - Train Epoch 6: LOSS= 1.30072, lr= 0.002000, acc1= 87.29,acc3= 88.98,acc10= 89.87\n",
      "eval E006: 100% 23/23 [00:08<00:00,  2.68it/s]\n",
      "INFO - 07/09/22 21:34:52 - 0:22:30 - #################################################################################################################\n",
      "INFO - 07/09/22 21:34:52 - 0:22:30 - Test Epoch 6: LOSS= 5.05295, acc1= 74.92, acc3= 78.18, acc10= 79.35\n",
      "INFO - 07/09/22 21:34:52 - 0:22:30 - #################################################################################################################\n",
      "train E007: 100% 432/432 [03:00<00:00,  2.39it/s]\n",
      "INFO - 07/09/22 21:37:52 - 0:25:31 - Train Epoch 7: LOSS= 1.24997, lr= 0.002000, acc1= 87.58,acc3= 89.17,acc10= 90.02\n",
      "eval E007: 100% 23/23 [00:08<00:00,  2.68it/s]\n",
      "INFO - 07/09/22 21:38:01 - 0:25:39 - #################################################################################################################\n",
      "INFO - 07/09/22 21:38:01 - 0:25:39 - Test Epoch 7: LOSS= 5.54884, acc1= 74.78, acc3= 78.21, acc10= 79.49\n",
      "INFO - 07/09/22 21:38:01 - 0:25:39 - #################################################################################################################\n",
      "train E008: 100% 432/432 [03:01<00:00,  2.38it/s]\n",
      "INFO - 07/09/22 21:41:03 - 0:28:41 - Train Epoch 8: LOSS= 1.18928, lr= 0.002000, acc1= 87.76,acc3= 89.23,acc10= 90.11\n",
      "eval E008: 100% 23/23 [00:08<00:00,  2.65it/s]\n",
      "INFO - 07/09/22 21:41:11 - 0:28:50 - #################################################################################################################\n",
      "INFO - 07/09/22 21:41:11 - 0:28:50 - Test Epoch 8: LOSS= 5.81026, acc1= 75.13, acc3= 78.82, acc10= 80.09\n",
      "INFO - 07/09/22 21:41:11 - 0:28:50 - #################################################################################################################\n",
      "train E009: 100% 432/432 [02:58<00:00,  2.42it/s]\n",
      "INFO - 07/09/22 21:44:10 - 0:31:48 - Train Epoch 9: LOSS= 1.16529, lr= 0.002000, acc1= 87.92,acc3= 89.39,acc10= 90.30\n",
      "eval E009: 100% 23/23 [00:08<00:00,  2.72it/s]\n",
      "INFO - 07/09/22 21:44:18 - 0:31:56 - #################################################################################################################\n",
      "INFO - 07/09/22 21:44:18 - 0:31:56 - Test Epoch 9: LOSS= 5.84867, acc1= 74.35, acc3= 78.25, acc10= 79.49\n",
      "INFO - 07/09/22 21:44:18 - 0:31:56 - #################################################################################################################\n",
      "train E010: 100% 432/432 [02:56<00:00,  2.45it/s]\n",
      "INFO - 07/09/22 21:47:14 - 0:34:53 - Train Epoch 10: LOSS= 1.13832, lr= 0.002000, acc1= 88.03,acc3= 89.38,acc10= 90.22\n",
      "eval E010: 100% 23/23 [00:08<00:00,  2.69it/s]\n",
      "INFO - 07/09/22 21:47:23 - 0:35:01 - #################################################################################################################\n",
      "INFO - 07/09/22 21:47:23 - 0:35:01 - Test Epoch 10: LOSS= 6.64932, acc1= 74.96, acc3= 78.00, acc10= 79.42\n",
      "INFO - 07/09/22 21:47:23 - 0:35:01 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E011:  93% 401/432 [02:44<00:12,  2.51it/s]"
     ]
    }
   ],
   "source": [
    "# entity空间训练 MLPQ\n",
    "%cd code\n",
    "!python main_relation.py --gpu_id 2 --exp_name fact_space --exp_id W2V --fusion_model MLPQ --data_choice 5 --method_choice W2V  --save_model 0 --fact_map 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8e0eceb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T15:17:22.712312Z",
     "start_time": "2022-07-08T15:16:44.868908Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 07/08/22 23:16:46 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 07/08/22 23:16:46 - 0:00:00 - The experiment will be stored in dump/0708-relation_space/W2V\n",
      "                                     \n",
      "INFO - 07/08/22 23:16:46 - 0:00:00 - Running command: python main_bert.py --gpu_id 8 --exp_name relation_space --exp_id W2V --fusion_model BERT --data_choice 3 --method_choice W2V --save_model 0 --batch_size 32 --relation_map 1\n",
      "\n",
      "2022-07-08 23:16:46.612170: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-08 23:16:46.612226: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 32\n",
      "batch_size 32\n",
      "INFO - 07/08/22 23:16:57 - 0:00:11 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO - 07/08/22 23:16:57 - 0:00:11 - extracting archive file /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp_3snq8mr\n",
      "embeddings.word_embeddings.weight:\tFalse\n",
      "embeddings.position_embeddings.weight:\tFalse\n",
      "embeddings.token_type_embeddings.weight:\tFalse\n",
      "embeddings.LayerNorm.weight:\tFalse\n",
      "embeddings.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.attention.self.query.weight:\tFalse\n",
      "encoder.layer.0.attention.self.query.bias:\tFalse\n",
      "encoder.layer.0.attention.self.key.weight:\tFalse\n",
      "encoder.layer.0.attention.self.key.bias:\tFalse\n",
      "encoder.layer.0.attention.self.value.weight:\tFalse\n",
      "encoder.layer.0.attention.self.value.bias:\tFalse\n",
      "encoder.layer.0.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.0.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.0.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.0.output.dense.weight:\tFalse\n",
      "encoder.layer.0.output.dense.bias:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.attention.self.query.weight:\tFalse\n",
      "encoder.layer.1.attention.self.query.bias:\tFalse\n",
      "encoder.layer.1.attention.self.key.weight:\tFalse\n",
      "encoder.layer.1.attention.self.key.bias:\tFalse\n",
      "encoder.layer.1.attention.self.value.weight:\tFalse\n",
      "encoder.layer.1.attention.self.value.bias:\tFalse\n",
      "encoder.layer.1.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.1.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.1.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.1.output.dense.weight:\tFalse\n",
      "encoder.layer.1.output.dense.bias:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.attention.self.query.weight:\tFalse\n",
      "encoder.layer.2.attention.self.query.bias:\tFalse\n",
      "encoder.layer.2.attention.self.key.weight:\tFalse\n",
      "encoder.layer.2.attention.self.key.bias:\tFalse\n",
      "encoder.layer.2.attention.self.value.weight:\tFalse\n",
      "encoder.layer.2.attention.self.value.bias:\tFalse\n",
      "encoder.layer.2.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.2.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.2.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.2.output.dense.weight:\tFalse\n",
      "encoder.layer.2.output.dense.bias:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.attention.self.query.weight:\tFalse\n",
      "encoder.layer.3.attention.self.query.bias:\tFalse\n",
      "encoder.layer.3.attention.self.key.weight:\tFalse\n",
      "encoder.layer.3.attention.self.key.bias:\tFalse\n",
      "encoder.layer.3.attention.self.value.weight:\tFalse\n",
      "encoder.layer.3.attention.self.value.bias:\tFalse\n",
      "encoder.layer.3.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.3.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.3.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.3.output.dense.weight:\tFalse\n",
      "encoder.layer.3.output.dense.bias:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.attention.self.query.weight:\tFalse\n",
      "encoder.layer.4.attention.self.query.bias:\tFalse\n",
      "encoder.layer.4.attention.self.key.weight:\tFalse\n",
      "encoder.layer.4.attention.self.key.bias:\tFalse\n",
      "encoder.layer.4.attention.self.value.weight:\tFalse\n",
      "encoder.layer.4.attention.self.value.bias:\tFalse\n",
      "encoder.layer.4.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.4.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.4.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.4.output.dense.weight:\tFalse\n",
      "encoder.layer.4.output.dense.bias:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.attention.self.query.weight:\tFalse\n",
      "encoder.layer.5.attention.self.query.bias:\tFalse\n",
      "encoder.layer.5.attention.self.key.weight:\tFalse\n",
      "encoder.layer.5.attention.self.key.bias:\tFalse\n",
      "encoder.layer.5.attention.self.value.weight:\tFalse\n",
      "encoder.layer.5.attention.self.value.bias:\tFalse\n",
      "encoder.layer.5.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.5.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.5.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.5.output.dense.weight:\tFalse\n",
      "encoder.layer.5.output.dense.bias:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.attention.self.query.weight:\tFalse\n",
      "encoder.layer.6.attention.self.query.bias:\tFalse\n",
      "encoder.layer.6.attention.self.key.weight:\tFalse\n",
      "encoder.layer.6.attention.self.key.bias:\tFalse\n",
      "encoder.layer.6.attention.self.value.weight:\tFalse\n",
      "encoder.layer.6.attention.self.value.bias:\tFalse\n",
      "encoder.layer.6.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.6.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.6.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.6.output.dense.weight:\tFalse\n",
      "encoder.layer.6.output.dense.bias:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.attention.self.query.weight:\tFalse\n",
      "encoder.layer.7.attention.self.query.bias:\tFalse\n",
      "encoder.layer.7.attention.self.key.weight:\tFalse\n",
      "encoder.layer.7.attention.self.key.bias:\tFalse\n",
      "encoder.layer.7.attention.self.value.weight:\tFalse\n",
      "encoder.layer.7.attention.self.value.bias:\tFalse\n",
      "encoder.layer.7.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.7.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.7.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.7.output.dense.weight:\tFalse\n",
      "encoder.layer.7.output.dense.bias:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.attention.self.query.weight:\tFalse\n",
      "encoder.layer.8.attention.self.query.bias:\tFalse\n",
      "encoder.layer.8.attention.self.key.weight:\tFalse\n",
      "encoder.layer.8.attention.self.key.bias:\tFalse\n",
      "encoder.layer.8.attention.self.value.weight:\tFalse\n",
      "encoder.layer.8.attention.self.value.bias:\tFalse\n",
      "encoder.layer.8.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.8.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.8.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.8.output.dense.weight:\tFalse\n",
      "encoder.layer.8.output.dense.bias:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.attention.self.query.weight:\tFalse\n",
      "encoder.layer.9.attention.self.query.bias:\tFalse\n",
      "encoder.layer.9.attention.self.key.weight:\tFalse\n",
      "encoder.layer.9.attention.self.key.bias:\tFalse\n",
      "encoder.layer.9.attention.self.value.weight:\tFalse\n",
      "encoder.layer.9.attention.self.value.bias:\tFalse\n",
      "encoder.layer.9.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.9.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.9.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.9.output.dense.weight:\tFalse\n",
      "encoder.layer.9.output.dense.bias:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.attention.self.query.weight:\tFalse\n",
      "encoder.layer.10.attention.self.query.bias:\tFalse\n",
      "encoder.layer.10.attention.self.key.weight:\tFalse\n",
      "encoder.layer.10.attention.self.key.bias:\tFalse\n",
      "encoder.layer.10.attention.self.value.weight:\tFalse\n",
      "encoder.layer.10.attention.self.value.bias:\tFalse\n",
      "encoder.layer.10.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.10.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.10.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.10.output.dense.weight:\tFalse\n",
      "encoder.layer.10.output.dense.bias:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.attention.self.query.weight:\tFalse\n",
      "encoder.layer.11.attention.self.query.bias:\tFalse\n",
      "encoder.layer.11.attention.self.key.weight:\tFalse\n",
      "encoder.layer.11.attention.self.key.bias:\tFalse\n",
      "encoder.layer.11.attention.self.value.weight:\tFalse\n",
      "encoder.layer.11.attention.self.value.bias:\tFalse\n",
      "encoder.layer.11.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.11.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.11.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.11.output.dense.weight:\tFalse\n",
      "encoder.layer.11.output.dense.bias:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.bias:\tFalse\n",
      "pooler.dense.weight:\tTrue\n",
      "pooler.dense.bias:\tTrue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "# entity空间训练 BERT\n",
    "%cd code\n",
    "!python main_bert.py --gpu_id 8 --exp_name relation_space --exp_id W2V --fusion_model BERT --data_choice 3 --method_choice W2V  --save_model 0 --batch_size 32 --relation_map 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "920b5e4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T11:43:49.646182Z",
     "start_time": "2022-07-16T11:43:10.568689Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 07/16/22 19:43:12 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 07/16/22 19:43:12 - 0:00:00 - The experiment will be stored in dump/0716-fact_space/bert\n",
      "                                     \n",
      "INFO - 07/16/22 19:43:12 - 0:00:00 - Running command: python main_bert.py --gpu_id 8 --exp_name fact_space --exp_id bert --fusion_model BERT --data_choice 5 --method_choice W2V --save_model 0 --now_test 1 --fact_map 1\n",
      "\n",
      "2022-07-16 19:43:12.506606: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-16 19:43:12.506670: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 5\n",
      "batch_size 128\n",
      "batch_size 128\n",
      "INFO - 07/16/22 19:43:32 - 0:00:21 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO - 07/16/22 19:43:32 - 0:00:21 - extracting archive file /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpp1dkt8o3\n",
      "embeddings.word_embeddings.weight:\tFalse\n",
      "embeddings.position_embeddings.weight:\tFalse\n",
      "embeddings.token_type_embeddings.weight:\tFalse\n",
      "embeddings.LayerNorm.weight:\tFalse\n",
      "embeddings.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.attention.self.query.weight:\tFalse\n",
      "encoder.layer.0.attention.self.query.bias:\tFalse\n",
      "encoder.layer.0.attention.self.key.weight:\tFalse\n",
      "encoder.layer.0.attention.self.key.bias:\tFalse\n",
      "encoder.layer.0.attention.self.value.weight:\tFalse\n",
      "encoder.layer.0.attention.self.value.bias:\tFalse\n",
      "encoder.layer.0.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.0.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.0.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.0.output.dense.weight:\tFalse\n",
      "encoder.layer.0.output.dense.bias:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.attention.self.query.weight:\tFalse\n",
      "encoder.layer.1.attention.self.query.bias:\tFalse\n",
      "encoder.layer.1.attention.self.key.weight:\tFalse\n",
      "encoder.layer.1.attention.self.key.bias:\tFalse\n",
      "encoder.layer.1.attention.self.value.weight:\tFalse\n",
      "encoder.layer.1.attention.self.value.bias:\tFalse\n",
      "encoder.layer.1.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.1.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.1.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.1.output.dense.weight:\tFalse\n",
      "encoder.layer.1.output.dense.bias:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.attention.self.query.weight:\tFalse\n",
      "encoder.layer.2.attention.self.query.bias:\tFalse\n",
      "encoder.layer.2.attention.self.key.weight:\tFalse\n",
      "encoder.layer.2.attention.self.key.bias:\tFalse\n",
      "encoder.layer.2.attention.self.value.weight:\tFalse\n",
      "encoder.layer.2.attention.self.value.bias:\tFalse\n",
      "encoder.layer.2.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.2.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.2.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.2.output.dense.weight:\tFalse\n",
      "encoder.layer.2.output.dense.bias:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.attention.self.query.weight:\tFalse\n",
      "encoder.layer.3.attention.self.query.bias:\tFalse\n",
      "encoder.layer.3.attention.self.key.weight:\tFalse\n",
      "encoder.layer.3.attention.self.key.bias:\tFalse\n",
      "encoder.layer.3.attention.self.value.weight:\tFalse\n",
      "encoder.layer.3.attention.self.value.bias:\tFalse\n",
      "encoder.layer.3.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.3.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.3.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.3.output.dense.weight:\tFalse\n",
      "encoder.layer.3.output.dense.bias:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.attention.self.query.weight:\tFalse\n",
      "encoder.layer.4.attention.self.query.bias:\tFalse\n",
      "encoder.layer.4.attention.self.key.weight:\tFalse\n",
      "encoder.layer.4.attention.self.key.bias:\tFalse\n",
      "encoder.layer.4.attention.self.value.weight:\tFalse\n",
      "encoder.layer.4.attention.self.value.bias:\tFalse\n",
      "encoder.layer.4.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.4.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.4.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.4.output.dense.weight:\tFalse\n",
      "encoder.layer.4.output.dense.bias:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.attention.self.query.weight:\tFalse\n",
      "encoder.layer.5.attention.self.query.bias:\tFalse\n",
      "encoder.layer.5.attention.self.key.weight:\tFalse\n",
      "encoder.layer.5.attention.self.key.bias:\tFalse\n",
      "encoder.layer.5.attention.self.value.weight:\tFalse\n",
      "encoder.layer.5.attention.self.value.bias:\tFalse\n",
      "encoder.layer.5.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.5.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.5.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.5.output.dense.weight:\tFalse\n",
      "encoder.layer.5.output.dense.bias:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.attention.self.query.weight:\tFalse\n",
      "encoder.layer.6.attention.self.query.bias:\tFalse\n",
      "encoder.layer.6.attention.self.key.weight:\tFalse\n",
      "encoder.layer.6.attention.self.key.bias:\tFalse\n",
      "encoder.layer.6.attention.self.value.weight:\tFalse\n",
      "encoder.layer.6.attention.self.value.bias:\tFalse\n",
      "encoder.layer.6.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.6.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.6.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.6.output.dense.weight:\tFalse\n",
      "encoder.layer.6.output.dense.bias:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.attention.self.query.weight:\tFalse\n",
      "encoder.layer.7.attention.self.query.bias:\tFalse\n",
      "encoder.layer.7.attention.self.key.weight:\tFalse\n",
      "encoder.layer.7.attention.self.key.bias:\tFalse\n",
      "encoder.layer.7.attention.self.value.weight:\tFalse\n",
      "encoder.layer.7.attention.self.value.bias:\tFalse\n",
      "encoder.layer.7.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.7.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.7.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.7.output.dense.weight:\tFalse\n",
      "encoder.layer.7.output.dense.bias:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.attention.self.query.weight:\tFalse\n",
      "encoder.layer.8.attention.self.query.bias:\tFalse\n",
      "encoder.layer.8.attention.self.key.weight:\tFalse\n",
      "encoder.layer.8.attention.self.key.bias:\tFalse\n",
      "encoder.layer.8.attention.self.value.weight:\tFalse\n",
      "encoder.layer.8.attention.self.value.bias:\tFalse\n",
      "encoder.layer.8.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.8.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.8.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.8.output.dense.weight:\tFalse\n",
      "encoder.layer.8.output.dense.bias:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.attention.self.query.weight:\tFalse\n",
      "encoder.layer.9.attention.self.query.bias:\tFalse\n",
      "encoder.layer.9.attention.self.key.weight:\tFalse\n",
      "encoder.layer.9.attention.self.key.bias:\tFalse\n",
      "encoder.layer.9.attention.self.value.weight:\tFalse\n",
      "encoder.layer.9.attention.self.value.bias:\tFalse\n",
      "encoder.layer.9.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.9.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.9.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.9.output.dense.weight:\tFalse\n",
      "encoder.layer.9.output.dense.bias:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.attention.self.query.weight:\tFalse\n",
      "encoder.layer.10.attention.self.query.bias:\tFalse\n",
      "encoder.layer.10.attention.self.key.weight:\tFalse\n",
      "encoder.layer.10.attention.self.key.bias:\tFalse\n",
      "encoder.layer.10.attention.self.value.weight:\tFalse\n",
      "encoder.layer.10.attention.self.value.bias:\tFalse\n",
      "encoder.layer.10.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.10.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.10.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.10.output.dense.weight:\tFalse\n",
      "encoder.layer.10.output.dense.bias:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.attention.self.query.weight:\tFalse\n",
      "encoder.layer.11.attention.self.query.bias:\tFalse\n",
      "encoder.layer.11.attention.self.key.weight:\tFalse\n",
      "encoder.layer.11.attention.self.key.bias:\tFalse\n",
      "encoder.layer.11.attention.self.value.weight:\tFalse\n",
      "encoder.layer.11.attention.self.value.bias:\tFalse\n",
      "encoder.layer.11.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.11.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.11.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.11.output.dense.weight:\tFalse\n",
      "encoder.layer.11.output.dense.bias:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.bias:\tFalse\n",
      "pooler.dense.weight:\tFalse\n",
      "pooler.dense.bias:\tFalse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fusion_model:\n",
      "BERT(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): BertLayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(768, 8192, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(8192, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      "  (fc): SimpleClassifier(\n",
      "    (main): Sequential(\n",
      "      (0): Linear(in_features=768, out_features=4096, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.5, inplace=True)\n",
      "      (3): Linear(in_features=4096, out_features=2791, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Answer Model:\n",
      "MLP(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "begin test! ...\n",
      "loading model  ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"main_bert.py\", line 386, in <module>\r\n",
      "    runner = Runner(cfg)\r\n",
      "  File \"main_bert.py\", line 88, in __init__\r\n",
      "    self._load_model(self.fusion_model, \"fusion\")\r\n",
      "  File \"main_bert.py\", line 342, in _load_model\r\n",
      "    model.load_state_dict(torch.load(save_path))\r\n",
      "  File \"/root/anaconda3/envs/ZS-F-VQA/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1045, in load_state_dict\r\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\r\n",
      "RuntimeError: Error(s) in loading state_dict for BERT:\r\n",
      "\tMissing key(s) in state_dict: \"bert.embeddings.word_embeddings.weight\", \"bert.embeddings.position_embeddings.weight\", \"bert.embeddings.token_type_embeddings.weight\", \"bert.embeddings.LayerNorm.weight\", \"bert.embeddings.LayerNorm.bias\", \"bert.encoder.layer.0.attention.self.query.weight\", \"bert.encoder.layer.0.attention.self.query.bias\", \"bert.encoder.layer.0.attention.self.key.weight\", \"bert.encoder.layer.0.attention.self.key.bias\", \"bert.encoder.layer.0.attention.self.value.weight\", \"bert.encoder.layer.0.attention.self.value.bias\", \"bert.encoder.layer.0.attention.output.dense.weight\", \"bert.encoder.layer.0.attention.output.dense.bias\", \"bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.encoder.layer.0.intermediate.dense.weight\", \"bert.encoder.layer.0.intermediate.dense.bias\", \"bert.encoder.layer.0.output.dense.weight\", \"bert.encoder.layer.0.output.dense.bias\", \"bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.encoder.layer.1.attention.self.query.weight\", \"bert.encoder.layer.1.attention.self.query.bias\", \"bert.encoder.layer.1.attention.self.key.weight\", \"bert.encoder.layer.1.attention.self.key.bias\", \"bert.encoder.layer.1.attention.self.value.weight\", \"bert.encoder.layer.1.attention.self.value.bias\", \"bert.encoder.layer.1.attention.output.dense.weight\", \"bert.encoder.layer.1.attention.output.dense.bias\", \"bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.encoder.layer.1.intermediate.dense.weight\", \"bert.encoder.layer.1.intermediate.dense.bias\", \"bert.encoder.layer.1.output.dense.weight\", \"bert.encoder.layer.1.output.dense.bias\", \"bert.encoder.layer.1.output.LayerNorm.weight\", \"bert.encoder.layer.1.output.LayerNorm.bias\", \"bert.encoder.layer.2.attention.self.query.weight\", \"bert.encoder.layer.2.attention.self.query.bias\", \"bert.encoder.layer.2.attention.self.key.weight\", \"bert.encoder.layer.2.attention.self.key.bias\", \"bert.encoder.layer.2.attention.self.value.weight\", \"bert.encoder.layer.2.attention.self.value.bias\", \"bert.encoder.layer.2.attention.output.dense.weight\", \"bert.encoder.layer.2.attention.output.dense.bias\", \"bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.encoder.layer.2.intermediate.dense.weight\", \"bert.encoder.layer.2.intermediate.dense.bias\", \"bert.encoder.layer.2.output.dense.weight\", \"bert.encoder.layer.2.output.dense.bias\", \"bert.encoder.layer.2.output.LayerNorm.weight\", \"bert.encoder.layer.2.output.LayerNorm.bias\", \"bert.encoder.layer.3.attention.self.query.weight\", \"bert.encoder.layer.3.attention.self.query.bias\", \"bert.encoder.layer.3.attention.self.key.weight\", \"bert.encoder.layer.3.attention.self.key.bias\", \"bert.encoder.layer.3.attention.self.value.weight\", \"bert.encoder.layer.3.attention.self.value.bias\", \"bert.encoder.layer.3.attention.output.dense.weight\", \"bert.encoder.layer.3.attention.output.dense.bias\", \"bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.encoder.layer.3.intermediate.dense.weight\", \"bert.encoder.layer.3.intermediate.dense.bias\", \"bert.encoder.layer.3.output.dense.weight\", \"bert.encoder.layer.3.output.dense.bias\", \"bert.encoder.layer.3.output.LayerNorm.weight\", \"bert.encoder.layer.3.output.LayerNorm.bias\", \"bert.encoder.layer.4.attention.self.query.weight\", \"bert.encoder.layer.4.attention.self.query.bias\", \"bert.encoder.layer.4.attention.self.key.weight\", \"bert.encoder.layer.4.attention.self.key.bias\", \"bert.encoder.layer.4.attention.self.value.weight\", \"bert.encoder.layer.4.attention.self.value.bias\", \"bert.encoder.layer.4.attention.output.dense.weight\", \"bert.encoder.layer.4.attention.output.dense.bias\", \"bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"bert.encoder.layer.4.intermediate.dense.weight\", \"bert.encoder.layer.4.intermediate.dense.bias\", \"bert.encoder.layer.4.output.dense.weight\", \"bert.encoder.layer.4.output.dense.bias\", \"bert.encoder.layer.4.output.LayerNorm.weight\", \"bert.encoder.layer.4.output.LayerNorm.bias\", \"bert.encoder.layer.5.attention.self.query.weight\", \"bert.encoder.layer.5.attention.self.query.bias\", \"bert.encoder.layer.5.attention.self.key.weight\", \"bert.encoder.layer.5.attention.self.key.bias\", \"bert.encoder.layer.5.attention.self.value.weight\", \"bert.encoder.layer.5.attention.self.value.bias\", \"bert.encoder.layer.5.attention.output.dense.weight\", \"bert.encoder.layer.5.attention.output.dense.bias\", \"bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"bert.encoder.layer.5.intermediate.dense.weight\", \"bert.encoder.layer.5.intermediate.dense.bias\", \"bert.encoder.layer.5.output.dense.weight\", \"bert.encoder.layer.5.output.dense.bias\", \"bert.encoder.layer.5.output.LayerNorm.weight\", \"bert.encoder.layer.5.output.LayerNorm.bias\", \"bert.encoder.layer.6.attention.self.query.weight\", \"bert.encoder.layer.6.attention.self.query.bias\", \"bert.encoder.layer.6.attention.self.key.weight\", \"bert.encoder.layer.6.attention.self.key.bias\", \"bert.encoder.layer.6.attention.self.value.weight\", \"bert.encoder.layer.6.attention.self.value.bias\", \"bert.encoder.layer.6.attention.output.dense.weight\", \"bert.encoder.layer.6.attention.output.dense.bias\", \"bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"bert.encoder.layer.6.intermediate.dense.weight\", \"bert.encoder.layer.6.intermediate.dense.bias\", \"bert.encoder.layer.6.output.dense.weight\", \"bert.encoder.layer.6.output.dense.bias\", \"bert.encoder.layer.6.output.LayerNorm.weight\", \"bert.encoder.layer.6.output.LayerNorm.bias\", \"bert.encoder.layer.7.attention.self.query.weight\", \"bert.encoder.layer.7.attention.self.query.bias\", \"bert.encoder.layer.7.attention.self.key.weight\", \"bert.encoder.layer.7.attention.self.key.bias\", \"bert.encoder.layer.7.attention.self.value.weight\", \"bert.encoder.layer.7.attention.self.value.bias\", \"bert.encoder.layer.7.attention.output.dense.weight\", \"bert.encoder.layer.7.attention.output.dense.bias\", \"bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"bert.encoder.layer.7.intermediate.dense.weight\", \"bert.encoder.layer.7.intermediate.dense.bias\", \"bert.encoder.layer.7.output.dense.weight\", \"bert.encoder.layer.7.output.dense.bias\", \"bert.encoder.layer.7.output.LayerNorm.weight\", \"bert.encoder.layer.7.output.LayerNorm.bias\", \"bert.encoder.layer.8.attention.self.query.weight\", \"bert.encoder.layer.8.attention.self.query.bias\", \"bert.encoder.layer.8.attention.self.key.weight\", \"bert.encoder.layer.8.attention.self.key.bias\", \"bert.encoder.layer.8.attention.self.value.weight\", \"bert.encoder.layer.8.attention.self.value.bias\", \"bert.encoder.layer.8.attention.output.dense.weight\", \"bert.encoder.layer.8.attention.output.dense.bias\", \"bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"bert.encoder.layer.8.intermediate.dense.weight\", \"bert.encoder.layer.8.intermediate.dense.bias\", \"bert.encoder.layer.8.output.dense.weight\", \"bert.encoder.layer.8.output.dense.bias\", \"bert.encoder.layer.8.output.LayerNorm.weight\", \"bert.encoder.layer.8.output.LayerNorm.bias\", \"bert.encoder.layer.9.attention.self.query.weight\", \"bert.encoder.layer.9.attention.self.query.bias\", \"bert.encoder.layer.9.attention.self.key.weight\", \"bert.encoder.layer.9.attention.self.key.bias\", \"bert.encoder.layer.9.attention.self.value.weight\", \"bert.encoder.layer.9.attention.self.value.bias\", \"bert.encoder.layer.9.attention.output.dense.weight\", \"bert.encoder.layer.9.attention.output.dense.bias\", \"bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"bert.encoder.layer.9.intermediate.dense.weight\", \"bert.encoder.layer.9.intermediate.dense.bias\", \"bert.encoder.layer.9.output.dense.weight\", \"bert.encoder.layer.9.output.dense.bias\", \"bert.encoder.layer.9.output.LayerNorm.weight\", \"bert.encoder.layer.9.output.LayerNorm.bias\", \"bert.encoder.layer.10.attention.self.query.weight\", \"bert.encoder.layer.10.attention.self.query.bias\", \"bert.encoder.layer.10.attention.self.key.weight\", \"bert.encoder.layer.10.attention.self.key.bias\", \"bert.encoder.layer.10.attention.self.value.weight\", \"bert.encoder.layer.10.attention.self.value.bias\", \"bert.encoder.layer.10.attention.output.dense.weight\", \"bert.encoder.layer.10.attention.output.dense.bias\", \"bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"bert.encoder.layer.10.intermediate.dense.weight\", \"bert.encoder.layer.10.intermediate.dense.bias\", \"bert.encoder.layer.10.output.dense.weight\", \"bert.encoder.layer.10.output.dense.bias\", \"bert.encoder.layer.10.output.LayerNorm.weight\", \"bert.encoder.layer.10.output.LayerNorm.bias\", \"bert.encoder.layer.11.attention.self.query.weight\", \"bert.encoder.layer.11.attention.self.query.bias\", \"bert.encoder.layer.11.attention.self.key.weight\", \"bert.encoder.layer.11.attention.self.key.bias\", \"bert.encoder.layer.11.attention.self.value.weight\", \"bert.encoder.layer.11.attention.self.value.bias\", \"bert.encoder.layer.11.attention.output.dense.weight\", \"bert.encoder.layer.11.attention.output.dense.bias\", \"bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"bert.encoder.layer.11.intermediate.dense.weight\", \"bert.encoder.layer.11.intermediate.dense.bias\", \"bert.encoder.layer.11.output.dense.weight\", \"bert.encoder.layer.11.output.dense.bias\", \"bert.encoder.layer.11.output.LayerNorm.weight\", \"bert.encoder.layer.11.output.LayerNorm.bias\", \"bert.pooler.dense.weight\", \"bert.pooler.dense.bias\", \"mlp.conv1.weight\", \"mlp.conv1.bias\", \"mlp.conv2.weight\", \"mlp.conv2.bias\", \"fc.main.0.bias\", \"fc.main.0.weight_g\", \"fc.main.0.weight_v\", \"fc.main.3.bias\", \"fc.main.3.weight_g\", \"fc.main.3.weight_v\". \r\n",
      "\tUnexpected key(s) in state_dict: \"module.bert.embeddings.word_embeddings.weight\", \"module.bert.embeddings.position_embeddings.weight\", \"module.bert.embeddings.token_type_embeddings.weight\", \"module.bert.embeddings.LayerNorm.weight\", \"module.bert.embeddings.LayerNorm.bias\", \"module.bert.encoder.layer.0.attention.self.query.weight\", \"module.bert.encoder.layer.0.attention.self.query.bias\", \"module.bert.encoder.layer.0.attention.self.key.weight\", \"module.bert.encoder.layer.0.attention.self.key.bias\", \"module.bert.encoder.layer.0.attention.self.value.weight\", \"module.bert.encoder.layer.0.attention.self.value.bias\", \"module.bert.encoder.layer.0.attention.output.dense.weight\", \"module.bert.encoder.layer.0.attention.output.dense.bias\", \"module.bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.0.intermediate.dense.weight\", \"module.bert.encoder.layer.0.intermediate.dense.bias\", \"module.bert.encoder.layer.0.output.dense.weight\", \"module.bert.encoder.layer.0.output.dense.bias\", \"module.bert.encoder.layer.0.output.LayerNorm.weight\", \"module.bert.encoder.layer.0.output.LayerNorm.bias\", \"module.bert.encoder.layer.1.attention.self.query.weight\", \"module.bert.encoder.layer.1.attention.self.query.bias\", \"module.bert.encoder.layer.1.attention.self.key.weight\", \"module.bert.encoder.layer.1.attention.self.key.bias\", \"module.bert.encoder.layer.1.attention.self.value.weight\", \"module.bert.encoder.layer.1.attention.self.value.bias\", \"module.bert.encoder.layer.1.attention.output.dense.weight\", \"module.bert.encoder.layer.1.attention.output.dense.bias\", \"module.bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.1.intermediate.dense.weight\", \"module.bert.encoder.layer.1.intermediate.dense.bias\", \"module.bert.encoder.layer.1.output.dense.weight\", \"module.bert.encoder.layer.1.output.dense.bias\", \"module.bert.encoder.layer.1.output.LayerNorm.weight\", \"module.bert.encoder.layer.1.output.LayerNorm.bias\", \"module.bert.encoder.layer.2.attention.self.query.weight\", \"module.bert.encoder.layer.2.attention.self.query.bias\", \"module.bert.encoder.layer.2.attention.self.key.weight\", \"module.bert.encoder.layer.2.attention.self.key.bias\", \"module.bert.encoder.layer.2.attention.self.value.weight\", \"module.bert.encoder.layer.2.attention.self.value.bias\", \"module.bert.encoder.layer.2.attention.output.dense.weight\", \"module.bert.encoder.layer.2.attention.output.dense.bias\", \"module.bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.2.intermediate.dense.weight\", \"module.bert.encoder.layer.2.intermediate.dense.bias\", \"module.bert.encoder.layer.2.output.dense.weight\", \"module.bert.encoder.layer.2.output.dense.bias\", \"module.bert.encoder.layer.2.output.LayerNorm.weight\", \"module.bert.encoder.layer.2.output.LayerNorm.bias\", \"module.bert.encoder.layer.3.attention.self.query.weight\", \"module.bert.encoder.layer.3.attention.self.query.bias\", \"module.bert.encoder.layer.3.attention.self.key.weight\", \"module.bert.encoder.layer.3.attention.self.key.bias\", \"module.bert.encoder.layer.3.attention.self.value.weight\", \"module.bert.encoder.layer.3.attention.self.value.bias\", \"module.bert.encoder.layer.3.attention.output.dense.weight\", \"module.bert.encoder.layer.3.attention.output.dense.bias\", \"module.bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.3.intermediate.dense.weight\", \"module.bert.encoder.layer.3.intermediate.dense.bias\", \"module.bert.encoder.layer.3.output.dense.weight\", \"module.bert.encoder.layer.3.output.dense.bias\", \"module.bert.encoder.layer.3.output.LayerNorm.weight\", \"module.bert.encoder.layer.3.output.LayerNorm.bias\", \"module.bert.encoder.layer.4.attention.self.query.weight\", \"module.bert.encoder.layer.4.attention.self.query.bias\", \"module.bert.encoder.layer.4.attention.self.key.weight\", \"module.bert.encoder.layer.4.attention.self.key.bias\", \"module.bert.encoder.layer.4.attention.self.value.weight\", \"module.bert.encoder.layer.4.attention.self.value.bias\", \"module.bert.encoder.layer.4.attention.output.dense.weight\", \"module.bert.encoder.layer.4.attention.output.dense.bias\", \"module.bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.4.intermediate.dense.weight\", \"module.bert.encoder.layer.4.intermediate.dense.bias\", \"module.bert.encoder.layer.4.output.dense.weight\", \"module.bert.encoder.layer.4.output.dense.bias\", \"module.bert.encoder.layer.4.output.LayerNorm.weight\", \"module.bert.encoder.layer.4.output.LayerNorm.bias\", \"module.bert.encoder.layer.5.attention.self.query.weight\", \"module.bert.encoder.layer.5.attention.self.query.bias\", \"module.bert.encoder.layer.5.attention.self.key.weight\", \"module.bert.encoder.layer.5.attention.self.key.bias\", \"module.bert.encoder.layer.5.attention.self.value.weight\", \"module.bert.encoder.layer.5.attention.self.value.bias\", \"module.bert.encoder.layer.5.attention.output.dense.weight\", \"module.bert.encoder.layer.5.attention.output.dense.bias\", \"module.bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.5.intermediate.dense.weight\", \"module.bert.encoder.layer.5.intermediate.dense.bias\", \"module.bert.encoder.layer.5.output.dense.weight\", \"module.bert.encoder.layer.5.output.dense.bias\", \"module.bert.encoder.layer.5.output.LayerNorm.weight\", \"module.bert.encoder.layer.5.output.LayerNorm.bias\", \"module.bert.encoder.layer.6.attention.self.query.weight\", \"module.bert.encoder.layer.6.attention.self.query.bias\", \"module.bert.encoder.layer.6.attention.self.key.weight\", \"module.bert.encoder.layer.6.attention.self.key.bias\", \"module.bert.encoder.layer.6.attention.self.value.weight\", \"module.bert.encoder.layer.6.attention.self.value.bias\", \"module.bert.encoder.layer.6.attention.output.dense.weight\", \"module.bert.encoder.layer.6.attention.output.dense.bias\", \"module.bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.6.intermediate.dense.weight\", \"module.bert.encoder.layer.6.intermediate.dense.bias\", \"module.bert.encoder.layer.6.output.dense.weight\", \"module.bert.encoder.layer.6.output.dense.bias\", \"module.bert.encoder.layer.6.output.LayerNorm.weight\", \"module.bert.encoder.layer.6.output.LayerNorm.bias\", \"module.bert.encoder.layer.7.attention.self.query.weight\", \"module.bert.encoder.layer.7.attention.self.query.bias\", \"module.bert.encoder.layer.7.attention.self.key.weight\", \"module.bert.encoder.layer.7.attention.self.key.bias\", \"module.bert.encoder.layer.7.attention.self.value.weight\", \"module.bert.encoder.layer.7.attention.self.value.bias\", \"module.bert.encoder.layer.7.attention.output.dense.weight\", \"module.bert.encoder.layer.7.attention.output.dense.bias\", \"module.bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.7.intermediate.dense.weight\", \"module.bert.encoder.layer.7.intermediate.dense.bias\", \"module.bert.encoder.layer.7.output.dense.weight\", \"module.bert.encoder.layer.7.output.dense.bias\", \"module.bert.encoder.layer.7.output.LayerNorm.weight\", \"module.bert.encoder.layer.7.output.LayerNorm.bias\", \"module.bert.encoder.layer.8.attention.self.query.weight\", \"module.bert.encoder.layer.8.attention.self.query.bias\", \"module.bert.encoder.layer.8.attention.self.key.weight\", \"module.bert.encoder.layer.8.attention.self.key.bias\", \"module.bert.encoder.layer.8.attention.self.value.weight\", \"module.bert.encoder.layer.8.attention.self.value.bias\", \"module.bert.encoder.layer.8.attention.output.dense.weight\", \"module.bert.encoder.layer.8.attention.output.dense.bias\", \"module.bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.8.intermediate.dense.weight\", \"module.bert.encoder.layer.8.intermediate.dense.bias\", \"module.bert.encoder.layer.8.output.dense.weight\", \"module.bert.encoder.layer.8.output.dense.bias\", \"module.bert.encoder.layer.8.output.LayerNorm.weight\", \"module.bert.encoder.layer.8.output.LayerNorm.bias\", \"module.bert.encoder.layer.9.attention.self.query.weight\", \"module.bert.encoder.layer.9.attention.self.query.bias\", \"module.bert.encoder.layer.9.attention.self.key.weight\", \"module.bert.encoder.layer.9.attention.self.key.bias\", \"module.bert.encoder.layer.9.attention.self.value.weight\", \"module.bert.encoder.layer.9.attention.self.value.bias\", \"module.bert.encoder.layer.9.attention.output.dense.weight\", \"module.bert.encoder.layer.9.attention.output.dense.bias\", \"module.bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.9.intermediate.dense.weight\", \"module.bert.encoder.layer.9.intermediate.dense.bias\", \"module.bert.encoder.layer.9.output.dense.weight\", \"module.bert.encoder.layer.9.output.dense.bias\", \"module.bert.encoder.layer.9.output.LayerNorm.weight\", \"module.bert.encoder.layer.9.output.LayerNorm.bias\", \"module.bert.encoder.layer.10.attention.self.query.weight\", \"module.bert.encoder.layer.10.attention.self.query.bias\", \"module.bert.encoder.layer.10.attention.self.key.weight\", \"module.bert.encoder.layer.10.attention.self.key.bias\", \"module.bert.encoder.layer.10.attention.self.value.weight\", \"module.bert.encoder.layer.10.attention.self.value.bias\", \"module.bert.encoder.layer.10.attention.output.dense.weight\", \"module.bert.encoder.layer.10.attention.output.dense.bias\", \"module.bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.10.intermediate.dense.weight\", \"module.bert.encoder.layer.10.intermediate.dense.bias\", \"module.bert.encoder.layer.10.output.dense.weight\", \"module.bert.encoder.layer.10.output.dense.bias\", \"module.bert.encoder.layer.10.output.LayerNorm.weight\", \"module.bert.encoder.layer.10.output.LayerNorm.bias\", \"module.bert.encoder.layer.11.attention.self.query.weight\", \"module.bert.encoder.layer.11.attention.self.query.bias\", \"module.bert.encoder.layer.11.attention.self.key.weight\", \"module.bert.encoder.layer.11.attention.self.key.bias\", \"module.bert.encoder.layer.11.attention.self.value.weight\", \"module.bert.encoder.layer.11.attention.self.value.bias\", \"module.bert.encoder.layer.11.attention.output.dense.weight\", \"module.bert.encoder.layer.11.attention.output.dense.bias\", \"module.bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.11.intermediate.dense.weight\", \"module.bert.encoder.layer.11.intermediate.dense.bias\", \"module.bert.encoder.layer.11.output.dense.weight\", \"module.bert.encoder.layer.11.output.dense.bias\", \"module.bert.encoder.layer.11.output.LayerNorm.weight\", \"module.bert.encoder.layer.11.output.LayerNorm.bias\", \"module.bert.pooler.dense.weight\", \"module.bert.pooler.dense.bias\", \"module.mlp.conv1.weight\", \"module.mlp.conv1.bias\", \"module.mlp.conv2.weight\", \"module.mlp.conv2.bias\". \r\n"
     ]
    }
   ],
   "source": [
    "# entity空间训练 BERT 双向 \n",
    "%cd code\n",
    "!python main_bert.py --gpu_id 8 --exp_name fact_space --exp_id bert --fusion_model BERT --data_choice 5 --method_choice W2V  --save_model 0 --now_test 1 --fact_map 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b0c11b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T08:27:37.414076Z",
     "start_time": "2022-07-22T08:15:28.685414Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 07/22/22 16:15:30 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 07/22/22 16:15:30 - 0:00:00 - The experiment will be stored in dump/0722-fact_space/bert\n",
      "                                     \n",
      "INFO - 07/22/22 16:15:30 - 0:00:00 - Running command: python main_bert_rnn.py --gpu_id 8 --exp_name fact_space --exp_id bert --fusion_model BERT --data_choice 3 --method_choice W2V --save_model 0 --now_test 0 --fact_map 1\n",
      "\n",
      "2022-07-22 16:15:30.945294: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-22 16:15:30.945367: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 128\n",
      "batch_size 128\n",
      "INFO - 07/22/22 16:15:44 - 0:00:14 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO - 07/22/22 16:15:44 - 0:00:14 - extracting archive file /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpt5y49x47\n",
      "embeddings.word_embeddings.weight:\tFalse\n",
      "embeddings.position_embeddings.weight:\tFalse\n",
      "embeddings.token_type_embeddings.weight:\tFalse\n",
      "embeddings.LayerNorm.weight:\tFalse\n",
      "embeddings.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.attention.self.query.weight:\tFalse\n",
      "encoder.layer.0.attention.self.query.bias:\tFalse\n",
      "encoder.layer.0.attention.self.key.weight:\tFalse\n",
      "encoder.layer.0.attention.self.key.bias:\tFalse\n",
      "encoder.layer.0.attention.self.value.weight:\tFalse\n",
      "encoder.layer.0.attention.self.value.bias:\tFalse\n",
      "encoder.layer.0.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.0.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.0.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.0.output.dense.weight:\tFalse\n",
      "encoder.layer.0.output.dense.bias:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.attention.self.query.weight:\tFalse\n",
      "encoder.layer.1.attention.self.query.bias:\tFalse\n",
      "encoder.layer.1.attention.self.key.weight:\tFalse\n",
      "encoder.layer.1.attention.self.key.bias:\tFalse\n",
      "encoder.layer.1.attention.self.value.weight:\tFalse\n",
      "encoder.layer.1.attention.self.value.bias:\tFalse\n",
      "encoder.layer.1.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.1.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.1.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.1.output.dense.weight:\tFalse\n",
      "encoder.layer.1.output.dense.bias:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.attention.self.query.weight:\tFalse\n",
      "encoder.layer.2.attention.self.query.bias:\tFalse\n",
      "encoder.layer.2.attention.self.key.weight:\tFalse\n",
      "encoder.layer.2.attention.self.key.bias:\tFalse\n",
      "encoder.layer.2.attention.self.value.weight:\tFalse\n",
      "encoder.layer.2.attention.self.value.bias:\tFalse\n",
      "encoder.layer.2.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.2.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.2.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.2.output.dense.weight:\tFalse\n",
      "encoder.layer.2.output.dense.bias:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.attention.self.query.weight:\tFalse\n",
      "encoder.layer.3.attention.self.query.bias:\tFalse\n",
      "encoder.layer.3.attention.self.key.weight:\tFalse\n",
      "encoder.layer.3.attention.self.key.bias:\tFalse\n",
      "encoder.layer.3.attention.self.value.weight:\tFalse\n",
      "encoder.layer.3.attention.self.value.bias:\tFalse\n",
      "encoder.layer.3.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.3.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.3.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.3.output.dense.weight:\tFalse\n",
      "encoder.layer.3.output.dense.bias:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.attention.self.query.weight:\tFalse\n",
      "encoder.layer.4.attention.self.query.bias:\tFalse\n",
      "encoder.layer.4.attention.self.key.weight:\tFalse\n",
      "encoder.layer.4.attention.self.key.bias:\tFalse\n",
      "encoder.layer.4.attention.self.value.weight:\tFalse\n",
      "encoder.layer.4.attention.self.value.bias:\tFalse\n",
      "encoder.layer.4.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.4.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.4.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.4.output.dense.weight:\tFalse\n",
      "encoder.layer.4.output.dense.bias:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.attention.self.query.weight:\tFalse\n",
      "encoder.layer.5.attention.self.query.bias:\tFalse\n",
      "encoder.layer.5.attention.self.key.weight:\tFalse\n",
      "encoder.layer.5.attention.self.key.bias:\tFalse\n",
      "encoder.layer.5.attention.self.value.weight:\tFalse\n",
      "encoder.layer.5.attention.self.value.bias:\tFalse\n",
      "encoder.layer.5.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.5.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.5.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.5.output.dense.weight:\tFalse\n",
      "encoder.layer.5.output.dense.bias:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.attention.self.query.weight:\tFalse\n",
      "encoder.layer.6.attention.self.query.bias:\tFalse\n",
      "encoder.layer.6.attention.self.key.weight:\tFalse\n",
      "encoder.layer.6.attention.self.key.bias:\tFalse\n",
      "encoder.layer.6.attention.self.value.weight:\tFalse\n",
      "encoder.layer.6.attention.self.value.bias:\tFalse\n",
      "encoder.layer.6.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.6.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.6.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.6.output.dense.weight:\tFalse\n",
      "encoder.layer.6.output.dense.bias:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.attention.self.query.weight:\tFalse\n",
      "encoder.layer.7.attention.self.query.bias:\tFalse\n",
      "encoder.layer.7.attention.self.key.weight:\tFalse\n",
      "encoder.layer.7.attention.self.key.bias:\tFalse\n",
      "encoder.layer.7.attention.self.value.weight:\tFalse\n",
      "encoder.layer.7.attention.self.value.bias:\tFalse\n",
      "encoder.layer.7.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.7.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.7.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.7.output.dense.weight:\tFalse\n",
      "encoder.layer.7.output.dense.bias:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.attention.self.query.weight:\tFalse\n",
      "encoder.layer.8.attention.self.query.bias:\tFalse\n",
      "encoder.layer.8.attention.self.key.weight:\tFalse\n",
      "encoder.layer.8.attention.self.key.bias:\tFalse\n",
      "encoder.layer.8.attention.self.value.weight:\tFalse\n",
      "encoder.layer.8.attention.self.value.bias:\tFalse\n",
      "encoder.layer.8.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.8.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.8.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.8.output.dense.weight:\tFalse\n",
      "encoder.layer.8.output.dense.bias:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.attention.self.query.weight:\tFalse\n",
      "encoder.layer.9.attention.self.query.bias:\tFalse\n",
      "encoder.layer.9.attention.self.key.weight:\tFalse\n",
      "encoder.layer.9.attention.self.key.bias:\tFalse\n",
      "encoder.layer.9.attention.self.value.weight:\tFalse\n",
      "encoder.layer.9.attention.self.value.bias:\tFalse\n",
      "encoder.layer.9.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.9.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.9.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.9.output.dense.weight:\tFalse\n",
      "encoder.layer.9.output.dense.bias:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.attention.self.query.weight:\tFalse\n",
      "encoder.layer.10.attention.self.query.bias:\tFalse\n",
      "encoder.layer.10.attention.self.key.weight:\tFalse\n",
      "encoder.layer.10.attention.self.key.bias:\tFalse\n",
      "encoder.layer.10.attention.self.value.weight:\tFalse\n",
      "encoder.layer.10.attention.self.value.bias:\tFalse\n",
      "encoder.layer.10.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.10.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.10.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.10.output.dense.weight:\tFalse\n",
      "encoder.layer.10.output.dense.bias:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.attention.self.query.weight:\tFalse\n",
      "encoder.layer.11.attention.self.query.bias:\tFalse\n",
      "encoder.layer.11.attention.self.key.weight:\tFalse\n",
      "encoder.layer.11.attention.self.key.bias:\tFalse\n",
      "encoder.layer.11.attention.self.value.weight:\tFalse\n",
      "encoder.layer.11.attention.self.value.bias:\tFalse\n",
      "encoder.layer.11.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.11.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.11.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.11.output.dense.weight:\tFalse\n",
      "encoder.layer.11.output.dense.bias:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.bias:\tFalse\n",
      "pooler.dense.weight:\tFalse\n",
      "pooler.dense.bias:\tFalse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fusion_model:\r\n",
      "BERT(\r\n",
      "  (bert): BertModel(\r\n",
      "    (embeddings): BertEmbeddings(\r\n",
      "      (word_embeddings): Embedding(30522, 768)\r\n",
      "      (position_embeddings): Embedding(512, 768)\r\n",
      "      (token_type_embeddings): Embedding(2, 768)\r\n",
      "      (LayerNorm): BertLayerNorm()\r\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "    )\r\n",
      "    (encoder): BertEncoder(\r\n",
      "      (layer): ModuleList(\r\n",
      "        (0): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (1): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (2): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (3): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (4): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (5): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (6): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (7): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (8): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (9): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (10): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (11): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (pooler): BertPooler(\r\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "      (activation): Tanh()\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (lstm): LSTM(768, 768, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\r\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "  (fc_rnn): Linear(in_features=1536, out_features=1024, bias=True)\r\n",
      "  (mlp): GroupMLP(\r\n",
      "    (conv1): Conv1d(768, 8192, kernel_size=(1,), stride=(1,))\r\n",
      "    (drop): Dropout(p=0.5, inplace=False)\r\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\r\n",
      "    (conv2): Conv1d(8192, 1024, kernel_size=(1,), stride=(1,), groups=64)\r\n",
      "  )\r\n",
      ")\r\n",
      "Answer Model:\r\n",
      "MLP(\r\n",
      "  (mlp): GroupMLP(\r\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\r\n",
      "    (drop): Dropout(p=0.0, inplace=False)\r\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\r\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\r\n",
      "  )\r\n",
      ")\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E000:   0% 0/21 [00:00<?, ?it/s]torch.Size([128, 1024]) torch.Size([2791, 1024])\n",
      "train E000: 100% 21/21 [00:07<00:00,  2.90it/s]\n",
      "INFO - 07/22/22 16:16:05 - 0:00:35 - Train Epoch 0: LOSS= 8.39505, lr= 0.000500, acc1= 5.02,acc3= 9.40,acc10= 12.29\n",
      "train E001: 100% 21/21 [00:07<00:00,  2.83it/s]\n",
      "INFO - 07/22/22 16:16:13 - 0:00:42 - Train Epoch 1: LOSS= 6.57063, lr= 0.000750, acc1= 16.07,acc3= 26.56,acc10= 33.53\n",
      "eval E001: 100% 23/23 [00:05<00:00,  3.94it/s]\n",
      "INFO - 07/22/22 16:16:18 - 0:00:48 - #################################################################################################################\n",
      "INFO - 07/22/22 16:16:18 - 0:00:48 - Test Epoch 1: LOSS= 6.44042, acc1= 16.44, acc3= 28.73, acc10= 36.20\n",
      "INFO - 07/22/22 16:16:18 - 0:00:48 - #################################################################################################################\n",
      "train E002: 100% 21/21 [00:07<00:00,  2.83it/s]\n",
      "INFO - 07/22/22 16:16:26 - 0:00:56 - Train Epoch 2: LOSS= 6.06526, lr= 0.001000, acc1= 22.59,acc3= 36.31,acc10= 43.39\n",
      "eval E002: 100% 23/23 [00:05<00:00,  4.04it/s]\n",
      "INFO - 07/22/22 16:16:32 - 0:01:01 - #################################################################################################################\n",
      "INFO - 07/22/22 16:16:32 - 0:01:01 - Test Epoch 2: LOSS= 6.21201, acc1= 21.43, acc3= 34.04, acc10= 41.94\n",
      "INFO - 07/22/22 16:16:32 - 0:01:01 - #################################################################################################################\n",
      "train E003: 100% 21/21 [00:07<00:00,  2.91it/s]\n",
      "INFO - 07/22/22 16:16:39 - 0:01:09 - Train Epoch 3: LOSS= 5.84448, lr= 0.001250, acc1= 26.15,acc3= 40.01,acc10= 47.62\n",
      "eval E003: 100% 23/23 [00:05<00:00,  4.12it/s]\n",
      "INFO - 07/22/22 16:16:44 - 0:01:14 - #################################################################################################################\n",
      "INFO - 07/22/22 16:16:44 - 0:01:14 - Test Epoch 3: LOSS= 6.15729, acc1= 22.46, acc3= 34.89, acc10= 42.26\n",
      "INFO - 07/22/22 16:16:44 - 0:01:14 - #################################################################################################################\n",
      "train E004: 100% 21/21 [00:07<00:00,  2.82it/s]\n",
      "INFO - 07/22/22 16:16:52 - 0:01:22 - Train Epoch 4: LOSS= 5.60151, lr= 0.001500, acc1= 30.54,acc3= 45.49,acc10= 53.32\n",
      "eval E004: 100% 23/23 [00:05<00:00,  4.12it/s]\n",
      "INFO - 07/22/22 16:16:57 - 0:01:27 - #################################################################################################################\n",
      "INFO - 07/22/22 16:16:57 - 0:01:27 - Test Epoch 4: LOSS= 6.39472, acc1= 20.23, acc3= 32.70, acc10= 40.03\n",
      "INFO - 07/22/22 16:16:57 - 0:01:27 - #################################################################################################################\n",
      "train E005: 100% 21/21 [00:07<00:00,  2.98it/s]\n",
      "INFO - 07/22/22 16:17:05 - 0:01:34 - Train Epoch 5: LOSS= 5.37692, lr= 0.001750, acc1= 32.82,acc3= 48.86,acc10= 57.40\n",
      "eval E005: 100% 23/23 [00:05<00:00,  4.02it/s]\n",
      "INFO - 07/22/22 16:17:10 - 0:01:40 - #################################################################################################################\n",
      "INFO - 07/22/22 16:17:10 - 0:01:40 - Test Epoch 5: LOSS= 6.32208, acc1= 22.53, acc3= 35.46, acc10= 43.61\n",
      "INFO - 07/22/22 16:17:10 - 0:01:40 - #################################################################################################################\n",
      "train E006: 100% 21/21 [00:07<00:00,  2.77it/s]\n",
      "INFO - 07/22/22 16:17:18 - 0:01:48 - Train Epoch 6: LOSS= 5.41647, lr= 0.002000, acc1= 32.56,acc3= 48.86,acc10= 56.35\n",
      "eval E006: 100% 23/23 [00:05<00:00,  4.10it/s]\n",
      "INFO - 07/22/22 16:17:23 - 0:01:53 - #################################################################################################################\n",
      "INFO - 07/22/22 16:17:23 - 0:01:53 - Test Epoch 6: LOSS= 6.40632, acc1= 21.64, acc3= 33.76, acc10= 40.56\n",
      "INFO - 07/22/22 16:17:23 - 0:01:53 - #################################################################################################################\n",
      "train E007: 100% 21/21 [00:06<00:00,  3.40it/s]\n",
      "INFO - 07/22/22 16:17:30 - 0:01:59 - Train Epoch 7: LOSS= 5.01215, lr= 0.002000, acc1= 39.12,acc3= 55.60,acc10= 64.52\n",
      "eval E007: 100% 23/23 [00:05<00:00,  4.46it/s]\n",
      "INFO - 07/22/22 16:17:35 - 0:02:05 - #################################################################################################################\n",
      "INFO - 07/22/22 16:17:35 - 0:02:05 - Test Epoch 7: LOSS= 6.16456, acc1= 24.76, acc3= 37.34, acc10= 43.71\n",
      "INFO - 07/22/22 16:17:35 - 0:02:05 - #################################################################################################################\n",
      "train E008: 100% 21/21 [00:06<00:00,  3.37it/s]\n",
      "INFO - 07/22/22 16:17:41 - 0:02:11 - Train Epoch 8: LOSS= 4.70450, lr= 0.002000, acc1= 43.87,acc3= 61.41,acc10= 68.86\n",
      "eval E008: 100% 23/23 [00:05<00:00,  4.55it/s]\n",
      "INFO - 07/22/22 16:17:46 - 0:02:16 - #################################################################################################################\n",
      "INFO - 07/22/22 16:17:46 - 0:02:16 - Test Epoch 8: LOSS= 6.22555, acc1= 25.19, acc3= 40.13, acc10= 48.14\n",
      "INFO - 07/22/22 16:17:46 - 0:02:16 - #################################################################################################################\n",
      "train E009: 100% 21/21 [00:06<00:00,  3.12it/s]\n",
      "INFO - 07/22/22 16:17:53 - 0:02:23 - Train Epoch 9: LOSS= 4.40456, lr= 0.002000, acc1= 48.41,acc3= 67.52,acc10= 75.31\n",
      "eval E009: 100% 23/23 [00:05<00:00,  4.20it/s]\n",
      "INFO - 07/22/22 16:17:58 - 0:02:28 - #################################################################################################################\n",
      "INFO - 07/22/22 16:17:58 - 0:02:28 - Test Epoch 9: LOSS= 6.03788, acc1= 30.04, acc3= 44.63, acc10= 53.24\n",
      "INFO - 07/22/22 16:17:58 - 0:02:28 - #################################################################################################################\n",
      "train E010: 100% 21/21 [00:07<00:00,  2.87it/s]\n",
      "INFO - 07/22/22 16:18:06 - 0:02:36 - Train Epoch 10: LOSS= 4.05952, lr= 0.002000, acc1= 55.38,acc3= 72.61,acc10= 79.73\n",
      "eval E010: 100% 23/23 [00:05<00:00,  4.07it/s]\n",
      "INFO - 07/22/22 16:18:11 - 0:02:41 - #################################################################################################################\n",
      "INFO - 07/22/22 16:18:11 - 0:02:41 - Test Epoch 10: LOSS= 6.04625, acc1= 30.64, acc3= 48.53, acc10= 56.08\n",
      "INFO - 07/22/22 16:18:11 - 0:02:41 - #################################################################################################################\n",
      "train E011: 100% 21/21 [00:07<00:00,  2.91it/s]\n",
      "INFO - 07/22/22 16:18:19 - 0:02:48 - Train Epoch 11: LOSS= 3.76089, lr= 0.002000, acc1= 60.88,acc3= 77.03,acc10= 83.44\n",
      "eval E011: 100% 23/23 [00:05<00:00,  4.12it/s]\n",
      "INFO - 07/22/22 16:18:24 - 0:02:54 - #################################################################################################################\n",
      "INFO - 07/22/22 16:18:24 - 0:02:54 - Test Epoch 11: LOSS= 5.86259, acc1= 34.96, acc3= 49.59, acc10= 58.31\n",
      "INFO - 07/22/22 16:18:24 - 0:02:54 - #################################################################################################################\n",
      "train E012: 100% 21/21 [00:07<00:00,  2.86it/s]\n",
      "INFO - 07/22/22 16:18:32 - 0:03:01 - Train Epoch 12: LOSS= 3.50148, lr= 0.002000, acc1= 64.71,acc3= 80.14,acc10= 85.65\n",
      "eval E012: 100% 23/23 [00:05<00:00,  4.06it/s]\n",
      "INFO - 07/22/22 16:18:37 - 0:03:07 - #################################################################################################################\n",
      "INFO - 07/22/22 16:18:37 - 0:03:07 - Test Epoch 12: LOSS= 5.78036, acc1= 35.07, acc3= 51.04, acc10= 58.45\n",
      "INFO - 07/22/22 16:18:37 - 0:03:07 - #################################################################################################################\n",
      "train E013: 100% 21/21 [00:07<00:00,  2.81it/s]\n",
      "INFO - 07/22/22 16:18:45 - 0:03:15 - Train Epoch 13: LOSS= 3.37392, lr= 0.002000, acc1= 67.18,acc3= 81.64,acc10= 87.22\n",
      "eval E013: 100% 23/23 [00:05<00:00,  4.05it/s]\n",
      "INFO - 07/22/22 16:18:51 - 0:03:20 - #################################################################################################################\n",
      "INFO - 07/22/22 16:18:51 - 0:03:20 - Test Epoch 13: LOSS= 6.09412, acc1= 34.79, acc3= 49.13, acc10= 57.21\n",
      "INFO - 07/22/22 16:18:51 - 0:03:20 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E014: 100% 21/21 [00:07<00:00,  2.84it/s]\n",
      "INFO - 07/22/22 16:18:58 - 0:03:28 - Train Epoch 14: LOSS= 2.84141, lr= 0.001400, acc1= 75.72,acc3= 88.24,acc10= 92.09\n",
      "eval E014: 100% 23/23 [00:05<00:00,  4.00it/s]\n",
      "INFO - 07/22/22 16:19:04 - 0:03:33 - #################################################################################################################\n",
      "INFO - 07/22/22 16:19:04 - 0:03:33 - Test Epoch 14: LOSS= 6.09129, acc1= 38.29, acc3= 54.52, acc10= 62.10\n",
      "INFO - 07/22/22 16:19:04 - 0:03:33 - #################################################################################################################\n",
      "train E015: 100% 21/21 [00:07<00:00,  2.83it/s]\n",
      "INFO - 07/22/22 16:19:11 - 0:03:41 - Train Epoch 15: LOSS= 2.53688, lr= 0.001400, acc1= 80.59,acc3= 91.42,acc10= 94.19\n",
      "eval E015: 100% 23/23 [00:05<00:00,  4.07it/s]\n",
      "INFO - 07/22/22 16:19:17 - 0:03:47 - #################################################################################################################\n",
      "INFO - 07/22/22 16:19:17 - 0:03:47 - Test Epoch 15: LOSS= 6.00654, acc1= 40.45, acc3= 55.69, acc10= 63.80\n",
      "INFO - 07/22/22 16:19:17 - 0:03:47 - #################################################################################################################\n",
      "train E016: 100% 21/21 [00:07<00:00,  2.84it/s]\n",
      "INFO - 07/22/22 16:19:24 - 0:03:54 - Train Epoch 16: LOSS= 2.38040, lr= 0.001400, acc1= 81.83,acc3= 92.09,acc10= 95.39\n",
      "eval E016: 100% 23/23 [00:05<00:00,  4.03it/s]\n",
      "INFO - 07/22/22 16:19:30 - 0:04:00 - #################################################################################################################\n",
      "INFO - 07/22/22 16:19:30 - 0:04:00 - Test Epoch 16: LOSS= 6.11317, acc1= 41.55, acc3= 57.95, acc10= 65.04\n",
      "INFO - 07/22/22 16:19:30 - 0:04:00 - #################################################################################################################\n",
      "train E017: 100% 21/21 [00:07<00:00,  2.80it/s]\n",
      "INFO - 07/22/22 16:19:37 - 0:04:07 - Train Epoch 17: LOSS= 1.94677, lr= 0.000980, acc1= 87.22,acc3= 95.58,acc10= 97.45\n",
      "eval E017: 100% 23/23 [00:05<00:00,  4.15it/s]\n",
      "INFO - 07/22/22 16:19:43 - 0:04:13 - #################################################################################################################\n",
      "INFO - 07/22/22 16:19:43 - 0:04:13 - Test Epoch 17: LOSS= 6.52738, acc1= 43.71, acc3= 58.52, acc10= 66.14\n",
      "INFO - 07/22/22 16:19:43 - 0:04:13 - #################################################################################################################\n",
      "train E018: 100% 21/21 [00:06<00:00,  3.23it/s]\n",
      "INFO - 07/22/22 16:19:50 - 0:04:19 - Train Epoch 18: LOSS= 1.76182, lr= 0.000980, acc1= 89.10,acc3= 96.55,acc10= 97.98\n",
      "eval E018: 100% 23/23 [00:05<00:00,  4.14it/s]\n",
      "INFO - 07/22/22 16:19:55 - 0:04:25 - #################################################################################################################\n",
      "INFO - 07/22/22 16:19:55 - 0:04:25 - Test Epoch 18: LOSS= 6.37468, acc1= 42.30, acc3= 58.31, acc10= 65.53\n",
      "INFO - 07/22/22 16:19:55 - 0:04:25 - #################################################################################################################\n",
      "train E019: 100% 21/21 [00:06<00:00,  3.24it/s]\n",
      "INFO - 07/22/22 16:20:02 - 0:04:31 - Train Epoch 19: LOSS= 1.70764, lr= 0.000980, acc1= 89.32,acc3= 95.88,acc10= 97.45\n",
      "eval E019: 100% 23/23 [00:05<00:00,  4.25it/s]\n",
      "INFO - 07/22/22 16:20:07 - 0:04:37 - #################################################################################################################\n",
      "INFO - 07/22/22 16:20:07 - 0:04:37 - Test Epoch 19: LOSS= 6.37825, acc1= 43.32, acc3= 59.30, acc10= 65.96\n",
      "INFO - 07/22/22 16:20:07 - 0:04:37 - #################################################################################################################\n",
      "train E020: 100% 21/21 [00:06<00:00,  3.01it/s]\n",
      "INFO - 07/22/22 16:20:14 - 0:04:44 - Train Epoch 20: LOSS= 1.45349, lr= 0.000686, acc1= 92.58,acc3= 97.56,acc10= 98.61\n",
      "eval E020: 100% 23/23 [00:05<00:00,  4.08it/s]\n",
      "INFO - 07/22/22 16:20:20 - 0:04:49 - #################################################################################################################\n",
      "INFO - 07/22/22 16:20:20 - 0:04:49 - Test Epoch 20: LOSS= 6.86117, acc1= 45.16, acc3= 60.22, acc10= 67.62\n",
      "INFO - 07/22/22 16:20:20 - 0:04:49 - #################################################################################################################\n",
      "train E021: 100% 21/21 [00:07<00:00,  2.90it/s]\n",
      "INFO - 07/22/22 16:20:27 - 0:04:57 - Train Epoch 21: LOSS= 1.25518, lr= 0.000686, acc1= 94.42,acc3= 98.16,acc10= 98.95\n",
      "eval E021: 100% 23/23 [00:05<00:00,  4.20it/s]\n",
      "INFO - 07/22/22 16:20:32 - 0:05:02 - #################################################################################################################\n",
      "INFO - 07/22/22 16:20:32 - 0:05:02 - Test Epoch 21: LOSS= 6.89409, acc1= 46.19, acc3= 61.60, acc10= 68.51\n",
      "INFO - 07/22/22 16:20:32 - 0:05:02 - #################################################################################################################\n",
      "train E022: 100% 21/21 [00:07<00:00,  2.83it/s]\n",
      "INFO - 07/22/22 16:20:40 - 0:05:10 - Train Epoch 22: LOSS= 1.18569, lr= 0.000686, acc1= 94.64,acc3= 98.31,acc10= 98.99\n",
      "eval E022: 100% 23/23 [00:05<00:00,  4.05it/s]\n",
      "INFO - 07/22/22 16:20:46 - 0:05:15 - #################################################################################################################\n",
      "INFO - 07/22/22 16:20:46 - 0:05:15 - Test Epoch 22: LOSS= 7.30236, acc1= 45.45, acc3= 61.42, acc10= 68.44\n",
      "INFO - 07/22/22 16:20:46 - 0:05:15 - #################################################################################################################\n",
      "train E023: 100% 21/21 [00:07<00:00,  2.82it/s]\n",
      "INFO - 07/22/22 16:20:53 - 0:05:23 - Train Epoch 23: LOSS= 1.13044, lr= 0.000480, acc1= 95.43,acc3= 98.58,acc10= 99.33\n",
      "eval E023: 100% 23/23 [00:05<00:00,  4.15it/s]\n",
      "INFO - 07/22/22 16:20:59 - 0:05:28 - #################################################################################################################\n",
      "INFO - 07/22/22 16:20:59 - 0:05:28 - Test Epoch 23: LOSS= 7.12857, acc1= 46.40, acc3= 62.27, acc10= 68.93\n",
      "INFO - 07/22/22 16:20:59 - 0:05:28 - #################################################################################################################\n",
      "train E024: 100% 21/21 [00:07<00:00,  2.83it/s]\n",
      "INFO - 07/22/22 16:21:06 - 0:05:36 - Train Epoch 24: LOSS= 0.96567, lr= 0.000480, acc1= 96.14,acc3= 99.03,acc10= 99.63\n",
      "eval E024: 100% 23/23 [00:05<00:00,  4.10it/s]\n",
      "INFO - 07/22/22 16:21:12 - 0:05:41 - #################################################################################################################\n",
      "INFO - 07/22/22 16:21:12 - 0:05:41 - Test Epoch 24: LOSS= 7.26010, acc1= 47.47, acc3= 62.13, acc10= 69.43\n",
      "INFO - 07/22/22 16:21:12 - 0:05:41 - #################################################################################################################\n",
      "train E025: 100% 21/21 [00:07<00:00,  2.88it/s]\n",
      "INFO - 07/22/22 16:21:19 - 0:05:49 - Train Epoch 25: LOSS= 0.93911, lr= 0.000480, acc1= 96.10,acc3= 98.95,acc10= 99.44\n",
      "eval E025: 100% 23/23 [00:05<00:00,  4.07it/s]\n",
      "INFO - 07/22/22 16:21:25 - 0:05:54 - #################################################################################################################\n",
      "INFO - 07/22/22 16:21:25 - 0:05:54 - Test Epoch 25: LOSS= 7.39993, acc1= 46.37, acc3= 61.32, acc10= 68.76\n",
      "INFO - 07/22/22 16:21:25 - 0:05:54 - #################################################################################################################\n",
      "train E026: 100% 21/21 [00:07<00:00,  2.85it/s]\n",
      "INFO - 07/22/22 16:21:32 - 0:06:02 - Train Epoch 26: LOSS= 0.82839, lr= 0.000336, acc1= 96.89,acc3= 99.36,acc10= 99.70\n",
      "eval E026: 100% 23/23 [00:05<00:00,  4.11it/s]\n",
      "INFO - 07/22/22 16:21:38 - 0:06:07 - #################################################################################################################\n",
      "INFO - 07/22/22 16:21:38 - 0:06:07 - Test Epoch 26: LOSS= 7.83614, acc1= 47.11, acc3= 61.71, acc10= 68.97\n",
      "INFO - 07/22/22 16:21:38 - 0:06:07 - #################################################################################################################\n",
      "train E027: 100% 21/21 [00:07<00:00,  2.82it/s]\n",
      "INFO - 07/22/22 16:21:45 - 0:06:15 - Train Epoch 27: LOSS= 0.78160, lr= 0.000336, acc1= 97.38,acc3= 99.48,acc10= 99.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E027: 100% 23/23 [00:05<00:00,  4.11it/s]\n",
      "INFO - 07/22/22 16:21:51 - 0:06:21 - #################################################################################################################\n",
      "INFO - 07/22/22 16:21:51 - 0:06:21 - Test Epoch 27: LOSS= 7.77444, acc1= 45.55, acc3= 60.68, acc10= 67.66\n",
      "INFO - 07/22/22 16:21:51 - 0:06:21 - #################################################################################################################\n",
      "train E028: 100% 21/21 [00:07<00:00,  2.84it/s]\n",
      "INFO - 07/22/22 16:21:58 - 0:06:28 - Train Epoch 28: LOSS= 0.79808, lr= 0.000336, acc1= 96.63,acc3= 99.25,acc10= 99.66\n",
      "eval E028: 100% 23/23 [00:05<00:00,  4.10it/s]\n",
      "INFO - 07/22/22 16:22:04 - 0:06:34 - #################################################################################################################\n",
      "INFO - 07/22/22 16:22:04 - 0:06:34 - Test Epoch 28: LOSS= 7.91159, acc1= 46.51, acc3= 61.49, acc10= 68.76\n",
      "INFO - 07/22/22 16:22:04 - 0:06:34 - #################################################################################################################\n",
      "train E029: 100% 21/21 [00:06<00:00,  3.10it/s]\n",
      "INFO - 07/22/22 16:22:11 - 0:06:40 - Train Epoch 29: LOSS= 0.72804, lr= 0.000235, acc1= 97.49,acc3= 99.33,acc10= 99.63\n",
      "eval E029: 100% 23/23 [00:05<00:00,  4.25it/s]\n",
      "INFO - 07/22/22 16:22:16 - 0:06:46 - #################################################################################################################\n",
      "INFO - 07/22/22 16:22:16 - 0:06:46 - Test Epoch 29: LOSS= 7.76979, acc1= 47.47, acc3= 61.96, acc10= 69.15\n",
      "INFO - 07/22/22 16:22:16 - 0:06:46 - #################################################################################################################\n",
      "train E030: 100% 21/21 [00:06<00:00,  3.28it/s]\n",
      "INFO - 07/22/22 16:22:22 - 0:06:52 - Train Epoch 30: LOSS= 0.67860, lr= 0.000235, acc1= 97.49,acc3= 99.70,acc10= 99.93\n",
      "eval E030: 100% 23/23 [00:05<00:00,  4.27it/s]\n",
      "INFO - 07/22/22 16:22:28 - 0:06:58 - #################################################################################################################\n",
      "INFO - 07/22/22 16:22:28 - 0:06:58 - Test Epoch 30: LOSS= 8.12226, acc1= 46.62, acc3= 61.46, acc10= 69.25\n",
      "INFO - 07/22/22 16:22:28 - 0:06:58 - #################################################################################################################\n",
      "train E031: 100% 21/21 [00:06<00:00,  3.05it/s]\n",
      "INFO - 07/22/22 16:22:35 - 0:07:04 - Train Epoch 31: LOSS= 0.67102, lr= 0.000235, acc1= 97.53,acc3= 99.36,acc10= 99.66\n",
      "eval E031: 100% 23/23 [00:05<00:00,  4.02it/s]\n",
      "INFO - 07/22/22 16:22:40 - 0:07:10 - #################################################################################################################\n",
      "INFO - 07/22/22 16:22:40 - 0:07:10 - Test Epoch 31: LOSS= 8.23732, acc1= 47.40, acc3= 61.81, acc10= 68.54\n",
      "INFO - 07/22/22 16:22:40 - 0:07:10 - #################################################################################################################\n",
      "train E032: 100% 21/21 [00:07<00:00,  2.83it/s]\n",
      "INFO - 07/22/22 16:22:48 - 0:07:18 - Train Epoch 32: LOSS= 0.60913, lr= 0.000165, acc1= 98.05,acc3= 99.63,acc10= 99.85\n",
      "eval E032: 100% 23/23 [00:05<00:00,  4.08it/s]\n",
      "INFO - 07/22/22 16:22:53 - 0:07:23 - #################################################################################################################\n",
      "INFO - 07/22/22 16:22:53 - 0:07:23 - Test Epoch 32: LOSS= 8.11988, acc1= 47.15, acc3= 62.06, acc10= 68.72\n",
      "INFO - 07/22/22 16:22:53 - 0:07:23 - #################################################################################################################\n",
      "train E033: 100% 21/21 [00:07<00:00,  2.89it/s]\n",
      "INFO - 07/22/22 16:23:01 - 0:07:30 - Train Epoch 33: LOSS= 0.54650, lr= 0.000165, acc1= 98.35,acc3= 99.55,acc10= 99.85\n",
      "eval E033: 100% 23/23 [00:05<00:00,  4.02it/s]\n",
      "INFO - 07/22/22 16:23:06 - 0:07:36 - #################################################################################################################\n",
      "INFO - 07/22/22 16:23:06 - 0:07:36 - Test Epoch 33: LOSS= 8.75007, acc1= 46.94, acc3= 61.85, acc10= 68.58\n",
      "INFO - 07/22/22 16:23:06 - 0:07:36 - #################################################################################################################\n",
      "train E034: 100% 21/21 [00:07<00:00,  2.87it/s]\n",
      "INFO - 07/22/22 16:23:14 - 0:07:44 - Train Epoch 34: LOSS= 0.56201, lr= 0.000165, acc1= 97.90,acc3= 99.66,acc10= 99.85\n",
      "eval E034: 100% 23/23 [00:05<00:00,  4.06it/s]\n",
      "INFO - 07/22/22 16:23:19 - 0:07:49 - #################################################################################################################\n",
      "INFO - 07/22/22 16:23:19 - 0:07:49 - Test Epoch 34: LOSS= 8.74983, acc1= 46.87, acc3= 61.81, acc10= 68.90\n",
      "INFO - 07/22/22 16:23:19 - 0:07:49 - #################################################################################################################\n",
      "train E035: 100% 21/21 [00:07<00:00,  2.80it/s]\n",
      "INFO - 07/22/22 16:23:27 - 0:07:57 - Train Epoch 35: LOSS= 0.54819, lr= 0.000115, acc1= 97.94,acc3= 99.55,acc10= 99.78\n",
      "eval E035: 100% 23/23 [00:05<00:00,  4.08it/s]\n",
      "INFO - 07/22/22 16:23:33 - 0:08:02 - #################################################################################################################\n",
      "INFO - 07/22/22 16:23:33 - 0:08:02 - Test Epoch 35: LOSS= 8.46916, acc1= 46.58, acc3= 61.57, acc10= 68.58\n",
      "INFO - 07/22/22 16:23:33 - 0:08:02 - #################################################################################################################\n",
      "train E036: 100% 21/21 [00:07<00:00,  2.83it/s]\n",
      "INFO - 07/22/22 16:23:40 - 0:08:10 - Train Epoch 36: LOSS= 0.50434, lr= 0.000115, acc1= 98.61,acc3= 99.85,acc10= 99.93\n",
      "eval E036: 100% 23/23 [00:05<00:00,  4.10it/s]\n",
      "INFO - 07/22/22 16:23:46 - 0:08:15 - #################################################################################################################\n",
      "INFO - 07/22/22 16:23:46 - 0:08:15 - Test Epoch 36: LOSS= 8.74491, acc1= 46.69, acc3= 62.20, acc10= 68.33\n",
      "INFO - 07/22/22 16:23:46 - 0:08:15 - #################################################################################################################\n",
      "train E037: 100% 21/21 [00:07<00:00,  2.86it/s]\n",
      "INFO - 07/22/22 16:23:53 - 0:08:23 - Train Epoch 37: LOSS= 0.51544, lr= 0.000115, acc1= 98.28,acc3= 99.78,acc10= 99.93\n",
      "eval E037: 100% 23/23 [00:05<00:00,  4.04it/s]\n",
      "INFO - 07/22/22 16:23:59 - 0:08:28 - #################################################################################################################\n",
      "INFO - 07/22/22 16:23:59 - 0:08:28 - Test Epoch 37: LOSS= 8.69240, acc1= 46.87, acc3= 61.74, acc10= 68.65\n",
      "INFO - 07/22/22 16:23:59 - 0:08:28 - #################################################################################################################\n",
      "train E038: 100% 21/21 [00:07<00:00,  2.87it/s]\n",
      "INFO - 07/22/22 16:24:06 - 0:08:36 - Train Epoch 38: LOSS= 0.49860, lr= 0.000081, acc1= 98.50,acc3= 99.74,acc10= 99.89\n",
      "eval E038: 100% 23/23 [00:05<00:00,  4.10it/s]\n",
      "INFO - 07/22/22 16:24:12 - 0:08:41 - #################################################################################################################\n",
      "INFO - 07/22/22 16:24:12 - 0:08:41 - Test Epoch 38: LOSS= 9.07766, acc1= 46.87, acc3= 61.78, acc10= 68.51\n",
      "INFO - 07/22/22 16:24:12 - 0:08:41 - #################################################################################################################\n",
      "train E039: 100% 21/21 [00:07<00:00,  2.79it/s]\n",
      "INFO - 07/22/22 16:24:19 - 0:08:49 - Train Epoch 39: LOSS= 0.49474, lr= 0.000081, acc1= 97.83,acc3= 99.66,acc10= 99.81\n",
      "eval E039: 100% 23/23 [00:05<00:00,  4.05it/s]\n",
      "INFO - 07/22/22 16:24:25 - 0:08:55 - #################################################################################################################\n",
      "INFO - 07/22/22 16:24:25 - 0:08:55 - Test Epoch 39: LOSS= 9.26674, acc1= 46.94, acc3= 61.71, acc10= 69.04\n",
      "INFO - 07/22/22 16:24:25 - 0:08:55 - #################################################################################################################\n",
      "train E040: 100% 21/21 [00:06<00:00,  3.16it/s]\n",
      "INFO - 07/22/22 16:24:32 - 0:09:01 - Train Epoch 40: LOSS= 0.45754, lr= 0.000081, acc1= 98.39,acc3= 99.81,acc10= 99.96\n",
      "eval E040: 100% 23/23 [00:05<00:00,  4.25it/s]\n",
      "INFO - 07/22/22 16:24:37 - 0:09:07 - #################################################################################################################\n",
      "INFO - 07/22/22 16:24:37 - 0:09:07 - Test Epoch 40: LOSS= 9.46570, acc1= 47.15, acc3= 62.35, acc10= 68.37\n",
      "INFO - 07/22/22 16:24:37 - 0:09:07 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E041: 100% 21/21 [00:06<00:00,  3.23it/s]\n",
      "INFO - 07/22/22 16:24:43 - 0:09:13 - Train Epoch 41: LOSS= 0.46158, lr= 0.000056, acc1= 98.46,acc3= 99.85,acc10= 99.96\n",
      "eval E041: 100% 23/23 [00:05<00:00,  4.32it/s]\n",
      "INFO - 07/22/22 16:24:49 - 0:09:19 - #################################################################################################################\n",
      "INFO - 07/22/22 16:24:49 - 0:09:19 - Test Epoch 41: LOSS= 9.24018, acc1= 47.57, acc3= 62.20, acc10= 68.40\n",
      "INFO - 07/22/22 16:24:49 - 0:09:19 - #################################################################################################################\n",
      "train E042: 100% 21/21 [00:06<00:00,  3.12it/s]\n",
      "INFO - 07/22/22 16:24:55 - 0:09:25 - Train Epoch 42: LOSS= 0.44299, lr= 0.000056, acc1= 98.46,acc3= 99.93,acc10= 99.96\n",
      "eval E042: 100% 23/23 [00:05<00:00,  4.06it/s]\n",
      "INFO - 07/22/22 16:25:01 - 0:09:31 - #################################################################################################################\n",
      "INFO - 07/22/22 16:25:01 - 0:09:31 - Test Epoch 42: LOSS= 9.32993, acc1= 47.36, acc3= 62.38, acc10= 68.86\n",
      "INFO - 07/22/22 16:25:01 - 0:09:31 - #################################################################################################################\n",
      "train E043: 100% 21/21 [00:07<00:00,  2.82it/s]\n",
      "INFO - 07/22/22 16:25:09 - 0:09:38 - Train Epoch 43: LOSS= 0.50089, lr= 0.000056, acc1= 98.28,acc3= 99.81,acc10= 99.93\n",
      "eval E043: 100% 23/23 [00:05<00:00,  3.97it/s]\n",
      "INFO - 07/22/22 16:25:14 - 0:09:44 - #################################################################################################################\n",
      "INFO - 07/22/22 16:25:14 - 0:09:44 - Test Epoch 43: LOSS= 9.35234, acc1= 47.22, acc3= 62.27, acc10= 68.65\n",
      "INFO - 07/22/22 16:25:14 - 0:09:44 - #################################################################################################################\n",
      "train E044: 100% 21/21 [00:07<00:00,  2.87it/s]\n",
      "INFO - 07/22/22 16:25:22 - 0:09:52 - Train Epoch 44: LOSS= 0.44187, lr= 0.000040, acc1= 98.61,acc3= 99.96,acc10= 100.00\n",
      "eval E044: 100% 23/23 [00:05<00:00,  4.05it/s]\n",
      "INFO - 07/22/22 16:25:27 - 0:09:57 - #################################################################################################################\n",
      "INFO - 07/22/22 16:25:27 - 0:09:57 - Test Epoch 44: LOSS= 9.20420, acc1= 46.94, acc3= 62.35, acc10= 68.72\n",
      "INFO - 07/22/22 16:25:27 - 0:09:57 - #################################################################################################################\n",
      "train E045: 100% 21/21 [00:07<00:00,  2.88it/s]\n",
      "INFO - 07/22/22 16:25:35 - 0:10:05 - Train Epoch 45: LOSS= 0.44290, lr= 0.000040, acc1= 98.65,acc3= 99.70,acc10= 99.78\n",
      "eval E045: 100% 23/23 [00:05<00:00,  4.00it/s]\n",
      "INFO - 07/22/22 16:25:41 - 0:10:10 - #################################################################################################################\n",
      "INFO - 07/22/22 16:25:41 - 0:10:10 - Test Epoch 45: LOSS= 9.06725, acc1= 47.08, acc3= 62.42, acc10= 69.11\n",
      "INFO - 07/22/22 16:25:41 - 0:10:10 - #################################################################################################################\n",
      "train E046: 100% 21/21 [00:07<00:00,  2.88it/s]\n",
      "INFO - 07/22/22 16:25:48 - 0:10:18 - Train Epoch 46: LOSS= 0.48216, lr= 0.000040, acc1= 98.35,acc3= 99.70,acc10= 99.89\n",
      "eval E046: 100% 23/23 [00:05<00:00,  4.04it/s]\n",
      "INFO - 07/22/22 16:25:53 - 0:10:23 - #################################################################################################################\n",
      "INFO - 07/22/22 16:25:53 - 0:10:23 - Test Epoch 46: LOSS= 9.43370, acc1= 46.94, acc3= 62.70, acc10= 69.00\n",
      "INFO - 07/22/22 16:25:53 - 0:10:23 - #################################################################################################################\n",
      "train E047: 100% 21/21 [00:07<00:00,  2.80it/s]\n",
      "INFO - 07/22/22 16:26:01 - 0:10:31 - Train Epoch 47: LOSS= 0.44677, lr= 0.000040, acc1= 98.24,acc3= 99.85,acc10= 99.89\n",
      "eval E047: 100% 23/23 [00:05<00:00,  4.01it/s]\n",
      "INFO - 07/22/22 16:26:07 - 0:10:36 - #################################################################################################################\n",
      "INFO - 07/22/22 16:26:07 - 0:10:36 - Test Epoch 47: LOSS= 9.62731, acc1= 46.90, acc3= 62.24, acc10= 68.83\n",
      "INFO - 07/22/22 16:26:07 - 0:10:36 - #################################################################################################################\n",
      "train E048: 100% 21/21 [00:07<00:00,  2.84it/s]\n",
      "INFO - 07/22/22 16:26:14 - 0:10:44 - Train Epoch 48: LOSS= 0.44107, lr= 0.000040, acc1= 98.50,acc3= 99.96,acc10= 100.00\n",
      "eval E048: 100% 23/23 [00:05<00:00,  3.99it/s]\n",
      "INFO - 07/22/22 16:26:20 - 0:10:50 - #################################################################################################################\n",
      "INFO - 07/22/22 16:26:20 - 0:10:50 - Test Epoch 48: LOSS= 9.31945, acc1= 47.04, acc3= 62.10, acc10= 68.83\n",
      "INFO - 07/22/22 16:26:20 - 0:10:50 - #################################################################################################################\n",
      "train E049: 100% 21/21 [00:07<00:00,  2.86it/s]\n",
      "INFO - 07/22/22 16:26:27 - 0:10:57 - Train Epoch 49: LOSS= 0.42326, lr= 0.000040, acc1= 98.73,acc3= 99.93,acc10= 99.96\n",
      "eval E049: 100% 23/23 [00:05<00:00,  4.12it/s]\n",
      "INFO - 07/22/22 16:26:33 - 0:11:03 - #################################################################################################################\n",
      "INFO - 07/22/22 16:26:33 - 0:11:03 - Test Epoch 49: LOSS= 9.44785, acc1= 46.79, acc3= 62.42, acc10= 68.76\n",
      "INFO - 07/22/22 16:26:33 - 0:11:03 - #################################################################################################################\n",
      "train E050: 100% 21/21 [00:07<00:00,  2.82it/s]\n",
      "INFO - 07/22/22 16:26:40 - 0:11:10 - Train Epoch 50: LOSS= 0.44529, lr= 0.000040, acc1= 98.43,acc3= 99.74,acc10= 99.89\n",
      "eval E050: 100% 23/23 [00:05<00:00,  4.10it/s]\n",
      "INFO - 07/22/22 16:26:46 - 0:11:16 - #################################################################################################################\n",
      "INFO - 07/22/22 16:26:46 - 0:11:16 - Test Epoch 50: LOSS= 9.47608, acc1= 46.97, acc3= 62.06, acc10= 68.79\n",
      "INFO - 07/22/22 16:26:46 - 0:11:16 - #################################################################################################################\n",
      "train E051: 100% 21/21 [00:06<00:00,  3.24it/s]\n",
      "INFO - 07/22/22 16:26:52 - 0:11:22 - Train Epoch 51: LOSS= 0.40709, lr= 0.000040, acc1= 98.76,acc3= 99.89,acc10= 100.00\n",
      "eval E051: 100% 23/23 [00:05<00:00,  4.41it/s]\n",
      "INFO - 07/22/22 16:26:58 - 0:11:27 - #################################################################################################################\n",
      "INFO - 07/22/22 16:26:58 - 0:11:27 - Test Epoch 51: LOSS= 9.51488, acc1= 47.01, acc3= 62.20, acc10= 68.65\n",
      "INFO - 07/22/22 16:26:58 - 0:11:27 - #################################################################################################################\n",
      "train E052: 100% 21/21 [00:06<00:00,  3.25it/s]\n",
      "INFO - 07/22/22 16:27:04 - 0:11:34 - Train Epoch 52: LOSS= 0.43439, lr= 0.000040, acc1= 98.24,acc3= 99.89,acc10= 99.93\n",
      "eval E052: 100% 23/23 [00:05<00:00,  4.32it/s]\n",
      "INFO - 07/22/22 16:27:09 - 0:11:39 - #################################################################################################################\n",
      "INFO - 07/22/22 16:27:09 - 0:11:39 - Test Epoch 52: LOSS= 9.59416, acc1= 46.94, acc3= 62.31, acc10= 68.54\n",
      "INFO - 07/22/22 16:27:09 - 0:11:39 - #################################################################################################################\n",
      "train E053: 100% 21/21 [00:06<00:00,  3.03it/s]\n",
      "INFO - 07/22/22 16:27:16 - 0:11:46 - Train Epoch 53: LOSS= 0.42881, lr= 0.000040, acc1= 98.65,acc3= 99.89,acc10= 99.96\n",
      "eval E053: 100% 23/23 [00:05<00:00,  4.13it/s]\n",
      "INFO - 07/22/22 16:27:22 - 0:11:52 - #################################################################################################################\n",
      "INFO - 07/22/22 16:27:22 - 0:11:52 - Test Epoch 53: LOSS= 9.27199, acc1= 46.94, acc3= 61.88, acc10= 67.98\n",
      "INFO - 07/22/22 16:27:22 - 0:11:52 - #################################################################################################################\n",
      "train E054: 100% 21/21 [00:07<00:00,  2.85it/s]\n",
      "INFO - 07/22/22 16:27:29 - 0:11:59 - Train Epoch 54: LOSS= 0.42138, lr= 0.000040, acc1= 98.58,acc3= 99.89,acc10= 99.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E054: 100% 23/23 [00:05<00:00,  4.01it/s]\n",
      "INFO - 07/22/22 16:27:35 - 0:12:05 - #################################################################################################################\n",
      "INFO - 07/22/22 16:27:35 - 0:12:05 - Test Epoch 54: LOSS= 9.37469, acc1= 47.33, acc3= 62.38, acc10= 68.40\n",
      "INFO - 07/22/22 16:27:35 - 0:12:05 - #################################################################################################################\n",
      "INFO - 07/22/22 16:27:35 - 0:12:05 - best performance =  47.47, 62.13, 69.43. best epoch = 24, correspond_loss= 7.2601\n",
      "Traceback (most recent call last):\n",
      "  File \"main_bert_rnn.py\", line 400, in <module>\n",
      "    logger.info(f\" fusion_model_path = {runner.fusion_model_path}\")\n",
      "AttributeError: 'Runner' object has no attribute 'fusion_model_path'\n"
     ]
    }
   ],
   "source": [
    "# entity空间训练 BERT cnn\n",
    "%cd code\n",
    "!python main_bert_rnn.py --gpu_id 8 --exp_name fact_space --exp_id bert --fusion_model BERT --data_choice 3 --method_choice W2V  --save_model 0 --now_test 0 --fact_map 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4c9d73b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T04:17:55.427429Z",
     "start_time": "2022-07-17T04:07:13.320444Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 07/17/22 12:07:15 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 07/17/22 12:07:15 - 0:00:00 - The experiment will be stored in dump/0717-relation_space/bert\n",
      "                                     \n",
      "INFO - 07/17/22 12:07:15 - 0:00:00 - Running command: python main_bert_rnn.py --gpu_id 8 --exp_name relation_space --exp_id bert --fusion_model BERT --data_choice 3 --method_choice W2V --save_model 1 --now_test 0 --relation_map 1\n",
      "\n",
      "2022-07-17 12:07:15.701031: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-17 12:07:15.701095: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 128\n",
      "batch_size 128\n",
      "INFO - 07/17/22 12:07:39 - 0:00:24 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO - 07/17/22 12:07:39 - 0:00:24 - extracting archive file /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpvk37afkj\n",
      "embeddings.word_embeddings.weight:\tFalse\n",
      "embeddings.position_embeddings.weight:\tFalse\n",
      "embeddings.token_type_embeddings.weight:\tFalse\n",
      "embeddings.LayerNorm.weight:\tFalse\n",
      "embeddings.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.attention.self.query.weight:\tFalse\n",
      "encoder.layer.0.attention.self.query.bias:\tFalse\n",
      "encoder.layer.0.attention.self.key.weight:\tFalse\n",
      "encoder.layer.0.attention.self.key.bias:\tFalse\n",
      "encoder.layer.0.attention.self.value.weight:\tFalse\n",
      "encoder.layer.0.attention.self.value.bias:\tFalse\n",
      "encoder.layer.0.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.0.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.0.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.0.output.dense.weight:\tFalse\n",
      "encoder.layer.0.output.dense.bias:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.attention.self.query.weight:\tFalse\n",
      "encoder.layer.1.attention.self.query.bias:\tFalse\n",
      "encoder.layer.1.attention.self.key.weight:\tFalse\n",
      "encoder.layer.1.attention.self.key.bias:\tFalse\n",
      "encoder.layer.1.attention.self.value.weight:\tFalse\n",
      "encoder.layer.1.attention.self.value.bias:\tFalse\n",
      "encoder.layer.1.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.1.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.1.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.1.output.dense.weight:\tFalse\n",
      "encoder.layer.1.output.dense.bias:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.attention.self.query.weight:\tFalse\n",
      "encoder.layer.2.attention.self.query.bias:\tFalse\n",
      "encoder.layer.2.attention.self.key.weight:\tFalse\n",
      "encoder.layer.2.attention.self.key.bias:\tFalse\n",
      "encoder.layer.2.attention.self.value.weight:\tFalse\n",
      "encoder.layer.2.attention.self.value.bias:\tFalse\n",
      "encoder.layer.2.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.2.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.2.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.2.output.dense.weight:\tFalse\n",
      "encoder.layer.2.output.dense.bias:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.attention.self.query.weight:\tFalse\n",
      "encoder.layer.3.attention.self.query.bias:\tFalse\n",
      "encoder.layer.3.attention.self.key.weight:\tFalse\n",
      "encoder.layer.3.attention.self.key.bias:\tFalse\n",
      "encoder.layer.3.attention.self.value.weight:\tFalse\n",
      "encoder.layer.3.attention.self.value.bias:\tFalse\n",
      "encoder.layer.3.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.3.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.3.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.3.output.dense.weight:\tFalse\n",
      "encoder.layer.3.output.dense.bias:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.attention.self.query.weight:\tFalse\n",
      "encoder.layer.4.attention.self.query.bias:\tFalse\n",
      "encoder.layer.4.attention.self.key.weight:\tFalse\n",
      "encoder.layer.4.attention.self.key.bias:\tFalse\n",
      "encoder.layer.4.attention.self.value.weight:\tFalse\n",
      "encoder.layer.4.attention.self.value.bias:\tFalse\n",
      "encoder.layer.4.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.4.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.4.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.4.output.dense.weight:\tFalse\n",
      "encoder.layer.4.output.dense.bias:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.attention.self.query.weight:\tFalse\n",
      "encoder.layer.5.attention.self.query.bias:\tFalse\n",
      "encoder.layer.5.attention.self.key.weight:\tFalse\n",
      "encoder.layer.5.attention.self.key.bias:\tFalse\n",
      "encoder.layer.5.attention.self.value.weight:\tFalse\n",
      "encoder.layer.5.attention.self.value.bias:\tFalse\n",
      "encoder.layer.5.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.5.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.5.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.5.output.dense.weight:\tFalse\n",
      "encoder.layer.5.output.dense.bias:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.attention.self.query.weight:\tFalse\n",
      "encoder.layer.6.attention.self.query.bias:\tFalse\n",
      "encoder.layer.6.attention.self.key.weight:\tFalse\n",
      "encoder.layer.6.attention.self.key.bias:\tFalse\n",
      "encoder.layer.6.attention.self.value.weight:\tFalse\n",
      "encoder.layer.6.attention.self.value.bias:\tFalse\n",
      "encoder.layer.6.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.6.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.6.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.6.output.dense.weight:\tFalse\n",
      "encoder.layer.6.output.dense.bias:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.attention.self.query.weight:\tFalse\n",
      "encoder.layer.7.attention.self.query.bias:\tFalse\n",
      "encoder.layer.7.attention.self.key.weight:\tFalse\n",
      "encoder.layer.7.attention.self.key.bias:\tFalse\n",
      "encoder.layer.7.attention.self.value.weight:\tFalse\n",
      "encoder.layer.7.attention.self.value.bias:\tFalse\n",
      "encoder.layer.7.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.7.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.7.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.7.output.dense.weight:\tFalse\n",
      "encoder.layer.7.output.dense.bias:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.attention.self.query.weight:\tFalse\n",
      "encoder.layer.8.attention.self.query.bias:\tFalse\n",
      "encoder.layer.8.attention.self.key.weight:\tFalse\n",
      "encoder.layer.8.attention.self.key.bias:\tFalse\n",
      "encoder.layer.8.attention.self.value.weight:\tFalse\n",
      "encoder.layer.8.attention.self.value.bias:\tFalse\n",
      "encoder.layer.8.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.8.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.8.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.8.output.dense.weight:\tFalse\n",
      "encoder.layer.8.output.dense.bias:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.attention.self.query.weight:\tFalse\n",
      "encoder.layer.9.attention.self.query.bias:\tFalse\n",
      "encoder.layer.9.attention.self.key.weight:\tFalse\n",
      "encoder.layer.9.attention.self.key.bias:\tFalse\n",
      "encoder.layer.9.attention.self.value.weight:\tFalse\n",
      "encoder.layer.9.attention.self.value.bias:\tFalse\n",
      "encoder.layer.9.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.9.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.9.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.9.output.dense.weight:\tFalse\n",
      "encoder.layer.9.output.dense.bias:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.attention.self.query.weight:\tFalse\n",
      "encoder.layer.10.attention.self.query.bias:\tFalse\n",
      "encoder.layer.10.attention.self.key.weight:\tFalse\n",
      "encoder.layer.10.attention.self.key.bias:\tFalse\n",
      "encoder.layer.10.attention.self.value.weight:\tFalse\n",
      "encoder.layer.10.attention.self.value.bias:\tFalse\n",
      "encoder.layer.10.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.10.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.10.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.10.output.dense.weight:\tFalse\n",
      "encoder.layer.10.output.dense.bias:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.attention.self.query.weight:\tFalse\n",
      "encoder.layer.11.attention.self.query.bias:\tFalse\n",
      "encoder.layer.11.attention.self.key.weight:\tFalse\n",
      "encoder.layer.11.attention.self.key.bias:\tFalse\n",
      "encoder.layer.11.attention.self.value.weight:\tFalse\n",
      "encoder.layer.11.attention.self.value.bias:\tFalse\n",
      "encoder.layer.11.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.11.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.11.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.11.output.dense.weight:\tFalse\n",
      "encoder.layer.11.output.dense.bias:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.bias:\tFalse\n",
      "pooler.dense.weight:\tFalse\n",
      "pooler.dense.bias:\tFalse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fusion_model:\r\n",
      "BERT(\r\n",
      "  (bert): BertModel(\r\n",
      "    (embeddings): BertEmbeddings(\r\n",
      "      (word_embeddings): Embedding(30522, 768)\r\n",
      "      (position_embeddings): Embedding(512, 768)\r\n",
      "      (token_type_embeddings): Embedding(2, 768)\r\n",
      "      (LayerNorm): BertLayerNorm()\r\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "    )\r\n",
      "    (encoder): BertEncoder(\r\n",
      "      (layer): ModuleList(\r\n",
      "        (0): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (1): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (2): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (3): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (4): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (5): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (6): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (7): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (8): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (9): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (10): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (11): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (pooler): BertPooler(\r\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "      (activation): Tanh()\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (lstm): LSTM(768, 768, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\r\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "  (fc_rnn): Linear(in_features=1536, out_features=1024, bias=True)\r\n",
      "  (mlp): GroupMLP(\r\n",
      "    (conv1): Conv1d(768, 8192, kernel_size=(1,), stride=(1,))\r\n",
      "    (drop): Dropout(p=0.5, inplace=False)\r\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\r\n",
      "    (conv2): Conv1d(8192, 1024, kernel_size=(1,), stride=(1,), groups=64)\r\n",
      "  )\r\n",
      ")\r\n",
      "Answer Model:\r\n",
      "MLP(\r\n",
      "  (mlp): GroupMLP(\r\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\r\n",
      "    (drop): Dropout(p=0.0, inplace=False)\r\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\r\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\r\n",
      "  )\r\n",
      ")\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E000:   0% 0/21 [00:00<?, ?it/s]torch.Size([128, 1024]) torch.Size([103, 1024])\n",
      "train E000: 100% 21/21 [00:04<00:00,  4.42it/s]\n",
      "INFO - 07/17/22 12:07:57 - 0:00:42 - Train Epoch 0: LOSS= 6.56301, lr= 0.000500, acc1= 18.40,acc3= 38.03,acc10= 68.79\n",
      "train E001: 100% 21/21 [00:04<00:00,  4.66it/s]\n",
      "INFO - 07/17/22 12:08:01 - 0:00:46 - Train Epoch 1: LOSS= 2.04492, lr= 0.000750, acc1= 42.15,acc3= 67.48,acc10= 92.88\n",
      "eval E001: 100% 23/23 [00:03<00:00,  6.19it/s]\n",
      "INFO - 07/17/22 12:08:05 - 0:00:50 - #################################################################################################################\n",
      "INFO - 07/17/22 12:08:05 - 0:00:50 - Test Epoch 1: LOSS= 1.70517, acc1= 51.04, acc3= 72.72, acc10= 93.94\n",
      "INFO - 07/17/22 12:08:05 - 0:00:50 - #################################################################################################################\n",
      "train E002: 100% 21/21 [00:04<00:00,  4.58it/s]\n",
      "INFO - 07/17/22 12:08:10 - 0:00:55 - Train Epoch 2: LOSS= 1.68899, lr= 0.001000, acc1= 51.33,acc3= 74.71,acc10= 94.45\n",
      "eval E002: 100% 23/23 [00:03<00:00,  6.10it/s]\n",
      "INFO - 07/17/22 12:08:13 - 0:00:58 - #################################################################################################################\n",
      "INFO - 07/17/22 12:08:13 - 0:00:58 - Test Epoch 2: LOSS= 1.44609, acc1= 59.26, acc3= 79.21, acc10= 95.25\n",
      "INFO - 07/17/22 12:08:13 - 0:00:58 - #################################################################################################################\n",
      "train E003: 100% 21/21 [00:04<00:00,  4.49it/s]\n",
      "INFO - 07/17/22 12:08:18 - 0:01:03 - Train Epoch 3: LOSS= 1.49642, lr= 0.001250, acc1= 57.17,acc3= 78.72,acc10= 95.58\n",
      "eval E003: 100% 23/23 [00:03<00:00,  5.99it/s]\n",
      "INFO - 07/17/22 12:08:22 - 0:01:07 - #################################################################################################################\n",
      "INFO - 07/17/22 12:08:22 - 0:01:07 - Test Epoch 3: LOSS= 1.41324, acc1= 63.62, acc3= 79.74, acc10= 95.54\n",
      "INFO - 07/17/22 12:08:22 - 0:01:07 - #################################################################################################################\n",
      "train E004: 100% 21/21 [00:04<00:00,  4.45it/s]\n",
      "INFO - 07/17/22 12:08:27 - 0:01:12 - Train Epoch 4: LOSS= 1.46771, lr= 0.001500, acc1= 57.03,acc3= 79.36,acc10= 95.92\n",
      "eval E004: 100% 23/23 [00:03<00:00,  5.79it/s]\n",
      "INFO - 07/17/22 12:08:31 - 0:01:16 - #################################################################################################################\n",
      "INFO - 07/17/22 12:08:31 - 0:01:16 - Test Epoch 4: LOSS= 1.43930, acc1= 61.18, acc3= 80.80, acc10= 95.29\n",
      "INFO - 07/17/22 12:08:31 - 0:01:16 - #################################################################################################################\n",
      "train E005: 100% 21/21 [00:04<00:00,  4.37it/s]\n",
      "INFO - 07/17/22 12:08:35 - 0:01:20 - Train Epoch 5: LOSS= 1.36052, lr= 0.001750, acc1= 59.76,acc3= 81.42,acc10= 96.89\n",
      "eval E005: 100% 23/23 [00:03<00:00,  5.96it/s]\n",
      "INFO - 07/17/22 12:08:39 - 0:01:24 - #################################################################################################################\n",
      "INFO - 07/17/22 12:08:39 - 0:01:24 - Test Epoch 5: LOSS= 1.34333, acc1= 60.82, acc3= 82.15, acc10= 96.21\n",
      "INFO - 07/17/22 12:08:39 - 0:01:24 - #################################################################################################################\n",
      "train E006: 100% 21/21 [00:04<00:00,  4.42it/s]\n",
      "INFO - 07/17/22 12:08:44 - 0:01:29 - Train Epoch 6: LOSS= 1.30165, lr= 0.002000, acc1= 59.80,acc3= 83.21,acc10= 97.79\n",
      "eval E006: 100% 23/23 [00:03<00:00,  5.86it/s]\n",
      "INFO - 07/17/22 12:08:48 - 0:01:33 - #################################################################################################################\n",
      "INFO - 07/17/22 12:08:48 - 0:01:33 - Test Epoch 6: LOSS= 1.34160, acc1= 62.06, acc3= 82.00, acc10= 95.86\n",
      "INFO - 07/17/22 12:08:48 - 0:01:33 - #################################################################################################################\n",
      "train E007: 100% 21/21 [00:04<00:00,  4.48it/s]\n",
      "INFO - 07/17/22 12:08:53 - 0:01:38 - Train Epoch 7: LOSS= 1.20585, lr= 0.002000, acc1= 62.83,acc3= 84.53,acc10= 98.16\n",
      "eval E007: 100% 23/23 [00:03<00:00,  5.93it/s]\n",
      "INFO - 07/17/22 12:08:57 - 0:01:42 - #################################################################################################################\n",
      "INFO - 07/17/22 12:08:57 - 0:01:42 - Test Epoch 7: LOSS= 1.28943, acc1= 65.43, acc3= 83.56, acc10= 96.17\n",
      "INFO - 07/17/22 12:08:57 - 0:01:42 - #################################################################################################################\n",
      "train E008: 100% 21/21 [00:04<00:00,  4.47it/s]\n",
      "INFO - 07/17/22 12:09:01 - 0:01:46 - Train Epoch 8: LOSS= 1.19252, lr= 0.002000, acc1= 63.43,acc3= 85.09,acc10= 97.83\n",
      "eval E008: 100% 23/23 [00:03<00:00,  5.90it/s]\n",
      "INFO - 07/17/22 12:09:05 - 0:01:50 - #################################################################################################################\n",
      "INFO - 07/17/22 12:09:05 - 0:01:50 - Test Epoch 8: LOSS= 1.55466, acc1= 57.03, acc3= 81.08, acc10= 95.01\n",
      "INFO - 07/17/22 12:09:05 - 0:01:50 - #################################################################################################################\n",
      "train E009: 100% 21/21 [00:04<00:00,  4.39it/s]\n",
      "INFO - 07/17/22 12:09:10 - 0:01:55 - Train Epoch 9: LOSS= 1.16213, lr= 0.002000, acc1= 63.84,acc3= 85.80,acc10= 98.05\n",
      "eval E009: 100% 23/23 [00:03<00:00,  5.92it/s]\n",
      "INFO - 07/17/22 12:09:14 - 0:01:59 - #################################################################################################################\n",
      "INFO - 07/17/22 12:09:14 - 0:01:59 - Test Epoch 9: LOSS= 1.29607, acc1= 65.18, acc3= 84.20, acc10= 96.49\n",
      "INFO - 07/17/22 12:09:14 - 0:01:59 - #################################################################################################################\n",
      "train E010: 100% 21/21 [00:04<00:00,  4.40it/s]\n",
      "INFO - 07/17/22 12:09:19 - 0:02:04 - Train Epoch 10: LOSS= 1.09265, lr= 0.002000, acc1= 66.50,acc3= 86.77,acc10= 98.46\n",
      "eval E010: 100% 23/23 [00:03<00:00,  5.85it/s]\n",
      "INFO - 07/17/22 12:09:23 - 0:02:08 - #################################################################################################################\n",
      "INFO - 07/17/22 12:09:23 - 0:02:08 - Test Epoch 10: LOSS= 1.33580, acc1= 66.49, acc3= 85.23, acc10= 96.21\n",
      "INFO - 07/17/22 12:09:23 - 0:02:08 - #################################################################################################################\n",
      "train E011: 100% 21/21 [00:04<00:00,  4.46it/s]\n",
      "INFO - 07/17/22 12:09:27 - 0:02:12 - Train Epoch 11: LOSS= 1.04483, lr= 0.002000, acc1= 67.37,acc3= 87.79,acc10= 99.03\n",
      "eval E011: 100% 23/23 [00:03<00:00,  5.89it/s]\n",
      "INFO - 07/17/22 12:09:31 - 0:02:16 - #################################################################################################################\n",
      "INFO - 07/17/22 12:09:31 - 0:02:16 - Test Epoch 11: LOSS= 1.29773, acc1= 67.48, acc3= 85.97, acc10= 96.56\n",
      "INFO - 07/17/22 12:09:31 - 0:02:16 - #################################################################################################################\n",
      "train E012: 100% 21/21 [00:04<00:00,  4.42it/s]\n",
      "INFO - 07/17/22 12:09:36 - 0:02:21 - Train Epoch 12: LOSS= 1.04241, lr= 0.002000, acc1= 67.97,acc3= 87.86,acc10= 98.99\n",
      "eval E012: 100% 23/23 [00:03<00:00,  5.96it/s]\n",
      "INFO - 07/17/22 12:09:40 - 0:02:25 - #################################################################################################################\n",
      "INFO - 07/17/22 12:09:40 - 0:02:25 - Test Epoch 12: LOSS= 1.25151, acc1= 66.49, acc3= 85.02, acc10= 96.56\n",
      "INFO - 07/17/22 12:09:40 - 0:02:25 - #################################################################################################################\n",
      "train E013: 100% 21/21 [00:04<00:00,  4.41it/s]\n",
      "INFO - 07/17/22 12:09:45 - 0:02:30 - Train Epoch 13: LOSS= 1.01433, lr= 0.002000, acc1= 68.71,acc3= 89.17,acc10= 99.21\n",
      "eval E013: 100% 23/23 [00:03<00:00,  5.90it/s]\n",
      "INFO - 07/17/22 12:09:49 - 0:02:34 - #################################################################################################################\n",
      "INFO - 07/17/22 12:09:49 - 0:02:34 - Test Epoch 13: LOSS= 1.27780, acc1= 67.98, acc3= 84.80, acc10= 96.32\n",
      "INFO - 07/17/22 12:09:49 - 0:02:34 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E014: 100% 21/21 [00:04<00:00,  4.50it/s]\n",
      "INFO - 07/17/22 12:09:53 - 0:02:38 - Train Epoch 14: LOSS= 0.94230, lr= 0.001400, acc1= 70.10,acc3= 89.92,acc10= 99.36\n",
      "eval E014: 100% 23/23 [00:03<00:00,  5.85it/s]\n",
      "INFO - 07/17/22 12:09:57 - 0:02:42 - #################################################################################################################\n",
      "INFO - 07/17/22 12:09:57 - 0:02:42 - Test Epoch 14: LOSS= 1.24746, acc1= 68.05, acc3= 86.26, acc10= 96.71\n",
      "INFO - 07/17/22 12:09:57 - 0:02:42 - #################################################################################################################\n",
      "train E015: 100% 21/21 [00:04<00:00,  4.60it/s]\n",
      "INFO - 07/17/22 12:10:02 - 0:02:47 - Train Epoch 15: LOSS= 0.84713, lr= 0.001400, acc1= 72.84,acc3= 91.91,acc10= 99.55\n",
      "eval E015: 100% 23/23 [00:03<00:00,  6.17it/s]\n",
      "INFO - 07/17/22 12:10:06 - 0:02:51 - #################################################################################################################\n",
      "INFO - 07/17/22 12:10:06 - 0:02:51 - Test Epoch 15: LOSS= 1.27343, acc1= 66.56, acc3= 87.14, acc10= 96.85\n",
      "INFO - 07/17/22 12:10:06 - 0:02:51 - #################################################################################################################\n",
      "train E016: 100% 21/21 [00:04<00:00,  4.64it/s]\n",
      "INFO - 07/17/22 12:10:10 - 0:02:55 - Train Epoch 16: LOSS= 0.84984, lr= 0.001400, acc1= 73.06,acc3= 92.02,acc10= 99.40\n",
      "eval E016: 100% 23/23 [00:03<00:00,  6.21it/s]\n",
      "INFO - 07/17/22 12:10:14 - 0:02:59 - #################################################################################################################\n",
      "INFO - 07/17/22 12:10:14 - 0:02:59 - Test Epoch 16: LOSS= 1.20106, acc1= 67.94, acc3= 86.36, acc10= 96.99\n",
      "INFO - 07/17/22 12:10:14 - 0:02:59 - #################################################################################################################\n",
      "train E017: 100% 21/21 [00:04<00:00,  4.64it/s]\n",
      "INFO - 07/17/22 12:10:18 - 0:03:03 - Train Epoch 17: LOSS= 0.81096, lr= 0.000980, acc1= 74.04,acc3= 92.69,acc10= 99.70\n",
      "eval E017: 100% 23/23 [00:03<00:00,  6.22it/s]\n",
      "INFO - 07/17/22 12:10:22 - 0:03:07 - #################################################################################################################\n",
      "INFO - 07/17/22 12:10:22 - 0:03:07 - Test Epoch 17: LOSS= 1.22646, acc1= 67.80, acc3= 87.96, acc10= 97.02\n",
      "INFO - 07/17/22 12:10:22 - 0:03:07 - #################################################################################################################\n",
      "train E018: 100% 21/21 [00:04<00:00,  4.56it/s]\n",
      "INFO - 07/17/22 12:10:27 - 0:03:12 - Train Epoch 18: LOSS= 0.76294, lr= 0.000980, acc1= 75.01,acc3= 93.26,acc10= 99.66\n",
      "eval E018: 100% 23/23 [00:03<00:00,  6.13it/s]\n",
      "INFO - 07/17/22 12:10:30 - 0:03:16 - #################################################################################################################\n",
      "INFO - 07/17/22 12:10:30 - 0:03:16 - Test Epoch 18: LOSS= 1.31987, acc1= 69.08, acc3= 86.01, acc10= 96.25\n",
      "INFO - 07/17/22 12:10:30 - 0:03:16 - #################################################################################################################\n",
      "train E019: 100% 21/21 [00:04<00:00,  4.66it/s]\n",
      "INFO - 07/17/22 12:10:35 - 0:03:20 - Train Epoch 19: LOSS= 0.73275, lr= 0.000980, acc1= 76.02,acc3= 93.63,acc10= 99.70\n",
      "eval E019: 100% 23/23 [00:03<00:00,  6.11it/s]\n",
      "INFO - 07/17/22 12:10:39 - 0:03:24 - #################################################################################################################\n",
      "INFO - 07/17/22 12:10:39 - 0:03:24 - Test Epoch 19: LOSS= 1.31960, acc1= 68.01, acc3= 86.68, acc10= 96.74\n",
      "INFO - 07/17/22 12:10:39 - 0:03:24 - #################################################################################################################\n",
      "train E020: 100% 21/21 [00:04<00:00,  4.64it/s]\n",
      "INFO - 07/17/22 12:10:43 - 0:03:28 - Train Epoch 20: LOSS= 0.69282, lr= 0.000686, acc1= 77.22,acc3= 94.23,acc10= 99.74\n",
      "eval E020: 100% 23/23 [00:03<00:00,  5.98it/s]\n",
      "INFO - 07/17/22 12:10:47 - 0:03:32 - #################################################################################################################\n",
      "INFO - 07/17/22 12:10:47 - 0:03:32 - Test Epoch 20: LOSS= 1.25564, acc1= 69.29, acc3= 86.96, acc10= 96.78\n",
      "INFO - 07/17/22 12:10:47 - 0:03:32 - #################################################################################################################\n",
      "train E021: 100% 21/21 [00:04<00:00,  4.54it/s]\n",
      "INFO - 07/17/22 12:10:52 - 0:03:37 - Train Epoch 21: LOSS= 0.65334, lr= 0.000686, acc1= 78.68,acc3= 95.32,acc10= 99.96\n",
      "eval E021: 100% 23/23 [00:03<00:00,  6.08it/s]\n",
      "INFO - 07/17/22 12:10:56 - 0:03:41 - #################################################################################################################\n",
      "INFO - 07/17/22 12:10:56 - 0:03:41 - Test Epoch 21: LOSS= 1.24370, acc1= 69.61, acc3= 87.28, acc10= 97.10\n",
      "INFO - 07/17/22 12:10:56 - 0:03:41 - #################################################################################################################\n",
      "train E022: 100% 21/21 [00:04<00:00,  4.51it/s]\n",
      "INFO - 07/17/22 12:11:00 - 0:03:45 - Train Epoch 22: LOSS= 0.64940, lr= 0.000686, acc1= 77.86,acc3= 95.13,acc10= 99.85\n",
      "eval E022: 100% 23/23 [00:03<00:00,  6.10it/s]\n",
      "INFO - 07/17/22 12:11:04 - 0:03:49 - #################################################################################################################\n",
      "INFO - 07/17/22 12:11:04 - 0:03:49 - Test Epoch 22: LOSS= 1.36366, acc1= 68.97, acc3= 87.21, acc10= 97.34\n",
      "INFO - 07/17/22 12:11:04 - 0:03:49 - #################################################################################################################\n",
      "train E023: 100% 21/21 [00:04<00:00,  4.61it/s]\n",
      "INFO - 07/17/22 12:11:09 - 0:03:54 - Train Epoch 23: LOSS= 0.63776, lr= 0.000480, acc1= 78.08,acc3= 95.24,acc10= 100.00\n",
      "eval E023: 100% 23/23 [00:03<00:00,  6.21it/s]\n",
      "INFO - 07/17/22 12:11:12 - 0:03:57 - #################################################################################################################\n",
      "INFO - 07/17/22 12:11:12 - 0:03:57 - Test Epoch 23: LOSS= 1.21942, acc1= 69.78, acc3= 87.64, acc10= 97.10\n",
      "INFO - 07/17/22 12:11:12 - 0:03:57 - #################################################################################################################\n",
      "train E024: 100% 21/21 [00:04<00:00,  4.63it/s]\n",
      "INFO - 07/17/22 12:11:17 - 0:04:02 - Train Epoch 24: LOSS= 0.61491, lr= 0.000480, acc1= 80.07,acc3= 95.88,acc10= 99.78\n",
      "eval E024: 100% 23/23 [00:03<00:00,  6.01it/s]\n",
      "INFO - 07/17/22 12:11:21 - 0:04:06 - #################################################################################################################\n",
      "INFO - 07/17/22 12:11:21 - 0:04:06 - Test Epoch 24: LOSS= 1.32107, acc1= 69.22, acc3= 88.03, acc10= 96.78\n",
      "INFO - 07/17/22 12:11:21 - 0:04:06 - #################################################################################################################\n",
      "train E025: 100% 21/21 [00:04<00:00,  4.57it/s]\n",
      "INFO - 07/17/22 12:11:25 - 0:04:10 - Train Epoch 25: LOSS= 0.59009, lr= 0.000480, acc1= 81.19,acc3= 96.10,acc10= 99.89\n",
      "eval E025: 100% 23/23 [00:03<00:00,  5.86it/s]\n",
      "INFO - 07/17/22 12:11:29 - 0:04:14 - #################################################################################################################\n",
      "INFO - 07/17/22 12:11:29 - 0:04:14 - Test Epoch 25: LOSS= 1.27735, acc1= 68.61, acc3= 88.27, acc10= 96.95\n",
      "INFO - 07/17/22 12:11:29 - 0:04:14 - #################################################################################################################\n",
      "train E026: 100% 21/21 [00:04<00:00,  4.36it/s]\n",
      "INFO - 07/17/22 12:11:34 - 0:04:19 - Train Epoch 26: LOSS= 0.55905, lr= 0.000336, acc1= 81.34,acc3= 96.70,acc10= 99.96\n",
      "eval E026: 100% 23/23 [00:03<00:00,  5.92it/s]\n",
      "INFO - 07/17/22 12:11:38 - 0:04:23 - #################################################################################################################\n",
      "INFO - 07/17/22 12:11:38 - 0:04:23 - Test Epoch 26: LOSS= 1.24021, acc1= 69.36, acc3= 88.24, acc10= 97.24\n",
      "INFO - 07/17/22 12:11:38 - 0:04:23 - #################################################################################################################\n",
      "train E027: 100% 21/21 [00:04<00:00,  4.51it/s]\n",
      "INFO - 07/17/22 12:11:43 - 0:04:28 - Train Epoch 27: LOSS= 0.54564, lr= 0.000336, acc1= 81.23,acc3= 96.89,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E027: 100% 23/23 [00:03<00:00,  5.90it/s]\n",
      "INFO - 07/17/22 12:11:47 - 0:04:32 - #################################################################################################################\n",
      "INFO - 07/17/22 12:11:47 - 0:04:32 - Test Epoch 27: LOSS= 1.35839, acc1= 68.51, acc3= 88.10, acc10= 96.92\n",
      "INFO - 07/17/22 12:11:47 - 0:04:32 - #################################################################################################################\n",
      "train E028: 100% 21/21 [00:04<00:00,  4.46it/s]\n",
      "INFO - 07/17/22 12:11:51 - 0:04:36 - Train Epoch 28: LOSS= 0.55727, lr= 0.000336, acc1= 80.55,acc3= 97.08,acc10= 99.93\n",
      "eval E028: 100% 23/23 [00:03<00:00,  5.88it/s]\n",
      "INFO - 07/17/22 12:11:55 - 0:04:40 - #################################################################################################################\n",
      "INFO - 07/17/22 12:11:55 - 0:04:40 - Test Epoch 28: LOSS= 1.31710, acc1= 69.11, acc3= 88.13, acc10= 97.34\n",
      "INFO - 07/17/22 12:11:55 - 0:04:40 - #################################################################################################################\n",
      "train E029: 100% 21/21 [00:04<00:00,  4.42it/s]\n",
      "INFO - 07/17/22 12:12:00 - 0:04:45 - Train Epoch 29: LOSS= 0.52955, lr= 0.000235, acc1= 82.50,acc3= 96.55,acc10= 99.96\n",
      "eval E029: 100% 23/23 [00:03<00:00,  5.79it/s]\n",
      "INFO - 07/17/22 12:12:04 - 0:04:49 - #################################################################################################################\n",
      "INFO - 07/17/22 12:12:04 - 0:04:49 - Test Epoch 29: LOSS= 1.39865, acc1= 70.46, acc3= 88.17, acc10= 97.17\n",
      "INFO - 07/17/22 12:12:04 - 0:04:49 - #################################################################################################################\n",
      "train E030: 100% 21/21 [00:04<00:00,  4.47it/s]\n",
      "INFO - 07/17/22 12:12:09 - 0:04:54 - Train Epoch 30: LOSS= 0.49001, lr= 0.000235, acc1= 83.18,acc3= 97.56,acc10= 99.89\n",
      "eval E030: 100% 23/23 [00:03<00:00,  5.96it/s]\n",
      "INFO - 07/17/22 12:12:13 - 0:04:58 - #################################################################################################################\n",
      "INFO - 07/17/22 12:12:13 - 0:04:58 - Test Epoch 30: LOSS= 1.48130, acc1= 69.71, acc3= 87.32, acc10= 96.99\n",
      "INFO - 07/17/22 12:12:13 - 0:04:58 - #################################################################################################################\n",
      "train E031: 100% 21/21 [00:04<00:00,  4.54it/s]\n",
      "INFO - 07/17/22 12:12:17 - 0:05:02 - Train Epoch 31: LOSS= 0.49679, lr= 0.000235, acc1= 82.28,acc3= 96.85,acc10= 99.96\n",
      "eval E031: 100% 23/23 [00:03<00:00,  5.81it/s]\n",
      "INFO - 07/17/22 12:12:21 - 0:05:06 - #################################################################################################################\n",
      "INFO - 07/17/22 12:12:21 - 0:05:06 - Test Epoch 31: LOSS= 1.44232, acc1= 70.10, acc3= 87.85, acc10= 96.99\n",
      "INFO - 07/17/22 12:12:21 - 0:05:06 - #################################################################################################################\n",
      "train E032: 100% 21/21 [00:04<00:00,  4.44it/s]\n",
      "INFO - 07/17/22 12:12:26 - 0:05:11 - Train Epoch 32: LOSS= 0.47261, lr= 0.000165, acc1= 83.78,acc3= 97.12,acc10= 99.96\n",
      "eval E032: 100% 23/23 [00:03<00:00,  5.97it/s]\n",
      "INFO - 07/17/22 12:12:30 - 0:05:15 - #################################################################################################################\n",
      "INFO - 07/17/22 12:12:30 - 0:05:15 - Test Epoch 32: LOSS= 1.36585, acc1= 69.18, acc3= 88.17, acc10= 97.02\n",
      "INFO - 07/17/22 12:12:30 - 0:05:15 - #################################################################################################################\n",
      "train E033: 100% 21/21 [00:04<00:00,  4.50it/s]\n",
      "INFO - 07/17/22 12:12:34 - 0:05:19 - Train Epoch 33: LOSS= 0.47844, lr= 0.000165, acc1= 84.11,acc3= 97.49,acc10= 99.93\n",
      "eval E033: 100% 23/23 [00:03<00:00,  5.92it/s]\n",
      "INFO - 07/17/22 12:12:38 - 0:05:23 - #################################################################################################################\n",
      "INFO - 07/17/22 12:12:38 - 0:05:23 - Test Epoch 33: LOSS= 1.48823, acc1= 70.00, acc3= 87.57, acc10= 97.10\n",
      "INFO - 07/17/22 12:12:38 - 0:05:23 - #################################################################################################################\n",
      "train E034: 100% 21/21 [00:04<00:00,  4.50it/s]\n",
      "INFO - 07/17/22 12:12:43 - 0:05:28 - Train Epoch 34: LOSS= 0.45536, lr= 0.000165, acc1= 84.11,acc3= 98.01,acc10= 100.00\n",
      "eval E034: 100% 23/23 [00:03<00:00,  5.91it/s]\n",
      "INFO - 07/17/22 12:12:47 - 0:05:32 - #################################################################################################################\n",
      "INFO - 07/17/22 12:12:47 - 0:05:32 - Test Epoch 34: LOSS= 1.39782, acc1= 70.63, acc3= 88.06, acc10= 97.13\n",
      "INFO - 07/17/22 12:12:47 - 0:05:32 - #################################################################################################################\n",
      "train E035: 100% 21/21 [00:04<00:00,  4.36it/s]\n",
      "INFO - 07/17/22 12:12:52 - 0:05:37 - Train Epoch 35: LOSS= 0.46639, lr= 0.000115, acc1= 84.49,acc3= 97.38,acc10= 99.96\n",
      "eval E035: 100% 23/23 [00:03<00:00,  5.83it/s]\n",
      "INFO - 07/17/22 12:12:56 - 0:05:41 - #################################################################################################################\n",
      "INFO - 07/17/22 12:12:56 - 0:05:41 - Test Epoch 35: LOSS= 1.39118, acc1= 69.71, acc3= 87.57, acc10= 97.10\n",
      "INFO - 07/17/22 12:12:56 - 0:05:41 - #################################################################################################################\n",
      "train E036: 100% 21/21 [00:04<00:00,  4.47it/s]\n",
      "INFO - 07/17/22 12:13:00 - 0:05:45 - Train Epoch 36: LOSS= 0.46168, lr= 0.000115, acc1= 83.74,acc3= 97.90,acc10= 99.93\n",
      "eval E036: 100% 23/23 [00:03<00:00,  5.80it/s]\n",
      "INFO - 07/17/22 12:13:04 - 0:05:49 - #################################################################################################################\n",
      "INFO - 07/17/22 12:13:04 - 0:05:49 - Test Epoch 36: LOSS= 1.39266, acc1= 70.67, acc3= 88.06, acc10= 97.10\n",
      "INFO - 07/17/22 12:13:04 - 0:05:49 - #################################################################################################################\n",
      "train E037: 100% 21/21 [00:04<00:00,  4.34it/s]\n",
      "INFO - 07/17/22 12:13:09 - 0:05:54 - Train Epoch 37: LOSS= 0.43048, lr= 0.000115, acc1= 85.39,acc3= 97.90,acc10= 99.96\n",
      "eval E037: 100% 23/23 [00:03<00:00,  6.09it/s]\n",
      "INFO - 07/17/22 12:13:13 - 0:05:58 - #################################################################################################################\n",
      "INFO - 07/17/22 12:13:13 - 0:05:58 - Test Epoch 37: LOSS= 1.41965, acc1= 70.67, acc3= 88.03, acc10= 97.13\n",
      "INFO - 07/17/22 12:13:13 - 0:05:58 - #################################################################################################################\n",
      "train E038: 100% 21/21 [00:04<00:00,  4.67it/s]\n",
      "INFO - 07/17/22 12:13:17 - 0:06:02 - Train Epoch 38: LOSS= 0.44243, lr= 0.000081, acc1= 84.68,acc3= 97.90,acc10= 99.96\n",
      "eval E038: 100% 23/23 [00:03<00:00,  6.19it/s]\n",
      "INFO - 07/17/22 12:13:21 - 0:06:06 - #################################################################################################################\n",
      "INFO - 07/17/22 12:13:21 - 0:06:06 - Test Epoch 38: LOSS= 1.43960, acc1= 70.14, acc3= 88.17, acc10= 97.17\n",
      "INFO - 07/17/22 12:13:21 - 0:06:06 - #################################################################################################################\n",
      "train E039: 100% 21/21 [00:04<00:00,  4.63it/s]\n",
      "INFO - 07/17/22 12:13:26 - 0:06:11 - Train Epoch 39: LOSS= 0.44478, lr= 0.000081, acc1= 84.90,acc3= 97.79,acc10= 100.00\n",
      "eval E039: 100% 23/23 [00:03<00:00,  6.12it/s]\n",
      "INFO - 07/17/22 12:13:29 - 0:06:14 - #################################################################################################################\n",
      "INFO - 07/17/22 12:13:29 - 0:06:14 - Test Epoch 39: LOSS= 1.52694, acc1= 70.14, acc3= 87.78, acc10= 97.13\n",
      "INFO - 07/17/22 12:13:29 - 0:06:14 - #################################################################################################################\n",
      "train E040: 100% 21/21 [00:04<00:00,  4.65it/s]\n",
      "INFO - 07/17/22 12:13:34 - 0:06:19 - Train Epoch 40: LOSS= 0.43240, lr= 0.000081, acc1= 85.16,acc3= 97.94,acc10= 100.00\n",
      "eval E040: 100% 23/23 [00:03<00:00,  6.19it/s]\n",
      "INFO - 07/17/22 12:13:38 - 0:06:23 - #################################################################################################################\n",
      "INFO - 07/17/22 12:13:38 - 0:06:23 - Test Epoch 40: LOSS= 1.51356, acc1= 71.27, acc3= 88.10, acc10= 97.13\n",
      "INFO - 07/17/22 12:13:38 - 0:06:23 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E041: 100% 21/21 [00:04<00:00,  4.63it/s]\n",
      "INFO - 07/17/22 12:13:42 - 0:06:27 - Train Epoch 41: LOSS= 0.43448, lr= 0.000056, acc1= 84.79,acc3= 98.01,acc10= 99.96\n",
      "eval E041: 100% 23/23 [00:03<00:00,  6.12it/s]\n",
      "INFO - 07/17/22 12:13:46 - 0:06:31 - #################################################################################################################\n",
      "INFO - 07/17/22 12:13:46 - 0:06:31 - Test Epoch 41: LOSS= 1.48124, acc1= 70.56, acc3= 88.03, acc10= 97.06\n",
      "INFO - 07/17/22 12:13:46 - 0:06:31 - #################################################################################################################\n",
      "train E042: 100% 21/21 [00:04<00:00,  4.63it/s]\n",
      "INFO - 07/17/22 12:13:51 - 0:06:36 - Train Epoch 42: LOSS= 0.41787, lr= 0.000056, acc1= 85.69,acc3= 97.90,acc10= 99.96\n",
      "eval E042: 100% 23/23 [00:03<00:00,  6.20it/s]\n",
      "INFO - 07/17/22 12:13:54 - 0:06:39 - #################################################################################################################\n",
      "INFO - 07/17/22 12:13:54 - 0:06:39 - Test Epoch 42: LOSS= 1.48296, acc1= 70.14, acc3= 88.13, acc10= 97.13\n",
      "INFO - 07/17/22 12:13:54 - 0:06:39 - #################################################################################################################\n",
      "train E043: 100% 21/21 [00:04<00:00,  4.67it/s]\n",
      "INFO - 07/17/22 12:13:59 - 0:06:44 - Train Epoch 43: LOSS= 0.41882, lr= 0.000056, acc1= 85.39,acc3= 97.45,acc10= 100.00\n",
      "eval E043: 100% 23/23 [00:03<00:00,  6.22it/s]\n",
      "INFO - 07/17/22 12:14:02 - 0:06:47 - #################################################################################################################\n",
      "INFO - 07/17/22 12:14:02 - 0:06:47 - Test Epoch 43: LOSS= 1.45896, acc1= 70.46, acc3= 87.99, acc10= 97.20\n",
      "INFO - 07/17/22 12:14:02 - 0:06:47 - #################################################################################################################\n",
      "train E044: 100% 21/21 [00:04<00:00,  4.64it/s]\n",
      "INFO - 07/17/22 12:14:07 - 0:06:52 - Train Epoch 44: LOSS= 0.43205, lr= 0.000040, acc1= 85.39,acc3= 97.83,acc10= 100.00\n",
      "eval E044: 100% 23/23 [00:03<00:00,  6.15it/s]\n",
      "INFO - 07/17/22 12:14:11 - 0:06:56 - #################################################################################################################\n",
      "INFO - 07/17/22 12:14:11 - 0:06:56 - Test Epoch 44: LOSS= 1.46643, acc1= 70.46, acc3= 88.06, acc10= 97.20\n",
      "INFO - 07/17/22 12:14:11 - 0:06:56 - #################################################################################################################\n",
      "train E045: 100% 21/21 [00:04<00:00,  4.63it/s]\n",
      "INFO - 07/17/22 12:14:15 - 0:07:00 - Train Epoch 45: LOSS= 0.40753, lr= 0.000040, acc1= 86.14,acc3= 98.05,acc10= 99.96\n",
      "eval E045: 100% 23/23 [00:03<00:00,  6.16it/s]\n",
      "INFO - 07/17/22 12:14:19 - 0:07:04 - #################################################################################################################\n",
      "INFO - 07/17/22 12:14:19 - 0:07:04 - Test Epoch 45: LOSS= 1.50482, acc1= 70.21, acc3= 87.96, acc10= 97.13\n",
      "INFO - 07/17/22 12:14:19 - 0:07:04 - #################################################################################################################\n",
      "train E046: 100% 21/21 [00:04<00:00,  4.62it/s]\n",
      "INFO - 07/17/22 12:14:24 - 0:07:09 - Train Epoch 46: LOSS= 0.41674, lr= 0.000040, acc1= 85.99,acc3= 98.20,acc10= 100.00\n",
      "eval E046: 100% 23/23 [00:03<00:00,  6.12it/s]\n",
      "INFO - 07/17/22 12:14:27 - 0:07:12 - #################################################################################################################\n",
      "INFO - 07/17/22 12:14:27 - 0:07:12 - Test Epoch 46: LOSS= 1.46710, acc1= 70.46, acc3= 88.20, acc10= 97.13\n",
      "INFO - 07/17/22 12:14:27 - 0:07:12 - #################################################################################################################\n",
      "train E047: 100% 21/21 [00:04<00:00,  4.60it/s]\n",
      "INFO - 07/17/22 12:14:32 - 0:07:17 - Train Epoch 47: LOSS= 0.41316, lr= 0.000040, acc1= 85.35,acc3= 98.01,acc10= 100.00\n",
      "eval E047: 100% 23/23 [00:03<00:00,  6.13it/s]\n",
      "INFO - 07/17/22 12:14:36 - 0:07:21 - #################################################################################################################\n",
      "INFO - 07/17/22 12:14:36 - 0:07:21 - Test Epoch 47: LOSS= 1.54587, acc1= 70.17, acc3= 88.20, acc10= 97.13\n",
      "INFO - 07/17/22 12:14:36 - 0:07:21 - #################################################################################################################\n",
      "train E048: 100% 21/21 [00:04<00:00,  4.38it/s]\n",
      "INFO - 07/17/22 12:14:40 - 0:07:25 - Train Epoch 48: LOSS= 0.41479, lr= 0.000040, acc1= 85.16,acc3= 98.13,acc10= 100.00\n",
      "eval E048: 100% 23/23 [00:03<00:00,  5.88it/s]\n",
      "INFO - 07/17/22 12:14:44 - 0:07:29 - #################################################################################################################\n",
      "INFO - 07/17/22 12:14:44 - 0:07:29 - Test Epoch 48: LOSS= 1.49033, acc1= 69.82, acc3= 87.92, acc10= 97.20\n",
      "INFO - 07/17/22 12:14:44 - 0:07:29 - #################################################################################################################\n",
      "train E049: 100% 21/21 [00:04<00:00,  4.44it/s]\n",
      "INFO - 07/17/22 12:14:49 - 0:07:34 - Train Epoch 49: LOSS= 0.40657, lr= 0.000040, acc1= 85.80,acc3= 98.35,acc10= 99.93\n",
      "eval E049: 100% 23/23 [00:03<00:00,  5.86it/s]\n",
      "INFO - 07/17/22 12:14:53 - 0:07:38 - #################################################################################################################\n",
      "INFO - 07/17/22 12:14:53 - 0:07:38 - Test Epoch 49: LOSS= 1.54666, acc1= 70.35, acc3= 88.06, acc10= 97.17\n",
      "INFO - 07/17/22 12:14:53 - 0:07:38 - #################################################################################################################\n",
      "train E050: 100% 21/21 [00:04<00:00,  4.39it/s]\n",
      "INFO - 07/17/22 12:14:58 - 0:07:43 - Train Epoch 50: LOSS= 0.39526, lr= 0.000040, acc1= 85.99,acc3= 97.90,acc10= 99.96\n",
      "eval E050: 100% 23/23 [00:03<00:00,  5.83it/s]\n",
      "INFO - 07/17/22 12:15:02 - 0:07:47 - #################################################################################################################\n",
      "INFO - 07/17/22 12:15:02 - 0:07:47 - Test Epoch 50: LOSS= 1.46399, acc1= 70.35, acc3= 88.13, acc10= 97.13\n",
      "INFO - 07/17/22 12:15:02 - 0:07:47 - #################################################################################################################\n",
      "train E051: 100% 21/21 [00:04<00:00,  4.47it/s]\n",
      "INFO - 07/17/22 12:15:06 - 0:07:51 - Train Epoch 51: LOSS= 0.38783, lr= 0.000040, acc1= 86.55,acc3= 98.73,acc10= 100.00\n",
      "eval E051: 100% 23/23 [00:03<00:00,  5.82it/s]\n",
      "INFO - 07/17/22 12:15:10 - 0:07:55 - #################################################################################################################\n",
      "INFO - 07/17/22 12:15:10 - 0:07:55 - Test Epoch 51: LOSS= 1.53190, acc1= 69.85, acc3= 87.85, acc10= 97.10\n",
      "INFO - 07/17/22 12:15:10 - 0:07:55 - #################################################################################################################\n",
      "train E052: 100% 21/21 [00:04<00:00,  4.46it/s]\n",
      "INFO - 07/17/22 12:15:15 - 0:08:00 - Train Epoch 52: LOSS= 0.38215, lr= 0.000040, acc1= 87.00,acc3= 98.31,acc10= 100.00\n",
      "eval E052: 100% 23/23 [00:03<00:00,  5.83it/s]\n",
      "INFO - 07/17/22 12:15:19 - 0:08:04 - #################################################################################################################\n",
      "INFO - 07/17/22 12:15:19 - 0:08:04 - Test Epoch 52: LOSS= 1.59276, acc1= 69.75, acc3= 87.67, acc10= 97.13\n",
      "INFO - 07/17/22 12:15:19 - 0:08:04 - #################################################################################################################\n",
      "train E053: 100% 21/21 [00:04<00:00,  4.44it/s]\n",
      "INFO - 07/17/22 12:15:24 - 0:08:09 - Train Epoch 53: LOSS= 0.39735, lr= 0.000040, acc1= 86.14,acc3= 98.31,acc10= 99.96\n",
      "eval E053: 100% 23/23 [00:03<00:00,  5.84it/s]\n",
      "INFO - 07/17/22 12:15:28 - 0:08:13 - #################################################################################################################\n",
      "INFO - 07/17/22 12:15:28 - 0:08:13 - Test Epoch 53: LOSS= 1.50982, acc1= 69.68, acc3= 88.17, acc10= 97.20\n",
      "INFO - 07/17/22 12:15:28 - 0:08:13 - #################################################################################################################\n",
      "train E054: 100% 21/21 [00:04<00:00,  4.45it/s]\n",
      "INFO - 07/17/22 12:15:32 - 0:08:17 - Train Epoch 54: LOSS= 0.41455, lr= 0.000040, acc1= 85.58,acc3= 97.90,acc10= 99.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E054: 100% 23/23 [00:03<00:00,  5.92it/s]\n",
      "INFO - 07/17/22 12:15:36 - 0:08:21 - #################################################################################################################\n",
      "INFO - 07/17/22 12:15:36 - 0:08:21 - Test Epoch 54: LOSS= 1.48876, acc1= 70.24, acc3= 88.24, acc10= 97.17\n",
      "INFO - 07/17/22 12:15:36 - 0:08:21 - #################################################################################################################\n",
      "train E055: 100% 21/21 [00:04<00:00,  4.43it/s]\n",
      "INFO - 07/17/22 12:15:41 - 0:08:26 - Train Epoch 55: LOSS= 0.40148, lr= 0.000040, acc1= 85.95,acc3= 98.20,acc10= 100.00\n",
      "eval E055: 100% 23/23 [00:03<00:00,  5.82it/s]\n",
      "INFO - 07/17/22 12:15:45 - 0:08:30 - #################################################################################################################\n",
      "INFO - 07/17/22 12:15:45 - 0:08:30 - Test Epoch 55: LOSS= 1.60502, acc1= 69.93, acc3= 88.31, acc10= 97.10\n",
      "INFO - 07/17/22 12:15:45 - 0:08:30 - #################################################################################################################\n",
      "train E056: 100% 21/21 [00:04<00:00,  4.38it/s]\n",
      "INFO - 07/17/22 12:15:50 - 0:08:35 - Train Epoch 56: LOSS= 0.38744, lr= 0.000040, acc1= 86.36,acc3= 98.35,acc10= 99.96\n",
      "eval E056: 100% 23/23 [00:03<00:00,  5.88it/s]\n",
      "INFO - 07/17/22 12:15:54 - 0:08:39 - #################################################################################################################\n",
      "INFO - 07/17/22 12:15:54 - 0:08:39 - Test Epoch 56: LOSS= 1.61243, acc1= 70.10, acc3= 87.99, acc10= 97.10\n",
      "INFO - 07/17/22 12:15:54 - 0:08:39 - #################################################################################################################\n",
      "train E057: 100% 21/21 [00:04<00:00,  4.39it/s]\n",
      "INFO - 07/17/22 12:15:59 - 0:08:44 - Train Epoch 57: LOSS= 0.39236, lr= 0.000040, acc1= 86.70,acc3= 98.24,acc10= 100.00\n",
      "eval E057: 100% 23/23 [00:03<00:00,  5.77it/s]\n",
      "INFO - 07/17/22 12:16:02 - 0:08:48 - #################################################################################################################\n",
      "INFO - 07/17/22 12:16:02 - 0:08:48 - Test Epoch 57: LOSS= 1.56008, acc1= 70.00, acc3= 87.92, acc10= 97.17\n",
      "INFO - 07/17/22 12:16:02 - 0:08:48 - #################################################################################################################\n",
      "train E058: 100% 21/21 [00:04<00:00,  4.37it/s]\n",
      "INFO - 07/17/22 12:16:07 - 0:08:52 - Train Epoch 58: LOSS= 0.40489, lr= 0.000040, acc1= 86.10,acc3= 98.01,acc10= 100.00\n",
      "eval E058: 100% 23/23 [00:03<00:00,  5.86it/s]\n",
      "INFO - 07/17/22 12:16:11 - 0:08:56 - #################################################################################################################\n",
      "INFO - 07/17/22 12:16:11 - 0:08:56 - Test Epoch 58: LOSS= 1.63354, acc1= 69.68, acc3= 88.06, acc10= 97.17\n",
      "INFO - 07/17/22 12:16:11 - 0:08:56 - #################################################################################################################\n",
      "train E059: 100% 21/21 [00:04<00:00,  4.47it/s]\n",
      "INFO - 07/17/22 12:16:16 - 0:09:01 - Train Epoch 59: LOSS= 0.40994, lr= 0.000040, acc1= 86.62,acc3= 98.46,acc10= 100.00\n",
      "eval E059: 100% 23/23 [00:03<00:00,  5.84it/s]\n",
      "INFO - 07/17/22 12:16:20 - 0:09:05 - #################################################################################################################\n",
      "INFO - 07/17/22 12:16:20 - 0:09:05 - Test Epoch 59: LOSS= 1.51962, acc1= 70.42, acc3= 88.20, acc10= 97.17\n",
      "INFO - 07/17/22 12:16:20 - 0:09:05 - #################################################################################################################\n",
      "train E060: 100% 21/21 [00:04<00:00,  4.57it/s]\n",
      "INFO - 07/17/22 12:16:24 - 0:09:10 - Train Epoch 60: LOSS= 0.40736, lr= 0.000040, acc1= 85.50,acc3= 98.16,acc10= 100.00\n",
      "eval E060: 100% 23/23 [00:03<00:00,  6.11it/s]\n",
      "INFO - 07/17/22 12:16:28 - 0:09:13 - #################################################################################################################\n",
      "INFO - 07/17/22 12:16:28 - 0:09:13 - Test Epoch 60: LOSS= 1.61416, acc1= 70.24, acc3= 87.92, acc10= 97.10\n",
      "INFO - 07/17/22 12:16:28 - 0:09:13 - #################################################################################################################\n",
      "train E061: 100% 21/21 [00:04<00:00,  4.60it/s]\n",
      "INFO - 07/17/22 12:16:33 - 0:09:18 - Train Epoch 61: LOSS= 0.37506, lr= 0.000040, acc1= 86.55,acc3= 98.28,acc10= 99.96\n",
      "eval E061: 100% 23/23 [00:03<00:00,  6.13it/s]\n",
      "INFO - 07/17/22 12:16:37 - 0:09:22 - #################################################################################################################\n",
      "INFO - 07/17/22 12:16:37 - 0:09:22 - Test Epoch 61: LOSS= 1.56414, acc1= 69.82, acc3= 87.99, acc10= 97.06\n",
      "INFO - 07/17/22 12:16:37 - 0:09:22 - #################################################################################################################\n",
      "train E062: 100% 21/21 [00:04<00:00,  4.62it/s]\n",
      "INFO - 07/17/22 12:16:41 - 0:09:26 - Train Epoch 62: LOSS= 0.38215, lr= 0.000040, acc1= 86.51,acc3= 98.46,acc10= 100.00\n",
      "eval E062: 100% 23/23 [00:03<00:00,  6.15it/s]\n",
      "INFO - 07/17/22 12:16:45 - 0:09:30 - #################################################################################################################\n",
      "INFO - 07/17/22 12:16:45 - 0:09:30 - Test Epoch 62: LOSS= 1.55123, acc1= 69.93, acc3= 88.20, acc10= 97.13\n",
      "INFO - 07/17/22 12:16:45 - 0:09:30 - #################################################################################################################\n",
      "train E063: 100% 21/21 [00:04<00:00,  4.60it/s]\n",
      "INFO - 07/17/22 12:16:49 - 0:09:34 - Train Epoch 63: LOSS= 0.38885, lr= 0.000040, acc1= 85.84,acc3= 98.28,acc10= 100.00\n",
      "eval E063: 100% 23/23 [00:03<00:00,  6.12it/s]\n",
      "INFO - 07/17/22 12:16:53 - 0:09:38 - #################################################################################################################\n",
      "INFO - 07/17/22 12:16:53 - 0:09:38 - Test Epoch 63: LOSS= 1.50850, acc1= 70.56, acc3= 88.24, acc10= 97.27\n",
      "INFO - 07/17/22 12:16:53 - 0:09:38 - #################################################################################################################\n",
      "train E064: 100% 21/21 [00:04<00:00,  4.57it/s]\n",
      "INFO - 07/17/22 12:16:58 - 0:09:43 - Train Epoch 64: LOSS= 0.37186, lr= 0.000040, acc1= 86.14,acc3= 98.46,acc10= 100.00\n",
      "eval E064: 100% 23/23 [00:03<00:00,  6.16it/s]\n",
      "INFO - 07/17/22 12:17:02 - 0:09:47 - #################################################################################################################\n",
      "INFO - 07/17/22 12:17:02 - 0:09:47 - Test Epoch 64: LOSS= 1.54139, acc1= 70.21, acc3= 88.45, acc10= 97.17\n",
      "INFO - 07/17/22 12:17:02 - 0:09:47 - #################################################################################################################\n",
      "train E065: 100% 21/21 [00:04<00:00,  4.63it/s]\n",
      "INFO - 07/17/22 12:17:06 - 0:09:51 - Train Epoch 65: LOSS= 0.37786, lr= 0.000040, acc1= 86.92,acc3= 98.50,acc10= 100.00\n",
      "eval E065: 100% 23/23 [00:03<00:00,  6.14it/s]\n",
      "INFO - 07/17/22 12:17:10 - 0:09:55 - #################################################################################################################\n",
      "INFO - 07/17/22 12:17:10 - 0:09:55 - Test Epoch 65: LOSS= 1.67200, acc1= 70.14, acc3= 88.49, acc10= 97.17\n",
      "INFO - 07/17/22 12:17:10 - 0:09:55 - #################################################################################################################\n",
      "train E066: 100% 21/21 [00:04<00:00,  4.59it/s]\n",
      "INFO - 07/17/22 12:17:14 - 0:09:59 - Train Epoch 66: LOSS= 0.39128, lr= 0.000040, acc1= 85.76,acc3= 98.39,acc10= 100.00\n",
      "eval E066: 100% 23/23 [00:03<00:00,  6.12it/s]\n",
      "INFO - 07/17/22 12:17:18 - 0:10:03 - #################################################################################################################\n",
      "INFO - 07/17/22 12:17:18 - 0:10:03 - Test Epoch 66: LOSS= 1.73043, acc1= 69.68, acc3= 88.24, acc10= 97.17\n",
      "INFO - 07/17/22 12:17:18 - 0:10:03 - #################################################################################################################\n",
      "train E067: 100% 21/21 [00:04<00:00,  4.63it/s]\n",
      "INFO - 07/17/22 12:17:23 - 0:10:08 - Train Epoch 67: LOSS= 0.39230, lr= 0.000040, acc1= 87.60,acc3= 98.46,acc10= 100.00\n",
      "eval E067: 100% 23/23 [00:03<00:00,  6.13it/s]\n",
      "INFO - 07/17/22 12:17:26 - 0:10:12 - #################################################################################################################\n",
      "INFO - 07/17/22 12:17:26 - 0:10:12 - Test Epoch 67: LOSS= 1.55496, acc1= 70.24, acc3= 88.13, acc10= 97.20\n",
      "INFO - 07/17/22 12:17:26 - 0:10:12 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E068: 100% 21/21 [00:04<00:00,  4.61it/s]\n",
      "INFO - 07/17/22 12:17:31 - 0:10:16 - Train Epoch 68: LOSS= 0.38326, lr= 0.000040, acc1= 86.44,acc3= 98.69,acc10= 100.00\n",
      "eval E068: 100% 23/23 [00:03<00:00,  6.14it/s]\n",
      "INFO - 07/17/22 12:17:35 - 0:10:20 - #################################################################################################################\n",
      "INFO - 07/17/22 12:17:35 - 0:10:20 - Test Epoch 68: LOSS= 1.54679, acc1= 70.17, acc3= 88.20, acc10= 97.13\n",
      "INFO - 07/17/22 12:17:35 - 0:10:20 - #################################################################################################################\n",
      "train E069: 100% 21/21 [00:04<00:00,  4.60it/s]\n",
      "INFO - 07/17/22 12:17:39 - 0:10:24 - Train Epoch 69: LOSS= 0.38768, lr= 0.000040, acc1= 86.14,acc3= 98.73,acc10= 100.00\n",
      "eval E069: 100% 23/23 [00:03<00:00,  6.19it/s]\n",
      "INFO - 07/17/22 12:17:43 - 0:10:28 - #################################################################################################################\n",
      "INFO - 07/17/22 12:17:43 - 0:10:28 - Test Epoch 69: LOSS= 1.55473, acc1= 70.17, acc3= 87.89, acc10= 97.20\n",
      "INFO - 07/17/22 12:17:43 - 0:10:28 - #################################################################################################################\n",
      "train E070: 100% 21/21 [00:04<00:00,  4.59it/s]\n",
      "INFO - 07/17/22 12:17:48 - 0:10:33 - Train Epoch 70: LOSS= 0.37072, lr= 0.000040, acc1= 87.49,acc3= 98.31,acc10= 100.00\n",
      "eval E070: 100% 23/23 [00:03<00:00,  5.90it/s]\n",
      "INFO - 07/17/22 12:17:52 - 0:10:37 - #################################################################################################################\n",
      "INFO - 07/17/22 12:17:52 - 0:10:37 - Test Epoch 70: LOSS= 1.57281, acc1= 69.71, acc3= 87.67, acc10= 97.27\n",
      "INFO - 07/17/22 12:17:52 - 0:10:37 - #################################################################################################################\n",
      "INFO - 07/17/22 12:17:53 - 0:10:38 - best performance =  71.27, 88.10, 97.13. best epoch = 40, correspond_loss= 1.5136\n",
      "INFO - 07/17/22 12:17:53 - 0:10:38 -  fusion_model_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_relation_BERT_3.pkl\n",
      "INFO - 07/17/22 12:17:53 - 0:10:38 -  answer_net_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_relation_MLP_3.pkl\n"
     ]
    }
   ],
   "source": [
    "# relation间训练 BERT rnn  \n",
    "#待跑\n",
    "%cd code\n",
    "!python main_bert_rnn.py --gpu_id 8 --exp_name relation_space --exp_id bert --fusion_model BERT --data_choice 3 --method_choice W2V  --save_model 1 --now_test 0 --relation_map 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "134647c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:44:52.887127Z",
     "start_time": "2022-07-10T07:16:02.948529Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 07/10/22 15:16:04 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 07/10/22 15:16:04 - 0:00:00 - The experiment will be stored in dump/0710-infoNCE_space/W2V\n",
      "                                     \n",
      "INFO - 07/10/22 15:16:04 - 0:00:00 - Running command: python main_infoNCE.py --gpu_id 6 --exp_name infoNCE_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --save_model 0 --fact_map 1\n",
      "\n",
      "2022-07-10 15:16:04.796667: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-10 15:16:04.796720: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 128\n",
      "batch_size 128\n",
      "fusion_model:\n",
      "SAN(\n",
      "  (w_emb): WordEmbedding(\n",
      "    (emb): Embedding(15422, 300, padding_idx=15421)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (text): Seq2SeqRNN(\n",
      "    (rnn): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (attention): SanAttention(\n",
      "    (v_conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (q_lin): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (x_conv): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(5120, 8192, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(8192, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "Answer Model:\n",
      "MLP(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "train E000: 100% 21/21 [00:16<00:00,  1.24it/s]\n",
      "INFO - 07/10/22 15:16:38 - 0:00:34 - Train Epoch 0: LOSS= 43.91008, lr= 0.000500, acc1= 10.45,acc3= 17.65,acc10= 21.32\n",
      "train E001: 100% 21/21 [00:10<00:00,  1.92it/s]\n",
      "INFO - 07/10/22 15:16:49 - 0:00:45 - Train Epoch 1: LOSS= 9.39990, lr= 0.000750, acc1= 45.90,acc3= 58.45,acc10= 64.11\n",
      "eval E001: 100% 23/23 [00:16<00:00,  1.40it/s]\n",
      "INFO - 07/10/22 15:17:05 - 0:01:01 - #################################################################################################################\n",
      "INFO - 07/10/22 15:17:05 - 0:01:01 - Test Epoch 1: LOSS= 7.58907, acc1= 52.75, acc3= 64.90, acc10= 69.89\n",
      "INFO - 07/10/22 15:17:05 - 0:01:01 - #################################################################################################################\n",
      "train E002: 100% 21/21 [00:10<00:00,  1.99it/s]\n",
      "INFO - 07/10/22 15:17:16 - 0:01:12 - Train Epoch 2: LOSS= 5.39320, lr= 0.001000, acc1= 66.84,acc3= 77.78,acc10= 81.94\n",
      "eval E002: 100% 23/23 [00:10<00:00,  2.22it/s]\n",
      "INFO - 07/10/22 15:17:26 - 0:01:22 - #################################################################################################################\n",
      "INFO - 07/10/22 15:17:26 - 0:01:22 - Test Epoch 2: LOSS= 7.11716, acc1= 57.24, acc3= 68.12, acc10= 73.04\n",
      "INFO - 07/10/22 15:17:26 - 0:01:22 - #################################################################################################################\n",
      "train E003: 100% 21/21 [00:10<00:00,  1.98it/s]\n",
      "INFO - 07/10/22 15:17:37 - 0:01:33 - Train Epoch 3: LOSS= 3.91418, lr= 0.001250, acc1= 78.01,acc3= 86.74,acc10= 89.47\n",
      "eval E003: 100% 23/23 [00:10<00:00,  2.24it/s]\n",
      "INFO - 07/10/22 15:17:47 - 0:01:43 - #################################################################################################################\n",
      "INFO - 07/10/22 15:17:47 - 0:01:43 - Test Epoch 3: LOSS= 7.18111, acc1= 60.43, acc3= 70.56, acc10= 74.11\n",
      "INFO - 07/10/22 15:17:47 - 0:01:43 - #################################################################################################################\n",
      "train E004: 100% 21/21 [00:10<00:00,  1.94it/s]\n",
      "INFO - 07/10/22 15:17:58 - 0:01:54 - Train Epoch 4: LOSS= 3.34919, lr= 0.001500, acc1= 84.30,acc3= 90.75,acc10= 92.77\n",
      "eval E004: 100% 23/23 [00:10<00:00,  2.24it/s]\n",
      "INFO - 07/10/22 15:18:08 - 0:02:04 - #################################################################################################################\n",
      "INFO - 07/10/22 15:18:08 - 0:02:04 - Test Epoch 4: LOSS= 8.00926, acc1= 61.96, acc3= 71.80, acc10= 75.17\n",
      "INFO - 07/10/22 15:18:08 - 0:02:04 - #################################################################################################################\n",
      "train E005: 100% 21/21 [00:10<00:00,  1.95it/s]\n",
      "INFO - 07/10/22 15:18:19 - 0:02:15 - Train Epoch 5: LOSS= 3.20688, lr= 0.001750, acc1= 87.52,acc3= 93.03,acc10= 94.68\n",
      "eval E005: 100% 23/23 [00:10<00:00,  2.24it/s]\n",
      "INFO - 07/10/22 15:18:29 - 0:02:25 - #################################################################################################################\n",
      "INFO - 07/10/22 15:18:29 - 0:02:25 - Test Epoch 5: LOSS= 8.76388, acc1= 62.52, acc3= 72.87, acc10= 75.77\n",
      "INFO - 07/10/22 15:18:29 - 0:02:25 - #################################################################################################################\n",
      "train E006: 100% 21/21 [00:10<00:00,  1.98it/s]\n",
      "INFO - 07/10/22 15:18:40 - 0:02:36 - Train Epoch 6: LOSS= 3.25353, lr= 0.002000, acc1= 88.80,acc3= 93.89,acc10= 95.35\n",
      "eval E006: 100% 23/23 [00:10<00:00,  2.29it/s]\n",
      "INFO - 07/10/22 15:18:50 - 0:02:46 - #################################################################################################################\n",
      "INFO - 07/10/22 15:18:50 - 0:02:46 - Test Epoch 6: LOSS= 9.82477, acc1= 65.25, acc3= 74.74, acc10= 77.65\n",
      "INFO - 07/10/22 15:18:50 - 0:02:46 - #################################################################################################################\n",
      "train E007: 100% 21/21 [00:10<00:00,  1.98it/s]\n",
      "INFO - 07/10/22 15:19:01 - 0:02:57 - Train Epoch 7: LOSS= 2.94342, lr= 0.002000, acc1= 91.42,acc3= 95.99,acc10= 97.19\n",
      "eval E007: 100% 23/23 [00:10<00:00,  2.26it/s]\n",
      "INFO - 07/10/22 15:19:11 - 0:03:07 - #################################################################################################################\n",
      "INFO - 07/10/22 15:19:11 - 0:03:07 - Test Epoch 7: LOSS= 10.67707, acc1= 62.56, acc3= 70.70, acc10= 74.85\n",
      "INFO - 07/10/22 15:19:11 - 0:03:07 - #################################################################################################################\n",
      "train E008: 100% 21/21 [00:10<00:00,  1.99it/s]\n",
      "INFO - 07/10/22 15:19:21 - 0:03:17 - Train Epoch 8: LOSS= 2.73502, lr= 0.002000, acc1= 93.44,acc3= 96.74,acc10= 97.86\n",
      "eval E008: 100% 23/23 [00:10<00:00,  2.28it/s]\n",
      "INFO - 07/10/22 15:19:31 - 0:03:27 - #################################################################################################################\n",
      "INFO - 07/10/22 15:19:31 - 0:03:27 - Test Epoch 8: LOSS= 11.03823, acc1= 64.36, acc3= 72.79, acc10= 75.98\n",
      "INFO - 07/10/22 15:19:31 - 0:03:27 - #################################################################################################################\n",
      "train E009: 100% 21/21 [00:10<00:00,  2.02it/s]\n",
      "INFO - 07/10/22 15:19:42 - 0:03:38 - Train Epoch 9: LOSS= 2.51997, lr= 0.002000, acc1= 93.74,acc3= 97.08,acc10= 97.94\n",
      "eval E009: 100% 23/23 [00:10<00:00,  2.27it/s]\n",
      "INFO - 07/10/22 15:19:52 - 0:03:48 - #################################################################################################################\n",
      "INFO - 07/10/22 15:19:52 - 0:03:48 - Test Epoch 9: LOSS= 10.77480, acc1= 65.60, acc3= 73.86, acc10= 76.94\n",
      "INFO - 07/10/22 15:19:52 - 0:03:48 - #################################################################################################################\n",
      "train E010: 100% 21/21 [00:10<00:00,  2.01it/s]\n",
      "INFO - 07/10/22 15:20:02 - 0:03:58 - Train Epoch 10: LOSS= 2.06261, lr= 0.002000, acc1= 95.43,acc3= 97.71,acc10= 98.50\n",
      "eval E010: 100% 23/23 [00:10<00:00,  2.30it/s]\n",
      "INFO - 07/10/22 15:20:12 - 0:04:08 - #################################################################################################################\n",
      "INFO - 07/10/22 15:20:12 - 0:04:08 - Test Epoch 10: LOSS= 11.44535, acc1= 65.57, acc3= 74.03, acc10= 78.18\n",
      "INFO - 07/10/22 15:20:12 - 0:04:08 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E011: 100% 21/21 [00:10<00:00,  1.99it/s]\n",
      "INFO - 07/10/22 15:20:23 - 0:04:19 - Train Epoch 11: LOSS= 1.87442, lr= 0.002000, acc1= 96.18,acc3= 98.39,acc10= 98.88\n",
      "eval E011: 100% 23/23 [00:10<00:00,  2.25it/s]\n",
      "INFO - 07/10/22 15:20:33 - 0:04:29 - #################################################################################################################\n",
      "INFO - 07/10/22 15:20:33 - 0:04:29 - Test Epoch 11: LOSS= 10.88462, acc1= 66.06, acc3= 75.56, acc10= 78.32\n",
      "INFO - 07/10/22 15:20:33 - 0:04:29 - #################################################################################################################\n",
      "train E012: 100% 21/21 [00:10<00:00,  2.04it/s]\n",
      "INFO - 07/10/22 15:20:44 - 0:04:40 - Train Epoch 12: LOSS= 1.57220, lr= 0.002000, acc1= 96.97,acc3= 98.61,acc10= 99.14\n",
      "eval E012: 100% 23/23 [00:09<00:00,  2.33it/s]\n",
      "INFO - 07/10/22 15:20:53 - 0:04:49 - #################################################################################################################\n",
      "INFO - 07/10/22 15:20:53 - 0:04:49 - Test Epoch 12: LOSS= 10.98893, acc1= 64.93, acc3= 74.14, acc10= 77.05\n",
      "INFO - 07/10/22 15:20:53 - 0:04:49 - #################################################################################################################\n",
      "train E013: 100% 21/21 [00:10<00:00,  2.02it/s]\n",
      "INFO - 07/10/22 15:21:04 - 0:05:00 - Train Epoch 13: LOSS= 1.49732, lr= 0.002000, acc1= 97.30,acc3= 98.76,acc10= 99.06\n",
      "eval E013: 100% 23/23 [00:10<00:00,  2.26it/s]\n",
      "INFO - 07/10/22 15:21:14 - 0:05:10 - #################################################################################################################\n",
      "INFO - 07/10/22 15:21:14 - 0:05:10 - Test Epoch 13: LOSS= 10.35767, acc1= 66.21, acc3= 75.06, acc10= 78.18\n",
      "INFO - 07/10/22 15:21:14 - 0:05:10 - #################################################################################################################\n",
      "train E014: 100% 21/21 [00:10<00:00,  2.03it/s]\n",
      "INFO - 07/10/22 15:21:24 - 0:05:20 - Train Epoch 14: LOSS= 1.10359, lr= 0.001400, acc1= 97.98,acc3= 99.40,acc10= 99.51\n",
      "eval E014: 100% 23/23 [00:10<00:00,  2.30it/s]\n",
      "INFO - 07/10/22 15:21:34 - 0:05:30 - #################################################################################################################\n",
      "INFO - 07/10/22 15:21:34 - 0:05:30 - Test Epoch 14: LOSS= 10.53601, acc1= 67.62, acc3= 75.95, acc10= 79.03\n",
      "INFO - 07/10/22 15:21:34 - 0:05:30 - #################################################################################################################\n",
      "train E015: 100% 21/21 [00:10<00:00,  2.05it/s]\n",
      "INFO - 07/10/22 15:21:45 - 0:05:41 - Train Epoch 15: LOSS= 0.82352, lr= 0.001400, acc1= 98.80,acc3= 99.70,acc10= 99.74\n",
      "eval E015: 100% 23/23 [00:09<00:00,  2.33it/s]\n",
      "INFO - 07/10/22 15:21:55 - 0:05:50 - #################################################################################################################\n",
      "INFO - 07/10/22 15:21:55 - 0:05:50 - Test Epoch 15: LOSS= 10.13453, acc1= 68.61, acc3= 75.81, acc10= 79.21\n",
      "INFO - 07/10/22 15:21:55 - 0:05:50 - #################################################################################################################\n",
      "train E016: 100% 21/21 [00:10<00:00,  2.00it/s]\n",
      "INFO - 07/10/22 15:22:05 - 0:06:01 - Train Epoch 16: LOSS= 0.69416, lr= 0.001400, acc1= 99.06,acc3= 99.74,acc10= 99.81\n",
      "eval E016: 100% 23/23 [00:10<00:00,  2.20it/s]\n",
      "INFO - 07/10/22 15:22:16 - 0:06:11 - #################################################################################################################\n",
      "INFO - 07/10/22 15:22:16 - 0:06:11 - Test Epoch 16: LOSS= 11.03141, acc1= 68.12, acc3= 76.76, acc10= 80.30\n",
      "INFO - 07/10/22 15:22:16 - 0:06:11 - #################################################################################################################\n",
      "train E017: 100% 21/21 [00:10<00:00,  2.06it/s]\n",
      "INFO - 07/10/22 15:22:26 - 0:06:22 - Train Epoch 17: LOSS= 0.49744, lr= 0.000980, acc1= 99.33,acc3= 99.81,acc10= 99.93\n",
      "eval E017: 100% 23/23 [00:09<00:00,  2.31it/s]\n",
      "INFO - 07/10/22 15:22:36 - 0:06:32 - #################################################################################################################\n",
      "INFO - 07/10/22 15:22:36 - 0:06:32 - Test Epoch 17: LOSS= 10.16510, acc1= 68.72, acc3= 76.44, acc10= 79.74\n",
      "INFO - 07/10/22 15:22:36 - 0:06:32 - #################################################################################################################\n",
      "train E018: 100% 21/21 [00:10<00:00,  1.97it/s]\n",
      "INFO - 07/10/22 15:22:46 - 0:06:42 - Train Epoch 18: LOSS= 0.35374, lr= 0.000980, acc1= 99.40,acc3= 99.96,acc10= 99.96\n",
      "eval E018: 100% 23/23 [00:10<00:00,  2.27it/s]\n",
      "INFO - 07/10/22 15:22:56 - 0:06:52 - #################################################################################################################\n",
      "INFO - 07/10/22 15:22:56 - 0:06:52 - Test Epoch 18: LOSS= 10.02580, acc1= 68.79, acc3= 76.94, acc10= 79.63\n",
      "INFO - 07/10/22 15:22:56 - 0:06:52 - #################################################################################################################\n",
      "train E019: 100% 21/21 [00:10<00:00,  1.98it/s]\n",
      "INFO - 07/10/22 15:23:07 - 0:07:03 - Train Epoch 19: LOSS= 0.39735, lr= 0.000980, acc1= 99.36,acc3= 99.93,acc10= 99.96\n",
      "eval E019: 100% 23/23 [00:10<00:00,  2.24it/s]\n",
      "INFO - 07/10/22 15:23:17 - 0:07:13 - #################################################################################################################\n",
      "INFO - 07/10/22 15:23:17 - 0:07:13 - Test Epoch 19: LOSS= 10.09697, acc1= 68.76, acc3= 77.05, acc10= 80.09\n",
      "INFO - 07/10/22 15:23:17 - 0:07:13 - #################################################################################################################\n",
      "train E020: 100% 21/21 [00:10<00:00,  1.95it/s]\n",
      "INFO - 07/10/22 15:23:28 - 0:07:24 - Train Epoch 20: LOSS= 0.23936, lr= 0.000686, acc1= 99.63,acc3= 99.96,acc10= 99.96\n",
      "eval E020: 100% 23/23 [00:10<00:00,  2.24it/s]\n",
      "INFO - 07/10/22 15:23:38 - 0:07:34 - #################################################################################################################\n",
      "INFO - 07/10/22 15:23:38 - 0:07:34 - Test Epoch 20: LOSS= 10.33685, acc1= 69.36, acc3= 77.68, acc10= 80.55\n",
      "INFO - 07/10/22 15:23:38 - 0:07:34 - #################################################################################################################\n",
      "train E021: 100% 21/21 [00:10<00:00,  1.98it/s]\n",
      "INFO - 07/10/22 15:23:49 - 0:07:45 - Train Epoch 21: LOSS= 0.24456, lr= 0.000686, acc1= 99.63,acc3= 99.93,acc10= 99.96\n",
      "eval E021: 100% 23/23 [00:10<00:00,  2.23it/s]\n",
      "INFO - 07/10/22 15:23:59 - 0:07:55 - #################################################################################################################\n",
      "INFO - 07/10/22 15:23:59 - 0:07:55 - Test Epoch 21: LOSS= 9.87476, acc1= 70.10, acc3= 78.18, acc10= 81.33\n",
      "INFO - 07/10/22 15:23:59 - 0:07:55 - #################################################################################################################\n",
      "train E022: 100% 21/21 [00:10<00:00,  1.98it/s]\n",
      "INFO - 07/10/22 15:24:10 - 0:08:06 - Train Epoch 22: LOSS= 0.16444, lr= 0.000686, acc1= 99.59,acc3= 100.00,acc10= 100.00\n",
      "eval E022: 100% 23/23 [00:10<00:00,  2.26it/s]\n",
      "INFO - 07/10/22 15:24:20 - 0:08:16 - #################################################################################################################\n",
      "INFO - 07/10/22 15:24:20 - 0:08:16 - Test Epoch 22: LOSS= 9.80251, acc1= 69.64, acc3= 76.97, acc10= 80.52\n",
      "INFO - 07/10/22 15:24:20 - 0:08:16 - #################################################################################################################\n",
      "train E023: 100% 21/21 [00:10<00:00,  2.00it/s]\n",
      "INFO - 07/10/22 15:24:31 - 0:08:27 - Train Epoch 23: LOSS= 0.18209, lr= 0.000480, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E023: 100% 23/23 [00:10<00:00,  2.24it/s]\n",
      "INFO - 07/10/22 15:24:41 - 0:08:37 - #################################################################################################################\n",
      "INFO - 07/10/22 15:24:41 - 0:08:37 - Test Epoch 23: LOSS= 9.39410, acc1= 70.24, acc3= 78.04, acc10= 81.37\n",
      "INFO - 07/10/22 15:24:41 - 0:08:37 - #################################################################################################################\n",
      "train E024: 100% 21/21 [00:10<00:00,  1.95it/s]\n",
      "INFO - 07/10/22 15:24:52 - 0:08:48 - Train Epoch 24: LOSS= 0.14286, lr= 0.000480, acc1= 99.59,acc3= 100.00,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E024: 100% 23/23 [00:10<00:00,  2.29it/s]\n",
      "INFO - 07/10/22 15:25:02 - 0:08:58 - #################################################################################################################\n",
      "INFO - 07/10/22 15:25:02 - 0:08:58 - Test Epoch 24: LOSS= 9.52000, acc1= 70.60, acc3= 78.36, acc10= 81.51\n",
      "INFO - 07/10/22 15:25:02 - 0:08:58 - #################################################################################################################\n",
      "train E025: 100% 21/21 [00:10<00:00,  2.02it/s]\n",
      "INFO - 07/10/22 15:25:12 - 0:09:08 - Train Epoch 25: LOSS= 0.15191, lr= 0.000480, acc1= 99.63,acc3= 100.00,acc10= 100.00\n",
      "eval E025: 100% 23/23 [00:10<00:00,  2.29it/s]\n",
      "INFO - 07/10/22 15:25:22 - 0:09:18 - #################################################################################################################\n",
      "INFO - 07/10/22 15:25:22 - 0:09:18 - Test Epoch 25: LOSS= 9.25272, acc1= 70.56, acc3= 78.53, acc10= 81.19\n",
      "INFO - 07/10/22 15:25:22 - 0:09:18 - #################################################################################################################\n",
      "train E026: 100% 21/21 [00:10<00:00,  2.00it/s]\n",
      "INFO - 07/10/22 15:25:33 - 0:09:29 - Train Epoch 26: LOSS= 0.15126, lr= 0.000336, acc1= 99.78,acc3= 99.96,acc10= 99.96\n",
      "eval E026: 100% 23/23 [00:09<00:00,  2.32it/s]\n",
      "INFO - 07/10/22 15:25:43 - 0:09:39 - #################################################################################################################\n",
      "INFO - 07/10/22 15:25:43 - 0:09:39 - Test Epoch 26: LOSS= 9.29132, acc1= 70.67, acc3= 78.14, acc10= 81.26\n",
      "INFO - 07/10/22 15:25:43 - 0:09:39 - #################################################################################################################\n",
      "train E027: 100% 21/21 [00:12<00:00,  1.73it/s]\n",
      "INFO - 07/10/22 15:25:55 - 0:09:51 - Train Epoch 27: LOSS= 0.13093, lr= 0.000336, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E027: 100% 23/23 [00:11<00:00,  2.08it/s]\n",
      "INFO - 07/10/22 15:26:06 - 0:10:02 - #################################################################################################################\n",
      "INFO - 07/10/22 15:26:06 - 0:10:02 - Test Epoch 27: LOSS= 9.48713, acc1= 70.24, acc3= 78.11, acc10= 81.26\n",
      "INFO - 07/10/22 15:26:06 - 0:10:02 - #################################################################################################################\n",
      "train E028: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 07/10/22 15:26:18 - 0:10:14 - Train Epoch 28: LOSS= 0.11301, lr= 0.000336, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E028: 100% 23/23 [00:10<00:00,  2.12it/s]\n",
      "INFO - 07/10/22 15:26:29 - 0:10:25 - #################################################################################################################\n",
      "INFO - 07/10/22 15:26:29 - 0:10:25 - Test Epoch 28: LOSS= 9.37505, acc1= 70.03, acc3= 78.14, acc10= 81.23\n",
      "INFO - 07/10/22 15:26:29 - 0:10:25 - #################################################################################################################\n",
      "train E029: 100% 21/21 [00:11<00:00,  1.78it/s]\n",
      "INFO - 07/10/22 15:26:40 - 0:10:36 - Train Epoch 29: LOSS= 0.10218, lr= 0.000235, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E029: 100% 23/23 [00:11<00:00,  2.09it/s]\n",
      "INFO - 07/10/22 15:26:51 - 0:10:47 - #################################################################################################################\n",
      "INFO - 07/10/22 15:26:51 - 0:10:47 - Test Epoch 29: LOSS= 9.62695, acc1= 70.28, acc3= 78.11, acc10= 81.05\n",
      "INFO - 07/10/22 15:26:51 - 0:10:47 - #################################################################################################################\n",
      "train E030: 100% 21/21 [00:11<00:00,  1.75it/s]\n",
      "INFO - 07/10/22 15:27:03 - 0:10:59 - Train Epoch 30: LOSS= 0.09061, lr= 0.000235, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E030: 100% 23/23 [00:11<00:00,  2.08it/s]\n",
      "INFO - 07/10/22 15:27:15 - 0:11:10 - #################################################################################################################\n",
      "INFO - 07/10/22 15:27:15 - 0:11:10 - Test Epoch 30: LOSS= 9.24923, acc1= 70.17, acc3= 78.29, acc10= 81.51\n",
      "INFO - 07/10/22 15:27:15 - 0:11:10 - #################################################################################################################\n",
      "train E031: 100% 21/21 [00:12<00:00,  1.71it/s]\n",
      "INFO - 07/10/22 15:27:27 - 0:11:23 - Train Epoch 31: LOSS= 0.08349, lr= 0.000235, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E031: 100% 23/23 [00:11<00:00,  2.03it/s]\n",
      "INFO - 07/10/22 15:27:38 - 0:11:34 - #################################################################################################################\n",
      "INFO - 07/10/22 15:27:38 - 0:11:34 - Test Epoch 31: LOSS= 9.65149, acc1= 71.09, acc3= 78.50, acc10= 81.97\n",
      "INFO - 07/10/22 15:27:38 - 0:11:34 - #################################################################################################################\n",
      "train E032: 100% 21/21 [00:12<00:00,  1.74it/s]\n",
      "INFO - 07/10/22 15:27:50 - 0:11:46 - Train Epoch 32: LOSS= 0.08223, lr= 0.000165, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E032: 100% 23/23 [00:11<00:00,  2.08it/s]\n",
      "INFO - 07/10/22 15:28:01 - 0:11:57 - #################################################################################################################\n",
      "INFO - 07/10/22 15:28:01 - 0:11:57 - Test Epoch 32: LOSS= 9.48038, acc1= 70.99, acc3= 78.43, acc10= 81.90\n",
      "INFO - 07/10/22 15:28:01 - 0:11:57 - #################################################################################################################\n",
      "train E033: 100% 21/21 [00:12<00:00,  1.71it/s]\n",
      "INFO - 07/10/22 15:28:14 - 0:12:09 - Train Epoch 33: LOSS= 0.08883, lr= 0.000165, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E033: 100% 23/23 [00:11<00:00,  2.07it/s]\n",
      "INFO - 07/10/22 15:28:25 - 0:12:21 - #################################################################################################################\n",
      "INFO - 07/10/22 15:28:25 - 0:12:21 - Test Epoch 33: LOSS= 9.16373, acc1= 71.02, acc3= 78.32, acc10= 81.97\n",
      "INFO - 07/10/22 15:28:25 - 0:12:21 - #################################################################################################################\n",
      "train E034: 100% 21/21 [00:12<00:00,  1.74it/s]\n",
      "INFO - 07/10/22 15:28:37 - 0:12:33 - Train Epoch 34: LOSS= 0.06526, lr= 0.000165, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E034: 100% 23/23 [00:11<00:00,  2.07it/s]\n",
      "INFO - 07/10/22 15:28:48 - 0:12:44 - #################################################################################################################\n",
      "INFO - 07/10/22 15:28:48 - 0:12:44 - Test Epoch 34: LOSS= 9.42603, acc1= 70.85, acc3= 78.53, acc10= 82.00\n",
      "INFO - 07/10/22 15:28:48 - 0:12:44 - #################################################################################################################\n",
      "train E035: 100% 21/21 [00:12<00:00,  1.72it/s]\n",
      "INFO - 07/10/22 15:29:00 - 0:12:56 - Train Epoch 35: LOSS= 0.07371, lr= 0.000115, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E035: 100% 23/23 [00:11<00:00,  2.06it/s]\n",
      "INFO - 07/10/22 15:29:11 - 0:13:07 - #################################################################################################################\n",
      "INFO - 07/10/22 15:29:11 - 0:13:07 - Test Epoch 35: LOSS= 9.24831, acc1= 70.81, acc3= 78.57, acc10= 81.86\n",
      "INFO - 07/10/22 15:29:11 - 0:13:07 - #################################################################################################################\n",
      "train E036: 100% 21/21 [00:12<00:00,  1.73it/s]\n",
      "INFO - 07/10/22 15:29:23 - 0:13:19 - Train Epoch 36: LOSS= 0.05928, lr= 0.000115, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E036: 100% 23/23 [00:11<00:00,  2.08it/s]\n",
      "INFO - 07/10/22 15:29:34 - 0:13:30 - #################################################################################################################\n",
      "INFO - 07/10/22 15:29:34 - 0:13:30 - Test Epoch 36: LOSS= 9.31424, acc1= 70.74, acc3= 78.60, acc10= 81.69\n",
      "INFO - 07/10/22 15:29:34 - 0:13:30 - #################################################################################################################\n",
      "train E037: 100% 21/21 [00:12<00:00,  1.69it/s]\n",
      "INFO - 07/10/22 15:29:47 - 0:13:43 - Train Epoch 37: LOSS= 0.09794, lr= 0.000115, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E037: 100% 23/23 [00:11<00:00,  2.08it/s]\n",
      "INFO - 07/10/22 15:29:58 - 0:13:54 - #################################################################################################################\n",
      "INFO - 07/10/22 15:29:58 - 0:13:54 - Test Epoch 37: LOSS= 9.35733, acc1= 70.63, acc3= 78.85, acc10= 81.86\n",
      "INFO - 07/10/22 15:29:58 - 0:13:54 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E038: 100% 21/21 [00:12<00:00,  1.71it/s]\n",
      "INFO - 07/10/22 15:30:10 - 0:14:06 - Train Epoch 38: LOSS= 0.08675, lr= 0.000081, acc1= 99.48,acc3= 100.00,acc10= 100.00\n",
      "eval E038: 100% 23/23 [00:11<00:00,  2.04it/s]\n",
      "INFO - 07/10/22 15:30:21 - 0:14:17 - #################################################################################################################\n",
      "INFO - 07/10/22 15:30:21 - 0:14:17 - Test Epoch 38: LOSS= 9.60151, acc1= 70.74, acc3= 78.92, acc10= 81.86\n",
      "INFO - 07/10/22 15:30:21 - 0:14:17 - #################################################################################################################\n",
      "train E039: 100% 21/21 [00:12<00:00,  1.72it/s]\n",
      "INFO - 07/10/22 15:30:34 - 0:14:30 - Train Epoch 39: LOSS= 0.08406, lr= 0.000081, acc1= 99.74,acc3= 100.00,acc10= 100.00\n",
      "eval E039: 100% 23/23 [00:11<00:00,  2.06it/s]\n",
      "INFO - 07/10/22 15:30:45 - 0:14:41 - #################################################################################################################\n",
      "INFO - 07/10/22 15:30:45 - 0:14:41 - Test Epoch 39: LOSS= 9.65520, acc1= 70.85, acc3= 78.82, acc10= 81.83\n",
      "INFO - 07/10/22 15:30:45 - 0:14:41 - #################################################################################################################\n",
      "train E040: 100% 21/21 [00:12<00:00,  1.73it/s]\n",
      "INFO - 07/10/22 15:30:57 - 0:14:53 - Train Epoch 40: LOSS= 0.06861, lr= 0.000081, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E040: 100% 23/23 [00:10<00:00,  2.12it/s]\n",
      "INFO - 07/10/22 15:31:08 - 0:15:04 - #################################################################################################################\n",
      "INFO - 07/10/22 15:31:08 - 0:15:04 - Test Epoch 40: LOSS= 9.70045, acc1= 70.95, acc3= 78.60, acc10= 81.76\n",
      "INFO - 07/10/22 15:31:08 - 0:15:04 - #################################################################################################################\n",
      "train E041: 100% 21/21 [00:12<00:00,  1.73it/s]\n",
      "INFO - 07/10/22 15:31:20 - 0:15:16 - Train Epoch 41: LOSS= 0.06325, lr= 0.000056, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E041: 100% 23/23 [00:10<00:00,  2.15it/s]\n",
      "INFO - 07/10/22 15:31:31 - 0:15:26 - #################################################################################################################\n",
      "INFO - 07/10/22 15:31:31 - 0:15:26 - Test Epoch 41: LOSS= 9.07301, acc1= 70.70, acc3= 78.75, acc10= 81.83\n",
      "INFO - 07/10/22 15:31:31 - 0:15:26 - #################################################################################################################\n",
      "eval E069: 100% 23/23 [00:10<00:00,  2.13it/s]]\n",
      "INFO - 07/10/22 15:42:10 - 0:26:06 - #################################################################################################################\n",
      "INFO - 07/10/22 15:42:10 - 0:26:06 - Test Epoch 69: LOSS= 9.55391, acc1= 70.74, acc3= 78.68, acc10= 81.97\n",
      "INFO - 07/10/22 15:42:10 - 0:26:06 - #################################################################################################################\n",
      "train E070: 100% 21/21 [00:11<00:00,  1.77it/s]\n",
      "INFO - 07/10/22 15:42:22 - 0:26:18 - Train Epoch 70: LOSS= 0.06616, lr= 0.000040, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E070: 100% 23/23 [00:10<00:00,  2.12it/s]\n",
      "INFO - 07/10/22 15:42:33 - 0:26:29 - #################################################################################################################\n",
      "INFO - 07/10/22 15:42:33 - 0:26:29 - Test Epoch 70: LOSS= 8.96917, acc1= 70.67, acc3= 78.60, acc10= 81.86\n",
      "INFO - 07/10/22 15:42:33 - 0:26:29 - #################################################################################################################\n",
      "train E071: 100% 21/21 [00:12<00:00,  1.74it/s]\n",
      "INFO - 07/10/22 15:42:45 - 0:26:41 - Train Epoch 71: LOSS= 0.06472, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E071: 100% 23/23 [00:10<00:00,  2.12it/s]\n",
      "INFO - 07/10/22 15:42:56 - 0:26:52 - #################################################################################################################\n",
      "INFO - 07/10/22 15:42:56 - 0:26:52 - Test Epoch 71: LOSS= 9.10952, acc1= 70.60, acc3= 78.57, acc10= 81.72\n",
      "INFO - 07/10/22 15:42:56 - 0:26:52 - #################################################################################################################\n",
      "train E072: 100% 21/21 [00:12<00:00,  1.75it/s]\n",
      "INFO - 07/10/22 15:43:08 - 0:27:04 - Train Epoch 72: LOSS= 0.08334, lr= 0.000040, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E072: 100% 23/23 [00:10<00:00,  2.11it/s]\n",
      "INFO - 07/10/22 15:43:19 - 0:27:15 - #################################################################################################################\n",
      "INFO - 07/10/22 15:43:19 - 0:27:15 - Test Epoch 72: LOSS= 9.22527, acc1= 70.67, acc3= 78.75, acc10= 81.86\n",
      "INFO - 07/10/22 15:43:19 - 0:27:15 - #################################################################################################################\n",
      "train E073: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 07/10/22 15:43:31 - 0:27:27 - Train Epoch 73: LOSS= 0.07247, lr= 0.000040, acc1= 99.78,acc3= 100.00,acc10= 100.00\n",
      "eval E073: 100% 23/23 [00:10<00:00,  2.10it/s]\n",
      "INFO - 07/10/22 15:43:42 - 0:27:37 - #################################################################################################################\n",
      "INFO - 07/10/22 15:43:42 - 0:27:37 - Test Epoch 73: LOSS= 9.30803, acc1= 70.70, acc3= 78.78, acc10= 81.79\n",
      "INFO - 07/10/22 15:43:42 - 0:27:37 - #################################################################################################################\n",
      "train E074: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 07/10/22 15:43:54 - 0:27:49 - Train Epoch 74: LOSS= 0.05393, lr= 0.000040, acc1= 99.66,acc3= 100.00,acc10= 100.00\n",
      "eval E074: 100% 23/23 [00:10<00:00,  2.11it/s]\n",
      "INFO - 07/10/22 15:44:04 - 0:28:00 - #################################################################################################################\n",
      "INFO - 07/10/22 15:44:04 - 0:28:00 - Test Epoch 74: LOSS= 9.03965, acc1= 70.70, acc3= 78.82, acc10= 81.93\n",
      "INFO - 07/10/22 15:44:04 - 0:28:00 - #################################################################################################################\n",
      "train E075: 100% 21/21 [00:12<00:00,  1.66it/s]\n",
      "INFO - 07/10/22 15:44:17 - 0:28:13 - Train Epoch 75: LOSS= 0.06849, lr= 0.000040, acc1= 99.70,acc3= 100.00,acc10= 100.00\n",
      "eval E075: 100% 23/23 [00:10<00:00,  2.11it/s]\n",
      "INFO - 07/10/22 15:44:28 - 0:28:24 - #################################################################################################################\n",
      "INFO - 07/10/22 15:44:28 - 0:28:24 - Test Epoch 75: LOSS= 9.38517, acc1= 70.78, acc3= 78.85, acc10= 81.72\n",
      "INFO - 07/10/22 15:44:28 - 0:28:24 - #################################################################################################################\n",
      "train E076: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 07/10/22 15:44:40 - 0:28:36 - Train Epoch 76: LOSS= 0.05643, lr= 0.000040, acc1= 99.55,acc3= 100.00,acc10= 100.00\n",
      "eval E076: 100% 23/23 [00:10<00:00,  2.17it/s]\n",
      "INFO - 07/10/22 15:44:51 - 0:28:46 - #################################################################################################################\n",
      "INFO - 07/10/22 15:44:51 - 0:28:46 - Test Epoch 76: LOSS= 9.10610, acc1= 70.60, acc3= 78.99, acc10= 81.76\n",
      "INFO - 07/10/22 15:44:51 - 0:28:46 - #################################################################################################################\n",
      "INFO - 07/10/22 15:44:51 - 0:28:46 - best performance =  70.74, 78.92, 82.11. best epoch = 46, correspond_loss= 9.1595\n",
      "Traceback (most recent call last):\n",
      "  File \"main_infoNCE.py\", line 379, in <module>\n",
      "    logger.info(f\" fusion_model_path = {runner.fusion_model_path}\")\n",
      "AttributeError: 'Runner' object has no attribute 'fusion_model_path'\n"
     ]
    }
   ],
   "source": [
    "# entity空间训练 infoNCE loss\n",
    "!python main_infoNCE.py --gpu_id 6 --exp_name infoNCE_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --save_model 0 --fact_map 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96a4b999",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T10:01:18.879717Z",
     "start_time": "2023-01-12T10:00:13.719492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 01/12/23 18:00:18 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 01/12/23 18:00:18 - 0:00:00 - The experiment will be stored in dump/0112-version_prediction/rel3_fact5data_3score_10\n",
      "                                     \n",
      "INFO - 01/12/23 18:00:18 - 0:00:00 - Running command: python joint_test_version.py --gpu_id 8 --exp_name version_prediction --ZSL 0 --exp_id rel3_fact5data_3score_10 --data_choice 3 --top_rel 3 --top_fact 1 --soft_score 10 --mrr 1\n",
      "\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 16\n",
      "batch_size 16\n",
      "begin test! ...\n",
      "loading model  ...\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_answer_SAN_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_answer_MLP_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_relation_SAN_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_relation_MLP_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_fact_SAN_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_fact_MLP_3.pkl model done!\n",
      "use train data: 3\n",
      "batch_size 16\n",
      "use train data: 3\n",
      "batch_size 16\n",
      "  0%|                                                   | 0/177 [00:00<?, ?it/s]pre tensor([379.8711, 378.6210, 377.1563, 370.5205, 370.6990, 372.7979, 379.3795,\n",
      "        409.5424, 372.6024, 375.1584, 373.2850, 379.0526, 378.3654, 372.6295,\n",
      "        378.6964, 378.2454, 377.4252, 379.5484, 374.0996, 367.8170, 374.8156,\n",
      "        374.9164, 378.6758, 383.4789, 375.7547, 369.2646, 372.4466, 375.2832,\n",
      "        374.0503, 378.2144, 382.3850, 379.1805, 379.4619, 376.2814, 384.5410,\n",
      "        381.3565, 393.8911, 372.4385, 379.9688, 368.8578, 378.2734, 378.8908,\n",
      "        371.0139, 373.5454, 374.4936, 374.6716, 378.8038, 375.7782, 378.2025,\n",
      "        369.1307, 386.0898, 377.3324, 382.3572, 387.5205, 387.5425, 369.0222,\n",
      "        383.7850, 376.6109, 374.9112, 391.5465, 373.5721, 385.1241, 381.3589,\n",
      "        375.5856, 378.3538, 384.5915, 382.8610, 367.1418, 381.1838, 380.2475,\n",
      "        375.8978, 372.6422, 387.5163, 373.8461, 378.8444, 383.0284, 380.2246,\n",
      "        392.9460, 378.1445, 372.4029, 372.4991, 370.8199, 379.0623, 381.7649,\n",
      "        378.5867, 377.5810, 379.7473, 375.7298, 374.7875, 374.9261, 381.0862,\n",
      "        368.9889, 368.3904, 375.3274, 378.1297, 381.2946, 376.1183, 378.4843,\n",
      "        378.4270, 373.9486, 375.7353, 379.8610, 374.7823, 386.8348, 385.6269,\n",
      "        382.4261, 383.6974, 376.8025, 374.6041, 372.1146, 377.9392, 388.3974,\n",
      "        373.5681, 376.4848, 371.4007, 375.3815, 376.0496, 386.0504, 385.4098,\n",
      "        377.5916, 379.6135, 382.9217, 390.0294, 366.5539, 384.3850, 367.9117,\n",
      "        370.7177, 396.8355, 369.0179, 382.5938, 373.3370, 378.0628, 371.2604,\n",
      "        381.6993, 385.0433, 378.7091, 378.3496, 375.2843, 376.7220, 377.6674,\n",
      "        384.3281, 374.2766, 375.8741, 385.4733, 370.1972, 376.6281, 365.4019,\n",
      "        366.0899, 395.7301, 375.8743, 397.7888, 383.8578, 389.1186, 388.0354,\n",
      "        371.7924, 377.5867, 383.1447, 384.0497, 370.9755, 378.8781, 373.3973,\n",
      "        379.4645, 378.2141, 379.4803, 375.4389, 371.3115, 384.5215, 370.6571,\n",
      "        391.2462, 374.7264, 368.9019, 385.5389, 377.0101, 373.4550, 371.5812,\n",
      "        381.9255, 371.4104, 386.6751, 368.6371, 381.9071, 365.2666, 381.5428,\n",
      "        365.0402, 375.7405, 378.4450, 380.3574, 366.5146, 375.0875, 370.5193,\n",
      "        376.6573, 370.7365, 374.4875, 371.1595, 369.3834, 380.5225, 366.0570,\n",
      "        384.7857, 393.0799, 379.3898, 384.7837, 390.0438, 379.7190, 379.9360,\n",
      "        372.3571, 367.9036, 369.8448, 374.4580, 368.2293, 367.8744, 380.6676,\n",
      "        369.9646, 379.7816, 364.9285, 378.6317, 370.1083, 380.4659, 376.4453,\n",
      "        377.6131, 369.2635, 368.0854, 380.7329, 370.7384, 377.4869, 387.9224,\n",
      "        382.8893, 367.4626, 388.0566, 380.0590, 362.6216, 375.2925, 382.1096,\n",
      "        374.7494, 379.7380, 378.8205, 381.6632, 370.6867, 380.1602, 385.5443,\n",
      "        381.8428, 378.8468, 371.9541, 371.2148, 379.0797, 368.4672, 381.4536,\n",
      "        375.5103, 369.8586, 376.0022, 375.7032, 381.0528, 373.4321, 376.0883,\n",
      "        369.9530, 378.3667, 380.3512, 372.5647, 372.7072, 372.5666, 377.0322,\n",
      "        372.6392, 376.4933, 372.5215, 381.1237, 370.1784, 380.2136, 375.9920,\n",
      "        373.7260, 376.7029, 382.4662, 385.0845, 366.7028, 380.3373, 373.2035,\n",
      "        363.2530, 374.2459, 386.0772, 386.0599, 378.0595, 371.2958, 379.7107,\n",
      "        386.0530, 377.2460, 376.6852, 377.3601, 371.9428, 373.8934, 368.5634,\n",
      "        379.3500, 374.8328, 374.7960, 378.3573, 380.5707, 374.0644, 371.6928,\n",
      "        373.2553, 368.9670, 378.5459, 373.4438, 383.3031, 372.3125, 376.2159,\n",
      "        379.8052, 378.8389, 370.9526, 370.7698, 378.6660, 369.9695, 363.9244,\n",
      "        374.1117, 373.5555, 377.4237, 369.5543, 373.2897, 374.0378, 367.9650,\n",
      "        384.7032, 369.3080, 366.6007, 371.0246, 377.6350, 376.7990, 369.7255,\n",
      "        368.1459, 393.0172, 371.6181, 367.4972, 380.8757, 378.8802, 372.0245,\n",
      "        373.1968, 375.7341, 377.2151, 378.5247, 370.7386, 374.9003, 370.8699,\n",
      "        375.0657, 370.7814, 373.4061, 365.7065, 376.3311, 384.5852, 377.8591,\n",
      "        372.2008, 378.7020, 371.2790, 373.3430, 376.7382, 374.7652, 386.3327,\n",
      "        379.9005, 385.2454, 367.8927, 365.8425, 381.4383, 374.5347, 383.2217,\n",
      "        369.9495, 375.9822, 374.0573, 374.0573, 372.7603, 383.3431, 369.7685,\n",
      "        384.0099, 376.9371, 364.1346, 387.1221, 378.5345, 369.1741, 367.8476,\n",
      "        379.9923, 374.7897, 383.7288, 386.3076, 375.2117, 365.7279, 380.4569,\n",
      "        369.6540, 375.5410, 381.9367, 389.1957, 367.0907, 382.8535, 389.4177,\n",
      "        377.1676, 389.1315, 371.3102, 375.7970, 381.7326, 372.2114, 370.3431,\n",
      "        383.0192, 374.2322, 385.3575, 385.8915, 372.9684, 382.6697, 371.8641,\n",
      "        376.6590, 378.4991, 373.1862, 376.8172, 389.1109, 375.8417, 375.1728,\n",
      "        368.1277, 378.6962, 376.4742, 367.8716, 369.3269, 374.7898, 368.8791,\n",
      "        366.5731, 376.0911, 369.3701, 368.5730, 371.5291, 374.2643, 372.6875,\n",
      "        384.3562, 373.6544, 373.8690, 368.5629, 368.6885, 371.8647, 384.3004,\n",
      "        368.9549, 373.1554, 371.9011, 386.2787, 378.7600, 373.0249, 374.6164,\n",
      "        384.8513, 372.0929, 375.2136, 372.2260, 371.7140, 379.9128, 370.5244,\n",
      "        365.6404, 375.0592, 372.8686, 373.0865, 370.6341, 364.0192, 371.2051,\n",
      "        371.7320, 370.8476, 380.0403, 379.0210, 371.9322, 372.3646, 384.2268,\n",
      "        387.3539, 391.7586, 368.8119, 372.2782, 381.5327, 395.9196, 371.3351,\n",
      "        379.4539, 378.1017, 382.2972, 376.6193, 386.4999, 373.9844, 376.8592,\n",
      "        371.6978, 370.5021, 373.8239, 374.1026, 374.6287, 367.3527, 378.7466,\n",
      "        373.2079, 369.3563, 374.2162, 370.6537, 367.2759, 377.4548, 382.1940,\n",
      "        375.5813, 380.8460, 384.8152, 380.9038, 374.1279, 378.7623, 388.8068,\n",
      "        374.0573, 367.8695, 382.7736, 381.6425, 372.7882, 373.3412, 373.3135,\n",
      "        374.1894, 365.1272, 374.0573], device='cuda:8', dtype=torch.float64)\n",
      "[]\n",
      "100%|█████████████████████████████████████████| 177/177 [00:36<00:00,  4.85it/s]\n",
      "self.min: 75.06101989746094\n",
      "self.max: 356.5176696777344\n",
      "INFO - 01/12/23 18:01:16 - 0:00:59 - #################################################################################################################\n",
      "INFO - 01/12/23 18:01:16 - 0:00:59 - ####  acc1= 48.03, acc3= 66.24, acc10= 80.73\n",
      "INFO - 01/12/23 18:01:16 - 0:00:59 - #################################################################################################################\n",
      "INFO - 01/12/23 18:01:16 - 0:00:59 - #################################################################################################################\n",
      "INFO - 01/12/23 18:01:16 - 0:00:59 - ####  mrr= 0.5933, mr = 15.61\n",
      "INFO - 01/12/23 18:01:16 - 0:00:59 - #################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "# 联合测试2\n",
    "%cd code\n",
    "!python joint_test_version.py --gpu_id 8 --exp_name version_prediction --ZSL 0 --exp_id rel3_fact5data_3score_10 --data_choice 3 --top_rel 3 --top_fact 1 --soft_score 10  --mrr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3479f0b",
   "metadata": {},
   "source": [
    "# ZS-F-VQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7d8e89ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T06:45:31.358007Z",
     "start_time": "2022-07-22T06:29:46.775213Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "ZSL setting...\n",
      "INFO - 07/22/22 14:29:48 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 07/22/22 14:29:48 - 0:00:00 - The experiment will be stored in dump/0722-answer_space/W2V\n",
      "                                     \n",
      "INFO - 07/22/22 14:29:48 - 0:00:00 - Running command: python main.py --gpu_id 9 --exp_name answer_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --ZSL 1 --save_model 1\n",
      "\n",
      "2022-07-22 14:29:48.471592: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-22 14:29:48.471654: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 128\n",
      "batch_size 128\n",
      "fusion_model:\n",
      "SAN(\n",
      "  (w_emb): WordEmbedding(\n",
      "    (emb): Embedding(15422, 300, padding_idx=15421)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (text): Seq2SeqRNN(\n",
      "    (rnn): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (attention): SanAttention(\n",
      "    (v_conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (q_lin): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (x_conv): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(5120, 8192, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(8192, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "Answer Model:\n",
      "MLP(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "train E000: 100% 23/23 [00:12<00:00,  1.83it/s]\n",
      "INFO - 07/22/22 14:30:15 - 0:00:27 - Train Epoch 0: LOSS= 5.88500, lr= 0.000500, acc1= 17.11,acc3= 28.87,acc10= 42.51\n",
      "train E001: 100% 23/23 [00:11<00:00,  1.95it/s]\n",
      "INFO - 07/22/22 14:30:27 - 0:00:39 - Train Epoch 1: LOSS= 1.97358, lr= 0.000750, acc1= 53.96,acc3= 72.62,acc10= 85.88\n",
      "eval E001: 100% 21/21 [00:09<00:00,  2.12it/s]\n",
      "INFO - 07/22/22 14:30:37 - 0:00:49 - #################################################################################################################\n",
      "INFO - 07/22/22 14:30:37 - 0:00:49 - Test Epoch 1: LOSS= 7.58726, acc1= 0.00, acc3= 0.61, acc10= 9.89\n",
      "INFO - 07/22/22 14:30:37 - 0:00:49 - Zsl Epoch 1: LOSS= 7.58726, acc1= 10.84, acc3= 24.90, acc10= 48.28\n",
      "INFO - 07/22/22 14:30:37 - 0:00:49 - #################################################################################################################\n",
      "train E002: 100% 23/23 [00:11<00:00,  1.97it/s]\n",
      "INFO - 07/22/22 14:30:49 - 0:01:01 - Train Epoch 2: LOSS= 1.17255, lr= 0.001000, acc1= 70.33,acc3= 86.61,acc10= 94.07\n",
      "eval E002: 100% 21/21 [00:10<00:00,  2.09it/s]\n",
      "INFO - 07/22/22 14:30:59 - 0:01:11 - #################################################################################################################\n",
      "INFO - 07/22/22 14:30:59 - 0:01:11 - Test Epoch 2: LOSS= 7.82149, acc1= 0.08, acc3= 1.53, acc10= 12.91\n",
      "INFO - 07/22/22 14:30:59 - 0:01:11 - Zsl Epoch 2: LOSS= 7.82149, acc1= 14.60, acc3= 28.97, acc10= 53.07\n",
      "INFO - 07/22/22 14:30:59 - 0:01:11 - #################################################################################################################\n",
      "train E003: 100% 23/23 [00:12<00:00,  1.88it/s]\n",
      "INFO - 07/22/22 14:31:11 - 0:01:23 - Train Epoch 3: LOSS= 0.78778, lr= 0.001250, acc1= 79.35,acc3= 91.85,acc10= 97.05\n",
      "eval E003: 100% 21/21 [00:09<00:00,  2.12it/s]\n",
      "INFO - 07/22/22 14:31:21 - 0:01:33 - #################################################################################################################\n",
      "INFO - 07/22/22 14:31:21 - 0:01:33 - Test Epoch 3: LOSS= 8.81503, acc1= 0.19, acc3= 1.88, acc10= 15.59\n",
      "INFO - 07/22/22 14:31:21 - 0:01:33 - Zsl Epoch 3: LOSS= 8.81503, acc1= 13.14, acc3= 28.12, acc10= 48.51\n",
      "INFO - 07/22/22 14:31:21 - 0:01:33 - #################################################################################################################\n",
      "train E004: 100% 23/23 [00:11<00:00,  2.03it/s]\n",
      "INFO - 07/22/22 14:31:32 - 0:01:44 - Train Epoch 4: LOSS= 0.66805, lr= 0.001500, acc1= 81.40,acc3= 94.55,acc10= 98.65\n",
      "eval E004: 100% 21/21 [00:09<00:00,  2.18it/s]\n",
      "INFO - 07/22/22 14:31:42 - 0:01:54 - #################################################################################################################\n",
      "INFO - 07/22/22 14:31:42 - 0:01:54 - Test Epoch 4: LOSS= 9.09879, acc1= 0.15, acc3= 2.34, acc10= 19.35\n",
      "INFO - 07/22/22 14:31:42 - 0:01:54 - Zsl Epoch 4: LOSS= 9.09879, acc1= 13.22, acc3= 27.85, acc10= 51.42\n",
      "INFO - 07/22/22 14:31:42 - 0:01:54 - #################################################################################################################\n",
      "train E005: 100% 23/23 [00:12<00:00,  1.91it/s]\n",
      "INFO - 07/22/22 14:31:54 - 0:02:06 - Train Epoch 5: LOSS= 0.65994, lr= 0.001750, acc1= 82.03,acc3= 94.52,acc10= 98.72\n",
      "eval E005: 100% 21/21 [00:09<00:00,  2.19it/s]\n",
      "INFO - 07/22/22 14:32:04 - 0:02:16 - #################################################################################################################\n",
      "INFO - 07/22/22 14:32:04 - 0:02:16 - Test Epoch 5: LOSS= 9.82389, acc1= 0.11, acc3= 2.38, acc10= 19.58\n",
      "INFO - 07/22/22 14:32:04 - 0:02:16 - Zsl Epoch 5: LOSS= 9.82389, acc1= 11.42, acc3= 29.08, acc10= 53.68\n",
      "INFO - 07/22/22 14:32:04 - 0:02:16 - #################################################################################################################\n",
      "train E006: 100% 23/23 [00:11<00:00,  1.94it/s]\n",
      "INFO - 07/22/22 14:32:15 - 0:02:28 - Train Epoch 6: LOSS= 0.69620, lr= 0.002000, acc1= 82.65,acc3= 94.34,acc10= 98.33\n",
      "eval E006: 100% 21/21 [00:10<00:00,  2.02it/s]\n",
      "INFO - 07/22/22 14:32:26 - 0:02:38 - #################################################################################################################\n",
      "INFO - 07/22/22 14:32:26 - 0:02:38 - Test Epoch 6: LOSS= 10.53618, acc1= 0.15, acc3= 4.44, acc10= 22.68\n",
      "INFO - 07/22/22 14:32:26 - 0:02:38 - Zsl Epoch 6: LOSS= 10.53618, acc1= 15.36, acc3= 29.89, acc10= 52.11\n",
      "INFO - 07/22/22 14:32:26 - 0:02:38 - #################################################################################################################\n",
      "train E007: 100% 23/23 [00:11<00:00,  1.93it/s]\n",
      "INFO - 07/22/22 14:32:38 - 0:02:50 - Train Epoch 7: LOSS= 0.69321, lr= 0.002000, acc1= 83.34,acc3= 94.03,acc10= 98.16\n",
      "eval E007: 100% 21/21 [00:09<00:00,  2.20it/s]\n",
      "INFO - 07/22/22 14:32:47 - 0:02:59 - #################################################################################################################\n",
      "INFO - 07/22/22 14:32:47 - 0:02:59 - Test Epoch 7: LOSS= 10.78392, acc1= 0.11, acc3= 3.03, acc10= 21.99\n",
      "INFO - 07/22/22 14:32:47 - 0:02:59 - Zsl Epoch 7: LOSS= 10.78392, acc1= 12.68, acc3= 30.46, acc10= 52.38\n",
      "INFO - 07/22/22 14:32:47 - 0:02:59 - #################################################################################################################\n",
      "train E008: 100% 23/23 [00:11<00:00,  1.98it/s]\n",
      "INFO - 07/22/22 14:32:59 - 0:03:11 - Train Epoch 8: LOSS= 0.53108, lr= 0.002000, acc1= 86.54,acc3= 95.91,acc10= 98.99\n",
      "eval E008: 100% 21/21 [00:09<00:00,  2.17it/s]\n",
      "INFO - 07/22/22 14:33:09 - 0:03:21 - #################################################################################################################\n",
      "INFO - 07/22/22 14:33:09 - 0:03:21 - Test Epoch 8: LOSS= 11.56826, acc1= 0.19, acc3= 5.56, acc10= 28.35\n",
      "INFO - 07/22/22 14:33:09 - 0:03:21 - Zsl Epoch 8: LOSS= 11.56826, acc1= 16.74, acc3= 34.71, acc10= 57.36\n",
      "INFO - 07/22/22 14:33:09 - 0:03:21 - #################################################################################################################\n",
      "train E009: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
      "INFO - 07/22/22 14:33:20 - 0:03:33 - Train Epoch 9: LOSS= 0.51683, lr= 0.002000, acc1= 87.47,acc3= 97.09,acc10= 99.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E009: 100% 21/21 [00:09<00:00,  2.15it/s]\n",
      "INFO - 07/22/22 14:33:30 - 0:03:42 - #################################################################################################################\n",
      "INFO - 07/22/22 14:33:30 - 0:03:42 - Test Epoch 9: LOSS= 11.66070, acc1= 0.15, acc3= 5.40, acc10= 27.16\n",
      "INFO - 07/22/22 14:33:30 - 0:03:42 - Zsl Epoch 9: LOSS= 11.66070, acc1= 15.98, acc3= 32.49, acc10= 55.02\n",
      "INFO - 07/22/22 14:33:30 - 0:03:42 - #################################################################################################################\n",
      "train E010: 100% 23/23 [00:11<00:00,  1.93it/s]\n",
      "INFO - 07/22/22 14:33:42 - 0:03:54 - Train Epoch 10: LOSS= 0.53266, lr= 0.002000, acc1= 88.06,acc3= 96.81,acc10= 99.24\n",
      "eval E010: 100% 21/21 [00:09<00:00,  2.14it/s]\n",
      "INFO - 07/22/22 14:33:52 - 0:04:04 - #################################################################################################################\n",
      "INFO - 07/22/22 14:33:52 - 0:04:04 - Test Epoch 10: LOSS= 12.43803, acc1= 0.11, acc3= 5.29, acc10= 22.07\n",
      "INFO - 07/22/22 14:33:52 - 0:04:04 - Zsl Epoch 10: LOSS= 12.43803, acc1= 11.76, acc3= 24.56, acc10= 45.33\n",
      "INFO - 07/22/22 14:33:52 - 0:04:04 - #################################################################################################################\n",
      "train E011: 100% 23/23 [00:11<00:00,  1.92it/s]\n",
      "INFO - 07/22/22 14:34:04 - 0:04:16 - Train Epoch 11: LOSS= 0.43744, lr= 0.002000, acc1= 89.87,acc3= 97.43,acc10= 99.41\n",
      "eval E011: 100% 21/21 [00:09<00:00,  2.10it/s]\n",
      "INFO - 07/22/22 14:34:14 - 0:04:26 - #################################################################################################################\n",
      "INFO - 07/22/22 14:34:14 - 0:04:26 - Test Epoch 11: LOSS= 13.15664, acc1= 0.08, acc3= 5.52, acc10= 25.86\n",
      "INFO - 07/22/22 14:34:14 - 0:04:26 - Zsl Epoch 11: LOSS= 13.15664, acc1= 13.79, acc3= 29.08, acc10= 52.07\n",
      "INFO - 07/22/22 14:34:14 - 0:04:26 - #################################################################################################################\n",
      "train E012: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
      "INFO - 07/22/22 14:34:26 - 0:04:38 - Train Epoch 12: LOSS= 0.36509, lr= 0.002000, acc1= 90.77,acc3= 98.09,acc10= 99.76\n",
      "eval E012: 100% 21/21 [00:09<00:00,  2.17it/s]\n",
      "INFO - 07/22/22 14:34:35 - 0:04:47 - #################################################################################################################\n",
      "INFO - 07/22/22 14:34:35 - 0:04:47 - Test Epoch 12: LOSS= 12.48149, acc1= 1.03, acc3= 6.86, acc10= 30.54\n",
      "INFO - 07/22/22 14:34:35 - 0:04:47 - Zsl Epoch 12: LOSS= 12.48149, acc1= 13.37, acc3= 31.76, acc10= 56.09\n",
      "INFO - 07/22/22 14:34:35 - 0:04:47 - #################################################################################################################\n",
      "train E013: 100% 23/23 [00:11<00:00,  1.94it/s]\n",
      "INFO - 07/22/22 14:34:47 - 0:04:59 - Train Epoch 13: LOSS= 0.35994, lr= 0.002000, acc1= 92.47,acc3= 98.40,acc10= 99.65\n",
      "eval E013: 100% 21/21 [00:10<00:00,  2.09it/s]\n",
      "INFO - 07/22/22 14:34:57 - 0:05:09 - #################################################################################################################\n",
      "INFO - 07/22/22 14:34:57 - 0:05:09 - Test Epoch 13: LOSS= 12.86519, acc1= 0.92, acc3= 5.59, acc10= 28.66\n",
      "INFO - 07/22/22 14:34:57 - 0:05:09 - Zsl Epoch 13: LOSS= 12.86519, acc1= 14.75, acc3= 32.99, acc10= 56.13\n",
      "INFO - 07/22/22 14:34:57 - 0:05:09 - #################################################################################################################\n",
      "train E014: 100% 23/23 [00:11<00:00,  1.97it/s]\n",
      "INFO - 07/22/22 14:35:09 - 0:05:21 - Train Epoch 14: LOSS= 0.22557, lr= 0.001400, acc1= 93.89,acc3= 98.96,acc10= 99.72\n",
      "eval E014: 100% 21/21 [00:09<00:00,  2.16it/s]\n",
      "INFO - 07/22/22 14:35:19 - 0:05:31 - #################################################################################################################\n",
      "INFO - 07/22/22 14:35:19 - 0:05:31 - Test Epoch 14: LOSS= 12.98237, acc1= 0.15, acc3= 5.25, acc10= 27.55\n",
      "INFO - 07/22/22 14:35:19 - 0:05:31 - Zsl Epoch 14: LOSS= 12.98237, acc1= 13.22, acc3= 29.89, acc10= 55.06\n",
      "INFO - 07/22/22 14:35:19 - 0:05:31 - #################################################################################################################\n",
      "train E015: 100% 23/23 [00:11<00:00,  1.94it/s]\n",
      "INFO - 07/22/22 14:35:30 - 0:05:43 - Train Epoch 15: LOSS= 0.15511, lr= 0.001400, acc1= 95.98,acc3= 99.48,acc10= 99.90\n",
      "eval E015: 100% 21/21 [00:09<00:00,  2.20it/s]\n",
      "INFO - 07/22/22 14:35:40 - 0:05:52 - #################################################################################################################\n",
      "INFO - 07/22/22 14:35:40 - 0:05:52 - Test Epoch 15: LOSS= 13.00229, acc1= 0.23, acc3= 6.17, acc10= 28.85\n",
      "INFO - 07/22/22 14:35:40 - 0:05:52 - Zsl Epoch 15: LOSS= 13.00229, acc1= 14.37, acc3= 31.15, acc10= 57.13\n",
      "INFO - 07/22/22 14:35:40 - 0:05:52 - #################################################################################################################\n",
      "train E016: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
      "INFO - 07/22/22 14:35:52 - 0:06:04 - Train Epoch 16: LOSS= 0.15878, lr= 0.001400, acc1= 95.59,acc3= 99.13,acc10= 99.83\n",
      "eval E016: 100% 21/21 [00:10<00:00,  2.07it/s]\n",
      "INFO - 07/22/22 14:36:02 - 0:06:14 - #################################################################################################################\n",
      "INFO - 07/22/22 14:36:02 - 0:06:14 - Test Epoch 16: LOSS= 13.23949, acc1= 0.11, acc3= 6.09, acc10= 27.43\n",
      "INFO - 07/22/22 14:36:02 - 0:06:14 - Zsl Epoch 16: LOSS= 13.23949, acc1= 14.71, acc3= 30.57, acc10= 56.59\n",
      "INFO - 07/22/22 14:36:02 - 0:06:14 - #################################################################################################################\n",
      "train E017: 100% 23/23 [00:11<00:00,  2.00it/s]\n",
      "INFO - 07/22/22 14:36:13 - 0:06:26 - Train Epoch 17: LOSS= 0.09607, lr= 0.000980, acc1= 97.57,acc3= 99.65,acc10= 99.97\n",
      "eval E017: 100% 21/21 [00:09<00:00,  2.14it/s]\n",
      "INFO - 07/22/22 14:36:23 - 0:06:35 - #################################################################################################################\n",
      "INFO - 07/22/22 14:36:23 - 0:06:35 - Test Epoch 17: LOSS= 13.79360, acc1= 0.11, acc3= 5.52, acc10= 27.09\n",
      "INFO - 07/22/22 14:36:23 - 0:06:35 - Zsl Epoch 17: LOSS= 13.79360, acc1= 12.87, acc3= 28.74, acc10= 55.44\n",
      "INFO - 07/22/22 14:36:23 - 0:06:35 - #################################################################################################################\n",
      "train E018: 100% 23/23 [00:11<00:00,  1.92it/s]\n",
      "INFO - 07/22/22 14:36:35 - 0:06:47 - Train Epoch 18: LOSS= 0.04330, lr= 0.000980, acc1= 98.75,acc3= 99.93,acc10= 100.00\n",
      "eval E018: 100% 21/21 [00:10<00:00,  2.09it/s]\n",
      "INFO - 07/22/22 14:36:45 - 0:06:57 - #################################################################################################################\n",
      "INFO - 07/22/22 14:36:45 - 0:06:57 - Test Epoch 18: LOSS= 13.42194, acc1= 0.04, acc3= 6.63, acc10= 29.69\n",
      "INFO - 07/22/22 14:36:45 - 0:06:57 - Zsl Epoch 18: LOSS= 13.42194, acc1= 14.44, acc3= 30.04, acc10= 58.51\n",
      "INFO - 07/22/22 14:36:45 - 0:06:57 - #################################################################################################################\n",
      "train E019: 100% 23/23 [00:12<00:00,  1.92it/s]\n",
      "INFO - 07/22/22 14:36:57 - 0:07:10 - Train Epoch 19: LOSS= 0.03956, lr= 0.000980, acc1= 98.82,acc3= 99.93,acc10= 99.97\n",
      "eval E019: 100% 21/21 [00:10<00:00,  2.08it/s]\n",
      "INFO - 07/22/22 14:37:07 - 0:07:20 - #################################################################################################################\n",
      "INFO - 07/22/22 14:37:07 - 0:07:20 - Test Epoch 19: LOSS= 13.15533, acc1= 0.11, acc3= 6.28, acc10= 29.54\n",
      "INFO - 07/22/22 14:37:07 - 0:07:20 - Zsl Epoch 19: LOSS= 13.15533, acc1= 14.87, acc3= 31.19, acc10= 57.97\n",
      "INFO - 07/22/22 14:37:07 - 0:07:20 - #################################################################################################################\n",
      "train E020: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
      "INFO - 07/22/22 14:37:19 - 0:07:31 - Train Epoch 20: LOSS= 0.03779, lr= 0.000686, acc1= 98.65,acc3= 99.93,acc10= 100.00\n",
      "eval E020: 100% 21/21 [00:10<00:00,  2.07it/s]\n",
      "INFO - 07/22/22 14:37:29 - 0:07:41 - #################################################################################################################\n",
      "INFO - 07/22/22 14:37:29 - 0:07:41 - Test Epoch 20: LOSS= 13.42398, acc1= 0.19, acc3= 5.90, acc10= 29.39\n",
      "INFO - 07/22/22 14:37:29 - 0:07:41 - Zsl Epoch 20: LOSS= 13.42398, acc1= 13.45, acc3= 31.15, acc10= 59.85\n",
      "INFO - 07/22/22 14:37:29 - 0:07:41 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E021: 100% 23/23 [00:12<00:00,  1.85it/s]\n",
      "INFO - 07/22/22 14:37:42 - 0:07:54 - Train Epoch 21: LOSS= 0.02369, lr= 0.000686, acc1= 99.38,acc3= 99.97,acc10= 100.00\n",
      "eval E021: 100% 21/21 [00:09<00:00,  2.14it/s]\n",
      "INFO - 07/22/22 14:37:51 - 0:08:04 - #################################################################################################################\n",
      "INFO - 07/22/22 14:37:51 - 0:08:04 - Test Epoch 21: LOSS= 13.23530, acc1= 1.00, acc3= 6.32, acc10= 29.23\n",
      "INFO - 07/22/22 14:37:51 - 0:08:04 - Zsl Epoch 21: LOSS= 13.23530, acc1= 13.83, acc3= 30.96, acc10= 57.93\n",
      "INFO - 07/22/22 14:37:51 - 0:08:04 - #################################################################################################################\n",
      "train E022: 100% 23/23 [00:12<00:00,  1.86it/s]\n",
      "INFO - 07/22/22 14:38:04 - 0:08:16 - Train Epoch 22: LOSS= 0.02240, lr= 0.000686, acc1= 99.13,acc3= 99.97,acc10= 100.00\n",
      "eval E022: 100% 21/21 [00:10<00:00,  2.08it/s]\n",
      "INFO - 07/22/22 14:38:14 - 0:08:26 - #################################################################################################################\n",
      "INFO - 07/22/22 14:38:14 - 0:08:26 - Test Epoch 22: LOSS= 13.48337, acc1= 1.03, acc3= 5.98, acc10= 28.24\n",
      "INFO - 07/22/22 14:38:14 - 0:08:26 - Zsl Epoch 22: LOSS= 13.48337, acc1= 13.91, acc3= 31.72, acc10= 57.36\n",
      "INFO - 07/22/22 14:38:14 - 0:08:26 - #################################################################################################################\n",
      "train E023: 100% 23/23 [00:11<00:00,  2.00it/s]\n",
      "INFO - 07/22/22 14:38:25 - 0:08:38 - Train Epoch 23: LOSS= 0.02148, lr= 0.000480, acc1= 99.48,acc3= 99.90,acc10= 99.97\n",
      "eval E023: 100% 21/21 [00:09<00:00,  2.17it/s]\n",
      "INFO - 07/22/22 14:38:35 - 0:08:47 - #################################################################################################################\n",
      "INFO - 07/22/22 14:38:35 - 0:08:47 - Test Epoch 23: LOSS= 13.55590, acc1= 0.04, acc3= 5.86, acc10= 28.89\n",
      "INFO - 07/22/22 14:38:35 - 0:08:47 - Zsl Epoch 23: LOSS= 13.55590, acc1= 14.29, acc3= 32.72, acc10= 59.23\n",
      "INFO - 07/22/22 14:38:35 - 0:08:47 - #################################################################################################################\n",
      "train E024: 100% 23/23 [00:12<00:00,  1.90it/s]\n",
      "INFO - 07/22/22 14:38:47 - 0:08:59 - Train Epoch 24: LOSS= 0.01303, lr= 0.000480, acc1= 99.58,acc3= 99.97,acc10= 100.00\n",
      "eval E024: 100% 21/21 [00:10<00:00,  2.08it/s]\n",
      "INFO - 07/22/22 14:38:57 - 0:09:09 - #################################################################################################################\n",
      "INFO - 07/22/22 14:38:57 - 0:09:09 - Test Epoch 24: LOSS= 13.71372, acc1= 0.04, acc3= 6.02, acc10= 28.51\n",
      "INFO - 07/22/22 14:38:57 - 0:09:09 - Zsl Epoch 24: LOSS= 13.71372, acc1= 14.06, acc3= 32.15, acc10= 59.62\n",
      "INFO - 07/22/22 14:38:57 - 0:09:09 - #################################################################################################################\n",
      "train E025: 100% 23/23 [00:11<00:00,  1.99it/s]\n",
      "INFO - 07/22/22 14:39:09 - 0:09:21 - Train Epoch 25: LOSS= 0.01354, lr= 0.000480, acc1= 99.65,acc3= 99.93,acc10= 100.00\n",
      "eval E025: 100% 21/21 [00:09<00:00,  2.11it/s]\n",
      "INFO - 07/22/22 14:39:19 - 0:09:31 - #################################################################################################################\n",
      "INFO - 07/22/22 14:39:19 - 0:09:31 - Test Epoch 25: LOSS= 13.53430, acc1= 0.96, acc3= 6.21, acc10= 29.39\n",
      "INFO - 07/22/22 14:39:19 - 0:09:31 - Zsl Epoch 25: LOSS= 13.53430, acc1= 14.48, acc3= 32.64, acc10= 60.15\n",
      "INFO - 07/22/22 14:39:19 - 0:09:31 - #################################################################################################################\n",
      "train E026: 100% 23/23 [00:11<00:00,  1.94it/s]\n",
      "INFO - 07/22/22 14:39:31 - 0:09:43 - Train Epoch 26: LOSS= 0.01101, lr= 0.000336, acc1= 99.55,acc3= 99.97,acc10= 100.00\n",
      "eval E026: 100% 21/21 [00:10<00:00,  2.08it/s]\n",
      "INFO - 07/22/22 14:39:41 - 0:09:53 - #################################################################################################################\n",
      "INFO - 07/22/22 14:39:41 - 0:09:53 - Test Epoch 26: LOSS= 13.51411, acc1= 0.96, acc3= 6.28, acc10= 29.16\n",
      "INFO - 07/22/22 14:39:41 - 0:09:53 - Zsl Epoch 26: LOSS= 13.51411, acc1= 14.75, acc3= 32.18, acc10= 59.62\n",
      "INFO - 07/22/22 14:39:41 - 0:09:53 - #################################################################################################################\n",
      "train E027: 100% 23/23 [00:12<00:00,  1.87it/s]\n",
      "INFO - 07/22/22 14:39:53 - 0:10:05 - Train Epoch 27: LOSS= 0.01679, lr= 0.000336, acc1= 99.44,acc3= 99.93,acc10= 100.00\n",
      "eval E027: 100% 21/21 [00:09<00:00,  2.13it/s]\n",
      "INFO - 07/22/22 14:40:03 - 0:10:15 - #################################################################################################################\n",
      "INFO - 07/22/22 14:40:03 - 0:10:15 - Test Epoch 27: LOSS= 13.60837, acc1= 0.92, acc3= 6.05, acc10= 29.27\n",
      "INFO - 07/22/22 14:40:03 - 0:10:15 - Zsl Epoch 27: LOSS= 13.60837, acc1= 14.52, acc3= 32.30, acc10= 59.69\n",
      "INFO - 07/22/22 14:40:03 - 0:10:15 - #################################################################################################################\n",
      "train E028: 100% 23/23 [00:11<00:00,  1.94it/s]\n",
      "INFO - 07/22/22 14:40:15 - 0:10:27 - Train Epoch 28: LOSS= 0.00918, lr= 0.000336, acc1= 99.69,acc3= 99.97,acc10= 100.00\n",
      "eval E028: 100% 21/21 [00:09<00:00,  2.13it/s]\n",
      "INFO - 07/22/22 14:40:25 - 0:10:37 - #################################################################################################################\n",
      "INFO - 07/22/22 14:40:25 - 0:10:37 - Test Epoch 28: LOSS= 13.39748, acc1= 0.04, acc3= 6.36, acc10= 29.50\n",
      "INFO - 07/22/22 14:40:25 - 0:10:37 - Zsl Epoch 28: LOSS= 13.39748, acc1= 14.79, acc3= 33.22, acc10= 60.57\n",
      "INFO - 07/22/22 14:40:25 - 0:10:37 - #################################################################################################################\n",
      "train E029: 100% 23/23 [00:11<00:00,  2.04it/s]\n",
      "INFO - 07/22/22 14:40:36 - 0:10:48 - Train Epoch 29: LOSS= 0.00843, lr= 0.000235, acc1= 99.76,acc3= 99.97,acc10= 100.00\n",
      "eval E029: 100% 21/21 [00:09<00:00,  2.13it/s]\n",
      "INFO - 07/22/22 14:40:46 - 0:10:58 - #################################################################################################################\n",
      "INFO - 07/22/22 14:40:46 - 0:10:58 - Test Epoch 29: LOSS= 13.45617, acc1= 0.04, acc3= 6.25, acc10= 29.31\n",
      "INFO - 07/22/22 14:40:46 - 0:10:58 - Zsl Epoch 29: LOSS= 13.45617, acc1= 14.83, acc3= 33.03, acc10= 60.38\n",
      "INFO - 07/22/22 14:40:46 - 0:10:58 - #################################################################################################################\n",
      "train E030: 100% 23/23 [00:11<00:00,  2.01it/s]\n",
      "INFO - 07/22/22 14:40:57 - 0:11:09 - Train Epoch 30: LOSS= 0.01105, lr= 0.000235, acc1= 99.62,acc3= 99.97,acc10= 100.00\n",
      "eval E030: 100% 21/21 [00:09<00:00,  2.19it/s]\n",
      "INFO - 07/22/22 14:41:07 - 0:11:19 - #################################################################################################################\n",
      "INFO - 07/22/22 14:41:07 - 0:11:19 - Test Epoch 30: LOSS= 13.55442, acc1= 0.96, acc3= 5.98, acc10= 29.46\n",
      "INFO - 07/22/22 14:41:07 - 0:11:19 - Zsl Epoch 30: LOSS= 13.55442, acc1= 14.56, acc3= 32.80, acc10= 60.27\n",
      "INFO - 07/22/22 14:41:07 - 0:11:19 - #################################################################################################################\n",
      "train E031: 100% 23/23 [00:11<00:00,  1.94it/s]\n",
      "INFO - 07/22/22 14:41:19 - 0:11:31 - Train Epoch 31: LOSS= 0.00666, lr= 0.000235, acc1= 99.79,acc3= 99.97,acc10= 100.00\n",
      "eval E031: 100% 21/21 [00:09<00:00,  2.15it/s]\n",
      "INFO - 07/22/22 14:41:28 - 0:11:41 - #################################################################################################################\n",
      "INFO - 07/22/22 14:41:28 - 0:11:41 - Test Epoch 31: LOSS= 13.56906, acc1= 0.08, acc3= 6.05, acc10= 29.66\n",
      "INFO - 07/22/22 14:41:28 - 0:11:41 - Zsl Epoch 31: LOSS= 13.56906, acc1= 14.71, acc3= 33.18, acc10= 60.54\n",
      "INFO - 07/22/22 14:41:28 - 0:11:41 - #################################################################################################################\n",
      "train E032: 100% 23/23 [00:11<00:00,  1.94it/s]\n",
      "INFO - 07/22/22 14:41:40 - 0:11:53 - Train Epoch 32: LOSS= 0.01575, lr= 0.000165, acc1= 99.44,acc3= 99.97,acc10= 100.00\n",
      "eval E032: 100% 21/21 [00:09<00:00,  2.16it/s]\n",
      "INFO - 07/22/22 14:41:50 - 0:12:02 - #################################################################################################################\n",
      "INFO - 07/22/22 14:41:50 - 0:12:02 - Test Epoch 32: LOSS= 13.60640, acc1= 0.04, acc3= 6.17, acc10= 29.54\n",
      "INFO - 07/22/22 14:41:50 - 0:12:02 - Zsl Epoch 32: LOSS= 13.60640, acc1= 14.67, acc3= 32.95, acc10= 60.15\n",
      "INFO - 07/22/22 14:41:50 - 0:12:02 - #################################################################################################################\n",
      "train E033: 100% 23/23 [00:12<00:00,  1.91it/s]\n",
      "INFO - 07/22/22 14:42:02 - 0:12:14 - Train Epoch 33: LOSS= 0.00812, lr= 0.000165, acc1= 99.62,acc3= 99.97,acc10= 100.00\n",
      "eval E033: 100% 21/21 [00:10<00:00,  2.06it/s]\n",
      "INFO - 07/22/22 14:42:12 - 0:12:25 - #################################################################################################################\n",
      "INFO - 07/22/22 14:42:12 - 0:12:25 - Test Epoch 33: LOSS= 13.61432, acc1= 0.04, acc3= 6.25, acc10= 29.31\n",
      "INFO - 07/22/22 14:42:12 - 0:12:25 - Zsl Epoch 33: LOSS= 13.61432, acc1= 14.56, acc3= 32.99, acc10= 60.34\n",
      "INFO - 07/22/22 14:42:12 - 0:12:25 - #################################################################################################################\n",
      "train E034: 100% 23/23 [00:12<00:00,  1.88it/s]\n",
      "INFO - 07/22/22 14:42:25 - 0:12:37 - Train Epoch 34: LOSS= 0.00813, lr= 0.000165, acc1= 99.76,acc3= 99.97,acc10= 100.00\n",
      "eval E034: 100% 21/21 [00:10<00:00,  2.07it/s]\n",
      "INFO - 07/22/22 14:42:35 - 0:12:47 - #################################################################################################################\n",
      "INFO - 07/22/22 14:42:35 - 0:12:47 - Test Epoch 34: LOSS= 13.71873, acc1= 0.04, acc3= 6.25, acc10= 29.62\n",
      "INFO - 07/22/22 14:42:35 - 0:12:47 - Zsl Epoch 34: LOSS= 13.71873, acc1= 14.87, acc3= 33.07, acc10= 60.73\n",
      "INFO - 07/22/22 14:42:35 - 0:12:47 - #################################################################################################################\n",
      "train E035: 100% 23/23 [00:11<00:00,  1.92it/s]\n",
      "INFO - 07/22/22 14:42:47 - 0:12:59 - Train Epoch 35: LOSS= 0.00577, lr= 0.000115, acc1= 99.76,acc3= 99.97,acc10= 100.00\n",
      "eval E035: 100% 21/21 [00:09<00:00,  2.10it/s]\n",
      "INFO - 07/22/22 14:42:57 - 0:13:09 - #################################################################################################################\n",
      "INFO - 07/22/22 14:42:57 - 0:13:09 - Test Epoch 35: LOSS= 13.67863, acc1= 0.04, acc3= 6.17, acc10= 29.46\n",
      "INFO - 07/22/22 14:42:57 - 0:13:09 - Zsl Epoch 35: LOSS= 13.67863, acc1= 14.56, acc3= 33.07, acc10= 60.54\n",
      "INFO - 07/22/22 14:42:57 - 0:13:09 - #################################################################################################################\n",
      "train E036: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
      "INFO - 07/22/22 14:43:08 - 0:13:21 - Train Epoch 36: LOSS= 0.00651, lr= 0.000115, acc1= 99.79,acc3= 99.97,acc10= 100.00\n",
      "eval E036: 100% 21/21 [00:09<00:00,  2.14it/s]\n",
      "INFO - 07/22/22 14:43:18 - 0:13:30 - #################################################################################################################\n",
      "INFO - 07/22/22 14:43:18 - 0:13:30 - Test Epoch 36: LOSS= 13.68151, acc1= 0.04, acc3= 6.17, acc10= 29.58\n",
      "INFO - 07/22/22 14:43:18 - 0:13:30 - Zsl Epoch 36: LOSS= 13.68151, acc1= 14.29, acc3= 33.18, acc10= 60.65\n",
      "INFO - 07/22/22 14:43:18 - 0:13:30 - #################################################################################################################\n",
      "train E037: 100% 23/23 [00:11<00:00,  2.01it/s]\n",
      "INFO - 07/22/22 14:43:30 - 0:13:42 - Train Epoch 37: LOSS= 0.00961, lr= 0.000115, acc1= 99.65,acc3= 99.97,acc10= 100.00\n",
      "eval E037: 100% 21/21 [00:10<00:00,  2.09it/s]\n",
      "INFO - 07/22/22 14:43:40 - 0:13:52 - #################################################################################################################\n",
      "INFO - 07/22/22 14:43:40 - 0:13:52 - Test Epoch 37: LOSS= 13.66140, acc1= 0.04, acc3= 6.13, acc10= 30.00\n",
      "INFO - 07/22/22 14:43:40 - 0:13:52 - Zsl Epoch 37: LOSS= 13.66140, acc1= 14.48, acc3= 33.30, acc10= 61.23\n",
      "INFO - 07/22/22 14:43:40 - 0:13:52 - #################################################################################################################\n",
      "train E038: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
      "INFO - 07/22/22 14:43:51 - 0:14:04 - Train Epoch 38: LOSS= 0.00656, lr= 0.000081, acc1= 99.72,acc3= 99.97,acc10= 100.00\n",
      "eval E038: 100% 21/21 [00:09<00:00,  2.18it/s]\n",
      "INFO - 07/22/22 14:44:01 - 0:14:13 - #################################################################################################################\n",
      "INFO - 07/22/22 14:44:01 - 0:14:13 - Test Epoch 38: LOSS= 13.66810, acc1= 0.04, acc3= 6.32, acc10= 29.81\n",
      "INFO - 07/22/22 14:44:01 - 0:14:13 - Zsl Epoch 38: LOSS= 13.66810, acc1= 14.44, acc3= 33.14, acc10= 61.07\n",
      "INFO - 07/22/22 14:44:01 - 0:14:13 - #################################################################################################################\n",
      "train E039: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
      "INFO - 07/22/22 14:44:13 - 0:14:25 - Train Epoch 39: LOSS= 0.00747, lr= 0.000081, acc1= 99.72,acc3= 99.97,acc10= 100.00\n",
      "eval E039: 100% 21/21 [00:09<00:00,  2.12it/s]\n",
      "INFO - 07/22/22 14:44:23 - 0:14:35 - #################################################################################################################\n",
      "INFO - 07/22/22 14:44:23 - 0:14:35 - Test Epoch 39: LOSS= 13.66166, acc1= 0.04, acc3= 6.32, acc10= 29.58\n",
      "INFO - 07/22/22 14:44:23 - 0:14:35 - Zsl Epoch 39: LOSS= 13.66166, acc1= 14.37, acc3= 33.14, acc10= 61.11\n",
      "INFO - 07/22/22 14:44:23 - 0:14:35 - #################################################################################################################\n",
      "train E040: 100% 23/23 [00:11<00:00,  1.98it/s]\n",
      "INFO - 07/22/22 14:44:34 - 0:14:46 - Train Epoch 40: LOSS= 0.00866, lr= 0.000081, acc1= 99.62,acc3= 99.97,acc10= 100.00\n",
      "eval E040: 100% 21/21 [00:10<00:00,  2.10it/s]\n",
      "INFO - 07/22/22 14:44:44 - 0:14:57 - #################################################################################################################\n",
      "INFO - 07/22/22 14:44:44 - 0:14:57 - Test Epoch 40: LOSS= 13.66818, acc1= 0.04, acc3= 6.40, acc10= 29.46\n",
      "INFO - 07/22/22 14:44:44 - 0:14:57 - Zsl Epoch 40: LOSS= 13.66818, acc1= 14.14, acc3= 33.18, acc10= 61.00\n",
      "INFO - 07/22/22 14:44:44 - 0:14:57 - #################################################################################################################\n",
      "train E041: 100% 23/23 [00:11<00:00,  1.93it/s]\n",
      "INFO - 07/22/22 14:44:56 - 0:15:08 - Train Epoch 41: LOSS= 0.00738, lr= 0.000056, acc1= 99.69,acc3= 99.97,acc10= 100.00\n",
      "eval E041: 100% 21/21 [00:09<00:00,  2.23it/s]\n",
      "INFO - 07/22/22 14:45:06 - 0:15:18 - #################################################################################################################\n",
      "INFO - 07/22/22 14:45:06 - 0:15:18 - Test Epoch 41: LOSS= 13.64572, acc1= 0.04, acc3= 6.32, acc10= 29.39\n",
      "INFO - 07/22/22 14:45:06 - 0:15:18 - Zsl Epoch 41: LOSS= 13.64572, acc1= 14.21, acc3= 33.14, acc10= 60.80\n",
      "INFO - 07/22/22 14:45:06 - 0:15:18 - #################################################################################################################\n",
      "train E042: 100% 23/23 [00:11<00:00,  1.95it/s]\n",
      "INFO - 07/22/22 14:45:17 - 0:15:30 - Train Epoch 42: LOSS= 0.00638, lr= 0.000056, acc1= 99.76,acc3= 99.97,acc10= 100.00\n",
      "eval E042: 100% 21/21 [00:09<00:00,  2.11it/s]\n",
      "INFO - 07/22/22 14:45:27 - 0:15:40 - #################################################################################################################\n",
      "INFO - 07/22/22 14:45:27 - 0:15:40 - Test Epoch 42: LOSS= 13.66351, acc1= 0.04, acc3= 6.25, acc10= 29.66\n",
      "INFO - 07/22/22 14:45:27 - 0:15:40 - Zsl Epoch 42: LOSS= 13.66351, acc1= 14.37, acc3= 33.18, acc10= 60.80\n",
      "INFO - 07/22/22 14:45:27 - 0:15:40 - #################################################################################################################\n",
      "INFO - 07/22/22 14:45:28 - 0:15:41 - best performance =  1.03, 6.86, 30.54. best epoch = 12, correspond_loss= 12.4815\n",
      "INFO - 07/22/22 14:45:28 - 0:15:41 -  zsl performance =  13.37, 31.76, 56.09\n",
      "INFO - 07/22/22 14:45:28 - 0:15:41 -  fusion_model_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/answer_SAN_3.pkl\n",
      "INFO - 07/22/22 14:45:28 - 0:15:41 -  answer_net_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/answer_MLP_3.pkl\n"
     ]
    }
   ],
   "source": [
    "# asnwer空间训练\n",
    "!python main.py --gpu_id 9 --exp_name answer_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --ZSL 1  --save_model 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2095d435",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T09:21:32.758232Z",
     "start_time": "2022-07-22T08:31:26.077731Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "ZSL setting...\n",
      "INFO - 07/22/22 16:31:28 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 07/22/22 16:31:28 - 0:00:00 - The experiment will be stored in dump/0722-answer_space/W2V\n",
      "                                     \n",
      "INFO - 07/22/22 16:31:28 - 0:00:00 - Running command: python main.py --gpu_id 9 --exp_name answer_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --ZSL 1 --fact_map 1 --save_model 0\n",
      "\n",
      "2022-07-22 16:31:28.230910: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-22 16:31:28.230959: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 128\n",
      "batch_size 128\n",
      "fusion_model:\n",
      "SAN(\n",
      "  (w_emb): WordEmbedding(\n",
      "    (emb): Embedding(15422, 300, padding_idx=15421)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (text): Seq2SeqRNN(\n",
      "    (rnn): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (attention): SanAttention(\n",
      "    (v_conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (q_lin): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (x_conv): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(5120, 8192, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(8192, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "Answer Model:\n",
      "MLP(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "train E000: 100% 23/23 [00:13<00:00,  1.73it/s]\n",
      "INFO - 07/22/22 16:32:01 - 0:00:34 - Train Epoch 0: LOSS= 7.26600, lr= 0.000500, acc1= 17.28,acc3= 27.38,acc10= 32.58\n",
      "train E001: 100% 23/23 [00:12<00:00,  1.81it/s]\n",
      "INFO - 07/22/22 16:32:14 - 0:00:46 - Train Epoch 1: LOSS= 3.55496, lr= 0.000750, acc1= 65.16,acc3= 76.93,acc10= 81.12\n",
      "eval E001: 100% 21/21 [00:10<00:00,  1.94it/s]\n",
      "INFO - 07/22/22 16:32:25 - 0:00:57 - #################################################################################################################\n",
      "INFO - 07/22/22 16:32:25 - 0:00:57 - Test Epoch 1: LOSS= 3.97071, acc1= 62.15, acc3= 72.38, acc10= 76.67\n",
      "INFO - 07/22/22 16:32:25 - 0:00:57 - #################################################################################################################\n",
      "train E002: 100% 23/23 [00:14<00:00,  1.63it/s]\n",
      "INFO - 07/22/22 16:32:39 - 0:01:11 - Train Epoch 2: LOSS= 2.21931, lr= 0.001000, acc1= 83.00,acc3= 90.28,acc10= 92.47\n",
      "eval E002: 100% 21/21 [00:11<00:00,  1.86it/s]\n",
      "INFO - 07/22/22 16:32:50 - 0:01:23 - #################################################################################################################\n",
      "INFO - 07/22/22 16:32:50 - 0:01:23 - Test Epoch 2: LOSS= 3.73234, acc1= 67.78, acc3= 76.32, acc10= 79.66\n",
      "INFO - 07/22/22 16:32:50 - 0:01:23 - #################################################################################################################\n",
      "train E003: 100% 23/23 [00:14<00:00,  1.57it/s]\n",
      "INFO - 07/22/22 16:33:05 - 0:01:37 - Train Epoch 3: LOSS= 1.68081, lr= 0.001250, acc1= 89.52,acc3= 94.76,acc10= 96.36\n",
      "eval E003: 100% 21/21 [00:11<00:00,  1.89it/s]\n",
      "INFO - 07/22/22 16:33:16 - 0:01:48 - #################################################################################################################\n",
      "INFO - 07/22/22 16:33:16 - 0:01:48 - Test Epoch 3: LOSS= 4.03640, acc1= 65.79, acc3= 74.94, acc10= 78.58\n",
      "INFO - 07/22/22 16:33:16 - 0:01:48 - #################################################################################################################\n",
      "train E004: 100% 23/23 [00:14<00:00,  1.57it/s]\n",
      "INFO - 07/22/22 16:33:31 - 0:02:03 - Train Epoch 4: LOSS= 1.26436, lr= 0.001500, acc1= 94.41,acc3= 97.85,acc10= 98.65\n",
      "eval E004: 100% 21/21 [00:12<00:00,  1.69it/s]\n",
      "INFO - 07/22/22 16:33:43 - 0:02:15 - #################################################################################################################\n",
      "INFO - 07/22/22 16:33:43 - 0:02:15 - Test Epoch 4: LOSS= 4.34697, acc1= 65.90, acc3= 75.44, acc10= 79.20\n",
      "INFO - 07/22/22 16:33:43 - 0:02:15 - #################################################################################################################\n",
      "train E005: 100% 23/23 [00:15<00:00,  1.51it/s]\n",
      "INFO - 07/22/22 16:33:58 - 0:02:31 - Train Epoch 5: LOSS= 1.19695, lr= 0.001750, acc1= 95.91,acc3= 98.02,acc10= 98.51\n",
      "eval E005: 100% 21/21 [00:11<00:00,  1.88it/s]\n",
      "INFO - 07/22/22 16:34:09 - 0:02:42 - #################################################################################################################\n",
      "INFO - 07/22/22 16:34:09 - 0:02:42 - Test Epoch 5: LOSS= 4.62752, acc1= 64.71, acc3= 74.75, acc10= 78.20\n",
      "INFO - 07/22/22 16:34:09 - 0:02:42 - #################################################################################################################\n",
      "train E006: 100% 23/23 [00:14<00:00,  1.62it/s]\n",
      "INFO - 07/22/22 16:34:24 - 0:02:56 - Train Epoch 6: LOSS= 1.09706, lr= 0.002000, acc1= 96.18,acc3= 98.30,acc10= 98.89\n",
      "eval E006: 100% 21/21 [00:11<00:00,  1.89it/s]\n",
      "INFO - 07/22/22 16:34:35 - 0:03:07 - #################################################################################################################\n",
      "INFO - 07/22/22 16:34:35 - 0:03:07 - Test Epoch 6: LOSS= 5.30276, acc1= 64.79, acc3= 73.33, acc10= 77.36\n",
      "INFO - 07/22/22 16:34:35 - 0:03:07 - #################################################################################################################\n",
      "train E007: 100% 23/23 [00:14<00:00,  1.63it/s]\n",
      "INFO - 07/22/22 16:34:49 - 0:03:21 - Train Epoch 7: LOSS= 1.18728, lr= 0.002000, acc1= 95.28,acc3= 98.20,acc10= 98.96\n",
      "eval E007: 100% 21/21 [00:10<00:00,  1.97it/s]\n",
      "INFO - 07/22/22 16:34:59 - 0:03:32 - #################################################################################################################\n",
      "INFO - 07/22/22 16:34:59 - 0:03:32 - Test Epoch 7: LOSS= 5.32562, acc1= 65.98, acc3= 74.60, acc10= 78.08\n",
      "INFO - 07/22/22 16:34:59 - 0:03:32 - #################################################################################################################\n",
      "train E008: 100% 23/23 [00:14<00:00,  1.62it/s]\n",
      "INFO - 07/22/22 16:35:14 - 0:03:46 - Train Epoch 8: LOSS= 1.01003, lr= 0.002000, acc1= 96.95,acc3= 98.72,acc10= 99.17\n",
      "eval E008: 100% 21/21 [00:11<00:00,  1.89it/s]\n",
      "INFO - 07/22/22 16:35:25 - 0:03:57 - #################################################################################################################\n",
      "INFO - 07/22/22 16:35:25 - 0:03:57 - Test Epoch 8: LOSS= 5.52421, acc1= 63.91, acc3= 74.29, acc10= 77.24\n",
      "INFO - 07/22/22 16:35:25 - 0:03:57 - #################################################################################################################\n",
      "train E009: 100% 23/23 [00:14<00:00,  1.63it/s]\n",
      "INFO - 07/22/22 16:35:39 - 0:04:11 - Train Epoch 9: LOSS= 0.89686, lr= 0.002000, acc1= 97.54,acc3= 99.13,acc10= 99.55\n",
      "eval E009: 100% 21/21 [00:11<00:00,  1.86it/s]\n",
      "INFO - 07/22/22 16:35:50 - 0:04:22 - #################################################################################################################\n",
      "INFO - 07/22/22 16:35:50 - 0:04:22 - Test Epoch 9: LOSS= 5.76126, acc1= 62.99, acc3= 73.75, acc10= 77.59\n",
      "INFO - 07/22/22 16:35:50 - 0:04:22 - #################################################################################################################\n",
      "train E010: 100% 23/23 [00:15<00:00,  1.52it/s]\n",
      "INFO - 07/22/22 16:36:05 - 0:04:38 - Train Epoch 10: LOSS= 0.87293, lr= 0.002000, acc1= 97.22,acc3= 98.85,acc10= 99.34\n",
      "eval E010: 100% 21/21 [00:11<00:00,  1.81it/s]\n",
      "INFO - 07/22/22 16:36:17 - 0:04:49 - #################################################################################################################\n",
      "INFO - 07/22/22 16:36:17 - 0:04:49 - Test Epoch 10: LOSS= 5.81075, acc1= 66.78, acc3= 75.48, acc10= 78.62\n",
      "INFO - 07/22/22 16:36:17 - 0:04:49 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E011: 100% 23/23 [00:14<00:00,  1.59it/s]\n",
      "INFO - 07/22/22 16:36:31 - 0:05:04 - Train Epoch 11: LOSS= 0.83982, lr= 0.002000, acc1= 98.09,acc3= 99.34,acc10= 99.51\n",
      "eval E011: 100% 21/21 [00:11<00:00,  1.86it/s]\n",
      "INFO - 07/22/22 16:36:43 - 0:05:15 - #################################################################################################################\n",
      "INFO - 07/22/22 16:36:43 - 0:05:15 - Test Epoch 11: LOSS= 5.69614, acc1= 67.43, acc3= 75.94, acc10= 78.81\n",
      "INFO - 07/22/22 16:36:43 - 0:05:15 - #################################################################################################################\n",
      "train E012: 100% 23/23 [00:14<00:00,  1.55it/s]\n",
      "INFO - 07/22/22 16:36:57 - 0:05:30 - Train Epoch 12: LOSS= 0.76264, lr= 0.002000, acc1= 98.20,acc3= 99.34,acc10= 99.44\n",
      "eval E012: 100% 21/21 [00:11<00:00,  1.88it/s]\n",
      "INFO - 07/22/22 16:37:09 - 0:05:41 - #################################################################################################################\n",
      "INFO - 07/22/22 16:37:09 - 0:05:41 - Test Epoch 12: LOSS= 6.15604, acc1= 65.98, acc3= 75.67, acc10= 78.81\n",
      "INFO - 07/22/22 16:37:09 - 0:05:41 - #################################################################################################################\n",
      "train E013: 100% 23/23 [00:14<00:00,  1.59it/s]\n",
      "INFO - 07/22/22 16:37:23 - 0:05:56 - Train Epoch 13: LOSS= 0.68552, lr= 0.002000, acc1= 98.47,acc3= 99.58,acc10= 99.76\n",
      "eval E013: 100% 21/21 [00:10<00:00,  1.95it/s]\n",
      "INFO - 07/22/22 16:37:34 - 0:06:06 - #################################################################################################################\n",
      "INFO - 07/22/22 16:37:34 - 0:06:06 - Test Epoch 13: LOSS= 6.42178, acc1= 66.17, acc3= 74.14, acc10= 77.51\n",
      "INFO - 07/22/22 16:37:34 - 0:06:06 - #################################################################################################################\n",
      "train E014: 100% 23/23 [00:13<00:00,  1.65it/s]\n",
      "INFO - 07/22/22 16:37:48 - 0:06:20 - Train Epoch 14: LOSS= 0.47891, lr= 0.001400, acc1= 98.92,acc3= 99.72,acc10= 99.93\n",
      "eval E014: 100% 21/21 [00:11<00:00,  1.86it/s]\n",
      "INFO - 07/22/22 16:37:59 - 0:06:32 - #################################################################################################################\n",
      "INFO - 07/22/22 16:37:59 - 0:06:32 - Test Epoch 14: LOSS= 6.01379, acc1= 68.62, acc3= 76.97, acc10= 79.77\n",
      "INFO - 07/22/22 16:37:59 - 0:06:32 - #################################################################################################################\n",
      "train E015: 100% 23/23 [00:14<00:00,  1.61it/s]\n",
      "INFO - 07/22/22 16:38:13 - 0:06:46 - Train Epoch 15: LOSS= 0.32581, lr= 0.001400, acc1= 99.41,acc3= 99.90,acc10= 99.90\n",
      "eval E015: 100% 21/21 [00:12<00:00,  1.68it/s]\n",
      "INFO - 07/22/22 16:38:26 - 0:06:58 - #################################################################################################################\n",
      "INFO - 07/22/22 16:38:26 - 0:06:58 - Test Epoch 15: LOSS= 6.24186, acc1= 67.74, acc3= 75.79, acc10= 79.20\n",
      "INFO - 07/22/22 16:38:26 - 0:06:58 - #################################################################################################################\n",
      "train E016: 100% 23/23 [00:15<00:00,  1.50it/s]\n",
      "INFO - 07/22/22 16:38:41 - 0:07:14 - Train Epoch 16: LOSS= 0.30698, lr= 0.001400, acc1= 99.48,acc3= 99.93,acc10= 99.93\n",
      "eval E016: 100% 21/21 [00:11<00:00,  1.86it/s]\n",
      "INFO - 07/22/22 16:38:52 - 0:07:25 - #################################################################################################################\n",
      "INFO - 07/22/22 16:38:52 - 0:07:25 - Test Epoch 16: LOSS= 6.00205, acc1= 68.54, acc3= 76.93, acc10= 79.77\n",
      "INFO - 07/22/22 16:38:52 - 0:07:25 - #################################################################################################################\n",
      "train E017: 100% 23/23 [00:14<00:00,  1.62it/s]\n",
      "INFO - 07/22/22 16:39:07 - 0:07:39 - Train Epoch 17: LOSS= 0.19830, lr= 0.000980, acc1= 99.69,acc3= 99.97,acc10= 99.97\n",
      "eval E017: 100% 21/21 [00:11<00:00,  1.84it/s]\n",
      "INFO - 07/22/22 16:39:18 - 0:07:51 - #################################################################################################################\n",
      "INFO - 07/22/22 16:39:18 - 0:07:51 - Test Epoch 17: LOSS= 5.92247, acc1= 68.77, acc3= 77.55, acc10= 80.34\n",
      "INFO - 07/22/22 16:39:18 - 0:07:51 - #################################################################################################################\n",
      "train E018: 100% 23/23 [00:14<00:00,  1.61it/s]\n",
      "INFO - 07/22/22 16:39:32 - 0:08:05 - Train Epoch 18: LOSS= 0.14069, lr= 0.000980, acc1= 99.72,acc3= 99.97,acc10= 99.97\n",
      "eval E018: 100% 21/21 [00:11<00:00,  1.89it/s]\n",
      "INFO - 07/22/22 16:39:43 - 0:08:16 - #################################################################################################################\n",
      "INFO - 07/22/22 16:39:43 - 0:08:16 - Test Epoch 18: LOSS= 5.85204, acc1= 69.85, acc3= 77.51, acc10= 80.92\n",
      "INFO - 07/22/22 16:39:43 - 0:08:16 - #################################################################################################################\n",
      "train E019: 100% 23/23 [00:14<00:00,  1.57it/s]\n",
      "INFO - 07/22/22 16:39:58 - 0:08:31 - Train Epoch 19: LOSS= 0.12535, lr= 0.000980, acc1= 99.65,acc3= 99.97,acc10= 100.00\n",
      "eval E019: 100% 21/21 [00:11<00:00,  1.83it/s]\n",
      "INFO - 07/22/22 16:40:10 - 0:08:42 - #################################################################################################################\n",
      "INFO - 07/22/22 16:40:10 - 0:08:42 - Test Epoch 19: LOSS= 5.99481, acc1= 69.12, acc3= 77.09, acc10= 79.92\n",
      "INFO - 07/22/22 16:40:10 - 0:08:42 - #################################################################################################################\n",
      "train E020: 100% 23/23 [00:14<00:00,  1.60it/s]\n",
      "INFO - 07/22/22 16:40:24 - 0:08:57 - Train Epoch 20: LOSS= 0.09334, lr= 0.000686, acc1= 99.86,acc3= 100.00,acc10= 100.00\n",
      "eval E020: 100% 21/21 [00:11<00:00,  1.87it/s]\n",
      "INFO - 07/22/22 16:40:35 - 0:09:08 - #################################################################################################################\n",
      "INFO - 07/22/22 16:40:35 - 0:09:08 - Test Epoch 20: LOSS= 5.89338, acc1= 69.62, acc3= 77.24, acc10= 80.42\n",
      "INFO - 07/22/22 16:40:35 - 0:09:08 - #################################################################################################################\n",
      "train E021: 100% 23/23 [00:15<00:00,  1.47it/s]\n",
      "INFO - 07/22/22 16:40:51 - 0:09:23 - Train Epoch 21: LOSS= 0.09318, lr= 0.000686, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E021: 100% 21/21 [00:12<00:00,  1.70it/s]\n",
      "INFO - 07/22/22 16:41:03 - 0:09:36 - #################################################################################################################\n",
      "INFO - 07/22/22 16:41:03 - 0:09:36 - Test Epoch 21: LOSS= 5.86169, acc1= 69.92, acc3= 77.62, acc10= 80.42\n",
      "INFO - 07/22/22 16:41:03 - 0:09:36 - #################################################################################################################\n",
      "train E022: 100% 23/23 [00:14<00:00,  1.60it/s]\n",
      "INFO - 07/22/22 16:41:18 - 0:09:50 - Train Epoch 22: LOSS= 0.07236, lr= 0.000686, acc1= 99.76,acc3= 99.97,acc10= 99.97\n",
      "eval E022: 100% 21/21 [00:11<00:00,  1.90it/s]\n",
      "INFO - 07/22/22 16:41:29 - 0:10:01 - #################################################################################################################\n",
      "INFO - 07/22/22 16:41:29 - 0:10:01 - Test Epoch 22: LOSS= 5.86655, acc1= 70.11, acc3= 78.74, acc10= 80.80\n",
      "INFO - 07/22/22 16:41:29 - 0:10:01 - #################################################################################################################\n",
      "train E023: 100% 23/23 [00:14<00:00,  1.59it/s]\n",
      "INFO - 07/22/22 16:41:43 - 0:10:16 - Train Epoch 23: LOSS= 0.06003, lr= 0.000480, acc1= 99.86,acc3= 100.00,acc10= 100.00\n",
      "eval E023: 100% 21/21 [00:11<00:00,  1.83it/s]\n",
      "INFO - 07/22/22 16:41:55 - 0:10:27 - #################################################################################################################\n",
      "INFO - 07/22/22 16:41:55 - 0:10:27 - Test Epoch 23: LOSS= 5.82999, acc1= 69.96, acc3= 78.43, acc10= 80.84\n",
      "INFO - 07/22/22 16:41:55 - 0:10:27 - #################################################################################################################\n",
      "train E024: 100% 23/23 [00:14<00:00,  1.59it/s]\n",
      "INFO - 07/22/22 16:42:09 - 0:10:42 - Train Epoch 24: LOSS= 0.06888, lr= 0.000480, acc1= 99.79,acc3= 100.00,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E024: 100% 21/21 [00:11<00:00,  1.90it/s]\n",
      "INFO - 07/22/22 16:42:20 - 0:10:53 - #################################################################################################################\n",
      "INFO - 07/22/22 16:42:20 - 0:10:53 - Test Epoch 24: LOSS= 5.85571, acc1= 70.11, acc3= 78.54, acc10= 81.03\n",
      "INFO - 07/22/22 16:42:20 - 0:10:53 - #################################################################################################################\n",
      "train E025: 100% 23/23 [00:14<00:00,  1.60it/s]\n",
      "INFO - 07/22/22 16:42:35 - 0:11:07 - Train Epoch 25: LOSS= 0.06394, lr= 0.000480, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E025: 100% 21/21 [00:11<00:00,  1.86it/s]\n",
      "INFO - 07/22/22 16:42:46 - 0:11:18 - #################################################################################################################\n",
      "INFO - 07/22/22 16:42:46 - 0:11:18 - Test Epoch 25: LOSS= 5.88674, acc1= 70.27, acc3= 78.39, acc10= 81.19\n",
      "INFO - 07/22/22 16:42:46 - 0:11:18 - #################################################################################################################\n",
      "train E026: 100% 23/23 [00:14<00:00,  1.60it/s]\n",
      "INFO - 07/22/22 16:43:00 - 0:11:33 - Train Epoch 26: LOSS= 0.05455, lr= 0.000336, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E026: 100% 21/21 [00:11<00:00,  1.77it/s]\n",
      "INFO - 07/22/22 16:43:12 - 0:11:45 - #################################################################################################################\n",
      "INFO - 07/22/22 16:43:12 - 0:11:45 - Test Epoch 26: LOSS= 5.88307, acc1= 70.23, acc3= 78.47, acc10= 81.42\n",
      "INFO - 07/22/22 16:43:12 - 0:11:45 - #################################################################################################################\n",
      "train E027: 100% 23/23 [00:14<00:00,  1.60it/s]\n",
      "INFO - 07/22/22 16:43:27 - 0:11:59 - Train Epoch 27: LOSS= 0.05148, lr= 0.000336, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E027: 100% 21/21 [00:11<00:00,  1.86it/s]\n",
      "INFO - 07/22/22 16:43:38 - 0:12:10 - #################################################################################################################\n",
      "INFO - 07/22/22 16:43:38 - 0:12:10 - Test Epoch 27: LOSS= 5.95146, acc1= 70.38, acc3= 78.58, acc10= 81.23\n",
      "INFO - 07/22/22 16:43:38 - 0:12:10 - #################################################################################################################\n",
      "train E028: 100% 23/23 [00:14<00:00,  1.60it/s]\n",
      "INFO - 07/22/22 16:43:52 - 0:12:25 - Train Epoch 28: LOSS= 0.05116, lr= 0.000336, acc1= 99.76,acc3= 100.00,acc10= 100.00\n",
      "eval E028: 100% 21/21 [00:11<00:00,  1.87it/s]\n",
      "INFO - 07/22/22 16:44:03 - 0:12:36 - #################################################################################################################\n",
      "INFO - 07/22/22 16:44:03 - 0:12:36 - Test Epoch 28: LOSS= 5.91979, acc1= 70.38, acc3= 78.66, acc10= 81.15\n",
      "INFO - 07/22/22 16:44:03 - 0:12:36 - #################################################################################################################\n",
      "train E029: 100% 23/23 [00:14<00:00,  1.63it/s]\n",
      "INFO - 07/22/22 16:44:18 - 0:12:50 - Train Epoch 29: LOSS= 0.05598, lr= 0.000235, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E029: 100% 21/21 [00:11<00:00,  1.90it/s]\n",
      "INFO - 07/22/22 16:44:29 - 0:13:01 - #################################################################################################################\n",
      "INFO - 07/22/22 16:44:29 - 0:13:01 - Test Epoch 29: LOSS= 5.95313, acc1= 70.23, acc3= 78.39, acc10= 80.80\n",
      "INFO - 07/22/22 16:44:29 - 0:13:01 - #################################################################################################################\n",
      "train E030: 100% 23/23 [00:14<00:00,  1.61it/s]\n",
      "INFO - 07/22/22 16:44:43 - 0:13:15 - Train Epoch 30: LOSS= 0.05318, lr= 0.000235, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E030: 100% 21/21 [00:11<00:00,  1.84it/s]\n",
      "INFO - 07/22/22 16:44:54 - 0:13:27 - #################################################################################################################\n",
      "INFO - 07/22/22 16:44:54 - 0:13:27 - Test Epoch 30: LOSS= 5.93864, acc1= 70.23, acc3= 78.24, acc10= 80.92\n",
      "INFO - 07/22/22 16:44:54 - 0:13:27 - #################################################################################################################\n",
      "train E031: 100% 23/23 [00:14<00:00,  1.59it/s]\n",
      "INFO - 07/22/22 16:45:09 - 0:13:41 - Train Epoch 31: LOSS= 0.03890, lr= 0.000235, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E031: 100% 21/21 [00:11<00:00,  1.85it/s]\n",
      "INFO - 07/22/22 16:45:20 - 0:13:53 - #################################################################################################################\n",
      "INFO - 07/22/22 16:45:20 - 0:13:53 - Test Epoch 31: LOSS= 5.92734, acc1= 70.38, acc3= 78.28, acc10= 80.80\n",
      "INFO - 07/22/22 16:45:20 - 0:13:53 - #################################################################################################################\n",
      "train E032: 100% 23/23 [00:15<00:00,  1.48it/s]\n",
      "INFO - 07/22/22 16:45:36 - 0:14:08 - Train Epoch 32: LOSS= 0.04390, lr= 0.000165, acc1= 99.86,acc3= 100.00,acc10= 100.00\n",
      "eval E032: 100% 21/21 [00:12<00:00,  1.67it/s]\n",
      "INFO - 07/22/22 16:45:48 - 0:14:21 - #################################################################################################################\n",
      "INFO - 07/22/22 16:45:48 - 0:14:21 - Test Epoch 32: LOSS= 5.89687, acc1= 70.27, acc3= 78.54, acc10= 80.88\n",
      "INFO - 07/22/22 16:45:48 - 0:14:21 - #################################################################################################################\n",
      "train E033: 100% 23/23 [00:14<00:00,  1.58it/s]\n",
      "INFO - 07/22/22 16:46:03 - 0:14:35 - Train Epoch 33: LOSS= 0.04491, lr= 0.000165, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E033: 100% 21/21 [00:11<00:00,  1.88it/s]\n",
      "INFO - 07/22/22 16:46:14 - 0:14:46 - #################################################################################################################\n",
      "INFO - 07/22/22 16:46:14 - 0:14:46 - Test Epoch 33: LOSS= 5.87625, acc1= 70.38, acc3= 78.54, acc10= 80.84\n",
      "INFO - 07/22/22 16:46:14 - 0:14:46 - #################################################################################################################\n",
      "train E034: 100% 23/23 [00:14<00:00,  1.57it/s]\n",
      "INFO - 07/22/22 16:46:29 - 0:15:01 - Train Epoch 34: LOSS= 0.04445, lr= 0.000165, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E034: 100% 21/21 [00:11<00:00,  1.88it/s]\n",
      "INFO - 07/22/22 16:46:40 - 0:15:12 - #################################################################################################################\n",
      "INFO - 07/22/22 16:46:40 - 0:15:12 - Test Epoch 34: LOSS= 5.90982, acc1= 70.69, acc3= 78.62, acc10= 80.92\n",
      "INFO - 07/22/22 16:46:40 - 0:15:12 - #################################################################################################################\n",
      "train E035: 100% 23/23 [00:14<00:00,  1.60it/s]\n",
      "INFO - 07/22/22 16:46:54 - 0:15:27 - Train Epoch 35: LOSS= 0.03331, lr= 0.000115, acc1= 99.90,acc3= 100.00,acc10= 100.00\n",
      "eval E035: 100% 21/21 [00:11<00:00,  1.88it/s]\n",
      "INFO - 07/22/22 16:47:05 - 0:15:38 - #################################################################################################################\n",
      "INFO - 07/22/22 16:47:05 - 0:15:38 - Test Epoch 35: LOSS= 5.94493, acc1= 70.73, acc3= 78.62, acc10= 80.96\n",
      "INFO - 07/22/22 16:47:05 - 0:15:38 - #################################################################################################################\n",
      "train E036: 100% 23/23 [00:14<00:00,  1.60it/s]\n",
      "INFO - 07/22/22 16:47:20 - 0:15:52 - Train Epoch 36: LOSS= 0.03651, lr= 0.000115, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E036: 100% 21/21 [00:10<00:00,  1.99it/s]\n",
      "INFO - 07/22/22 16:47:30 - 0:16:03 - #################################################################################################################\n",
      "INFO - 07/22/22 16:47:30 - 0:16:03 - Test Epoch 36: LOSS= 5.89210, acc1= 70.65, acc3= 78.62, acc10= 81.11\n",
      "INFO - 07/22/22 16:47:30 - 0:16:03 - #################################################################################################################\n",
      "train E037: 100% 23/23 [00:14<00:00,  1.58it/s]\n",
      "INFO - 07/22/22 16:47:45 - 0:16:17 - Train Epoch 37: LOSS= 0.03302, lr= 0.000115, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E037: 100% 21/21 [00:13<00:00,  1.60it/s]\n",
      "INFO - 07/22/22 16:47:58 - 0:16:31 - #################################################################################################################\n",
      "INFO - 07/22/22 16:47:58 - 0:16:31 - Test Epoch 37: LOSS= 5.94183, acc1= 70.65, acc3= 78.58, acc10= 81.03\n",
      "INFO - 07/22/22 16:47:58 - 0:16:31 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E038: 100% 23/23 [00:15<00:00,  1.47it/s]\n",
      "INFO - 07/22/22 16:48:14 - 0:16:46 - Train Epoch 38: LOSS= 0.03688, lr= 0.000081, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E038: 100% 21/21 [00:11<00:00,  1.82it/s]\n",
      "INFO - 07/22/22 16:48:25 - 0:16:58 - #################################################################################################################\n",
      "INFO - 07/22/22 16:48:25 - 0:16:58 - Test Epoch 38: LOSS= 5.99079, acc1= 70.61, acc3= 78.47, acc10= 81.11\n",
      "INFO - 07/22/22 16:48:25 - 0:16:58 - #################################################################################################################\n",
      "train E039: 100% 23/23 [00:14<00:00,  1.59it/s]\n",
      "INFO - 07/22/22 16:48:40 - 0:17:12 - Train Epoch 39: LOSS= 0.03611, lr= 0.000081, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E039: 100% 21/21 [00:11<00:00,  1.80it/s]\n",
      "INFO - 07/22/22 16:48:51 - 0:17:24 - #################################################################################################################\n",
      "INFO - 07/22/22 16:48:51 - 0:17:24 - Test Epoch 39: LOSS= 5.93963, acc1= 70.73, acc3= 78.31, acc10= 81.07\n",
      "INFO - 07/22/22 16:48:51 - 0:17:24 - #################################################################################################################\n",
      "train E040: 100% 23/23 [00:13<00:00,  1.70it/s]\n",
      "INFO - 07/22/22 16:49:05 - 0:17:37 - Train Epoch 40: LOSS= 0.03931, lr= 0.000081, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E040: 100% 21/21 [00:11<00:00,  1.82it/s]\n",
      "INFO - 07/22/22 16:49:17 - 0:17:49 - #################################################################################################################\n",
      "INFO - 07/22/22 16:49:17 - 0:17:49 - Test Epoch 40: LOSS= 5.92289, acc1= 70.57, acc3= 78.43, acc10= 81.07\n",
      "INFO - 07/22/22 16:49:17 - 0:17:49 - #################################################################################################################\n",
      "train E041: 100% 23/23 [00:15<00:00,  1.52it/s]\n",
      "INFO - 07/22/22 16:49:32 - 0:18:04 - Train Epoch 41: LOSS= 0.03380, lr= 0.000056, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E041: 100% 21/21 [00:11<00:00,  1.80it/s]\n",
      "INFO - 07/22/22 16:49:43 - 0:18:16 - #################################################################################################################\n",
      "INFO - 07/22/22 16:49:43 - 0:18:16 - Test Epoch 41: LOSS= 5.89195, acc1= 70.69, acc3= 78.70, acc10= 81.15\n",
      "INFO - 07/22/22 16:49:43 - 0:18:16 - #################################################################################################################\n",
      "train E042: 100% 23/23 [00:15<00:00,  1.48it/s]\n",
      "INFO - 07/22/22 16:49:59 - 0:18:31 - Train Epoch 42: LOSS= 0.03896, lr= 0.000056, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E042: 100% 21/21 [00:11<00:00,  1.80it/s]\n",
      "INFO - 07/22/22 16:50:10 - 0:18:43 - #################################################################################################################\n",
      "INFO - 07/22/22 16:50:10 - 0:18:43 - Test Epoch 42: LOSS= 5.95058, acc1= 70.73, acc3= 78.74, acc10= 81.19\n",
      "INFO - 07/22/22 16:50:10 - 0:18:43 - #################################################################################################################\n",
      "train E043: 100% 23/23 [00:16<00:00,  1.43it/s]\n",
      "INFO - 07/22/22 16:50:27 - 0:18:59 - Train Epoch 43: LOSS= 0.04201, lr= 0.000056, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E043: 100% 21/21 [00:12<00:00,  1.71it/s]\n",
      "INFO - 07/22/22 16:50:39 - 0:19:11 - #################################################################################################################\n",
      "INFO - 07/22/22 16:50:39 - 0:19:11 - Test Epoch 43: LOSS= 5.86327, acc1= 70.77, acc3= 78.70, acc10= 81.26\n",
      "INFO - 07/22/22 16:50:39 - 0:19:11 - #################################################################################################################\n",
      "train E044: 100% 23/23 [00:14<00:00,  1.56it/s]\n",
      "INFO - 07/22/22 16:50:54 - 0:19:26 - Train Epoch 44: LOSS= 0.03302, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E044: 100% 21/21 [00:11<00:00,  1.79it/s]\n",
      "INFO - 07/22/22 16:51:05 - 0:19:38 - #################################################################################################################\n",
      "INFO - 07/22/22 16:51:05 - 0:19:38 - Test Epoch 44: LOSS= 5.94418, acc1= 70.69, acc3= 78.70, acc10= 81.23\n",
      "INFO - 07/22/22 16:51:05 - 0:19:38 - #################################################################################################################\n",
      "train E045: 100% 23/23 [00:14<00:00,  1.58it/s]\n",
      "INFO - 07/22/22 16:51:20 - 0:19:52 - Train Epoch 45: LOSS= 0.03961, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E045: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 07/22/22 16:51:32 - 0:20:04 - #################################################################################################################\n",
      "INFO - 07/22/22 16:51:32 - 0:20:04 - Test Epoch 45: LOSS= 5.90371, acc1= 70.77, acc3= 78.70, acc10= 81.26\n",
      "INFO - 07/22/22 16:51:32 - 0:20:04 - #################################################################################################################\n",
      "train E046: 100% 23/23 [00:15<00:00,  1.51it/s]\n",
      "INFO - 07/22/22 16:51:47 - 0:20:20 - Train Epoch 46: LOSS= 0.03212, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E046: 100% 21/21 [00:11<00:00,  1.81it/s]\n",
      "INFO - 07/22/22 16:51:59 - 0:20:31 - #################################################################################################################\n",
      "INFO - 07/22/22 16:51:59 - 0:20:31 - Test Epoch 46: LOSS= 5.84790, acc1= 70.84, acc3= 78.62, acc10= 81.23\n",
      "INFO - 07/22/22 16:51:59 - 0:20:31 - #################################################################################################################\n",
      "train E047: 100% 23/23 [00:15<00:00,  1.53it/s]\n",
      "INFO - 07/22/22 16:52:14 - 0:20:46 - Train Epoch 47: LOSS= 0.03002, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E047: 100% 21/21 [00:11<00:00,  1.81it/s]\n",
      "INFO - 07/22/22 16:52:25 - 0:20:58 - #################################################################################################################\n",
      "INFO - 07/22/22 16:52:25 - 0:20:58 - Test Epoch 47: LOSS= 5.93614, acc1= 71.00, acc3= 78.70, acc10= 81.23\n",
      "INFO - 07/22/22 16:52:25 - 0:20:58 - #################################################################################################################\n",
      "train E048: 100% 23/23 [00:15<00:00,  1.53it/s]\n",
      "INFO - 07/22/22 16:52:40 - 0:21:13 - Train Epoch 48: LOSS= 0.03553, lr= 0.000040, acc1= 99.76,acc3= 100.00,acc10= 100.00\n",
      "eval E048: 100% 21/21 [00:12<00:00,  1.71it/s]\n",
      "INFO - 07/22/22 16:52:53 - 0:21:25 - #################################################################################################################\n",
      "INFO - 07/22/22 16:52:53 - 0:21:25 - Test Epoch 48: LOSS= 5.88443, acc1= 70.96, acc3= 78.70, acc10= 81.23\n",
      "INFO - 07/22/22 16:52:53 - 0:21:25 - #################################################################################################################\n",
      "train E049: 100% 23/23 [00:16<00:00,  1.37it/s]\n",
      "INFO - 07/22/22 16:53:09 - 0:21:42 - Train Epoch 49: LOSS= 0.03513, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E049: 100% 21/21 [00:12<00:00,  1.70it/s]\n",
      "INFO - 07/22/22 16:53:22 - 0:21:54 - #################################################################################################################\n",
      "INFO - 07/22/22 16:53:22 - 0:21:54 - Test Epoch 49: LOSS= 5.92791, acc1= 70.96, acc3= 78.66, acc10= 81.23\n",
      "INFO - 07/22/22 16:53:22 - 0:21:54 - #################################################################################################################\n",
      "train E050: 100% 23/23 [00:15<00:00,  1.52it/s]\n",
      "INFO - 07/22/22 16:53:37 - 0:22:09 - Train Epoch 50: LOSS= 0.03461, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E050: 100% 21/21 [00:11<00:00,  1.84it/s]\n",
      "INFO - 07/22/22 16:53:48 - 0:22:21 - #################################################################################################################\n",
      "INFO - 07/22/22 16:53:48 - 0:22:21 - Test Epoch 50: LOSS= 5.91710, acc1= 71.03, acc3= 78.62, acc10= 81.38\n",
      "INFO - 07/22/22 16:53:48 - 0:22:21 - #################################################################################################################\n",
      "train E051: 100% 23/23 [00:14<00:00,  1.56it/s]\n",
      "INFO - 07/22/22 16:54:03 - 0:22:36 - Train Epoch 51: LOSS= 0.03203, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E051: 100% 21/21 [00:11<00:00,  1.79it/s]\n",
      "INFO - 07/22/22 16:54:15 - 0:22:47 - #################################################################################################################\n",
      "INFO - 07/22/22 16:54:15 - 0:22:47 - Test Epoch 51: LOSS= 5.93045, acc1= 70.96, acc3= 78.74, acc10= 81.38\n",
      "INFO - 07/22/22 16:54:15 - 0:22:47 - #################################################################################################################\n",
      "train E052: 100% 23/23 [00:15<00:00,  1.51it/s]\n",
      "INFO - 07/22/22 16:54:30 - 0:23:03 - Train Epoch 52: LOSS= 0.03842, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E052: 100% 21/21 [00:11<00:00,  1.84it/s]\n",
      "INFO - 07/22/22 16:54:42 - 0:23:14 - #################################################################################################################\n",
      "INFO - 07/22/22 16:54:42 - 0:23:14 - Test Epoch 52: LOSS= 5.93483, acc1= 71.00, acc3= 78.77, acc10= 81.38\n",
      "INFO - 07/22/22 16:54:42 - 0:23:14 - #################################################################################################################\n",
      "train E053: 100% 23/23 [00:14<00:00,  1.55it/s]\n",
      "INFO - 07/22/22 16:54:56 - 0:23:29 - Train Epoch 53: LOSS= 0.03606, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E053: 100% 21/21 [00:11<00:00,  1.80it/s]\n",
      "INFO - 07/22/22 16:55:08 - 0:23:41 - #################################################################################################################\n",
      "INFO - 07/22/22 16:55:08 - 0:23:41 - Test Epoch 53: LOSS= 5.89549, acc1= 70.84, acc3= 78.74, acc10= 81.34\n",
      "INFO - 07/22/22 16:55:08 - 0:23:41 - #################################################################################################################\n",
      "train E054: 100% 23/23 [00:15<00:00,  1.49it/s]\n",
      "INFO - 07/22/22 16:55:24 - 0:23:56 - Train Epoch 54: LOSS= 0.03265, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E054: 100% 21/21 [00:13<00:00,  1.55it/s]\n",
      "INFO - 07/22/22 16:55:37 - 0:24:09 - #################################################################################################################\n",
      "INFO - 07/22/22 16:55:37 - 0:24:09 - Test Epoch 54: LOSS= 5.92942, acc1= 70.88, acc3= 78.74, acc10= 81.38\n",
      "INFO - 07/22/22 16:55:37 - 0:24:09 - #################################################################################################################\n",
      "train E055: 100% 23/23 [00:15<00:00,  1.44it/s]\n",
      "INFO - 07/22/22 16:55:53 - 0:24:25 - Train Epoch 55: LOSS= 0.03770, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E055: 100% 21/21 [00:12<00:00,  1.73it/s]\n",
      "INFO - 07/22/22 16:56:05 - 0:24:38 - #################################################################################################################\n",
      "INFO - 07/22/22 16:56:05 - 0:24:38 - Test Epoch 55: LOSS= 5.88315, acc1= 71.03, acc3= 78.70, acc10= 81.42\n",
      "INFO - 07/22/22 16:56:05 - 0:24:38 - #################################################################################################################\n",
      "train E056: 100% 23/23 [00:15<00:00,  1.52it/s]\n",
      "INFO - 07/22/22 16:56:20 - 0:24:53 - Train Epoch 56: LOSS= 0.03664, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E056: 100% 21/21 [00:12<00:00,  1.73it/s]\n",
      "INFO - 07/22/22 16:56:32 - 0:25:05 - #################################################################################################################\n",
      "INFO - 07/22/22 16:56:32 - 0:25:05 - Test Epoch 56: LOSS= 5.87526, acc1= 70.92, acc3= 78.77, acc10= 81.42\n",
      "INFO - 07/22/22 16:56:32 - 0:25:05 - #################################################################################################################\n",
      "train E057: 100% 23/23 [00:14<00:00,  1.54it/s]\n",
      "INFO - 07/22/22 16:56:47 - 0:25:20 - Train Epoch 57: LOSS= 0.03631, lr= 0.000040, acc1= 99.86,acc3= 100.00,acc10= 100.00\n",
      "eval E057: 100% 21/21 [00:11<00:00,  1.77it/s]\n",
      "INFO - 07/22/22 16:56:59 - 0:25:32 - #################################################################################################################\n",
      "INFO - 07/22/22 16:56:59 - 0:25:32 - Test Epoch 57: LOSS= 5.89232, acc1= 71.03, acc3= 78.74, acc10= 81.46\n",
      "INFO - 07/22/22 16:56:59 - 0:25:32 - #################################################################################################################\n",
      "train E058: 100% 23/23 [00:14<00:00,  1.55it/s]\n",
      "INFO - 07/22/22 16:57:14 - 0:25:47 - Train Epoch 58: LOSS= 0.03327, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E058: 100% 21/21 [00:11<00:00,  1.78it/s]\n",
      "INFO - 07/22/22 16:57:26 - 0:25:58 - #################################################################################################################\n",
      "INFO - 07/22/22 16:57:26 - 0:25:58 - Test Epoch 58: LOSS= 5.96378, acc1= 71.07, acc3= 78.74, acc10= 81.38\n",
      "INFO - 07/22/22 16:57:26 - 0:25:58 - #################################################################################################################\n",
      "train E059: 100% 23/23 [00:15<00:00,  1.53it/s]\n",
      "INFO - 07/22/22 16:57:41 - 0:26:13 - Train Epoch 59: LOSS= 0.03817, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E059: 100% 21/21 [00:12<00:00,  1.72it/s]\n",
      "INFO - 07/22/22 16:57:53 - 0:26:26 - #################################################################################################################\n",
      "INFO - 07/22/22 16:57:53 - 0:26:26 - Test Epoch 59: LOSS= 5.97176, acc1= 71.15, acc3= 78.70, acc10= 81.38\n",
      "INFO - 07/22/22 16:57:53 - 0:26:26 - #################################################################################################################\n",
      "train E060: 100% 23/23 [00:15<00:00,  1.45it/s]\n",
      "INFO - 07/22/22 16:58:09 - 0:26:42 - Train Epoch 60: LOSS= 0.03215, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E060: 100% 21/21 [00:13<00:00,  1.58it/s]\n",
      "INFO - 07/22/22 16:58:22 - 0:26:55 - #################################################################################################################\n",
      "INFO - 07/22/22 16:58:22 - 0:26:55 - Test Epoch 60: LOSS= 5.88188, acc1= 71.11, acc3= 78.74, acc10= 81.30\n",
      "INFO - 07/22/22 16:58:22 - 0:26:55 - #################################################################################################################\n",
      "train E061: 100% 23/23 [00:16<00:00,  1.40it/s]\n",
      "INFO - 07/22/22 16:58:39 - 0:27:11 - Train Epoch 61: LOSS= 0.03033, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E061: 100% 21/21 [00:11<00:00,  1.78it/s]\n",
      "INFO - 07/22/22 16:58:51 - 0:27:23 - #################################################################################################################\n",
      "INFO - 07/22/22 16:58:51 - 0:27:23 - Test Epoch 61: LOSS= 5.88237, acc1= 71.23, acc3= 78.77, acc10= 81.42\n",
      "INFO - 07/22/22 16:58:51 - 0:27:23 - #################################################################################################################\n",
      "train E062: 100% 23/23 [00:15<00:00,  1.53it/s]\n",
      "INFO - 07/22/22 16:59:06 - 0:27:38 - Train Epoch 62: LOSS= 0.03324, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E062: 100% 21/21 [00:12<00:00,  1.73it/s]\n",
      "INFO - 07/22/22 16:59:18 - 0:27:50 - #################################################################################################################\n",
      "INFO - 07/22/22 16:59:18 - 0:27:50 - Test Epoch 62: LOSS= 5.91851, acc1= 71.19, acc3= 78.70, acc10= 81.38\n",
      "INFO - 07/22/22 16:59:18 - 0:27:50 - #################################################################################################################\n",
      "train E063: 100% 23/23 [00:15<00:00,  1.52it/s]\n",
      "INFO - 07/22/22 16:59:33 - 0:28:05 - Train Epoch 63: LOSS= 0.03215, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E063: 100% 21/21 [00:11<00:00,  1.78it/s]\n",
      "INFO - 07/22/22 16:59:45 - 0:28:17 - #################################################################################################################\n",
      "INFO - 07/22/22 16:59:45 - 0:28:17 - Test Epoch 63: LOSS= 5.89922, acc1= 71.11, acc3= 78.81, acc10= 81.26\n",
      "INFO - 07/22/22 16:59:45 - 0:28:17 - #################################################################################################################\n",
      "train E064: 100% 23/23 [00:15<00:00,  1.48it/s]\n",
      "INFO - 07/22/22 17:00:00 - 0:28:33 - Train Epoch 64: LOSS= 0.03809, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E064: 100% 21/21 [00:11<00:00,  1.81it/s]\n",
      "INFO - 07/22/22 17:00:12 - 0:28:44 - #################################################################################################################\n",
      "INFO - 07/22/22 17:00:12 - 0:28:44 - Test Epoch 64: LOSS= 5.88766, acc1= 71.03, acc3= 78.77, acc10= 81.19\n",
      "INFO - 07/22/22 17:00:12 - 0:28:44 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E065: 100% 23/23 [00:13<00:00,  1.70it/s]\n",
      "INFO - 07/22/22 17:00:25 - 0:28:58 - Train Epoch 65: LOSS= 0.03131, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E065: 100% 21/21 [00:12<00:00,  1.72it/s]\n",
      "INFO - 07/22/22 17:00:38 - 0:29:10 - #################################################################################################################\n",
      "INFO - 07/22/22 17:00:38 - 0:29:10 - Test Epoch 65: LOSS= 5.88393, acc1= 71.00, acc3= 78.70, acc10= 81.19\n",
      "INFO - 07/22/22 17:00:38 - 0:29:10 - #################################################################################################################\n",
      "train E066: 100% 23/23 [00:16<00:00,  1.40it/s]\n",
      "INFO - 07/22/22 17:00:54 - 0:29:27 - Train Epoch 66: LOSS= 0.02990, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E066: 100% 21/21 [00:13<00:00,  1.60it/s]\n",
      "INFO - 07/22/22 17:01:07 - 0:29:40 - #################################################################################################################\n",
      "INFO - 07/22/22 17:01:07 - 0:29:40 - Test Epoch 66: LOSS= 5.91905, acc1= 71.11, acc3= 78.85, acc10= 81.23\n",
      "INFO - 07/22/22 17:01:07 - 0:29:40 - #################################################################################################################\n",
      "train E067: 100% 23/23 [00:15<00:00,  1.53it/s]\n",
      "INFO - 07/22/22 17:01:22 - 0:29:55 - Train Epoch 67: LOSS= 0.03415, lr= 0.000040, acc1= 99.76,acc3= 100.00,acc10= 100.00\n",
      "eval E067: 100% 21/21 [00:11<00:00,  1.82it/s]\n",
      "INFO - 07/22/22 17:01:34 - 0:30:06 - #################################################################################################################\n",
      "INFO - 07/22/22 17:01:34 - 0:30:06 - Test Epoch 67: LOSS= 5.91698, acc1= 71.15, acc3= 78.89, acc10= 81.19\n",
      "INFO - 07/22/22 17:01:34 - 0:30:06 - #################################################################################################################\n",
      "train E068: 100% 23/23 [00:15<00:00,  1.50it/s]\n",
      "INFO - 07/22/22 17:01:49 - 0:30:22 - Train Epoch 68: LOSS= 0.03108, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E068: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 07/22/22 17:02:01 - 0:30:33 - #################################################################################################################\n",
      "INFO - 07/22/22 17:02:01 - 0:30:34 - Test Epoch 68: LOSS= 5.92308, acc1= 71.07, acc3= 78.85, acc10= 81.26\n",
      "INFO - 07/22/22 17:02:01 - 0:30:34 - #################################################################################################################\n",
      "train E069: 100% 23/23 [00:15<00:00,  1.52it/s]\n",
      "INFO - 07/22/22 17:02:16 - 0:30:49 - Train Epoch 69: LOSS= 0.02864, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E069: 100% 21/21 [00:11<00:00,  1.82it/s]\n",
      "INFO - 07/22/22 17:02:28 - 0:31:00 - #################################################################################################################\n",
      "INFO - 07/22/22 17:02:28 - 0:31:00 - Test Epoch 69: LOSS= 5.90750, acc1= 71.07, acc3= 78.85, acc10= 81.26\n",
      "INFO - 07/22/22 17:02:28 - 0:31:00 - #################################################################################################################\n",
      "train E070: 100% 23/23 [00:15<00:00,  1.51it/s]\n",
      "INFO - 07/22/22 17:02:43 - 0:31:15 - Train Epoch 70: LOSS= 0.03229, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E070: 100% 21/21 [00:11<00:00,  1.79it/s]\n",
      "INFO - 07/22/22 17:02:55 - 0:31:27 - #################################################################################################################\n",
      "INFO - 07/22/22 17:02:55 - 0:31:27 - Test Epoch 70: LOSS= 5.94470, acc1= 71.11, acc3= 78.81, acc10= 81.26\n",
      "INFO - 07/22/22 17:02:55 - 0:31:27 - #################################################################################################################\n",
      "train E071: 100% 23/23 [00:15<00:00,  1.52it/s]\n",
      "INFO - 07/22/22 17:03:10 - 0:31:42 - Train Epoch 71: LOSS= 0.03266, lr= 0.000040, acc1= 99.90,acc3= 100.00,acc10= 100.00\n",
      "eval E071: 100% 21/21 [00:13<00:00,  1.60it/s]\n",
      "INFO - 07/22/22 17:03:23 - 0:31:55 - #################################################################################################################\n",
      "INFO - 07/22/22 17:03:23 - 0:31:55 - Test Epoch 71: LOSS= 5.96921, acc1= 71.07, acc3= 78.77, acc10= 81.23\n",
      "INFO - 07/22/22 17:03:23 - 0:31:55 - #################################################################################################################\n",
      "train E072: 100% 23/23 [00:16<00:00,  1.43it/s]\n",
      "INFO - 07/22/22 17:03:39 - 0:32:12 - Train Epoch 72: LOSS= 0.03985, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E072: 100% 21/21 [00:11<00:00,  1.80it/s]\n",
      "INFO - 07/22/22 17:03:51 - 0:32:23 - #################################################################################################################\n",
      "INFO - 07/22/22 17:03:51 - 0:32:23 - Test Epoch 72: LOSS= 5.90185, acc1= 71.07, acc3= 78.85, acc10= 81.30\n",
      "INFO - 07/22/22 17:03:51 - 0:32:23 - #################################################################################################################\n",
      "train E073: 100% 23/23 [00:15<00:00,  1.53it/s]\n",
      "INFO - 07/22/22 17:04:06 - 0:32:38 - Train Epoch 73: LOSS= 0.03187, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E073: 100% 21/21 [00:12<00:00,  1.75it/s]\n",
      "INFO - 07/22/22 17:04:18 - 0:32:50 - #################################################################################################################\n",
      "INFO - 07/22/22 17:04:18 - 0:32:50 - Test Epoch 73: LOSS= 5.95499, acc1= 71.15, acc3= 78.74, acc10= 81.23\n",
      "INFO - 07/22/22 17:04:18 - 0:32:50 - #################################################################################################################\n",
      "train E074: 100% 23/23 [00:15<00:00,  1.49it/s]\n",
      "INFO - 07/22/22 17:04:33 - 0:33:06 - Train Epoch 74: LOSS= 0.04376, lr= 0.000040, acc1= 99.86,acc3= 100.00,acc10= 100.00\n",
      "eval E074: 100% 21/21 [00:11<00:00,  1.80it/s]\n",
      "INFO - 07/22/22 17:04:45 - 0:33:17 - #################################################################################################################\n",
      "INFO - 07/22/22 17:04:45 - 0:33:17 - Test Epoch 74: LOSS= 5.96700, acc1= 71.19, acc3= 78.70, acc10= 81.23\n",
      "INFO - 07/22/22 17:04:45 - 0:33:17 - #################################################################################################################\n",
      "train E075: 100% 23/23 [00:15<00:00,  1.53it/s]\n",
      "INFO - 07/22/22 17:05:00 - 0:33:32 - Train Epoch 75: LOSS= 0.03585, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E075: 100% 21/21 [00:11<00:00,  1.78it/s]\n",
      "INFO - 07/22/22 17:05:12 - 0:33:44 - #################################################################################################################\n",
      "INFO - 07/22/22 17:05:12 - 0:33:44 - Test Epoch 75: LOSS= 5.92606, acc1= 71.23, acc3= 78.77, acc10= 81.19\n",
      "INFO - 07/22/22 17:05:12 - 0:33:44 - #################################################################################################################\n",
      "train E076: 100% 23/23 [00:14<00:00,  1.54it/s]\n",
      "INFO - 07/22/22 17:05:27 - 0:33:59 - Train Epoch 76: LOSS= 0.03662, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E076: 100% 21/21 [00:12<00:00,  1.71it/s]\n",
      "INFO - 07/22/22 17:05:39 - 0:34:11 - #################################################################################################################\n",
      "INFO - 07/22/22 17:05:39 - 0:34:11 - Test Epoch 76: LOSS= 5.93053, acc1= 71.23, acc3= 78.77, acc10= 81.15\n",
      "INFO - 07/22/22 17:05:39 - 0:34:11 - #################################################################################################################\n",
      "train E077: 100% 23/23 [00:16<00:00,  1.37it/s]\n",
      "INFO - 07/22/22 17:05:56 - 0:34:28 - Train Epoch 77: LOSS= 0.02972, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E077: 100% 21/21 [00:12<00:00,  1.64it/s]\n",
      "INFO - 07/22/22 17:06:09 - 0:34:41 - #################################################################################################################\n",
      "INFO - 07/22/22 17:06:09 - 0:34:41 - Test Epoch 77: LOSS= 5.91796, acc1= 71.19, acc3= 78.89, acc10= 81.23\n",
      "INFO - 07/22/22 17:06:09 - 0:34:41 - #################################################################################################################\n",
      "train E078: 100% 23/23 [00:15<00:00,  1.53it/s]\n",
      "INFO - 07/22/22 17:06:24 - 0:34:56 - Train Epoch 78: LOSS= 0.03751, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E078: 100% 21/21 [00:11<00:00,  1.79it/s]\n",
      "INFO - 07/22/22 17:06:35 - 0:35:08 - #################################################################################################################\n",
      "INFO - 07/22/22 17:06:35 - 0:35:08 - Test Epoch 78: LOSS= 5.96610, acc1= 71.26, acc3= 78.81, acc10= 81.30\n",
      "INFO - 07/22/22 17:06:35 - 0:35:08 - #################################################################################################################\n",
      "train E079: 100% 23/23 [00:14<00:00,  1.56it/s]\n",
      "INFO - 07/22/22 17:06:50 - 0:35:23 - Train Epoch 79: LOSS= 0.03303, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E079: 100% 21/21 [00:11<00:00,  1.84it/s]\n",
      "INFO - 07/22/22 17:07:01 - 0:35:34 - #################################################################################################################\n",
      "INFO - 07/22/22 17:07:01 - 0:35:34 - Test Epoch 79: LOSS= 5.95615, acc1= 71.34, acc3= 78.81, acc10= 81.34\n",
      "INFO - 07/22/22 17:07:01 - 0:35:34 - #################################################################################################################\n",
      "train E080: 100% 23/23 [00:15<00:00,  1.52it/s]\n",
      "INFO - 07/22/22 17:07:17 - 0:35:49 - Train Epoch 80: LOSS= 0.03509, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E080: 100% 21/21 [00:12<00:00,  1.75it/s]\n",
      "INFO - 07/22/22 17:07:29 - 0:36:01 - #################################################################################################################\n",
      "INFO - 07/22/22 17:07:29 - 0:36:01 - Test Epoch 80: LOSS= 5.95230, acc1= 71.30, acc3= 78.77, acc10= 81.38\n",
      "INFO - 07/22/22 17:07:29 - 0:36:01 - #################################################################################################################\n",
      "train E081: 100% 23/23 [00:15<00:00,  1.53it/s]\n",
      "INFO - 07/22/22 17:07:44 - 0:36:16 - Train Epoch 81: LOSS= 0.03188, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E081: 100% 21/21 [00:11<00:00,  1.77it/s]\n",
      "INFO - 07/22/22 17:07:55 - 0:36:28 - #################################################################################################################\n",
      "INFO - 07/22/22 17:07:55 - 0:36:28 - Test Epoch 81: LOSS= 5.90545, acc1= 71.38, acc3= 78.85, acc10= 81.42\n",
      "INFO - 07/22/22 17:07:55 - 0:36:28 - #################################################################################################################\n",
      "train E082: 100% 23/23 [00:15<00:00,  1.53it/s]\n",
      "INFO - 07/22/22 17:08:11 - 0:36:43 - Train Epoch 82: LOSS= 0.03087, lr= 0.000040, acc1= 99.86,acc3= 100.00,acc10= 100.00\n",
      "eval E082: 100% 21/21 [00:12<00:00,  1.66it/s]\n",
      "INFO - 07/22/22 17:08:23 - 0:36:56 - #################################################################################################################\n",
      "INFO - 07/22/22 17:08:23 - 0:36:56 - Test Epoch 82: LOSS= 5.94649, acc1= 71.34, acc3= 78.85, acc10= 81.42\n",
      "INFO - 07/22/22 17:08:23 - 0:36:56 - #################################################################################################################\n",
      "train E083: 100% 23/23 [00:16<00:00,  1.37it/s]\n",
      "INFO - 07/22/22 17:08:40 - 0:37:12 - Train Epoch 83: LOSS= 0.03367, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E083: 100% 21/21 [00:12<00:00,  1.70it/s]\n",
      "INFO - 07/22/22 17:08:52 - 0:37:25 - #################################################################################################################\n",
      "INFO - 07/22/22 17:08:52 - 0:37:25 - Test Epoch 83: LOSS= 5.87087, acc1= 71.42, acc3= 78.89, acc10= 81.34\n",
      "INFO - 07/22/22 17:08:52 - 0:37:25 - #################################################################################################################\n",
      "train E084: 100% 23/23 [00:14<00:00,  1.56it/s]\n",
      "INFO - 07/22/22 17:09:07 - 0:37:40 - Train Epoch 84: LOSS= 0.03314, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E084: 100% 21/21 [00:12<00:00,  1.73it/s]\n",
      "INFO - 07/22/22 17:09:19 - 0:37:52 - #################################################################################################################\n",
      "INFO - 07/22/22 17:09:19 - 0:37:52 - Test Epoch 84: LOSS= 5.93257, acc1= 71.34, acc3= 78.77, acc10= 81.34\n",
      "INFO - 07/22/22 17:09:19 - 0:37:52 - #################################################################################################################\n",
      "train E085: 100% 23/23 [00:15<00:00,  1.52it/s]\n",
      "INFO - 07/22/22 17:09:34 - 0:38:07 - Train Epoch 85: LOSS= 0.03553, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E085: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 07/22/22 17:09:46 - 0:38:19 - #################################################################################################################\n",
      "INFO - 07/22/22 17:09:46 - 0:38:19 - Test Epoch 85: LOSS= 5.91259, acc1= 71.26, acc3= 78.81, acc10= 81.46\n",
      "INFO - 07/22/22 17:09:46 - 0:38:19 - #################################################################################################################\n",
      "train E086: 100% 23/23 [00:14<00:00,  1.54it/s]\n",
      "INFO - 07/22/22 17:10:01 - 0:38:34 - Train Epoch 86: LOSS= 0.03631, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E086: 100% 21/21 [00:11<00:00,  1.84it/s]\n",
      "INFO - 07/22/22 17:10:13 - 0:38:45 - #################################################################################################################\n",
      "INFO - 07/22/22 17:10:13 - 0:38:45 - Test Epoch 86: LOSS= 5.93878, acc1= 71.30, acc3= 78.93, acc10= 81.46\n",
      "INFO - 07/22/22 17:10:13 - 0:38:45 - #################################################################################################################\n",
      "train E087: 100% 23/23 [00:14<00:00,  1.56it/s]\n",
      "INFO - 07/22/22 17:10:27 - 0:39:00 - Train Epoch 87: LOSS= 0.02951, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E087: 100% 21/21 [00:11<00:00,  1.75it/s]\n",
      "INFO - 07/22/22 17:10:39 - 0:39:12 - #################################################################################################################\n",
      "INFO - 07/22/22 17:10:39 - 0:39:12 - Test Epoch 87: LOSS= 5.90561, acc1= 71.26, acc3= 78.89, acc10= 81.46\n",
      "INFO - 07/22/22 17:10:39 - 0:39:12 - #################################################################################################################\n",
      "train E088: 100% 23/23 [00:15<00:00,  1.48it/s]\n",
      "INFO - 07/22/22 17:10:55 - 0:39:27 - Train Epoch 88: LOSS= 0.04177, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E088: 100% 21/21 [00:13<00:00,  1.60it/s]\n",
      "INFO - 07/22/22 17:11:08 - 0:39:41 - #################################################################################################################\n",
      "INFO - 07/22/22 17:11:08 - 0:39:41 - Test Epoch 88: LOSS= 5.96153, acc1= 71.34, acc3= 78.89, acc10= 81.46\n",
      "INFO - 07/22/22 17:11:08 - 0:39:41 - #################################################################################################################\n",
      "train E089: 100% 23/23 [00:15<00:00,  1.45it/s]\n",
      "INFO - 07/22/22 17:11:24 - 0:39:56 - Train Epoch 89: LOSS= 0.03421, lr= 0.000040, acc1= 99.86,acc3= 100.00,acc10= 100.00\n",
      "eval E089: 100% 21/21 [00:11<00:00,  1.84it/s]\n",
      "INFO - 07/22/22 17:11:35 - 0:40:08 - #################################################################################################################\n",
      "INFO - 07/22/22 17:11:35 - 0:40:08 - Test Epoch 89: LOSS= 5.88627, acc1= 71.26, acc3= 78.93, acc10= 81.53\n",
      "INFO - 07/22/22 17:11:35 - 0:40:08 - #################################################################################################################\n",
      "train E090: 100% 23/23 [00:13<00:00,  1.69it/s]\n",
      "INFO - 07/22/22 17:11:49 - 0:40:21 - Train Epoch 90: LOSS= 0.03429, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E090: 100% 21/21 [00:11<00:00,  1.83it/s]\n",
      "INFO - 07/22/22 17:12:00 - 0:40:33 - #################################################################################################################\n",
      "INFO - 07/22/22 17:12:00 - 0:40:33 - Test Epoch 90: LOSS= 5.93045, acc1= 71.26, acc3= 78.77, acc10= 81.38\n",
      "INFO - 07/22/22 17:12:00 - 0:40:33 - #################################################################################################################\n",
      "train E091: 100% 23/23 [00:15<00:00,  1.49it/s]\n",
      "INFO - 07/22/22 17:12:16 - 0:40:48 - Train Epoch 91: LOSS= 0.03252, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E091: 100% 21/21 [00:11<00:00,  1.75it/s]\n",
      "INFO - 07/22/22 17:12:28 - 0:41:00 - #################################################################################################################\n",
      "INFO - 07/22/22 17:12:28 - 0:41:00 - Test Epoch 91: LOSS= 5.91755, acc1= 71.15, acc3= 78.85, acc10= 81.46\n",
      "INFO - 07/22/22 17:12:28 - 0:41:00 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E092: 100% 23/23 [00:14<00:00,  1.54it/s]\n",
      "INFO - 07/22/22 17:12:43 - 0:41:15 - Train Epoch 92: LOSS= 0.03394, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E092: 100% 21/21 [00:12<00:00,  1.71it/s]\n",
      "INFO - 07/22/22 17:12:55 - 0:41:28 - #################################################################################################################\n",
      "INFO - 07/22/22 17:12:55 - 0:41:28 - Test Epoch 92: LOSS= 5.95170, acc1= 71.15, acc3= 78.85, acc10= 81.46\n",
      "INFO - 07/22/22 17:12:55 - 0:41:28 - #################################################################################################################\n",
      "train E093: 100% 23/23 [00:14<00:00,  1.63it/s]\n",
      "INFO - 07/22/22 17:13:09 - 0:41:42 - Train Epoch 93: LOSS= 0.03020, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E093: 100% 21/21 [00:11<00:00,  1.79it/s]\n",
      "INFO - 07/22/22 17:13:21 - 0:41:53 - #################################################################################################################\n",
      "INFO - 07/22/22 17:13:21 - 0:41:53 - Test Epoch 93: LOSS= 5.91862, acc1= 71.11, acc3= 78.89, acc10= 81.38\n",
      "INFO - 07/22/22 17:13:21 - 0:41:53 - #################################################################################################################\n",
      "train E094: 100% 23/23 [00:15<00:00,  1.52it/s]\n",
      "INFO - 07/22/22 17:13:36 - 0:42:09 - Train Epoch 94: LOSS= 0.03222, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E094: 100% 21/21 [00:11<00:00,  1.80it/s]\n",
      "INFO - 07/22/22 17:13:48 - 0:42:20 - #################################################################################################################\n",
      "INFO - 07/22/22 17:13:48 - 0:42:20 - Test Epoch 94: LOSS= 5.99940, acc1= 71.19, acc3= 78.85, acc10= 81.38\n",
      "INFO - 07/22/22 17:13:48 - 0:42:20 - #################################################################################################################\n",
      "train E095: 100% 23/23 [00:14<00:00,  1.54it/s]\n",
      "INFO - 07/22/22 17:14:03 - 0:42:35 - Train Epoch 95: LOSS= 0.03216, lr= 0.000040, acc1= 99.86,acc3= 100.00,acc10= 100.00\n",
      "eval E095: 100% 21/21 [00:13<00:00,  1.60it/s]\n",
      "INFO - 07/22/22 17:14:16 - 0:42:48 - #################################################################################################################\n",
      "INFO - 07/22/22 17:14:16 - 0:42:48 - Test Epoch 95: LOSS= 5.97528, acc1= 71.11, acc3= 78.85, acc10= 81.34\n",
      "INFO - 07/22/22 17:14:16 - 0:42:48 - #################################################################################################################\n",
      "train E096: 100% 23/23 [00:16<00:00,  1.38it/s]\n",
      "INFO - 07/22/22 17:14:33 - 0:43:05 - Train Epoch 96: LOSS= 0.03211, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E096: 100% 21/21 [00:12<00:00,  1.73it/s]\n",
      "INFO - 07/22/22 17:14:45 - 0:43:17 - #################################################################################################################\n",
      "INFO - 07/22/22 17:14:45 - 0:43:17 - Test Epoch 96: LOSS= 5.95710, acc1= 71.03, acc3= 78.81, acc10= 81.23\n",
      "INFO - 07/22/22 17:14:45 - 0:43:17 - #################################################################################################################\n",
      "train E097: 100% 23/23 [00:14<00:00,  1.54it/s]\n",
      "INFO - 07/22/22 17:15:00 - 0:43:32 - Train Epoch 97: LOSS= 0.03304, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E097: 100% 21/21 [00:11<00:00,  1.80it/s]\n",
      "INFO - 07/22/22 17:15:11 - 0:43:44 - #################################################################################################################\n",
      "INFO - 07/22/22 17:15:11 - 0:43:44 - Test Epoch 97: LOSS= 5.92083, acc1= 71.03, acc3= 78.85, acc10= 81.23\n",
      "INFO - 07/22/22 17:15:11 - 0:43:44 - #################################################################################################################\n",
      "train E098: 100% 23/23 [00:14<00:00,  1.55it/s]\n",
      "INFO - 07/22/22 17:15:26 - 0:43:59 - Train Epoch 98: LOSS= 0.02829, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E098: 100% 21/21 [00:11<00:00,  1.82it/s]\n",
      "INFO - 07/22/22 17:15:38 - 0:44:10 - #################################################################################################################\n",
      "INFO - 07/22/22 17:15:38 - 0:44:10 - Test Epoch 98: LOSS= 5.92281, acc1= 70.92, acc3= 78.93, acc10= 81.19\n",
      "INFO - 07/22/22 17:15:38 - 0:44:10 - #################################################################################################################\n",
      "train E099: 100% 23/23 [00:15<00:00,  1.53it/s]\n",
      "INFO - 07/22/22 17:15:53 - 0:44:25 - Train Epoch 99: LOSS= 0.03259, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E099: 100% 21/21 [00:11<00:00,  1.77it/s]\n",
      "INFO - 07/22/22 17:16:05 - 0:44:37 - #################################################################################################################\n",
      "INFO - 07/22/22 17:16:05 - 0:44:37 - Test Epoch 99: LOSS= 5.91269, acc1= 70.96, acc3= 78.97, acc10= 81.23\n",
      "INFO - 07/22/22 17:16:05 - 0:44:37 - #################################################################################################################\n",
      "train E100: 100% 23/23 [00:14<00:00,  1.55it/s]\n",
      "INFO - 07/22/22 17:16:19 - 0:44:52 - Train Epoch 100: LOSS= 0.03310, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E100: 100% 21/21 [00:11<00:00,  1.82it/s]\n",
      "INFO - 07/22/22 17:16:31 - 0:45:03 - #################################################################################################################\n",
      "INFO - 07/22/22 17:16:31 - 0:45:03 - Test Epoch 100: LOSS= 5.94741, acc1= 71.03, acc3= 78.89, acc10= 81.23\n",
      "INFO - 07/22/22 17:16:31 - 0:45:03 - #################################################################################################################\n",
      "train E101: 100% 23/23 [00:15<00:00,  1.45it/s]\n",
      "INFO - 07/22/22 17:16:47 - 0:45:19 - Train Epoch 101: LOSS= 0.03608, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E101: 100% 21/21 [00:12<00:00,  1.62it/s]\n",
      "INFO - 07/22/22 17:17:00 - 0:45:32 - #################################################################################################################\n",
      "INFO - 07/22/22 17:17:00 - 0:45:32 - Test Epoch 101: LOSS= 5.96530, acc1= 71.15, acc3= 78.97, acc10= 81.23\n",
      "INFO - 07/22/22 17:17:00 - 0:45:32 - #################################################################################################################\n",
      "train E102: 100% 23/23 [00:15<00:00,  1.48it/s]\n",
      "INFO - 07/22/22 17:17:15 - 0:45:48 - Train Epoch 102: LOSS= 0.03009, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E102: 100% 21/21 [00:10<00:00,  1.94it/s]\n",
      "INFO - 07/22/22 17:17:26 - 0:45:59 - #################################################################################################################\n",
      "INFO - 07/22/22 17:17:26 - 0:45:59 - Test Epoch 102: LOSS= 5.94029, acc1= 71.23, acc3= 78.89, acc10= 81.23\n",
      "INFO - 07/22/22 17:17:26 - 0:45:59 - #################################################################################################################\n",
      "train E103: 100% 23/23 [00:14<00:00,  1.56it/s]\n",
      "INFO - 07/22/22 17:17:41 - 0:46:13 - Train Epoch 103: LOSS= 0.03361, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E103: 100% 21/21 [00:11<00:00,  1.79it/s]\n",
      "INFO - 07/22/22 17:17:53 - 0:46:25 - #################################################################################################################\n",
      "INFO - 07/22/22 17:17:53 - 0:46:25 - Test Epoch 103: LOSS= 5.96772, acc1= 71.19, acc3= 78.89, acc10= 81.23\n",
      "INFO - 07/22/22 17:17:53 - 0:46:25 - #################################################################################################################\n",
      "train E104: 100% 23/23 [00:15<00:00,  1.52it/s]\n",
      "INFO - 07/22/22 17:18:08 - 0:46:40 - Train Epoch 104: LOSS= 0.03200, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E104: 100% 21/21 [00:11<00:00,  1.77it/s]\n",
      "INFO - 07/22/22 17:18:20 - 0:46:52 - #################################################################################################################\n",
      "INFO - 07/22/22 17:18:20 - 0:46:52 - Test Epoch 104: LOSS= 5.93201, acc1= 71.03, acc3= 78.93, acc10= 81.30\n",
      "INFO - 07/22/22 17:18:20 - 0:46:52 - #################################################################################################################\n",
      "train E105: 100% 23/23 [00:14<00:00,  1.55it/s]\n",
      "INFO - 07/22/22 17:18:35 - 0:47:07 - Train Epoch 105: LOSS= 0.03475, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E105: 100% 21/21 [00:11<00:00,  1.82it/s]\n",
      "INFO - 07/22/22 17:18:46 - 0:47:19 - #################################################################################################################\n",
      "INFO - 07/22/22 17:18:46 - 0:47:19 - Test Epoch 105: LOSS= 5.94313, acc1= 71.19, acc3= 78.97, acc10= 81.19\n",
      "INFO - 07/22/22 17:18:46 - 0:47:19 - #################################################################################################################\n",
      "train E106: 100% 23/23 [00:15<00:00,  1.53it/s]\n",
      "INFO - 07/22/22 17:19:01 - 0:47:34 - Train Epoch 106: LOSS= 0.03298, lr= 0.000040, acc1= 99.86,acc3= 100.00,acc10= 100.00\n",
      "eval E106: 100% 21/21 [00:11<00:00,  1.78it/s]\n",
      "INFO - 07/22/22 17:19:13 - 0:47:45 - #################################################################################################################\n",
      "INFO - 07/22/22 17:19:13 - 0:47:45 - Test Epoch 106: LOSS= 5.99113, acc1= 71.19, acc3= 78.81, acc10= 81.19\n",
      "INFO - 07/22/22 17:19:13 - 0:47:45 - #################################################################################################################\n",
      "train E107: 100% 23/23 [00:16<00:00,  1.40it/s]\n",
      "INFO - 07/22/22 17:19:29 - 0:48:02 - Train Epoch 107: LOSS= 0.03368, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E107: 100% 21/21 [00:12<00:00,  1.65it/s]\n",
      "INFO - 07/22/22 17:19:42 - 0:48:15 - #################################################################################################################\n",
      "INFO - 07/22/22 17:19:42 - 0:48:15 - Test Epoch 107: LOSS= 5.99649, acc1= 71.19, acc3= 79.12, acc10= 81.19\n",
      "INFO - 07/22/22 17:19:42 - 0:48:15 - #################################################################################################################\n",
      "train E108: 100% 23/23 [00:15<00:00,  1.53it/s]\n",
      "INFO - 07/22/22 17:19:57 - 0:48:30 - Train Epoch 108: LOSS= 0.02847, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E108: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 07/22/22 17:20:09 - 0:48:42 - #################################################################################################################\n",
      "INFO - 07/22/22 17:20:09 - 0:48:42 - Test Epoch 108: LOSS= 6.00114, acc1= 71.26, acc3= 78.97, acc10= 81.19\n",
      "INFO - 07/22/22 17:20:09 - 0:48:42 - #################################################################################################################\n",
      "train E109: 100% 23/23 [00:15<00:00,  1.51it/s]\n",
      "INFO - 07/22/22 17:20:24 - 0:48:57 - Train Epoch 109: LOSS= 0.03046, lr= 0.000040, acc1= 99.86,acc3= 100.00,acc10= 100.00\n",
      "eval E109: 100% 21/21 [00:11<00:00,  1.77it/s]\n",
      "INFO - 07/22/22 17:20:36 - 0:49:09 - #################################################################################################################\n",
      "INFO - 07/22/22 17:20:36 - 0:49:09 - Test Epoch 109: LOSS= 6.03809, acc1= 71.26, acc3= 78.93, acc10= 81.26\n",
      "INFO - 07/22/22 17:20:36 - 0:49:09 - #################################################################################################################\n",
      "train E110: 100% 23/23 [00:15<00:00,  1.52it/s]\n",
      "INFO - 07/22/22 17:20:51 - 0:49:24 - Train Epoch 110: LOSS= 0.03099, lr= 0.000040, acc1= 99.83,acc3= 100.00,acc10= 100.00\n",
      "eval E110: 100% 21/21 [00:11<00:00,  1.76it/s]\n",
      "INFO - 07/22/22 17:21:03 - 0:49:36 - #################################################################################################################\n",
      "INFO - 07/22/22 17:21:03 - 0:49:36 - Test Epoch 110: LOSS= 5.96108, acc1= 71.26, acc3= 79.00, acc10= 81.15\n",
      "INFO - 07/22/22 17:21:03 - 0:49:36 - #################################################################################################################\n",
      "train E111: 100% 23/23 [00:14<00:00,  1.54it/s]\n",
      "INFO - 07/22/22 17:21:18 - 0:49:51 - Train Epoch 111: LOSS= 0.02652, lr= 0.000040, acc1= 99.79,acc3= 100.00,acc10= 100.00\n",
      "eval E111: 100% 21/21 [00:11<00:00,  1.75it/s]\n",
      "INFO - 07/22/22 17:21:30 - 0:50:03 - #################################################################################################################\n",
      "INFO - 07/22/22 17:21:30 - 0:50:03 - Test Epoch 111: LOSS= 5.99736, acc1= 71.30, acc3= 78.97, acc10= 81.19\n",
      "INFO - 07/22/22 17:21:30 - 0:50:03 - #################################################################################################################\n",
      "INFO - 07/22/22 17:21:30 - 0:50:03 - best performance =  71.38, 78.85, 81.42. best epoch = 81, correspond_loss= 5.9055\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 349, in <module>\n",
      "    logger.info(f\" fusion_model_path = {runner.fusion_model_path}\")\n",
      "AttributeError: 'Runner' object has no attribute 'fusion_model_path'\n"
     ]
    }
   ],
   "source": [
    "# fact空间训练\n",
    "!python main.py --gpu_id 9 --exp_name answer_space --exp_id W2V --fusion_model SAN --data_choice 3 --method_choice W2V --ZSL 1  --fact_map 1 --save_model 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7561ba54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T07:12:16.965815Z",
     "start_time": "2022-07-22T07:03:39.647797Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "ZSL setting...\n",
      "INFO - 07/22/22 15:03:41 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 07/22/22 15:03:41 - 0:00:00 - The experiment will be stored in dump/0722-relation_space/bert\n",
      "                                     \n",
      "INFO - 07/22/22 15:03:41 - 0:00:00 - Running command: python main_bert_rnn.py --gpu_id 8 --exp_name relation_space --exp_id bert --fusion_model BERT --data_choice 3 --method_choice W2V --save_model 1 --ZSL 1 --now_test 0 --fact_map 1\n",
      "\n",
      "2022-07-22 15:03:41.451800: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-22 15:03:41.451878: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 128\n",
      "batch_size 128\n",
      "INFO - 07/22/22 15:03:52 - 0:00:11 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO - 07/22/22 15:03:52 - 0:00:11 - extracting archive file /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp6md9h27u\n",
      "embeddings.word_embeddings.weight:\tFalse\n",
      "embeddings.position_embeddings.weight:\tFalse\n",
      "embeddings.token_type_embeddings.weight:\tFalse\n",
      "embeddings.LayerNorm.weight:\tFalse\n",
      "embeddings.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.attention.self.query.weight:\tFalse\n",
      "encoder.layer.0.attention.self.query.bias:\tFalse\n",
      "encoder.layer.0.attention.self.key.weight:\tFalse\n",
      "encoder.layer.0.attention.self.key.bias:\tFalse\n",
      "encoder.layer.0.attention.self.value.weight:\tFalse\n",
      "encoder.layer.0.attention.self.value.bias:\tFalse\n",
      "encoder.layer.0.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.0.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.0.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.0.output.dense.weight:\tFalse\n",
      "encoder.layer.0.output.dense.bias:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.attention.self.query.weight:\tFalse\n",
      "encoder.layer.1.attention.self.query.bias:\tFalse\n",
      "encoder.layer.1.attention.self.key.weight:\tFalse\n",
      "encoder.layer.1.attention.self.key.bias:\tFalse\n",
      "encoder.layer.1.attention.self.value.weight:\tFalse\n",
      "encoder.layer.1.attention.self.value.bias:\tFalse\n",
      "encoder.layer.1.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.1.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.1.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.1.output.dense.weight:\tFalse\n",
      "encoder.layer.1.output.dense.bias:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.attention.self.query.weight:\tFalse\n",
      "encoder.layer.2.attention.self.query.bias:\tFalse\n",
      "encoder.layer.2.attention.self.key.weight:\tFalse\n",
      "encoder.layer.2.attention.self.key.bias:\tFalse\n",
      "encoder.layer.2.attention.self.value.weight:\tFalse\n",
      "encoder.layer.2.attention.self.value.bias:\tFalse\n",
      "encoder.layer.2.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.2.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.2.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.2.output.dense.weight:\tFalse\n",
      "encoder.layer.2.output.dense.bias:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.attention.self.query.weight:\tFalse\n",
      "encoder.layer.3.attention.self.query.bias:\tFalse\n",
      "encoder.layer.3.attention.self.key.weight:\tFalse\n",
      "encoder.layer.3.attention.self.key.bias:\tFalse\n",
      "encoder.layer.3.attention.self.value.weight:\tFalse\n",
      "encoder.layer.3.attention.self.value.bias:\tFalse\n",
      "encoder.layer.3.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.3.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.3.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.3.output.dense.weight:\tFalse\n",
      "encoder.layer.3.output.dense.bias:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.attention.self.query.weight:\tFalse\n",
      "encoder.layer.4.attention.self.query.bias:\tFalse\n",
      "encoder.layer.4.attention.self.key.weight:\tFalse\n",
      "encoder.layer.4.attention.self.key.bias:\tFalse\n",
      "encoder.layer.4.attention.self.value.weight:\tFalse\n",
      "encoder.layer.4.attention.self.value.bias:\tFalse\n",
      "encoder.layer.4.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.4.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.4.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.4.output.dense.weight:\tFalse\n",
      "encoder.layer.4.output.dense.bias:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.attention.self.query.weight:\tFalse\n",
      "encoder.layer.5.attention.self.query.bias:\tFalse\n",
      "encoder.layer.5.attention.self.key.weight:\tFalse\n",
      "encoder.layer.5.attention.self.key.bias:\tFalse\n",
      "encoder.layer.5.attention.self.value.weight:\tFalse\n",
      "encoder.layer.5.attention.self.value.bias:\tFalse\n",
      "encoder.layer.5.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.5.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.5.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.5.output.dense.weight:\tFalse\n",
      "encoder.layer.5.output.dense.bias:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.attention.self.query.weight:\tFalse\n",
      "encoder.layer.6.attention.self.query.bias:\tFalse\n",
      "encoder.layer.6.attention.self.key.weight:\tFalse\n",
      "encoder.layer.6.attention.self.key.bias:\tFalse\n",
      "encoder.layer.6.attention.self.value.weight:\tFalse\n",
      "encoder.layer.6.attention.self.value.bias:\tFalse\n",
      "encoder.layer.6.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.6.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.6.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.6.output.dense.weight:\tFalse\n",
      "encoder.layer.6.output.dense.bias:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.attention.self.query.weight:\tFalse\n",
      "encoder.layer.7.attention.self.query.bias:\tFalse\n",
      "encoder.layer.7.attention.self.key.weight:\tFalse\n",
      "encoder.layer.7.attention.self.key.bias:\tFalse\n",
      "encoder.layer.7.attention.self.value.weight:\tFalse\n",
      "encoder.layer.7.attention.self.value.bias:\tFalse\n",
      "encoder.layer.7.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.7.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.7.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.7.output.dense.weight:\tFalse\n",
      "encoder.layer.7.output.dense.bias:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.attention.self.query.weight:\tFalse\n",
      "encoder.layer.8.attention.self.query.bias:\tFalse\n",
      "encoder.layer.8.attention.self.key.weight:\tFalse\n",
      "encoder.layer.8.attention.self.key.bias:\tFalse\n",
      "encoder.layer.8.attention.self.value.weight:\tFalse\n",
      "encoder.layer.8.attention.self.value.bias:\tFalse\n",
      "encoder.layer.8.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.8.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.8.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.8.output.dense.weight:\tFalse\n",
      "encoder.layer.8.output.dense.bias:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.attention.self.query.weight:\tFalse\n",
      "encoder.layer.9.attention.self.query.bias:\tFalse\n",
      "encoder.layer.9.attention.self.key.weight:\tFalse\n",
      "encoder.layer.9.attention.self.key.bias:\tFalse\n",
      "encoder.layer.9.attention.self.value.weight:\tFalse\n",
      "encoder.layer.9.attention.self.value.bias:\tFalse\n",
      "encoder.layer.9.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.9.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.9.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.9.output.dense.weight:\tFalse\n",
      "encoder.layer.9.output.dense.bias:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.attention.self.query.weight:\tFalse\n",
      "encoder.layer.10.attention.self.query.bias:\tFalse\n",
      "encoder.layer.10.attention.self.key.weight:\tFalse\n",
      "encoder.layer.10.attention.self.key.bias:\tFalse\n",
      "encoder.layer.10.attention.self.value.weight:\tFalse\n",
      "encoder.layer.10.attention.self.value.bias:\tFalse\n",
      "encoder.layer.10.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.10.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.10.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.10.output.dense.weight:\tFalse\n",
      "encoder.layer.10.output.dense.bias:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.attention.self.query.weight:\tFalse\n",
      "encoder.layer.11.attention.self.query.bias:\tFalse\n",
      "encoder.layer.11.attention.self.key.weight:\tFalse\n",
      "encoder.layer.11.attention.self.key.bias:\tFalse\n",
      "encoder.layer.11.attention.self.value.weight:\tFalse\n",
      "encoder.layer.11.attention.self.value.bias:\tFalse\n",
      "encoder.layer.11.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.11.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.11.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.11.output.dense.weight:\tFalse\n",
      "encoder.layer.11.output.dense.bias:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.bias:\tFalse\n",
      "pooler.dense.weight:\tFalse\n",
      "pooler.dense.bias:\tFalse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fusion_model:\r\n",
      "BERT(\r\n",
      "  (bert): BertModel(\r\n",
      "    (embeddings): BertEmbeddings(\r\n",
      "      (word_embeddings): Embedding(30522, 768)\r\n",
      "      (position_embeddings): Embedding(512, 768)\r\n",
      "      (token_type_embeddings): Embedding(2, 768)\r\n",
      "      (LayerNorm): BertLayerNorm()\r\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "    )\r\n",
      "    (encoder): BertEncoder(\r\n",
      "      (layer): ModuleList(\r\n",
      "        (0): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (1): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (2): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (3): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (4): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (5): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (6): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (7): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (8): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (9): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (10): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (11): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (pooler): BertPooler(\r\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "      (activation): Tanh()\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (lstm): LSTM(768, 768, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\r\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "  (fc_rnn): Linear(in_features=1536, out_features=1024, bias=True)\r\n",
      "  (mlp): GroupMLP(\r\n",
      "    (conv1): Conv1d(768, 8192, kernel_size=(1,), stride=(1,))\r\n",
      "    (drop): Dropout(p=0.5, inplace=False)\r\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\r\n",
      "    (conv2): Conv1d(8192, 1024, kernel_size=(1,), stride=(1,), groups=64)\r\n",
      "  )\r\n",
      ")\r\n",
      "Answer Model:\r\n",
      "MLP(\r\n",
      "  (mlp): GroupMLP(\r\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\r\n",
      "    (drop): Dropout(p=0.0, inplace=False)\r\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\r\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\r\n",
      "  )\r\n",
      ")\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E000:   0% 0/23 [00:00<?, ?it/s]torch.Size([128, 1024]) torch.Size([2791, 1024])\n",
      "train E000: 100% 23/23 [00:05<00:00,  4.26it/s]\n",
      "INFO - 07/22/22 15:04:11 - 0:00:31 - Train Epoch 0: LOSS= 8.39823, lr= 0.000500, acc1= 4.86,acc3= 8.78,acc10= 11.73\n",
      "train E001: 100% 23/23 [00:05<00:00,  4.30it/s]\n",
      "INFO - 07/22/22 15:04:17 - 0:00:36 - Train Epoch 1: LOSS= 6.63610, lr= 0.000750, acc1= 16.17,acc3= 26.51,acc10= 32.41\n",
      "eval E001: 100% 21/21 [00:03<00:00,  5.91it/s]\n",
      "INFO - 07/22/22 15:04:20 - 0:00:40 - #################################################################################################################\n",
      "INFO - 07/22/22 15:04:20 - 0:00:40 - Test Epoch 1: LOSS= 7.06086, acc1= 10.08, acc3= 18.16, acc10= 24.48\n",
      "INFO - 07/22/22 15:04:20 - 0:00:40 - #################################################################################################################\n",
      "train E002: 100% 23/23 [00:05<00:00,  4.35it/s]\n",
      "INFO - 07/22/22 15:04:26 - 0:00:45 - Train Epoch 2: LOSS= 6.05912, lr= 0.001000, acc1= 23.18,acc3= 36.50,acc10= 44.14\n",
      "eval E002: 100% 21/21 [00:03<00:00,  5.62it/s]\n",
      "INFO - 07/22/22 15:04:29 - 0:00:49 - #################################################################################################################\n",
      "INFO - 07/22/22 15:04:29 - 0:00:49 - Test Epoch 2: LOSS= 6.92054, acc1= 12.49, acc3= 23.87, acc10= 31.46\n",
      "INFO - 07/22/22 15:04:29 - 0:00:49 - #################################################################################################################\n",
      "train E003: 100% 23/23 [00:05<00:00,  4.30it/s]\n",
      "INFO - 07/22/22 15:04:35 - 0:00:54 - Train Epoch 3: LOSS= 5.87305, lr= 0.001250, acc1= 26.34,acc3= 42.05,acc10= 49.41\n",
      "eval E003: 100% 21/21 [00:03<00:00,  5.83it/s]\n",
      "INFO - 07/22/22 15:04:38 - 0:00:58 - #################################################################################################################\n",
      "INFO - 07/22/22 15:04:38 - 0:00:58 - Test Epoch 3: LOSS= 6.74975, acc1= 13.45, acc3= 25.17, acc10= 33.26\n",
      "INFO - 07/22/22 15:04:38 - 0:00:58 - #################################################################################################################\n",
      "train E004: 100% 23/23 [00:05<00:00,  4.29it/s]\n",
      "INFO - 07/22/22 15:04:44 - 0:01:03 - Train Epoch 4: LOSS= 5.61027, lr= 0.001500, acc1= 29.25,acc3= 45.59,acc10= 53.16\n",
      "eval E004: 100% 21/21 [00:03<00:00,  5.69it/s]\n",
      "INFO - 07/22/22 15:04:47 - 0:01:07 - #################################################################################################################\n",
      "INFO - 07/22/22 15:04:47 - 0:01:07 - Test Epoch 4: LOSS= 6.93714, acc1= 13.07, acc3= 24.83, acc10= 31.61\n",
      "INFO - 07/22/22 15:04:47 - 0:01:07 - #################################################################################################################\n",
      "train E005: 100% 23/23 [00:05<00:00,  4.23it/s]\n",
      "INFO - 07/22/22 15:04:53 - 0:01:12 - Train Epoch 5: LOSS= 5.39968, lr= 0.001750, acc1= 32.76,acc3= 49.13,acc10= 57.91\n",
      "eval E005: 100% 21/21 [00:03<00:00,  5.75it/s]\n",
      "INFO - 07/22/22 15:04:57 - 0:01:16 - #################################################################################################################\n",
      "INFO - 07/22/22 15:04:57 - 0:01:16 - Test Epoch 5: LOSS= 6.99852, acc1= 14.10, acc3= 25.67, acc10= 33.14\n",
      "INFO - 07/22/22 15:04:57 - 0:01:16 - #################################################################################################################\n",
      "train E006: 100% 23/23 [00:05<00:00,  4.31it/s]\n",
      "INFO - 07/22/22 15:05:02 - 0:01:21 - Train Epoch 6: LOSS= 5.23163, lr= 0.002000, acc1= 35.67,acc3= 52.98,acc10= 61.21\n",
      "eval E006: 100% 21/21 [00:03<00:00,  5.96it/s]\n",
      "INFO - 07/22/22 15:05:06 - 0:01:25 - #################################################################################################################\n",
      "INFO - 07/22/22 15:05:06 - 0:01:25 - Test Epoch 6: LOSS= 6.82940, acc1= 16.21, acc3= 28.31, acc10= 34.98\n",
      "INFO - 07/22/22 15:05:06 - 0:01:25 - #################################################################################################################\n",
      "train E007: 100% 23/23 [00:05<00:00,  4.21it/s]\n",
      "INFO - 07/22/22 15:05:11 - 0:01:30 - Train Epoch 7: LOSS= 4.89203, lr= 0.002000, acc1= 41.22,acc3= 59.20,acc10= 67.14\n",
      "eval E007: 100% 21/21 [00:03<00:00,  5.84it/s]\n",
      "INFO - 07/22/22 15:05:15 - 0:01:34 - #################################################################################################################\n",
      "INFO - 07/22/22 15:05:15 - 0:01:34 - Test Epoch 7: LOSS= 7.11678, acc1= 15.36, acc3= 26.82, acc10= 33.30\n",
      "INFO - 07/22/22 15:05:15 - 0:01:34 - #################################################################################################################\n",
      "train E008: 100% 23/23 [00:05<00:00,  4.29it/s]\n",
      "INFO - 07/22/22 15:05:20 - 0:01:39 - Train Epoch 8: LOSS= 4.62892, lr= 0.002000, acc1= 46.50,acc3= 63.78,acc10= 71.24\n",
      "eval E008: 100% 21/21 [00:03<00:00,  5.95it/s]\n",
      "INFO - 07/22/22 15:05:24 - 0:01:43 - #################################################################################################################\n",
      "INFO - 07/22/22 15:05:24 - 0:01:43 - Test Epoch 8: LOSS= 6.88049, acc1= 18.66, acc3= 33.14, acc10= 41.03\n",
      "INFO - 07/22/22 15:05:24 - 0:01:43 - #################################################################################################################\n",
      "train E009: 100% 23/23 [00:05<00:00,  4.28it/s]\n",
      "INFO - 07/22/22 15:05:29 - 0:01:48 - Train Epoch 9: LOSS= 4.21875, lr= 0.002000, acc1= 53.89,acc3= 71.03,acc10= 77.59\n",
      "eval E009: 100% 21/21 [00:03<00:00,  5.91it/s]\n",
      "INFO - 07/22/22 15:05:32 - 0:01:52 - #################################################################################################################\n",
      "INFO - 07/22/22 15:05:32 - 0:01:52 - Test Epoch 9: LOSS= 6.91401, acc1= 18.66, acc3= 34.29, acc10= 42.72\n",
      "INFO - 07/22/22 15:05:32 - 0:01:52 - #################################################################################################################\n",
      "train E010: 100% 23/23 [00:05<00:00,  4.31it/s]\n",
      "INFO - 07/22/22 15:05:38 - 0:01:57 - Train Epoch 10: LOSS= 4.02987, lr= 0.002000, acc1= 55.66,acc3= 73.73,acc10= 80.67\n",
      "eval E010: 100% 21/21 [00:03<00:00,  5.91it/s]\n",
      "INFO - 07/22/22 15:05:41 - 0:02:01 - #################################################################################################################\n",
      "INFO - 07/22/22 15:05:41 - 0:02:01 - Test Epoch 10: LOSS= 7.49851, acc1= 20.61, acc3= 35.36, acc10= 43.75\n",
      "INFO - 07/22/22 15:05:41 - 0:02:01 - #################################################################################################################\n",
      "train E011: 100% 23/23 [00:05<00:00,  4.20it/s]\n",
      "INFO - 07/22/22 15:05:47 - 0:02:06 - Train Epoch 11: LOSS= 3.70621, lr= 0.002000, acc1= 62.39,acc3= 79.39,acc10= 85.60\n",
      "eval E011: 100% 21/21 [00:03<00:00,  5.92it/s]\n",
      "INFO - 07/22/22 15:05:50 - 0:02:10 - #################################################################################################################\n",
      "INFO - 07/22/22 15:05:50 - 0:02:10 - Test Epoch 11: LOSS= 6.92578, acc1= 22.99, acc3= 38.93, acc10= 48.43\n",
      "INFO - 07/22/22 15:05:50 - 0:02:10 - #################################################################################################################\n",
      "train E012: 100% 23/23 [00:05<00:00,  4.23it/s]\n",
      "INFO - 07/22/22 15:05:56 - 0:02:15 - Train Epoch 12: LOSS= 3.51445, lr= 0.002000, acc1= 65.61,acc3= 80.78,acc10= 86.75\n",
      "eval E012: 100% 21/21 [00:03<00:00,  5.74it/s]\n",
      "INFO - 07/22/22 15:06:00 - 0:02:19 - #################################################################################################################\n",
      "INFO - 07/22/22 15:06:00 - 0:02:19 - Test Epoch 12: LOSS= 6.60493, acc1= 26.67, acc3= 43.33, acc10= 51.03\n",
      "INFO - 07/22/22 15:06:00 - 0:02:19 - #################################################################################################################\n",
      "train E013: 100% 23/23 [00:05<00:00,  4.21it/s]\n",
      "INFO - 07/22/22 15:06:05 - 0:02:24 - Train Epoch 13: LOSS= 3.27173, lr= 0.002000, acc1= 69.40,acc3= 84.04,acc10= 89.24\n",
      "eval E013: 100% 21/21 [00:03<00:00,  5.95it/s]\n",
      "INFO - 07/22/22 15:06:09 - 0:02:28 - #################################################################################################################\n",
      "INFO - 07/22/22 15:06:09 - 0:02:28 - Test Epoch 13: LOSS= 6.91255, acc1= 25.67, acc3= 40.50, acc10= 50.31\n",
      "INFO - 07/22/22 15:06:09 - 0:02:28 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E014: 100% 23/23 [00:05<00:00,  4.18it/s]\n",
      "INFO - 07/22/22 15:06:14 - 0:02:33 - Train Epoch 14: LOSS= 2.71873, lr= 0.001400, acc1= 78.11,acc3= 89.00,acc10= 92.96\n",
      "eval E014: 100% 21/21 [00:03<00:00,  5.99it/s]\n",
      "INFO - 07/22/22 15:06:18 - 0:02:37 - #################################################################################################################\n",
      "INFO - 07/22/22 15:06:18 - 0:02:37 - Test Epoch 14: LOSS= 6.84943, acc1= 28.39, acc3= 44.21, acc10= 52.26\n",
      "INFO - 07/22/22 15:06:18 - 0:02:37 - #################################################################################################################\n",
      "train E015: 100% 23/23 [00:05<00:00,  4.32it/s]\n",
      "INFO - 07/22/22 15:06:23 - 0:02:42 - Train Epoch 15: LOSS= 2.43876, lr= 0.001400, acc1= 81.40,acc3= 91.64,acc10= 94.69\n",
      "eval E015: 100% 21/21 [00:03<00:00,  5.51it/s]\n",
      "INFO - 07/22/22 15:06:27 - 0:02:46 - #################################################################################################################\n",
      "INFO - 07/22/22 15:06:27 - 0:02:46 - Test Epoch 15: LOSS= 7.28605, acc1= 30.31, acc3= 48.89, acc10= 57.28\n",
      "INFO - 07/22/22 15:06:27 - 0:02:46 - #################################################################################################################\n",
      "train E016: 100% 23/23 [00:05<00:00,  4.24it/s]\n",
      "INFO - 07/22/22 15:06:32 - 0:02:51 - Train Epoch 16: LOSS= 2.27609, lr= 0.001400, acc1= 83.59,acc3= 93.89,acc10= 96.36\n",
      "eval E016: 100% 21/21 [00:03<00:00,  5.73it/s]\n",
      "INFO - 07/22/22 15:06:36 - 0:02:55 - #################################################################################################################\n",
      "INFO - 07/22/22 15:06:36 - 0:02:55 - Test Epoch 16: LOSS= 7.06861, acc1= 30.23, acc3= 47.01, acc10= 55.67\n",
      "INFO - 07/22/22 15:06:36 - 0:02:55 - #################################################################################################################\n",
      "train E017: 100% 23/23 [00:05<00:00,  4.28it/s]\n",
      "INFO - 07/22/22 15:06:41 - 0:03:01 - Train Epoch 17: LOSS= 1.94553, lr= 0.000980, acc1= 87.72,acc3= 94.80,acc10= 96.84\n",
      "eval E017: 100% 21/21 [00:03<00:00,  5.53it/s]\n",
      "INFO - 07/22/22 15:06:45 - 0:03:04 - #################################################################################################################\n",
      "INFO - 07/22/22 15:06:45 - 0:03:04 - Test Epoch 17: LOSS= 7.15703, acc1= 32.18, acc3= 49.23, acc10= 57.28\n",
      "INFO - 07/22/22 15:06:45 - 0:03:04 - #################################################################################################################\n",
      "train E018: 100% 23/23 [00:05<00:00,  4.21it/s]\n",
      "INFO - 07/22/22 15:06:51 - 0:03:10 - Train Epoch 18: LOSS= 1.66082, lr= 0.000980, acc1= 90.98,acc3= 96.74,acc10= 97.78\n",
      "eval E018: 100% 21/21 [00:03<00:00,  5.81it/s]\n",
      "INFO - 07/22/22 15:06:54 - 0:03:13 - #################################################################################################################\n",
      "INFO - 07/22/22 15:06:54 - 0:03:13 - Test Epoch 18: LOSS= 7.59254, acc1= 31.38, acc3= 49.73, acc10= 57.66\n",
      "INFO - 07/22/22 15:06:54 - 0:03:13 - #################################################################################################################\n",
      "train E019: 100% 23/23 [00:05<00:00,  4.18it/s]\n",
      "INFO - 07/22/22 15:07:00 - 0:03:19 - Train Epoch 19: LOSS= 1.54954, lr= 0.000980, acc1= 92.05,acc3= 97.05,acc10= 98.40\n",
      "eval E019: 100% 21/21 [00:03<00:00,  5.76it/s]\n",
      "INFO - 07/22/22 15:07:03 - 0:03:23 - #################################################################################################################\n",
      "INFO - 07/22/22 15:07:03 - 0:03:23 - Test Epoch 19: LOSS= 7.43642, acc1= 33.41, acc3= 50.61, acc10= 58.93\n",
      "INFO - 07/22/22 15:07:03 - 0:03:23 - #################################################################################################################\n",
      "train E020: 100% 23/23 [00:05<00:00,  4.27it/s]\n",
      "INFO - 07/22/22 15:07:09 - 0:03:28 - Train Epoch 20: LOSS= 1.46005, lr= 0.000686, acc1= 92.82,acc3= 97.92,acc10= 98.85\n",
      "eval E020: 100% 21/21 [00:03<00:00,  5.79it/s]\n",
      "INFO - 07/22/22 15:07:12 - 0:03:32 - #################################################################################################################\n",
      "INFO - 07/22/22 15:07:12 - 0:03:32 - Test Epoch 20: LOSS= 7.45321, acc1= 34.71, acc3= 51.65, acc10= 59.50\n",
      "INFO - 07/22/22 15:07:12 - 0:03:32 - #################################################################################################################\n",
      "train E021: 100% 23/23 [00:05<00:00,  4.23it/s]\n",
      "INFO - 07/22/22 15:07:18 - 0:03:37 - Train Epoch 21: LOSS= 1.26721, lr= 0.000686, acc1= 94.69,acc3= 98.47,acc10= 98.99\n",
      "eval E021: 100% 21/21 [00:03<00:00,  5.82it/s]\n",
      "INFO - 07/22/22 15:07:22 - 0:03:41 - #################################################################################################################\n",
      "INFO - 07/22/22 15:07:22 - 0:03:41 - Test Epoch 21: LOSS= 8.14415, acc1= 34.71, acc3= 52.57, acc10= 60.15\n",
      "INFO - 07/22/22 15:07:22 - 0:03:41 - #################################################################################################################\n",
      "train E022: 100% 23/23 [00:05<00:00,  4.20it/s]\n",
      "INFO - 07/22/22 15:07:27 - 0:03:46 - Train Epoch 22: LOSS= 1.18468, lr= 0.000686, acc1= 95.59,acc3= 98.65,acc10= 99.24\n",
      "eval E022: 100% 21/21 [00:03<00:00,  5.84it/s]\n",
      "INFO - 07/22/22 15:07:31 - 0:03:50 - #################################################################################################################\n",
      "INFO - 07/22/22 15:07:31 - 0:03:50 - Test Epoch 22: LOSS= 7.67169, acc1= 36.59, acc3= 53.41, acc10= 60.34\n",
      "INFO - 07/22/22 15:07:31 - 0:03:50 - #################################################################################################################\n",
      "train E023: 100% 23/23 [00:05<00:00,  4.21it/s]\n",
      "INFO - 07/22/22 15:07:36 - 0:03:55 - Train Epoch 23: LOSS= 1.06054, lr= 0.000480, acc1= 96.15,acc3= 98.99,acc10= 99.55\n",
      "eval E023: 100% 21/21 [00:03<00:00,  5.72it/s]\n",
      "INFO - 07/22/22 15:07:40 - 0:03:59 - #################################################################################################################\n",
      "INFO - 07/22/22 15:07:40 - 0:03:59 - Test Epoch 23: LOSS= 8.31399, acc1= 37.13, acc3= 53.91, acc10= 60.96\n",
      "INFO - 07/22/22 15:07:40 - 0:03:59 - #################################################################################################################\n",
      "train E024: 100% 23/23 [00:05<00:00,  4.17it/s]\n",
      "INFO - 07/22/22 15:07:45 - 0:04:05 - Train Epoch 24: LOSS= 0.97133, lr= 0.000480, acc1= 96.91,acc3= 99.20,acc10= 99.76\n",
      "eval E024: 100% 21/21 [00:03<00:00,  5.86it/s]\n",
      "INFO - 07/22/22 15:07:49 - 0:04:08 - #################################################################################################################\n",
      "INFO - 07/22/22 15:07:49 - 0:04:08 - Test Epoch 24: LOSS= 8.62699, acc1= 35.44, acc3= 53.37, acc10= 60.88\n",
      "INFO - 07/22/22 15:07:49 - 0:04:08 - #################################################################################################################\n",
      "train E025: 100% 23/23 [00:05<00:00,  4.19it/s]\n",
      "INFO - 07/22/22 15:07:54 - 0:04:14 - Train Epoch 25: LOSS= 0.95463, lr= 0.000480, acc1= 96.43,acc3= 99.13,acc10= 99.58\n",
      "eval E025: 100% 21/21 [00:03<00:00,  5.80it/s]\n",
      "INFO - 07/22/22 15:07:58 - 0:04:17 - #################################################################################################################\n",
      "INFO - 07/22/22 15:07:58 - 0:04:17 - Test Epoch 25: LOSS= 8.35717, acc1= 35.75, acc3= 53.03, acc10= 61.03\n",
      "INFO - 07/22/22 15:07:58 - 0:04:17 - #################################################################################################################\n",
      "train E026: 100% 23/23 [00:05<00:00,  4.20it/s]\n",
      "INFO - 07/22/22 15:08:04 - 0:04:23 - Train Epoch 26: LOSS= 0.85152, lr= 0.000336, acc1= 97.15,acc3= 99.27,acc10= 99.65\n",
      "eval E026: 100% 21/21 [00:03<00:00,  5.54it/s]\n",
      "INFO - 07/22/22 15:08:07 - 0:04:27 - #################################################################################################################\n",
      "INFO - 07/22/22 15:08:07 - 0:04:27 - Test Epoch 26: LOSS= 8.73377, acc1= 36.55, acc3= 53.49, acc10= 61.30\n",
      "INFO - 07/22/22 15:08:07 - 0:04:27 - #################################################################################################################\n",
      "train E027: 100% 23/23 [00:05<00:00,  4.17it/s]\n",
      "INFO - 07/22/22 15:08:13 - 0:04:32 - Train Epoch 27: LOSS= 0.75301, lr= 0.000336, acc1= 97.54,acc3= 99.62,acc10= 99.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E027: 100% 21/21 [00:03<00:00,  5.80it/s]\n",
      "INFO - 07/22/22 15:08:17 - 0:04:36 - #################################################################################################################\n",
      "INFO - 07/22/22 15:08:17 - 0:04:36 - Test Epoch 27: LOSS= 9.19831, acc1= 36.17, acc3= 53.22, acc10= 60.61\n",
      "INFO - 07/22/22 15:08:17 - 0:04:36 - #################################################################################################################\n",
      "train E028: 100% 23/23 [00:05<00:00,  4.18it/s]\n",
      "INFO - 07/22/22 15:08:22 - 0:04:41 - Train Epoch 28: LOSS= 0.75086, lr= 0.000336, acc1= 97.33,acc3= 99.51,acc10= 99.79\n",
      "eval E028: 100% 21/21 [00:03<00:00,  5.72it/s]\n",
      "INFO - 07/22/22 15:08:26 - 0:04:45 - #################################################################################################################\n",
      "INFO - 07/22/22 15:08:26 - 0:04:45 - Test Epoch 28: LOSS= 9.11631, acc1= 35.98, acc3= 53.75, acc10= 61.49\n",
      "INFO - 07/22/22 15:08:26 - 0:04:45 - #################################################################################################################\n",
      "train E029: 100% 23/23 [00:05<00:00,  4.16it/s]\n",
      "INFO - 07/22/22 15:08:31 - 0:04:50 - Train Epoch 29: LOSS= 0.71103, lr= 0.000235, acc1= 97.81,acc3= 99.65,acc10= 99.76\n",
      "eval E029: 100% 21/21 [00:03<00:00,  5.88it/s]\n",
      "INFO - 07/22/22 15:08:35 - 0:04:54 - #################################################################################################################\n",
      "INFO - 07/22/22 15:08:35 - 0:04:54 - Test Epoch 29: LOSS= 9.14917, acc1= 36.05, acc3= 53.79, acc10= 61.69\n",
      "INFO - 07/22/22 15:08:35 - 0:04:54 - #################################################################################################################\n",
      "train E030: 100% 23/23 [00:05<00:00,  4.25it/s]\n",
      "INFO - 07/22/22 15:08:40 - 0:04:59 - Train Epoch 30: LOSS= 0.65566, lr= 0.000235, acc1= 97.99,acc3= 99.44,acc10= 99.72\n",
      "eval E030: 100% 21/21 [00:03<00:00,  5.65it/s]\n",
      "INFO - 07/22/22 15:08:44 - 0:05:03 - #################################################################################################################\n",
      "INFO - 07/22/22 15:08:44 - 0:05:03 - Test Epoch 30: LOSS= 9.26355, acc1= 34.94, acc3= 52.26, acc10= 59.81\n",
      "INFO - 07/22/22 15:08:44 - 0:05:03 - #################################################################################################################\n",
      "train E031: 100% 23/23 [00:05<00:00,  4.26it/s]\n",
      "INFO - 07/22/22 15:08:49 - 0:05:09 - Train Epoch 31: LOSS= 0.63744, lr= 0.000235, acc1= 97.88,acc3= 99.69,acc10= 99.79\n",
      "eval E031: 100% 21/21 [00:03<00:00,  5.85it/s]\n",
      "INFO - 07/22/22 15:08:53 - 0:05:12 - #################################################################################################################\n",
      "INFO - 07/22/22 15:08:53 - 0:05:12 - Test Epoch 31: LOSS= 9.60145, acc1= 35.82, acc3= 53.37, acc10= 61.46\n",
      "INFO - 07/22/22 15:08:53 - 0:05:12 - #################################################################################################################\n",
      "train E032: 100% 23/23 [00:05<00:00,  4.23it/s]\n",
      "INFO - 07/22/22 15:08:58 - 0:05:18 - Train Epoch 32: LOSS= 0.60708, lr= 0.000165, acc1= 98.33,acc3= 99.76,acc10= 99.83\n",
      "eval E032: 100% 21/21 [00:03<00:00,  5.92it/s]\n",
      "INFO - 07/22/22 15:09:02 - 0:05:21 - #################################################################################################################\n",
      "INFO - 07/22/22 15:09:02 - 0:05:21 - Test Epoch 32: LOSS= 9.59171, acc1= 35.82, acc3= 53.30, acc10= 60.80\n",
      "INFO - 07/22/22 15:09:02 - 0:05:21 - #################################################################################################################\n",
      "train E033: 100% 23/23 [00:05<00:00,  4.21it/s]\n",
      "INFO - 07/22/22 15:09:07 - 0:05:27 - Train Epoch 33: LOSS= 0.60822, lr= 0.000165, acc1= 98.27,acc3= 99.76,acc10= 99.90\n",
      "eval E033: 100% 21/21 [00:03<00:00,  5.73it/s]\n",
      "INFO - 07/22/22 15:09:11 - 0:05:30 - #################################################################################################################\n",
      "INFO - 07/22/22 15:09:11 - 0:05:30 - Test Epoch 33: LOSS= 9.66102, acc1= 36.40, acc3= 52.64, acc10= 61.03\n",
      "INFO - 07/22/22 15:09:11 - 0:05:30 - #################################################################################################################\n",
      "train E034: 100% 23/23 [00:05<00:00,  4.20it/s]\n",
      "INFO - 07/22/22 15:09:17 - 0:05:36 - Train Epoch 34: LOSS= 0.59545, lr= 0.000165, acc1= 98.40,acc3= 99.83,acc10= 99.97\n",
      "eval E034: 100% 21/21 [00:03<00:00,  5.65it/s]\n",
      "INFO - 07/22/22 15:09:20 - 0:05:39 - #################################################################################################################\n",
      "INFO - 07/22/22 15:09:20 - 0:05:39 - Test Epoch 34: LOSS= 9.66375, acc1= 35.59, acc3= 52.87, acc10= 60.34\n",
      "INFO - 07/22/22 15:09:20 - 0:05:39 - #################################################################################################################\n",
      "train E035: 100% 23/23 [00:05<00:00,  4.23it/s]\n",
      "INFO - 07/22/22 15:09:26 - 0:05:45 - Train Epoch 35: LOSS= 0.55336, lr= 0.000115, acc1= 98.40,acc3= 99.83,acc10= 100.00\n",
      "eval E035: 100% 21/21 [00:03<00:00,  5.61it/s]\n",
      "INFO - 07/22/22 15:09:29 - 0:05:49 - #################################################################################################################\n",
      "INFO - 07/22/22 15:09:29 - 0:05:49 - Test Epoch 35: LOSS= 9.89944, acc1= 35.94, acc3= 53.07, acc10= 61.23\n",
      "INFO - 07/22/22 15:09:29 - 0:05:49 - #################################################################################################################\n",
      "train E036: 100% 23/23 [00:05<00:00,  4.23it/s]\n",
      "INFO - 07/22/22 15:09:35 - 0:05:54 - Train Epoch 36: LOSS= 0.53018, lr= 0.000115, acc1= 98.72,acc3= 99.86,acc10= 99.97\n",
      "eval E036: 100% 21/21 [00:03<00:00,  5.69it/s]\n",
      "INFO - 07/22/22 15:09:39 - 0:05:58 - #################################################################################################################\n",
      "INFO - 07/22/22 15:09:39 - 0:05:58 - Test Epoch 36: LOSS= 10.11726, acc1= 36.36, acc3= 52.91, acc10= 60.73\n",
      "INFO - 07/22/22 15:09:39 - 0:05:58 - #################################################################################################################\n",
      "train E037: 100% 23/23 [00:05<00:00,  4.27it/s]\n",
      "INFO - 07/22/22 15:09:44 - 0:06:03 - Train Epoch 37: LOSS= 0.54642, lr= 0.000115, acc1= 98.40,acc3= 99.76,acc10= 99.93\n",
      "eval E037: 100% 21/21 [00:03<00:00,  5.83it/s]\n",
      "INFO - 07/22/22 15:09:48 - 0:06:07 - #################################################################################################################\n",
      "INFO - 07/22/22 15:09:48 - 0:06:07 - Test Epoch 37: LOSS= 10.15666, acc1= 35.63, acc3= 52.91, acc10= 61.03\n",
      "INFO - 07/22/22 15:09:48 - 0:06:07 - #################################################################################################################\n",
      "train E038: 100% 23/23 [00:05<00:00,  4.25it/s]\n",
      "INFO - 07/22/22 15:09:53 - 0:06:12 - Train Epoch 38: LOSS= 0.54104, lr= 0.000081, acc1= 98.47,acc3= 99.83,acc10= 99.93\n",
      "eval E038: 100% 21/21 [00:03<00:00,  5.83it/s]\n",
      "INFO - 07/22/22 15:09:57 - 0:06:16 - #################################################################################################################\n",
      "INFO - 07/22/22 15:09:57 - 0:06:16 - Test Epoch 38: LOSS= 10.20303, acc1= 35.52, acc3= 52.76, acc10= 60.61\n",
      "INFO - 07/22/22 15:09:57 - 0:06:16 - #################################################################################################################\n",
      "train E039: 100% 23/23 [00:05<00:00,  4.21it/s]\n",
      "INFO - 07/22/22 15:10:02 - 0:06:21 - Train Epoch 39: LOSS= 0.51724, lr= 0.000081, acc1= 98.47,acc3= 99.83,acc10= 99.93\n",
      "eval E039: 100% 21/21 [00:03<00:00,  5.77it/s]\n",
      "INFO - 07/22/22 15:10:06 - 0:06:25 - #################################################################################################################\n",
      "INFO - 07/22/22 15:10:06 - 0:06:25 - Test Epoch 39: LOSS= 10.17954, acc1= 35.67, acc3= 52.34, acc10= 60.88\n",
      "INFO - 07/22/22 15:10:06 - 0:06:25 - #################################################################################################################\n",
      "train E040: 100% 23/23 [00:05<00:00,  4.10it/s]\n",
      "INFO - 07/22/22 15:10:11 - 0:06:31 - Train Epoch 40: LOSS= 0.52116, lr= 0.000081, acc1= 98.72,acc3= 99.83,acc10= 99.93\n",
      "eval E040: 100% 21/21 [00:03<00:00,  5.71it/s]\n",
      "INFO - 07/22/22 15:10:15 - 0:06:34 - #################################################################################################################\n",
      "INFO - 07/22/22 15:10:15 - 0:06:34 - Test Epoch 40: LOSS= 10.33279, acc1= 35.94, acc3= 53.03, acc10= 61.03\n",
      "INFO - 07/22/22 15:10:15 - 0:06:34 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E041: 100% 23/23 [00:05<00:00,  4.13it/s]\n",
      "INFO - 07/22/22 15:10:21 - 0:06:40 - Train Epoch 41: LOSS= 0.52981, lr= 0.000056, acc1= 98.72,acc3= 99.90,acc10= 99.97\n",
      "eval E041: 100% 21/21 [00:03<00:00,  5.74it/s]\n",
      "INFO - 07/22/22 15:10:24 - 0:06:43 - #################################################################################################################\n",
      "INFO - 07/22/22 15:10:24 - 0:06:43 - Test Epoch 41: LOSS= 10.35951, acc1= 35.40, acc3= 52.99, acc10= 60.80\n",
      "INFO - 07/22/22 15:10:24 - 0:06:43 - #################################################################################################################\n",
      "train E042: 100% 23/23 [00:05<00:00,  4.17it/s]\n",
      "INFO - 07/22/22 15:10:30 - 0:06:49 - Train Epoch 42: LOSS= 0.49625, lr= 0.000056, acc1= 98.75,acc3= 99.83,acc10= 99.93\n",
      "eval E042: 100% 21/21 [00:03<00:00,  5.70it/s]\n",
      "INFO - 07/22/22 15:10:33 - 0:06:53 - #################################################################################################################\n",
      "INFO - 07/22/22 15:10:33 - 0:06:53 - Test Epoch 42: LOSS= 10.40726, acc1= 35.36, acc3= 52.11, acc10= 60.57\n",
      "INFO - 07/22/22 15:10:33 - 0:06:53 - #################################################################################################################\n",
      "train E043: 100% 23/23 [00:05<00:00,  4.22it/s]\n",
      "INFO - 07/22/22 15:10:39 - 0:06:58 - Train Epoch 43: LOSS= 0.50002, lr= 0.000056, acc1= 98.75,acc3= 99.86,acc10= 99.93\n",
      "eval E043: 100% 21/21 [00:03<00:00,  5.87it/s]\n",
      "INFO - 07/22/22 15:10:42 - 0:07:02 - #################################################################################################################\n",
      "INFO - 07/22/22 15:10:42 - 0:07:02 - Test Epoch 43: LOSS= 10.36806, acc1= 35.79, acc3= 52.26, acc10= 60.77\n",
      "INFO - 07/22/22 15:10:42 - 0:07:02 - #################################################################################################################\n",
      "train E044: 100% 23/23 [00:05<00:00,  4.22it/s]\n",
      "INFO - 07/22/22 15:10:48 - 0:07:07 - Train Epoch 44: LOSS= 0.45328, lr= 0.000040, acc1= 98.96,acc3= 99.86,acc10= 99.97\n",
      "eval E044: 100% 21/21 [00:03<00:00,  5.51it/s]\n",
      "INFO - 07/22/22 15:10:52 - 0:07:11 - #################################################################################################################\n",
      "INFO - 07/22/22 15:10:52 - 0:07:11 - Test Epoch 44: LOSS= 10.48301, acc1= 35.79, acc3= 52.45, acc10= 61.07\n",
      "INFO - 07/22/22 15:10:52 - 0:07:11 - #################################################################################################################\n",
      "train E045: 100% 23/23 [00:05<00:00,  4.21it/s]\n",
      "INFO - 07/22/22 15:10:57 - 0:07:16 - Train Epoch 45: LOSS= 0.47941, lr= 0.000040, acc1= 98.85,acc3= 99.86,acc10= 99.90\n",
      "eval E045: 100% 21/21 [00:03<00:00,  5.67it/s]\n",
      "INFO - 07/22/22 15:11:01 - 0:07:20 - #################################################################################################################\n",
      "INFO - 07/22/22 15:11:01 - 0:07:20 - Test Epoch 45: LOSS= 10.55131, acc1= 35.75, acc3= 52.45, acc10= 60.92\n",
      "INFO - 07/22/22 15:11:01 - 0:07:20 - #################################################################################################################\n",
      "train E046: 100% 23/23 [00:05<00:00,  4.23it/s]\n",
      "INFO - 07/22/22 15:11:06 - 0:07:26 - Train Epoch 46: LOSS= 0.47934, lr= 0.000040, acc1= 99.03,acc3= 99.86,acc10= 99.90\n",
      "eval E046: 100% 21/21 [00:03<00:00,  5.68it/s]\n",
      "INFO - 07/22/22 15:11:10 - 0:07:29 - #################################################################################################################\n",
      "INFO - 07/22/22 15:11:10 - 0:07:29 - Test Epoch 46: LOSS= 10.54403, acc1= 35.48, acc3= 52.49, acc10= 60.84\n",
      "INFO - 07/22/22 15:11:10 - 0:07:29 - #################################################################################################################\n",
      "train E047: 100% 23/23 [00:05<00:00,  4.24it/s]\n",
      "INFO - 07/22/22 15:11:15 - 0:07:35 - Train Epoch 47: LOSS= 0.47317, lr= 0.000040, acc1= 98.75,acc3= 99.93,acc10= 99.97\n",
      "eval E047: 100% 21/21 [00:03<00:00,  5.71it/s]\n",
      "INFO - 07/22/22 15:11:19 - 0:07:38 - #################################################################################################################\n",
      "INFO - 07/22/22 15:11:19 - 0:07:38 - Test Epoch 47: LOSS= 10.62605, acc1= 35.90, acc3= 52.61, acc10= 60.54\n",
      "INFO - 07/22/22 15:11:19 - 0:07:38 - #################################################################################################################\n",
      "train E048: 100% 23/23 [00:05<00:00,  4.23it/s]\n",
      "INFO - 07/22/22 15:11:25 - 0:07:44 - Train Epoch 48: LOSS= 0.46266, lr= 0.000040, acc1= 98.47,acc3= 99.90,acc10= 99.97\n",
      "eval E048: 100% 21/21 [00:03<00:00,  5.83it/s]\n",
      "INFO - 07/22/22 15:11:28 - 0:07:47 - #################################################################################################################\n",
      "INFO - 07/22/22 15:11:28 - 0:07:47 - Test Epoch 48: LOSS= 10.69819, acc1= 36.02, acc3= 52.80, acc10= 60.77\n",
      "INFO - 07/22/22 15:11:28 - 0:07:47 - #################################################################################################################\n",
      "train E049: 100% 23/23 [00:05<00:00,  4.23it/s]\n",
      "INFO - 07/22/22 15:11:34 - 0:07:53 - Train Epoch 49: LOSS= 0.44503, lr= 0.000040, acc1= 98.89,acc3= 99.90,acc10= 100.00\n",
      "eval E049: 100% 21/21 [00:03<00:00,  5.85it/s]\n",
      "INFO - 07/22/22 15:11:37 - 0:07:56 - #################################################################################################################\n",
      "INFO - 07/22/22 15:11:37 - 0:07:56 - Test Epoch 49: LOSS= 10.63946, acc1= 35.86, acc3= 52.76, acc10= 60.80\n",
      "INFO - 07/22/22 15:11:37 - 0:07:56 - #################################################################################################################\n",
      "train E050: 100% 23/23 [00:05<00:00,  4.25it/s]\n",
      "INFO - 07/22/22 15:11:43 - 0:08:02 - Train Epoch 50: LOSS= 0.44470, lr= 0.000040, acc1= 99.10,acc3= 99.79,acc10= 99.97\n",
      "eval E050: 100% 21/21 [00:03<00:00,  5.84it/s]\n",
      "INFO - 07/22/22 15:11:46 - 0:08:05 - #################################################################################################################\n",
      "INFO - 07/22/22 15:11:46 - 0:08:05 - Test Epoch 50: LOSS= 10.75847, acc1= 35.82, acc3= 52.45, acc10= 60.92\n",
      "INFO - 07/22/22 15:11:46 - 0:08:05 - #################################################################################################################\n",
      "train E051: 100% 23/23 [00:05<00:00,  4.23it/s]\n",
      "INFO - 07/22/22 15:11:52 - 0:08:11 - Train Epoch 51: LOSS= 0.44522, lr= 0.000040, acc1= 98.82,acc3= 99.93,acc10= 100.00\n",
      "eval E051: 100% 21/21 [00:03<00:00,  5.86it/s]\n",
      "INFO - 07/22/22 15:11:55 - 0:08:15 - #################################################################################################################\n",
      "INFO - 07/22/22 15:11:55 - 0:08:15 - Test Epoch 51: LOSS= 10.95031, acc1= 35.90, acc3= 52.49, acc10= 60.84\n",
      "INFO - 07/22/22 15:11:55 - 0:08:15 - #################################################################################################################\n",
      "train E052: 100% 23/23 [00:05<00:00,  4.21it/s]\n",
      "INFO - 07/22/22 15:12:01 - 0:08:20 - Train Epoch 52: LOSS= 0.45327, lr= 0.000040, acc1= 98.85,acc3= 99.97,acc10= 99.97\n",
      "eval E052: 100% 21/21 [00:03<00:00,  5.78it/s]\n",
      "INFO - 07/22/22 15:12:04 - 0:08:24 - #################################################################################################################\n",
      "INFO - 07/22/22 15:12:04 - 0:08:24 - Test Epoch 52: LOSS= 10.95542, acc1= 35.71, acc3= 52.72, acc10= 60.34\n",
      "INFO - 07/22/22 15:12:04 - 0:08:24 - #################################################################################################################\n",
      "train E053: 100% 23/23 [00:05<00:00,  4.19it/s]\n",
      "INFO - 07/22/22 15:12:10 - 0:08:29 - Train Epoch 53: LOSS= 0.43861, lr= 0.000040, acc1= 98.89,acc3= 99.90,acc10= 100.00\n",
      "eval E053: 100% 21/21 [00:03<00:00,  5.87it/s]\n",
      "INFO - 07/22/22 15:12:13 - 0:08:33 - #################################################################################################################\n",
      "INFO - 07/22/22 15:12:13 - 0:08:33 - Test Epoch 53: LOSS= 10.90998, acc1= 35.82, acc3= 52.26, acc10= 60.77\n",
      "INFO - 07/22/22 15:12:13 - 0:08:33 - #################################################################################################################\n",
      "INFO - 07/22/22 15:12:15 - 0:08:34 - best performance =  37.13, 53.91, 60.96. best epoch = 23, correspond_loss= 8.3140\n",
      "INFO - 07/22/22 15:12:15 - 0:08:34 -  fusion_model_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/fact_BERT_3.pkl\n",
      "INFO - 07/22/22 15:12:15 - 0:08:34 -  answer_net_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/fact_MLP_3.pkl\n"
     ]
    }
   ],
   "source": [
    "# relation间训练 BERT rnn  \n",
    "#待跑\n",
    "%cd code\n",
    "!python main_bert_rnn.py --gpu_id 8 --exp_name relation_space --exp_id bert --fusion_model BERT --data_choice 3 --method_choice W2V  --save_model 1 --ZSL 1 --now_test 0 --fact_map 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7677ac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-13T11:56:11.422504Z",
     "start_time": "2023-01-13T11:52:11.531554Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 01/13/23 19:52:22 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 01/13/23 19:52:22 - 0:00:00 - The experiment will be stored in dump/0113-version_prediction/rel3_fact5data_3score_10\n",
      "                                     \n",
      "INFO - 01/13/23 19:52:22 - 0:00:00 - Running command: python joint_test_version.py --gpu_id 8 --exp_name version_prediction --ZSL 0 --exp_id rel3_fact5data_3score_10 --data_choice 3 --top_rel 15 --top_fact 15 --soft_score 100 --mrr 1\n",
      "\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 16\n",
      "batch_size 16\n",
      "INFO - 01/13/23 19:52:56 - 0:00:34 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO - 01/13/23 19:52:56 - 0:00:34 - extracting archive file /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpeaq_c7eo\n",
      "embeddings.word_embeddings.weight:\tFalse\n",
      "embeddings.position_embeddings.weight:\tFalse\n",
      "embeddings.token_type_embeddings.weight:\tFalse\n",
      "embeddings.LayerNorm.weight:\tFalse\n",
      "embeddings.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.attention.self.query.weight:\tFalse\n",
      "encoder.layer.0.attention.self.query.bias:\tFalse\n",
      "encoder.layer.0.attention.self.key.weight:\tFalse\n",
      "encoder.layer.0.attention.self.key.bias:\tFalse\n",
      "encoder.layer.0.attention.self.value.weight:\tFalse\n",
      "encoder.layer.0.attention.self.value.bias:\tFalse\n",
      "encoder.layer.0.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.0.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.0.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.0.output.dense.weight:\tFalse\n",
      "encoder.layer.0.output.dense.bias:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.attention.self.query.weight:\tFalse\n",
      "encoder.layer.1.attention.self.query.bias:\tFalse\n",
      "encoder.layer.1.attention.self.key.weight:\tFalse\n",
      "encoder.layer.1.attention.self.key.bias:\tFalse\n",
      "encoder.layer.1.attention.self.value.weight:\tFalse\n",
      "encoder.layer.1.attention.self.value.bias:\tFalse\n",
      "encoder.layer.1.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.1.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.1.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.1.output.dense.weight:\tFalse\n",
      "encoder.layer.1.output.dense.bias:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.attention.self.query.weight:\tFalse\n",
      "encoder.layer.2.attention.self.query.bias:\tFalse\n",
      "encoder.layer.2.attention.self.key.weight:\tFalse\n",
      "encoder.layer.2.attention.self.key.bias:\tFalse\n",
      "encoder.layer.2.attention.self.value.weight:\tFalse\n",
      "encoder.layer.2.attention.self.value.bias:\tFalse\n",
      "encoder.layer.2.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.2.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.2.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.2.output.dense.weight:\tFalse\n",
      "encoder.layer.2.output.dense.bias:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.attention.self.query.weight:\tFalse\n",
      "encoder.layer.3.attention.self.query.bias:\tFalse\n",
      "encoder.layer.3.attention.self.key.weight:\tFalse\n",
      "encoder.layer.3.attention.self.key.bias:\tFalse\n",
      "encoder.layer.3.attention.self.value.weight:\tFalse\n",
      "encoder.layer.3.attention.self.value.bias:\tFalse\n",
      "encoder.layer.3.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.3.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.3.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.3.output.dense.weight:\tFalse\n",
      "encoder.layer.3.output.dense.bias:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.attention.self.query.weight:\tFalse\n",
      "encoder.layer.4.attention.self.query.bias:\tFalse\n",
      "encoder.layer.4.attention.self.key.weight:\tFalse\n",
      "encoder.layer.4.attention.self.key.bias:\tFalse\n",
      "encoder.layer.4.attention.self.value.weight:\tFalse\n",
      "encoder.layer.4.attention.self.value.bias:\tFalse\n",
      "encoder.layer.4.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.4.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.4.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.4.output.dense.weight:\tFalse\n",
      "encoder.layer.4.output.dense.bias:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.attention.self.query.weight:\tFalse\n",
      "encoder.layer.5.attention.self.query.bias:\tFalse\n",
      "encoder.layer.5.attention.self.key.weight:\tFalse\n",
      "encoder.layer.5.attention.self.key.bias:\tFalse\n",
      "encoder.layer.5.attention.self.value.weight:\tFalse\n",
      "encoder.layer.5.attention.self.value.bias:\tFalse\n",
      "encoder.layer.5.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.5.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.5.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.5.output.dense.weight:\tFalse\n",
      "encoder.layer.5.output.dense.bias:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.attention.self.query.weight:\tFalse\n",
      "encoder.layer.6.attention.self.query.bias:\tFalse\n",
      "encoder.layer.6.attention.self.key.weight:\tFalse\n",
      "encoder.layer.6.attention.self.key.bias:\tFalse\n",
      "encoder.layer.6.attention.self.value.weight:\tFalse\n",
      "encoder.layer.6.attention.self.value.bias:\tFalse\n",
      "encoder.layer.6.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.6.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.6.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.6.output.dense.weight:\tFalse\n",
      "encoder.layer.6.output.dense.bias:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.attention.self.query.weight:\tFalse\n",
      "encoder.layer.7.attention.self.query.bias:\tFalse\n",
      "encoder.layer.7.attention.self.key.weight:\tFalse\n",
      "encoder.layer.7.attention.self.key.bias:\tFalse\n",
      "encoder.layer.7.attention.self.value.weight:\tFalse\n",
      "encoder.layer.7.attention.self.value.bias:\tFalse\n",
      "encoder.layer.7.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.7.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.7.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.7.output.dense.weight:\tFalse\n",
      "encoder.layer.7.output.dense.bias:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.attention.self.query.weight:\tFalse\n",
      "encoder.layer.8.attention.self.query.bias:\tFalse\n",
      "encoder.layer.8.attention.self.key.weight:\tFalse\n",
      "encoder.layer.8.attention.self.key.bias:\tFalse\n",
      "encoder.layer.8.attention.self.value.weight:\tFalse\n",
      "encoder.layer.8.attention.self.value.bias:\tFalse\n",
      "encoder.layer.8.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.8.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.8.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.8.output.dense.weight:\tFalse\n",
      "encoder.layer.8.output.dense.bias:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.attention.self.query.weight:\tFalse\n",
      "encoder.layer.9.attention.self.query.bias:\tFalse\n",
      "encoder.layer.9.attention.self.key.weight:\tFalse\n",
      "encoder.layer.9.attention.self.key.bias:\tFalse\n",
      "encoder.layer.9.attention.self.value.weight:\tFalse\n",
      "encoder.layer.9.attention.self.value.bias:\tFalse\n",
      "encoder.layer.9.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.9.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.9.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.9.output.dense.weight:\tFalse\n",
      "encoder.layer.9.output.dense.bias:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.attention.self.query.weight:\tFalse\n",
      "encoder.layer.10.attention.self.query.bias:\tFalse\n",
      "encoder.layer.10.attention.self.key.weight:\tFalse\n",
      "encoder.layer.10.attention.self.key.bias:\tFalse\n",
      "encoder.layer.10.attention.self.value.weight:\tFalse\n",
      "encoder.layer.10.attention.self.value.bias:\tFalse\n",
      "encoder.layer.10.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.10.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.10.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.10.output.dense.weight:\tFalse\n",
      "encoder.layer.10.output.dense.bias:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.attention.self.query.weight:\tFalse\n",
      "encoder.layer.11.attention.self.query.bias:\tFalse\n",
      "encoder.layer.11.attention.self.key.weight:\tFalse\n",
      "encoder.layer.11.attention.self.key.bias:\tFalse\n",
      "encoder.layer.11.attention.self.value.weight:\tFalse\n",
      "encoder.layer.11.attention.self.value.bias:\tFalse\n",
      "encoder.layer.11.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.11.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.11.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.11.output.dense.weight:\tFalse\n",
      "encoder.layer.11.output.dense.bias:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.bias:\tFalse\n",
      "pooler.dense.weight:\tFalse\n",
      "pooler.dense.bias:\tFalse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 01/13/23 19:53:09 - 0:00:48 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO - 01/13/23 19:53:09 - 0:00:48 - extracting archive file /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpxx469jq7\n",
      "embeddings.word_embeddings.weight:\tFalse\n",
      "embeddings.position_embeddings.weight:\tFalse\n",
      "embeddings.token_type_embeddings.weight:\tFalse\n",
      "embeddings.LayerNorm.weight:\tFalse\n",
      "embeddings.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.attention.self.query.weight:\tFalse\n",
      "encoder.layer.0.attention.self.query.bias:\tFalse\n",
      "encoder.layer.0.attention.self.key.weight:\tFalse\n",
      "encoder.layer.0.attention.self.key.bias:\tFalse\n",
      "encoder.layer.0.attention.self.value.weight:\tFalse\n",
      "encoder.layer.0.attention.self.value.bias:\tFalse\n",
      "encoder.layer.0.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.0.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.0.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.0.output.dense.weight:\tFalse\n",
      "encoder.layer.0.output.dense.bias:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.attention.self.query.weight:\tFalse\n",
      "encoder.layer.1.attention.self.query.bias:\tFalse\n",
      "encoder.layer.1.attention.self.key.weight:\tFalse\n",
      "encoder.layer.1.attention.self.key.bias:\tFalse\n",
      "encoder.layer.1.attention.self.value.weight:\tFalse\n",
      "encoder.layer.1.attention.self.value.bias:\tFalse\n",
      "encoder.layer.1.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.1.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.1.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.1.output.dense.weight:\tFalse\n",
      "encoder.layer.1.output.dense.bias:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.attention.self.query.weight:\tFalse\n",
      "encoder.layer.2.attention.self.query.bias:\tFalse\n",
      "encoder.layer.2.attention.self.key.weight:\tFalse\n",
      "encoder.layer.2.attention.self.key.bias:\tFalse\n",
      "encoder.layer.2.attention.self.value.weight:\tFalse\n",
      "encoder.layer.2.attention.self.value.bias:\tFalse\n",
      "encoder.layer.2.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.2.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.2.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.2.output.dense.weight:\tFalse\n",
      "encoder.layer.2.output.dense.bias:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.attention.self.query.weight:\tFalse\n",
      "encoder.layer.3.attention.self.query.bias:\tFalse\n",
      "encoder.layer.3.attention.self.key.weight:\tFalse\n",
      "encoder.layer.3.attention.self.key.bias:\tFalse\n",
      "encoder.layer.3.attention.self.value.weight:\tFalse\n",
      "encoder.layer.3.attention.self.value.bias:\tFalse\n",
      "encoder.layer.3.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.3.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.3.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.3.output.dense.weight:\tFalse\n",
      "encoder.layer.3.output.dense.bias:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.attention.self.query.weight:\tFalse\n",
      "encoder.layer.4.attention.self.query.bias:\tFalse\n",
      "encoder.layer.4.attention.self.key.weight:\tFalse\n",
      "encoder.layer.4.attention.self.key.bias:\tFalse\n",
      "encoder.layer.4.attention.self.value.weight:\tFalse\n",
      "encoder.layer.4.attention.self.value.bias:\tFalse\n",
      "encoder.layer.4.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.4.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.4.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.4.output.dense.weight:\tFalse\n",
      "encoder.layer.4.output.dense.bias:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.attention.self.query.weight:\tFalse\n",
      "encoder.layer.5.attention.self.query.bias:\tFalse\n",
      "encoder.layer.5.attention.self.key.weight:\tFalse\n",
      "encoder.layer.5.attention.self.key.bias:\tFalse\n",
      "encoder.layer.5.attention.self.value.weight:\tFalse\n",
      "encoder.layer.5.attention.self.value.bias:\tFalse\n",
      "encoder.layer.5.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.5.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.5.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.5.output.dense.weight:\tFalse\n",
      "encoder.layer.5.output.dense.bias:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.attention.self.query.weight:\tFalse\n",
      "encoder.layer.6.attention.self.query.bias:\tFalse\n",
      "encoder.layer.6.attention.self.key.weight:\tFalse\n",
      "encoder.layer.6.attention.self.key.bias:\tFalse\n",
      "encoder.layer.6.attention.self.value.weight:\tFalse\n",
      "encoder.layer.6.attention.self.value.bias:\tFalse\n",
      "encoder.layer.6.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.6.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.6.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.6.output.dense.weight:\tFalse\n",
      "encoder.layer.6.output.dense.bias:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.attention.self.query.weight:\tFalse\n",
      "encoder.layer.7.attention.self.query.bias:\tFalse\n",
      "encoder.layer.7.attention.self.key.weight:\tFalse\n",
      "encoder.layer.7.attention.self.key.bias:\tFalse\n",
      "encoder.layer.7.attention.self.value.weight:\tFalse\n",
      "encoder.layer.7.attention.self.value.bias:\tFalse\n",
      "encoder.layer.7.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.7.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.7.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.7.output.dense.weight:\tFalse\n",
      "encoder.layer.7.output.dense.bias:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.attention.self.query.weight:\tFalse\n",
      "encoder.layer.8.attention.self.query.bias:\tFalse\n",
      "encoder.layer.8.attention.self.key.weight:\tFalse\n",
      "encoder.layer.8.attention.self.key.bias:\tFalse\n",
      "encoder.layer.8.attention.self.value.weight:\tFalse\n",
      "encoder.layer.8.attention.self.value.bias:\tFalse\n",
      "encoder.layer.8.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.8.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.8.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.8.output.dense.weight:\tFalse\n",
      "encoder.layer.8.output.dense.bias:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.attention.self.query.weight:\tFalse\n",
      "encoder.layer.9.attention.self.query.bias:\tFalse\n",
      "encoder.layer.9.attention.self.key.weight:\tFalse\n",
      "encoder.layer.9.attention.self.key.bias:\tFalse\n",
      "encoder.layer.9.attention.self.value.weight:\tFalse\n",
      "encoder.layer.9.attention.self.value.bias:\tFalse\n",
      "encoder.layer.9.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.9.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.9.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.9.output.dense.weight:\tFalse\n",
      "encoder.layer.9.output.dense.bias:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.attention.self.query.weight:\tFalse\n",
      "encoder.layer.10.attention.self.query.bias:\tFalse\n",
      "encoder.layer.10.attention.self.key.weight:\tFalse\n",
      "encoder.layer.10.attention.self.key.bias:\tFalse\n",
      "encoder.layer.10.attention.self.value.weight:\tFalse\n",
      "encoder.layer.10.attention.self.value.bias:\tFalse\n",
      "encoder.layer.10.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.10.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.10.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.10.output.dense.weight:\tFalse\n",
      "encoder.layer.10.output.dense.bias:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.attention.self.query.weight:\tFalse\n",
      "encoder.layer.11.attention.self.query.bias:\tFalse\n",
      "encoder.layer.11.attention.self.key.weight:\tFalse\n",
      "encoder.layer.11.attention.self.key.bias:\tFalse\n",
      "encoder.layer.11.attention.self.value.weight:\tFalse\n",
      "encoder.layer.11.attention.self.value.bias:\tFalse\n",
      "encoder.layer.11.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.11.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.11.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.11.output.dense.weight:\tFalse\n",
      "encoder.layer.11.output.dense.bias:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.bias:\tFalse\n",
      "pooler.dense.weight:\tFalse\n",
      "pooler.dense.bias:\tFalse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin test! ...\n",
      "loading model  ...\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_answer_SAN_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_answer_MLP_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_relation_BERT_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_relation_MLP_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_fact_BERT_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_fact_MLP_3.pkl model done!\n",
      "use train data: 3\n",
      "batch_size 16\n",
      "use train data: 3\n",
      "batch_size 16\n",
      "  0%|                                                   | 0/177 [00:00<?, ?it/s]pre tensor([386.9286, 371.5141, 376.7064, 375.9800, 366.6866, 372.2118, 371.3592,\n",
      "        373.5807, 373.6490, 375.8623, 376.1014, 376.3922, 381.6834, 362.3331,\n",
      "        367.5013, 370.7850, 371.6125, 375.0930, 367.1594, 378.9278, 373.6362,\n",
      "        378.5078, 373.6599, 371.5910, 375.7466, 369.5147, 376.2896, 372.6909,\n",
      "        370.4674, 389.1327, 378.7975, 375.7608, 375.1910, 374.2358, 378.6134,\n",
      "        368.5847, 377.8743, 370.0181, 380.4366, 373.4613, 374.8338, 377.0964,\n",
      "        371.6338, 372.0348, 368.3272, 388.5518, 373.9667, 370.7385, 372.5083,\n",
      "        373.5888, 372.2126, 369.6272, 371.2002, 374.5714, 373.1840, 366.5234,\n",
      "        371.8215, 371.9816, 371.6165, 371.8439, 371.5936, 378.1164, 380.7767,\n",
      "        368.3373, 375.1746, 369.9627, 372.7731, 374.5197, 368.3874, 372.5567,\n",
      "        372.7754, 369.0997, 377.9821, 369.1196, 381.1201, 372.0715, 376.9895,\n",
      "        380.2001, 373.7561, 379.3671, 371.4486, 363.7784, 373.1221, 378.1415,\n",
      "        370.2228, 370.9104, 372.5097, 373.0848, 372.3928, 371.3384, 369.7683,\n",
      "        369.0226, 364.5896, 372.9369, 376.5022, 371.3099, 370.4955, 371.9656,\n",
      "        375.1903, 372.0938, 372.8540, 368.5471, 372.5778, 370.7752, 369.6954,\n",
      "        371.6538, 371.5379, 374.4388, 377.1044, 376.3625, 368.4376, 378.4771,\n",
      "        370.7952, 368.7847, 364.7378, 378.2247, 376.3443, 371.5275, 373.1121,\n",
      "        368.0703, 368.3649, 372.4991, 373.7934, 365.5123, 372.1589, 365.7944,\n",
      "        369.4307, 376.7881, 364.2015, 371.6818, 376.9226, 385.7921, 366.7657,\n",
      "        373.0811, 375.9550, 372.6851, 367.6453, 373.3631, 372.2709, 373.1212,\n",
      "        372.4577, 370.7418, 369.0401, 375.9668, 374.4433, 374.1141, 367.5647,\n",
      "        369.1978, 375.8498, 375.0301, 371.8015, 367.3114, 371.9182, 377.1360,\n",
      "        368.6415, 370.5481, 373.6548, 372.9131, 374.0620, 375.8507, 375.2032,\n",
      "        375.3422, 378.6185, 378.0239, 372.2980, 368.8026, 370.8521, 366.5617,\n",
      "        375.6878, 371.5477, 370.4425, 370.7112, 376.2189, 375.9651, 374.5490,\n",
      "        373.2501, 370.2202, 380.4350, 362.7056, 370.9871, 366.8391, 376.6432,\n",
      "        368.9308, 371.5958, 376.0944, 368.3701, 370.7157, 375.2812, 369.8256,\n",
      "        377.5303, 370.7830, 375.6617, 372.2664, 371.6468, 373.4466, 372.8994,\n",
      "        377.9849, 373.7993, 370.4412, 374.8203, 371.5511, 372.7602, 375.5386,\n",
      "        373.6263, 366.5970, 371.1533, 372.3980, 370.2059, 374.5344, 370.7185,\n",
      "        371.2592, 373.2323, 371.3751, 374.6761, 374.6819, 369.1862, 371.9829,\n",
      "        368.4129, 368.2761, 373.3847, 370.4780, 372.6628, 370.8554, 373.0102,\n",
      "        374.2010, 376.4780, 376.0703, 370.1248, 377.6180, 368.3634, 374.2067,\n",
      "        376.2625, 367.9960, 369.5977, 373.5944, 371.8387, 369.9774, 373.9732,\n",
      "        370.5825, 366.7677, 372.6557, 371.4843, 371.2992, 369.6763, 369.4458,\n",
      "        374.4180, 365.6345, 370.3968, 374.7016, 373.6004, 375.9504, 369.2225,\n",
      "        368.0502, 368.9911, 373.1559, 371.4178, 371.0926, 372.5866, 374.2018,\n",
      "        371.5569, 373.3597, 375.1251, 374.1238, 372.6583, 376.2604, 369.3087,\n",
      "        370.7607, 371.0760, 372.9354, 372.1866, 370.0873, 373.2681, 369.9381,\n",
      "        371.1748, 367.2596, 377.6887, 373.1499, 369.0215, 371.6963, 370.6526,\n",
      "        374.3147, 368.5027, 367.7502, 374.8318, 379.3007, 375.3337, 368.5176,\n",
      "        374.7830, 370.0655, 375.4307, 370.2916, 377.4366, 367.2892, 368.3595,\n",
      "        378.4800, 370.0006, 373.4086, 370.9148, 368.0813, 367.4451, 374.7333,\n",
      "        369.9381, 378.9333, 369.0564, 373.2357, 371.6651, 369.3739, 365.5505,\n",
      "        367.2499, 362.6373, 371.7695, 368.4475, 368.5846, 367.8299, 361.8168,\n",
      "        373.2832, 374.4037, 368.2831, 366.1902, 371.1682, 372.1265, 365.2901,\n",
      "        368.3587, 372.1288, 368.8881, 372.5251, 369.0235, 368.8581, 375.6326,\n",
      "        371.5344, 368.5010, 369.3076, 374.4183, 371.3999, 379.5674, 362.4073,\n",
      "        367.0898, 370.3214, 371.5383, 368.4140, 372.4802, 374.3955, 377.1093,\n",
      "        371.1205, 371.7500, 371.3256, 365.6866, 374.4208, 367.1552, 372.7908,\n",
      "        372.6810, 375.2879, 371.7238, 372.1974, 373.0750, 372.2315, 374.4902,\n",
      "        376.3565, 374.6936, 374.7717, 374.7717, 366.8837, 378.4669, 365.6096,\n",
      "        372.6514, 374.1039, 370.8664, 378.8289, 371.5984, 369.1082, 367.1306,\n",
      "        374.4724, 376.5309, 377.3848, 372.6365, 373.3628, 368.0371, 370.0469,\n",
      "        368.1010, 372.3564, 371.9691, 374.6633, 372.3061, 370.4759, 375.1233,\n",
      "        373.3797, 376.2073, 371.4198, 372.0728, 376.0100, 369.0958, 371.0405,\n",
      "        371.1689, 370.0557, 374.5738, 376.0669, 374.6090, 374.3348, 370.1053,\n",
      "        373.6504, 370.0886, 371.3633, 371.0873, 378.3287, 371.9883, 374.1203,\n",
      "        368.0535, 368.9685, 368.4755, 373.8166, 370.7553, 376.1326, 368.5836,\n",
      "        370.1727, 376.0182, 368.2784, 362.5569, 366.6991, 375.8978, 373.2300,\n",
      "        374.0600, 378.0414, 371.4514, 359.9733, 367.7634, 377.8215, 375.2698,\n",
      "        374.8185, 368.1281, 369.4856, 370.3595, 369.5955, 369.9055, 381.0020,\n",
      "        367.4968, 374.0597, 373.7450, 373.2985, 374.6313, 371.1577, 373.6279,\n",
      "        373.2333, 376.2387, 373.0669, 368.6260, 366.7709, 373.9908, 369.4152,\n",
      "        371.9704, 368.9865, 370.7713, 371.7690, 372.2060, 369.4078, 370.7071,\n",
      "        375.3031, 374.8302, 373.4221, 370.5434, 371.4395, 372.9901, 372.9055,\n",
      "        369.1267, 370.3513, 372.8308, 369.0800, 375.5677, 366.7560, 375.4822,\n",
      "        369.1064, 374.4235, 372.4902, 371.9394, 370.2299, 368.6228, 369.0755,\n",
      "        367.1780, 372.5267, 374.5037, 367.0230, 369.5396, 370.2688, 374.1852,\n",
      "        368.9571, 370.6666, 371.5732, 371.5457, 370.5449, 369.8071, 376.8877,\n",
      "        374.7717, 367.8876, 374.2752, 371.0693, 369.4258, 373.4577, 375.9797,\n",
      "        374.7619, 379.1418, 374.7717], device='cuda:8', dtype=torch.float64)\n",
      "[[0, 29, tensor(973.2560, device='cuda:8', dtype=torch.float64), 35.817874908447266, tensor(6150.7729, device='cuda:8', dtype=torch.float64)], [0, 7, tensor(970.6783, device='cuda:8', dtype=torch.float64), 35.817874908447266, tensor(6124.9956, device='cuda:8', dtype=torch.float64)], [0, 7, tensor(970.6783, device='cuda:8', dtype=torch.float64), 35.817874908447266, tensor(6124.9956, device='cuda:8', dtype=torch.float64)], [0, 29, tensor(970.6783, device='cuda:8', dtype=torch.float64), 35.817874908447266, tensor(6124.9956, device='cuda:8', dtype=torch.float64)], [0, 77, tensor(970.5632, device='cuda:8', dtype=torch.float64), 35.817874908447266, tensor(6123.8442, device='cuda:8', dtype=torch.float64)], [0, 197, tensor(970.5121, device='cuda:8', dtype=torch.float64), 35.817874908447266, tensor(6123.3340, device='cuda:8', dtype=torch.float64)], [0, 11, tensor(970.4230, device='cuda:8', dtype=torch.float64), 35.817874908447266, tensor(6122.4424, device='cuda:8', dtype=torch.float64)], [0, 71, tensor(947.2313, device='cuda:8', dtype=torch.float64), 33.48354721069336, tensor(6123.9585, device='cuda:8', dtype=torch.float64)], [0, 28, tensor(947.1652, device='cuda:8', dtype=torch.float64), 33.48354721069336, tensor(6123.2969, device='cuda:8', dtype=torch.float64)], [0, 28, tensor(947.1652, device='cuda:8', dtype=torch.float64), 33.48354721069336, tensor(6123.2969, device='cuda:8', dtype=torch.float64)], [0, 191, tensor(931.3085, device='cuda:8', dtype=torch.float64), 31.85163116455078, tensor(6127.9219, device='cuda:8', dtype=torch.float64)], [0, 36, tensor(930.7110, device='cuda:8', dtype=torch.float64), 31.85163116455078, tensor(6121.9468, device='cuda:8', dtype=torch.float64)], [0, 36, tensor(930.7110, device='cuda:8', dtype=torch.float64), 31.85163116455078, tensor(6121.9468, device='cuda:8', dtype=torch.float64)], [0, 24, tensor(911.7611, device='cuda:8', dtype=torch.float64), 29.905853271484375, tensor(6127.0259, device='cuda:8', dtype=torch.float64)], [0, 29, tensor(911.7611, device='cuda:8', dtype=torch.float64), 29.905853271484375, tensor(6127.0259, device='cuda:8', dtype=torch.float64)], [0, 35, tensor(894.3078, device='cuda:8', dtype=torch.float64), 28.211313247680664, tensor(6121.9468, device='cuda:8', dtype=torch.float64)], [0, 12, tensor(894.3078, device='cuda:8', dtype=torch.float64), 28.211313247680664, tensor(6121.9468, device='cuda:8', dtype=torch.float64)], [0, 34, tensor(894.3067, device='cuda:8', dtype=torch.float64), 28.211313247680664, tensor(6121.9360, device='cuda:8', dtype=torch.float64)], [0, 34, tensor(894.3067, device='cuda:8', dtype=torch.float64), 28.211313247680664, tensor(6121.9360, device='cuda:8', dtype=torch.float64)], [0, 12, tensor(894.2955, device='cuda:8', dtype=torch.float64), 28.211313247680664, tensor(6121.8237, device='cuda:8', dtype=torch.float64)], [0, 24, tensor(894.2323, device='cuda:8', dtype=torch.float64), 28.211313247680664, tensor(6121.1919, device='cuda:8', dtype=torch.float64)], [0, 29, tensor(889.4728, device='cuda:8', dtype=torch.float64), 27.680131912231445, tensor(6126.7148, device='cuda:8', dtype=torch.float64)], [0, 0, tensor(850.1248, device='cuda:8', dtype=torch.float64), 23.79290771484375, tensor(6121.9575, device='cuda:8', dtype=torch.float64)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 177/177 [02:37<00:00,  1.13it/s]\n",
      "self.min: 75.06101989746094\n",
      "self.max: 372.00726318359375\n",
      "INFO - 01/13/23 19:56:09 - 0:03:47 - #################################################################################################################\n",
      "INFO - 01/13/23 19:56:09 - 0:03:47 - orig  acc1= 48.10, acc3= 66.24, acc10= 80.73\n",
      "INFO - 01/13/23 19:56:09 - 0:03:47 - ####  acc1= 58.77, acc3= 73.82, acc10= 88.45\n",
      "INFO - 01/13/23 19:56:09 - 0:03:47 - #################################################################################################################\n",
      "INFO - 01/13/23 19:56:09 - 0:03:47 - #################################################################################################################\n",
      "INFO - 01/13/23 19:56:09 - 0:03:47 - orig  mrr= 0.5937, mr = 15.61\n",
      "INFO - 01/13/23 19:56:09 - 0:03:47 - ####  mrr= 0.6854, mr = 9.78\n",
      "INFO - 01/13/23 19:56:09 - 0:03:47 - #################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "# 联合测试2\n",
    "%cd code\n",
    "!python joint_test_version.py --gpu_id 8 --exp_name version_prediction --ZSL 0 --exp_id rel3_fact5data_3score_10 --data_choice 3  --top_rel 15 --top_fact 15 --soft_score 100  --mrr 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "094bce4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T02:50:28.285630Z",
     "start_time": "2022-08-13T02:50:28.128371Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'fact_surface': '[[lipstick]] belongs to the category of [[Cosmetics]]', 'answer': 'lipstick', 'question': 'Tell me the name of the cosmetics shown in this image?', 'img_file': 'ILSVRC2012_test_00000444.JPEG', 'kb_source': 'dbpedia', 'fact': ['lipstick', 'belong to', 'cosmetics'], 'question_id': '271'}, '1': {'fact_surface': '[[A kite]] has [[a tail]]', 'answer': 'kite', 'question': 'Which object in this image has a tail', 'img_file': 'COCO_val2014_000000005599.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'has a', 'tail'], 'question_id': '274'}, '2': {'fact_surface': '[[A bus]] is used to [[carry people]]', 'answer': 'bus', 'question': 'Which object in this image can carry person?', 'img_file': 'COCO_val2014_000000001584.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'used for', 'carry person'], 'question_id': '3519'}, '3': {'fact_surface': '[[a lizard]] can [[sun itself on a rock]]', 'answer': 'lizard', 'question': 'Which animal in this image can sun itself on a rock?', 'img_file': 'ILSVRC2012_test_00053239.JPEG', 'kb_source': 'conceptnet', 'fact': ['lizard', 'capable of', 'sun itself on rock'], 'question_id': '3513'}, '4': {'fact_surface': '[[Wii]] is a kind of [[Gaming System]].', 'answer': 'wii', 'question': 'Which object pictured in this image is a game system?', 'img_file': 'COCO_val2014_000000105480.jpg', 'kb_source': 'conceptnet', 'fact': ['wii', 'is a', 'game system'], 'question_id': '3512'}, '5': {'fact_surface': 'You are likely to find [[a dog]] in [[petshop]].', 'answer': 'dog', 'question': 'Which object in this image can be found in petshop?', 'img_file': 'ILSVRC2012_test_00000650.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'at location', 'petshop'], 'question_id': '3515'}, '6': {'fact_surface': '[[a hotel room]] can be used for [[temporary residence]]', 'answer': 'temporary residence', 'question': 'What is this place used for?', 'img_file': 'COCO_val2014_000000100187.jpg', 'kb_source': 'conceptnet', 'fact': ['hotel room', 'used for', 'temporary residence'], 'question_id': '3514'}, '7': {'fact_surface': '[[people]] are [[male or female]]', 'answer': 'person', 'question': 'what object in this image can be male or female?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'has property', 'male or female'], 'question_id': '2688'}, '8': {'fact_surface': 'A [[person]] can [[smell]].', 'answer': 'person', 'question': 'what object in this image can smell things?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'smell'], 'question_id': '2689'}, '9': {'fact_surface': '[[People]] do [[jobs in order to earn money]]', 'answer': 'person', 'question': 'which object in this image is capable of doing a job to earn money?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'job in order to earn money'], 'question_id': '2684'}, '10': {'fact_surface': '[[People]] often [[dance to music]]', 'answer': 'person', 'question': 'what object in this image can dance to music?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'dance to music'], 'question_id': '2685'}, '11': {'fact_surface': '[[A person]] can [[send a letter in the mail]]', 'answer': 'person', 'question': 'what object in this image can post a letter?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'send letter in mail'], 'question_id': '2686'}, '12': {'fact_surface': 'A [[person]] can [[walk]].', 'answer': 'person', 'question': 'what object in this image can walk?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'walk'], 'question_id': '2687'}, '13': {'fact_surface': '[[People]] often [[paints houses, including the bedroom]]', 'answer': 'person', 'question': 'which object in this image is capable of painting a house and a bedroom?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'paint house include bedroom'], 'question_id': '2680'}, '14': {'fact_surface': '[[people]] can [[smell dirty shoes]]', 'answer': 'person', 'question': 'which object in this image is capable of smelling dirty shoes?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'smell dirty shoe'], 'question_id': '2681'}, '15': {'fact_surface': '[[a person]] can [[own an object]]', 'answer': 'person', 'question': 'which object in this image is capable of owning an object?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'own object'], 'question_id': '2682'}, '16': {'fact_surface': '[[people]] can [[lose weight]]', 'answer': 'person', 'question': 'what object in this image can loose weight?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'lose weight'], 'question_id': '2683'}, '17': {'fact_surface': '[[airplane]] is a kind of [[vehicle]].', 'answer': 'airplane', 'question': 'What is the vehicle in the water?', 'img_file': 'COCO_val2014_000000101088.jpg', 'kb_source': 'conceptnet', 'fact': ['airplane', 'is a', 'vehicle'], 'question_id': '97'}, '18': {'fact_surface': '[[vegetables]] belongs to the category of [[Edible plants]]', 'answer': 'vegetable', 'question': 'Which object in this image belongs to the category Edible plants?', 'img_file': 'COCO_val2014_000000130438.jpg', 'kb_source': 'dbpedia', 'fact': ['vegetable', 'belong to', 'edible plants'], 'question_id': '1177'}, '19': {'fact_surface': 'A [[carrot]] is a [[orange vegetable]]', 'answer': 'carrot', 'question': 'Which object in this image belongs to orange vegetables?', 'img_file': 'COCO_val2014_000000130438.jpg', 'kb_source': 'conceptnet', 'fact': ['carrot', 'is a', 'orange vegetable'], 'question_id': '1176'}, '20': {'fact_surface': 'A [[tree]] is a [[very large plant]]', 'answer': 'tree', 'question': 'Which object in this image is a very large plant?', 'img_file': 'COCO_val2014_000000109889.jpg', 'kb_source': 'conceptnet', 'fact': ['tree', 'is a', 'very large plant'], 'question_id': '1174'}, '21': {'fact_surface': '[[a tree]] is [[made of wood]].', 'answer': 'tree', 'question': 'Which object in this image is made of wood?', 'img_file': 'COCO_val2014_000000109889.jpg', 'kb_source': 'conceptnet', 'fact': ['tree', 'has property', 'make of wood'], 'question_id': '1173'}, '22': {'fact_surface': '[[snow]] is [[usually white]]', 'answer': 'snow', 'question': 'What is white in this image?', 'img_file': 'COCO_val2014_000000109889.jpg', 'kb_source': 'conceptnet', 'fact': ['snow', 'has property', 'usually white'], 'question_id': '1172'}, '23': {'fact_surface': '[[skis]] belongs to the category of [[Winter sports]]', 'answer': 'ski', 'question': 'Which winter sport is presented in this image?', 'img_file': 'COCO_val2014_000000109889.jpg', 'kb_source': 'dbpedia', 'fact': ['ski', 'belong to', 'winter sports'], 'question_id': '1171'}, '24': {'fact_surface': '[[mountains]] are often [[covered in snow]]', 'answer': 'mountain', 'question': 'What is covered in snow in this image?', 'img_file': 'COCO_val2014_000000109889.jpg', 'kb_source': 'conceptnet', 'fact': ['mountain', 'has property', 'cover in snow'], 'question_id': '1170'}, '25': {'fact_surface': '[[sandwich]] belongs to the category of [[European cuisine]]', 'answer': 'sandwich', 'question': 'Which European cuisine is shown in this image?', 'img_file': 'COCO_val2014_000000130438.jpg', 'kb_source': 'dbpedia', 'fact': ['sandwich', 'belong to', 'european cuisine'], 'question_id': '1179'}, '26': {'fact_surface': '[[hot dog]] is for [[eating]]', 'answer': 'eat', 'question': 'What is the object in the middle used for?', 'img_file': 'COCO_val2014_000000130438.jpg', 'kb_source': 'conceptnet', 'fact': ['hot dog', 'used for', 'eat'], 'question_id': '1178'}, '27': {'fact_surface': '[[A banjo]] is [[a stringed instrumetnt]]', 'answer': 'banjo', 'question': 'What stringed instrument is seen here?', 'img_file': 'ILSVRC2012_test_00000658.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'is a', 'string instrumetnt'], 'question_id': '876'}, '28': {'fact_surface': '[[a refrigerator]] can [[stock food]]', 'answer': 'refrigerator', 'question': 'Which object in this image is able to stock food?', 'img_file': 'COCO_val2014_000000122954.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'capable of', 'stock food'], 'question_id': '3432'}, '29': {'fact_surface': '[[motorcycle]] are cooler than [[car]]', 'answer': 'motorcycle', 'question': 'Which is cooler? Them machine in the image or car?', 'img_file': 'COCO_val2014_000000115314.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'cool', 'car'], 'question_id': '875'}, '30': {'fact_surface': '[[a bicycle]] is for [[Racing]]', 'answer': 'racing', 'question': 'What are they doing with the bicycle?', 'img_file': 'ILSVRC2012_test_00002886.JPEG', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'used for', 'racing'], 'question_id': '872'}, '31': {'fact_surface': '[[Dogs]] have [[wet noses]]', 'answer': 'dog', 'question': 'Which object in this image has a wet nose?', 'img_file': 'COCO_val2014_000000008351.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'has a', 'wet nose'], 'question_id': '3435'}, '32': {'fact_surface': '[[A bicycle]] has [[two weheels]]', 'answer': 'bicycle', 'question': 'Which vehicle has two wheels in this image', 'img_file': 'COCO_val2014_000000017244.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'has a', 'two weheels'], 'question_id': '620'}, '33': {'fact_surface': '[[A camera]] can [[record a scene]]', 'answer': 'camera', 'question': 'What thing in the image can be used to record a scene?', 'img_file': 'ILSVRC2012_test_00000595.JPEG', 'kb_source': 'conceptnet', 'fact': ['camera', 'capable of', 'record scene'], 'question_id': '870'}, '34': {'fact_surface': 'A [[bus]] can [[run]].', 'answer': 'bus', 'question': 'Which thing in the image can run?', 'img_file': 'COCO_val2014_000000024195.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'capable of', 'run'], 'question_id': '627'}, '35': {'fact_surface': '[[bus]] were more important than [[bike]]', 'answer': 'bus', 'question': 'Which vehicle is more important?', 'img_file': 'COCO_val2014_000000120340.jpg', 'kb_source': 'webchild', 'fact': ['bus', 'important', 'bike'], 'question_id': '624'}, '36': {'fact_surface': '[[traffic light]] belongs to the category of [[Road safety]]', 'answer': 'traffic light', 'question': 'What object is used to guarantee road safety?', 'img_file': 'COCO_val2014_000000102741.jpg', 'kb_source': 'dbpedia', 'fact': ['traffic light', 'belong to', 'road safety'], 'question_id': '4598'}, '37': {'fact_surface': '[[A toddler]] can [[drink a glass of milk]]', 'answer': 'toddler', 'question': 'What is one thing in this image that can drink a glass of milk?', 'img_file': 'COCO_val2014_000000018150.jpg', 'kb_source': 'conceptnet', 'fact': ['toddler', 'capable of', 'drink glass of milk'], 'question_id': '4734'}, '38': {'fact_surface': '[[pizza]] belongs to the category of [[Flatbread]]', 'answer': 'pizza', 'question': 'Which object in this image is related to flatbread?', 'img_file': 'COCO_val2014_000000018150.jpg', 'kb_source': 'dbpedia', 'fact': ['pizza', 'belong to', 'flatbread'], 'question_id': '4735'}, '39': {'fact_surface': '[[sweet potato]] has less natural sugar than [[banana]]', 'answer': 'banana', 'question': 'which fruit in this image has less natural sugar than sweet potato?', 'img_file': 'COCO_val2014_000000016161.jpg', 'kb_source': 'webchild', 'fact': ['sweet potato', 'natural', 'banana'], 'question_id': '2039'}, '40': {'fact_surface': '[[pizza]] belongs to the category of [[Fast food]]', 'answer': 'pizza', 'question': 'What fast food item is in this image?', 'img_file': 'COCO_val2014_000000018150.jpg', 'kb_source': 'dbpedia', 'fact': ['pizza', 'belong to', 'fast food'], 'question_id': '4738'}, '41': {'fact_surface': '[[Table tennis]] is [[played with small balls]]', 'answer': 'small', 'question': 'Do you need small balls or big balls for this game?', 'img_file': 'ILSVRC2012_test_00042019.JPEG', 'kb_source': 'conceptnet', 'fact': ['table tennis', 'receives action', 'small'], 'question_id': '393'}, '42': {'fact_surface': '[[oranges]] are [[full of vitamin C]]', 'answer': 'vitamin c', 'question': 'What kind of vitamin does this breakfast contain?', 'img_file': 'COCO_val2014_000000135029.jpg', 'kb_source': 'conceptnet', 'fact': ['orange', 'has property', 'vitamin c'], 'question_id': '395'}, '43': {'fact_surface': '[[chocolate]] is related to [[cake]]', 'answer': 'cake', 'question': 'What are they making?', 'img_file': 'COCO_val2014_000000125106.jpg', 'kb_source': 'conceptnet', 'fact': ['chocolate', 'related to', 'cake'], 'question_id': '394'}, '44': {'fact_surface': '[[dogs]] are [[very playful and friendly]]', 'answer': 'dog', 'question': 'What animal is playful and friendly', 'img_file': 'COCO_val2014_000000142722.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'has property', 'very playful and friendly'], 'question_id': '399'}, '45': {'fact_surface': '[[A dog]] can [[be a friend to humans]]', 'answer': 'dog', 'question': 'Which animal in this image can be a friend to humans?', 'img_file': 'COCO_val2014_000000142722.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'capable of', 'be friend to human'], 'question_id': '398'}, '46': {'fact_surface': '[[lignify]] is related to [[wood]]', 'answer': 'wood', 'question': 'Which object in this image is related to lignify?', 'img_file': 'ILSVRC2012_test_00054961.JPEG', 'kb_source': 'conceptnet', 'fact': ['lignify', 'related to', 'wood'], 'question_id': '2308'}, '47': {'fact_surface': 'You are likely to find [[a horse]] in [[a horserace]]', 'answer': 'horse', 'question': 'Which object in this image can sometimes be found in a horserace?', 'img_file': 'COCO_val2014_000000102672.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'at location', 'horserace'], 'question_id': '4729'}, '48': {'fact_surface': '[[microwaves]] can [[heat food]]', 'answer': 'microwave', 'question': 'Which object in this image can be used to heat food?', 'img_file': 'ILSVRC2012_test_00054961.JPEG', 'kb_source': 'conceptnet', 'fact': ['microwave', 'capable of', 'heat food'], 'question_id': '2305'}, '49': {'fact_surface': '[[a kitchenette]] is for [[cooking]]', 'answer': 'cooking', 'question': 'What is the place in this image used for?', 'img_file': 'ILSVRC2012_test_00054961.JPEG', 'kb_source': 'conceptnet', 'fact': ['kitchenette', 'used for', 'cooking'], 'question_id': '2304'}, '50': {'fact_surface': '[[lemon]] is a kind of [[fruit]].', 'answer': 'lemon', 'question': 'which object in this image comes from the fruit category', 'img_file': 'ILSVRC2012_test_00027003.JPEG', 'kb_source': 'conceptnet', 'fact': ['lemon', 'is a', 'fruit'], 'question_id': '4723'}, '51': {'fact_surface': '[[tree]] are generally taller than [[shrub]]', 'answer': 'tree', 'question': 'which object in this image is taller than shrub?', 'img_file': 'ILSVRC2012_test_00027003.JPEG', 'kb_source': 'webchild', 'fact': ['tree', 'tall', 'shrub'], 'question_id': '4722'}, '52': {'fact_surface': '[[baseball]] is [[an american sport]]', 'answer': 'baseball', 'question': 'Which kind of sport in this image comes from North America?', 'img_file': 'COCO_val2014_000000104417.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'is a', 'american sport'], 'question_id': '5846'}, '53': {'fact_surface': '[[baseball]] belongs to the category of [[Team sports]]', 'answer': 'baseball', 'question': 'What sport in the image belongs to team sports?', 'img_file': 'COCO_val2014_000000104417.jpg', 'kb_source': 'dbpedia', 'fact': ['baseball', 'belong to', 'team sports'], 'question_id': '5845'}, '54': {'fact_surface': '[[baseball glove]] is related to [[mitt]]', 'answer': 'baseball glove', 'question': 'What object in this image is related to mitts?', 'img_file': 'COCO_val2014_000000104417.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball glove', 'related to', 'mitt'], 'question_id': '5844'}, '55': {'fact_surface': '[[helmets]] can be used to [[protect heads]]', 'answer': 'helmet', 'question': 'What objects in this image are used to protect heads?', 'img_file': 'COCO_val2014_000000104417.jpg', 'kb_source': 'conceptnet', 'fact': ['helmet', 'used for', 'protect head'], 'question_id': '5843'}, '56': {'fact_surface': '[[helmet]] is a subclass of [[protective garment]]', 'answer': 'helmet', 'question': 'What object in this image is a type of protective garment?', 'img_file': 'COCO_val2014_000000104417.jpg', 'kb_source': 'conceptnet', 'fact': ['helmet', 'is a', 'protective garment'], 'question_id': '5842'}, '57': {'fact_surface': '[[a baseball bat]] can be used to [[hit a baseball]]', 'answer': 'baseball bat', 'question': 'What object in this image is used to hit a baseball?', 'img_file': 'COCO_val2014_000000104417.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball bat', 'used for', 'hit baseball'], 'question_id': '5841'}, '58': {'fact_surface': '[[baseball]] belongs to the category of [[Ball games]]', 'answer': 'baseball', 'question': 'What ball game is in this image?', 'img_file': 'COCO_val2014_000000104417.jpg', 'kb_source': 'dbpedia', 'fact': ['baseball', 'belong to', 'ball games'], 'question_id': '5840'}, '59': {'fact_surface': '[[whey]] is related to [[cheese]]', 'answer': 'cheese', 'question': 'Which object in this image is related to whey?', 'img_file': 'COCO_val2014_000000114108.jpg', 'kb_source': 'conceptnet', 'fact': ['whey', 'related to', 'cheese'], 'question_id': '5849'}, '60': {'fact_surface': '[[knot]] is related to [[tie]]', 'answer': 'tie', 'question': 'Which object in this image is related to knot?', 'img_file': 'ILSVRC2012_test_00000026.JPEG', 'kb_source': 'conceptnet', 'fact': ['knot', 'related to', 'tie'], 'question_id': '3746'}, '61': {'fact_surface': '[[turtle]] belongs to the category of [[Herpetology]]', 'answer': 'turtle', 'question': 'Which animal in this image belongs to the category Herpetology?', 'img_file': 'ILSVRC2012_test_00002980.JPEG', 'kb_source': 'dbpedia', 'fact': ['turtle', 'belong to', 'herpetology'], 'question_id': '3744'}, '62': {'fact_surface': '[[turtle]] has [[a shell]]', 'answer': 'turtle', 'question': 'Which object in the image has shell?', 'img_file': 'ILSVRC2012_test_00002980.JPEG', 'kb_source': 'conceptnet', 'fact': ['turtle', 'part of', 'shell'], 'question_id': '3745'}, '63': {'fact_surface': '[[pillows]] belongs to the category of [[Bedding]]', 'answer': 'pillows', 'question': 'Which object in this image belongs to the category Bedding?', 'img_file': 'COCO_val2014_000000111609.jpg', 'kb_source': 'dbpedia', 'fact': ['pillows', 'belong to', 'bedding'], 'question_id': '3743'}, '64': {'fact_surface': '[[traffic light]] belongs to the category of [[Road traffic safety]]', 'answer': 'traffic light', 'question': 'What object in this image is used for ensure  the Road traffic safety?', 'img_file': 'COCO_val2014_000000137156.jpg', 'kb_source': 'dbpedia', 'fact': ['traffic light', 'belong to', 'road traffic safety'], 'question_id': '4620'}, '65': {'fact_surface': 'A [[giraffe]] is a [[animal]]', 'answer': 'giraffe', 'question': 'Which object in this image is an animal?', 'img_file': 'COCO_val2014_000000012179.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'is a', 'animal'], 'question_id': '4621'}, '66': {'fact_surface': '[[giraffe]] is [[long-necked]].', 'answer': 'giraffe', 'question': 'Which object in this image is long-necked?', 'img_file': 'COCO_val2014_000000012179.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'has property', 'long neck'], 'question_id': '4622'}, '67': {'fact_surface': '[[okapi]] is related to [[giraffe]]', 'answer': 'giraffe', 'question': 'Which object in this image is related to okapi?', 'img_file': 'COCO_val2014_000000012179.jpg', 'kb_source': 'conceptnet', 'fact': ['okapi', 'related to', 'giraffe'], 'question_id': '4623'}, '68': {'fact_surface': '[[person]] wants [[time alone]]', 'answer': 'person', 'question': 'which object in this image sometimes wants stay alone', 'img_file': 'ILSVRC2012_test_00018275.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'time alone'], 'question_id': '4624'}, '69': {'fact_surface': '[[position]] work better than [[standing]]', 'answer': 'position', 'question': 'Which action is better than the action shown in this image', 'img_file': 'COCO_val2014_000000147025.jpg', 'kb_source': 'webchild', 'fact': ['position', 'good', 'standing'], 'question_id': '4627'}, '70': {'fact_surface': '[[cell phone]] belongs to the category of [[Portable electronics]]', 'answer': 'cell phone', 'question': 'What portable electronic devices appear in this image? ', 'img_file': 'COCO_val2014_000000147025.jpg', 'kb_source': 'dbpedia', 'fact': ['cell phone', 'belong to', 'portable electronics'], 'question_id': '4628'}, '71': {'fact_surface': '[[cell phone]] belongs to the category of [[Portable electronics]]', 'answer': 'cell phone', 'question': 'What portable electronic devices appear in this image? ', 'img_file': 'COCO_val2014_000000147025.jpg', 'kb_source': 'dbpedia', 'fact': ['cell phone', 'belong to', 'portable electronics'], 'question_id': '4629'}, '72': {'fact_surface': '[[an umbrella]] can [[shade a table]]', 'answer': 'shade table', 'question': 'Why the woman in the image move the umbrella?', 'img_file': 'COCO_val2014_000000003109.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'capable of', 'shade table'], 'question_id': '177'}, '73': {'fact_surface': 'You can use [[a knife]] to [[pare an apple]]', 'answer': 'pare apple', 'question': 'What might be the next step?', 'img_file': 'COCO_val2014_000000107831.jpg', 'kb_source': 'conceptnet', 'fact': ['knife', 'used for', 'pare apple'], 'question_id': '176'}, '74': {'fact_surface': '[[cucumbers]] are [[green]]', 'answer': 'cucumber', 'question': 'What are the green long object in the image?', 'img_file': 'ILSVRC2012_test_00021218.JPEG', 'kb_source': 'conceptnet', 'fact': ['cucumber', 'has property', 'green'], 'question_id': '175'}, '75': {'fact_surface': 'You can use [[a clock]] to [[see what time it is]]', 'answer': 'clock', 'question': 'Which thing in this picture is used to see the time?', 'img_file': 'COCO_val2014_000000008498.jpg', 'kb_source': 'conceptnet', 'fact': ['clock', 'used for', 'see what time it be'], 'question_id': '172'}, '76': {'fact_surface': '[[French horn]] is related to [[brass]]', 'answer': 'french horn', 'question': 'Which object in this image is made of brass?', 'img_file': 'ILSVRC2012_test_00027806.JPEG', 'kb_source': 'conceptnet', 'fact': ['french horn', 'related to', 'brass'], 'question_id': '1768'}, '77': {'fact_surface': '[[A French horn]] has [[three keys]]', 'answer': 'french horn', 'question': 'Which object in this image has three keys?', 'img_file': 'ILSVRC2012_test_00027806.JPEG', 'kb_source': 'conceptnet', 'fact': ['french horn', 'has a', 'three key'], 'question_id': '1766'}, '78': {'fact_surface': '[[French horn]] is related to [[coiled]]', 'answer': 'french horn', 'question': 'Which object in this image is coiled?', 'img_file': 'ILSVRC2012_test_00027806.JPEG', 'kb_source': 'conceptnet', 'fact': ['french horn', 'related to', 'coil'], 'question_id': '1767'}, '79': {'fact_surface': '[[lip liner]] be darker than [[lipstick]]', 'answer': 'lipstick', 'question': \"What's less dark than lip liner and visible in this image?\", 'img_file': 'ILSVRC2012_test_00009576.JPEG', 'kb_source': 'webchild', 'fact': ['lip liner', 'dark', 'lipstick'], 'question_id': '1765'}, '80': {'fact_surface': '[[Snakes]] can be [[poisonous]]', 'answer': 'poisonous', 'question': 'Why people can be killed by this animal?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'has property', 'poisonous'], 'question_id': '691'}, '81': {'fact_surface': '[[a microwave]] can be used to [[heat food]]', 'answer': 'microwave', 'question': 'Which object in this image is used to heat food?', 'img_file': 'ILSVRC2012_test_00007262.JPEG', 'kb_source': 'conceptnet', 'fact': ['microwave', 'used for', 'heat food'], 'question_id': '697'}, '82': {'fact_surface': '[[beer]] belongs to the category of [[Alcoholic beverages]]', 'answer': 'beer', 'question': 'What alcoholic beverage can be seen in this image?', 'img_file': 'ILSVRC2012_test_00005726.JPEG', 'kb_source': 'dbpedia', 'fact': ['beer', 'belong to', 'alcoholic beverage'], 'question_id': '694'}, '83': {'fact_surface': 'A [[dog]] can [[growl]].', 'answer': 'dog', 'question': 'What animal in this image can growl?', 'img_file': 'COCO_val2014_000000125405.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'capable of', 'growl'], 'question_id': '1541'}, '84': {'fact_surface': '[[refrigerator]] is for [[store food]].', 'answer': 'refrigerator', 'question': 'Which object in this image is used to store food', 'img_file': 'ILSVRC2012_test_00007262.JPEG', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'used for', 'store food'], 'question_id': '698'}, '85': {'fact_surface': 'Somewhere [[tourists]] can be is in [[a zoo]]', 'answer': 'tourist', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000103723.jpg', 'kb_source': 'conceptnet', 'fact': ['tourist', 'at location', 'zoo'], 'question_id': '5618'}, '86': {'fact_surface': '[[The zoo]] is in [[the city]]', 'answer': 'city', 'question': 'Where does the place in this image can be found in?', 'img_file': 'COCO_val2014_000000103723.jpg', 'kb_source': 'conceptnet', 'fact': ['zoo', 'at location', 'city'], 'question_id': '5619'}, '87': {'fact_surface': '[[dogs]] are [[faithful pets]]', 'answer': 'dog', 'question': 'Which object in this image is a faithful pet?', 'img_file': 'COCO_val2014_000000147787.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'is a', 'faithful pet'], 'question_id': '5611'}, '88': {'fact_surface': 'You are likely to find [[elephants]] in [[zoos]]', 'answer': 'elephant', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000103723.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'at location', 'zoo'], 'question_id': '5617'}, '89': {'fact_surface': '[[ray]] belongs to the category of [[Cartilaginous fish]]', 'answer': 'ray', 'question': 'Which object in this image is a cartilaginous fish?', 'img_file': 'ILSVRC2012_test_00000980.JPEG', 'kb_source': 'dbpedia', 'fact': ['batoidea', 'belong to', 'ray'], 'question_id': '4668'}, '90': {'fact_surface': '[[red]] is related to [[wine]]', 'answer': 'wine', 'question': 'Which object in this image is related to red?', 'img_file': 'COCO_val2014_000000111032.jpg', 'kb_source': 'conceptnet', 'fact': ['red', 'related to', 'wine'], 'question_id': '3580'}, '91': {'fact_surface': '[[Pizza]] has [[cheese on it]]', 'answer': 'cheese', 'question': 'What is on the pizza?', 'img_file': 'COCO_val2014_000000114586.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'has a', 'cheese'], 'question_id': '252'}, '92': {'fact_surface': '[[a sheep]] is for [[shearing]]', 'answer': 'sheep', 'question': 'What object in this image is used for shearing?', 'img_file': 'COCO_val2014_000000112128.jpg', 'kb_source': 'conceptnet', 'fact': ['sheep', 'used for', 'hear'], 'question_id': '250'}, '93': {'fact_surface': '[[A book]] is [[made of paper]]', 'answer': 'book', 'question': 'Which object in this image is made of paper?', 'img_file': 'COCO_val2014_000000127585.jpg', 'kb_source': 'conceptnet', 'fact': ['book', 'has property', 'make of paper'], 'question_id': '256'}, '94': {'fact_surface': '[[book]] has [[many pages]]', 'answer': 'book', 'question': 'Which object in this image has many pages?', 'img_file': 'COCO_val2014_000000127585.jpg', 'kb_source': 'conceptnet', 'fact': ['book', 'part of', 'many page'], 'question_id': '257'}, '95': {'fact_surface': '[[a bicycle]] can [[travel on a road]]', 'answer': 'bicycle', 'question': 'Which object in this image is capable of travel on road?', 'img_file': 'COCO_val2014_000000140908.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'capable of', 'travel on road'], 'question_id': '3681'}, '96': {'fact_surface': '[[a sofa]] is for [[lying on]]', 'answer': 'sofa', 'question': 'What is the dog lying on in the image?', 'img_file': 'ILSVRC2012_test_00011808.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'used for', 'lie on'], 'question_id': '2518'}, '97': {'fact_surface': '[[a sofa]] is for [[lying on]]', 'answer': 'sofa', 'question': 'What is the dog lying on in the image?', 'img_file': 'ILSVRC2012_test_00011808.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'used for', 'lie on'], 'question_id': '2519'}, '98': {'fact_surface': '[[a sofa]] can be used for [[sitting]]', 'answer': 'sofa', 'question': 'Which object in this image is used for sitting on?', 'img_file': 'COCO_val2014_000000004125.jpg', 'kb_source': 'conceptnet', 'fact': ['sofa', 'used for', 'it'], 'question_id': '2514'}, '99': {'fact_surface': '[[a couch]] can be used for [[sitting down]]', 'answer': 'couch', 'question': 'Which object in this image is used for sitting down?', 'img_file': 'COCO_val2014_000000004125.jpg', 'kb_source': 'conceptnet', 'fact': ['couch', 'used for', 'sit down'], 'question_id': '2515'}, '100': {'fact_surface': '[[wine glass]] is related to [[wine]]', 'answer': 'wine glass', 'question': 'Which object in this image is related to wine?', 'img_file': 'COCO_val2014_000000004125.jpg', 'kb_source': 'conceptnet', 'fact': ['wine glass', 'related to', 'wine'], 'question_id': '2516'}, '101': {'fact_surface': '[[a sofa]] is for [[lying on]]', 'answer': 'sofa', 'question': 'What is the dog lying on in the image?', 'img_file': 'ILSVRC2012_test_00011808.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'used for', 'lie on'], 'question_id': '2517'}, '102': {'fact_surface': '[[giraffe]] is [[long-necked]].', 'answer': 'giraffe', 'question': 'Which object has long neck in this image?', 'img_file': 'COCO_val2014_000000022969.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'has property', 'long neck'], 'question_id': '2510'}, '103': {'fact_surface': '[[giraffe]] belongs to the category of [[Regions of Africa]]', 'answer': 'giraffe', 'question': 'what kind of object in this image can be found in African regions', 'img_file': 'COCO_val2014_000000022969.jpg', 'kb_source': 'dbpedia', 'fact': ['giraffe', 'belong to', 'regions of africa'], 'question_id': '2511'}, '104': {'fact_surface': '[[Giraffes]] have [[bones in their necks]]', 'answer': 'giraffe', 'question': 'Which object in this image has a bone in their neck', 'img_file': 'COCO_val2014_000000022969.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'has a', 'bone in their neck'], 'question_id': '2512'}, '105': {'fact_surface': '[[A glass]] can [[hold liquid]]', 'answer': 'glass', 'question': 'Which object in this image can hold liquid?', 'img_file': 'COCO_val2014_000000004125.jpg', 'kb_source': 'conceptnet', 'fact': ['glass', 'capable of', 'hold liquid'], 'question_id': '2513'}, '106': {'fact_surface': '[[a computer]] is for [[calculations]]', 'answer': 'computer', 'question': 'Which object in this image is capable of calculation?', 'img_file': 'COCO_val2014_000000006608.jpg', 'kb_source': 'conceptnet', 'fact': ['computer', 'used for', 'calculation'], 'question_id': '1151'}, '107': {'fact_surface': '[[home offices]] can be [[hard to keep tidy]]', 'answer': 'home office', 'question': 'What property does the place in this image have?', 'img_file': 'COCO_val2014_000000006608.jpg', 'kb_source': 'conceptnet', 'fact': ['home office', 'has property', 'hard to keep tidy'], 'question_id': '1150'}, '108': {'fact_surface': '[[a court]] is for [[playing tennis on]]', 'answer': 'play tennis', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000121744.jpg', 'kb_source': 'conceptnet', 'fact': ['court', 'used for', 'play tennis'], 'question_id': '1153'}, '109': {'fact_surface': 'A [[umbrella]] is a [[device to protect something placed beneath it]]', 'answer': 'umbrella', 'question': 'Which object in this image is a device to protect something placed beneath it?', 'img_file': 'COCO_val2014_000000022118.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'is a', 'device to protect something place beneath it'], 'question_id': '4295'}, '110': {'fact_surface': 'You are likely to find [[sand]] in [[an hourglass]]', 'answer': 'sand', 'question': 'Which object in this image can be found in an hourglass?', 'img_file': 'COCO_val2014_000000022118.jpg', 'kb_source': 'conceptnet', 'fact': ['sand', 'at location', 'hourglass'], 'question_id': '4294'}, '111': {'fact_surface': '[[An umbrella]] is used to [[protect people from sun and rain]]', 'answer': 'umbrella', 'question': 'Which object in this image is used for protect people from sun and rain?', 'img_file': 'COCO_val2014_000000022118.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'used for', 'protect person from sun and rain'], 'question_id': '4297'}, '112': {'fact_surface': '[[an umbrella]] is for [[shading the user]]', 'answer': 'umbrella', 'question': 'Which object in this image is used for shade?', 'img_file': 'COCO_val2014_000000022118.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'used for', 'shade user'], 'question_id': '4296'}, '113': {'fact_surface': 'You are likely to find [[sand]] in [[your shoes]]', 'answer': 'sand', 'question': 'Which thing in this image can be found in your shoes?', 'img_file': 'COCO_val2014_000000022118.jpg', 'kb_source': 'conceptnet', 'fact': ['sand', 'at location', 'your shoe'], 'question_id': '4291'}, '114': {'fact_surface': '[[hiss]] is related to [[snake]]', 'answer': 'snake', 'question': 'Which animal in this image is related to hiss?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['hiss', 'related to', 'snake'], 'question_id': '4290'}, '115': {'fact_surface': '[[sand]] is related to [[deserts]]', 'answer': 'sand', 'question': 'Which object in this image is related to desert?', 'img_file': 'COCO_val2014_000000022118.jpg', 'kb_source': 'conceptnet', 'fact': ['sand', 'related to', 'desert'], 'question_id': '4293'}, '116': {'fact_surface': '[[sand]] is [[gritty]]', 'answer': 'sand', 'question': 'Which object in this image is gritty?', 'img_file': 'COCO_val2014_000000022118.jpg', 'kb_source': 'conceptnet', 'fact': ['sand', 'has property', 'gritty'], 'question_id': '4292'}, '117': {'fact_surface': '[[a lamp]] is for [[lighten rooms and places]]', 'answer': 'lamp', 'question': 'What is lightening the room and place in this image?', 'img_file': 'ILSVRC2012_test_00002967.JPEG', 'kb_source': 'conceptnet', 'fact': ['lamp', 'used for', 'lighten room and place'], 'question_id': '4748'}, '118': {'fact_surface': '[[motorcycle]] belongs to the category of [[Land transport]]', 'answer': 'motorcycle', 'question': 'Which object in this image belongs to the category Land transport?', 'img_file': 'COCO_val2014_000000005205.jpg', 'kb_source': 'dbpedia', 'fact': ['motorcycle', 'belong to', 'land transport'], 'question_id': '1324'}, '119': {'fact_surface': '[[laptop]] get much hotter than [[desktop]]', 'answer': 'laptop', 'question': 'Which object in this image gets hotter than a desktop?', 'img_file': 'ILSVRC2012_test_00002967.JPEG', 'kb_source': 'webchild', 'fact': ['laptop', 'hot', 'desktop'], 'question_id': '4743'}, '120': {'fact_surface': '[[a glass]] is for [[holding a drink]]', 'answer': 'glass', 'question': 'Which object in this image is used for holding a drink?', 'img_file': 'ILSVRC2012_test_00002967.JPEG', 'kb_source': 'conceptnet', 'fact': ['glass', 'used for', 'hold drink'], 'question_id': '4742'}, '121': {'fact_surface': '[[lamps]] can be used to [[generate light]]', 'answer': 'lamp', 'question': 'Which object is gererating light in this image?', 'img_file': 'ILSVRC2012_test_00002967.JPEG', 'kb_source': 'conceptnet', 'fact': ['lamp', 'used for', 'generate light'], 'question_id': '4747'}, '122': {'fact_surface': '[[a bottle]] can contain [[wine]]', 'answer': 'bottle', 'question': 'Which object in this image contains wine?', 'img_file': 'ILSVRC2012_test_00002967.JPEG', 'kb_source': 'conceptnet', 'fact': ['bottle', 'has a', 'wine'], 'question_id': '4746'}, '123': {'fact_surface': '[[laptop]] is a kind of [[computer]]', 'answer': 'laptop', 'question': 'Which object in this image is a computer?', 'img_file': 'ILSVRC2012_test_00002967.JPEG', 'kb_source': 'conceptnet', 'fact': ['laptop', 'is a', 'computer'], 'question_id': '4745'}, '124': {'fact_surface': '[[laptop]] get much hotter than [[desktop]]', 'answer': 'laptop', 'question': 'which object in this image often produces more heat than desktop when works', 'img_file': 'ILSVRC2012_test_00002967.JPEG', 'kb_source': 'webchild', 'fact': ['laptop', 'hot', 'desktop'], 'question_id': '4744'}, '125': {'fact_surface': '[[a guitar]] is used for [[music]]', 'answer': 'music', 'question': 'What is the instrument in the middle used for?', 'img_file': 'ILSVRC2012_test_00051302.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'used for', 'music'], 'question_id': '5869'}, '126': {'fact_surface': '[[guitar]] is related to [[play]]', 'answer': 'guitar', 'question': 'Which object in this image is being played?', 'img_file': 'ILSVRC2012_test_00051302.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'related to', 'play'], 'question_id': '5868'}, '127': {'fact_surface': '[[volleyball]] is a kind of [[ball sport]].', 'answer': 'volleyball', 'question': 'Which ball sport is shown in this image?', 'img_file': 'ILSVRC2012_test_00004234.JPEG', 'kb_source': 'conceptnet', 'fact': ['volleyball', 'is a', 'ball sport'], 'question_id': '5865'}, '128': {'fact_surface': '[[Dogs]] have [[four legs]]', 'answer': 'dog', 'question': 'Which object in this image has four legs?', 'img_file': 'ILSVRC2012_test_00051302.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'has a', 'four leg'], 'question_id': '5867'}, '129': {'fact_surface': '[[hot dogs]] are [[fat]]', 'answer': 'hot dog', 'question': 'Which object in this image has the property of fat', 'img_file': 'COCO_val2014_000000140963.jpg', 'kb_source': 'conceptnet', 'fact': ['hot dog', 'has property', 'fat'], 'question_id': '5866'}, '130': {'fact_surface': '[[Soccer balls]] are [[round]].', 'answer': 'soccer ball', 'question': '￼Which object in this image is round?', 'img_file': 'COCO_val2014_000000107564.jpg', 'kb_source': 'conceptnet', 'fact': ['soccer ball', 'has property', 'round'], 'question_id': '5863'}, '131': {'fact_surface': '*Something you find in [[a sporting goods store]] is [[soccer balls]]', 'answer': 'soccer ball', 'question': 'Which object in this image might be found in a sporting goods store?', 'img_file': 'COCO_val2014_000000107564.jpg', 'kb_source': 'conceptnet', 'fact': ['soccer ball', 'at location', 'sport good store'], 'question_id': '5862'}, '132': {'fact_surface': '[[bagels]] are [[round with holes in them]]', 'answer': 'bagel', 'question': 'Which food in this images is round and has a whole in it?', 'img_file': 'ILSVRC2012_test_00017846.JPEG', 'kb_source': 'conceptnet', 'fact': ['bagel', 'is a', 'round with hole in them'], 'question_id': '2180'}, '133': {'fact_surface': '[[motorcycle]] belongs to the category of [[Land transport]]', 'answer': 'motorcycle', 'question': 'which object in this image is a form of land transportation?', 'img_file': 'COCO_val2014_000000015827.jpg', 'kb_source': 'dbpedia', 'fact': ['motorcycle', 'belong to', 'land transport'], 'question_id': '2187'}, '134': {'fact_surface': '[[motorcycle]] belongs to the category of [[Road transport]]', 'answer': 'motorcycle', 'question': 'which object in this image can be as a means of road transportation?', 'img_file': 'COCO_val2014_000000015827.jpg', 'kb_source': 'dbpedia', 'fact': ['motorcycle', 'belong to', 'road transport'], 'question_id': '2186'}, '135': {'fact_surface': '[[cat]] tend to be more skittish than [[dog]]', 'answer': 'dog', 'question': 'which object in this image is less skittish than cat?', 'img_file': 'COCO_val2014_000000105611.jpg', 'kb_source': 'webchild', 'fact': ['cat', 'skittish', 'dog'], 'question_id': '4606'}, '136': {'fact_surface': '[[dogs]] are usually [[bigger than cats]]', 'answer': 'dog', 'question': 'What animal in the image is bigger than cat?', 'img_file': 'COCO_val2014_000000105611.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'is a', 'big than cat'], 'question_id': '4607'}, '137': {'fact_surface': '[[motorcyclist]] is related to [[motorcycle]]', 'answer': 'motorcycle', 'question': 'which object in this image is driven by a motorcyclist?', 'img_file': 'COCO_val2014_000000015827.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcyclist', 'related to', 'motorcycle'], 'question_id': '2189'}, '138': {'fact_surface': 'A [[motorcycle]] is a [[vehicle]].', 'answer': 'motorcycle', 'question': 'which object in this image is a vehicle?', 'img_file': 'COCO_val2014_000000015827.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'is a', 'vehicle'], 'question_id': '2188'}, '139': {'fact_surface': '[[stethoscopes]] are used to [[listen to the body]]', 'answer': 'stethoscope', 'question': 'Which object in this image is used to listen to the body?', 'img_file': 'ILSVRC2012_test_00040213.JPEG', 'kb_source': 'conceptnet', 'fact': ['stethoscope', 'used for', 'listen to body'], 'question_id': '4602'}, '140': {'fact_surface': '[[A stethoscope]] is [[a listening instrument]]', 'answer': 'stethoscope', 'question': 'Which object in this image is a listening instrument?', 'img_file': 'ILSVRC2012_test_00040213.JPEG', 'kb_source': 'conceptnet', 'fact': ['stethoscope', 'is a', 'listen instrument'], 'question_id': '4603'}, '141': {'fact_surface': '[[a kitchenette]] is [[usually small]]', 'answer': 'kitchenette', 'question': 'What property does the place in this image have?', 'img_file': 'ILSVRC2012_test_00009893.JPEG', 'kb_source': 'conceptnet', 'fact': ['kitchenette', 'has property', 'usually small'], 'question_id': '4600'}, '142': {'fact_surface': '[[stethoscopes]] can [[listen to your heart]]', 'answer': 'stethoscope', 'question': 'Which object in this image is used to listen to your heart?', 'img_file': 'ILSVRC2012_test_00040213.JPEG', 'kb_source': 'conceptnet', 'fact': ['stethoscope', 'capable of', 'listen to your heart'], 'question_id': '4601'}, '143': {'fact_surface': '[[chairs]] is for [[sitting in]]', 'answer': 'chair', 'question': 'Which object will you use when you want to sit?', 'img_file': 'COCO_val2014_000000100430.jpg', 'kb_source': 'conceptnet', 'fact': ['chair', 'used for', 'sit in'], 'question_id': '155'}, '144': {'fact_surface': '[[pizza]] is related to [[bread]]', 'answer': 'bread', 'question': 'What is the base of this pizza?', 'img_file': 'COCO_val2014_000000100582.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'related to', 'bread'], 'question_id': '154'}, '145': {'fact_surface': '(dining table,/r/IsA,kitchen)', 'answer': 'kitchen', 'question': 'Where can people find a dining table', 'img_file': 'ILSVRC2012_test_00001283.JPEG', 'kb_source': 'conceptnet', 'fact': ['dining table', 'is a', 'kitchen'], 'question_id': '159'}, '146': {'fact_surface': '[[a seed]] is part of [[an apple]]', 'answer': 'apple', 'question': 'Which thing in this image has seeds?', 'img_file': 'ILSVRC2012_test_00055836.JPEG', 'kb_source': 'conceptnet', 'fact': ['seed', 'part of', 'apple'], 'question_id': '2724'}, '147': {'fact_surface': '[[apples]] are [[edible by humans]]', 'answer': 'apple', 'question': 'Which thing in this image is edible?', 'img_file': 'ILSVRC2012_test_00055836.JPEG', 'kb_source': 'conceptnet', 'fact': ['apple', 'has property', 'edible by human'], 'question_id': '2723'}, '148': {'fact_surface': '*Something you find in [[the kitchen]] is [[a stove and oven]]', 'answer': 'oven', 'question': 'What can usually be found in this place?', 'img_file': 'ILSVRC2012_test_00055836.JPEG', 'kb_source': 'conceptnet', 'fact': ['oven', 'at location', 'kitchen'], 'question_id': '2722'}, '149': {'fact_surface': '[[a kitchen]] is for [[Cooking in]]', 'answer': 'cooking', 'question': 'What is the place in this image used for?', 'img_file': 'ILSVRC2012_test_00055836.JPEG', 'kb_source': 'conceptnet', 'fact': ['kitchen', 'used for', 'cooking'], 'question_id': '2721'}, '150': {'fact_surface': '[[a kitchenette]] is for [[cooking]]', 'answer': 'cooking', 'question': 'What is the place in this image used for?', 'img_file': 'ILSVRC2012_test_00055836.JPEG', 'kb_source': 'conceptnet', 'fact': ['kitchenette', 'used for', 'cooking'], 'question_id': '2720'}, '151': {'fact_surface': '[[baseball glove]] is a subclass of [[physical impact buffer]]', 'answer': 'glove', 'question': 'What equipment in the image has a physical impact buffer?', 'img_file': 'COCO_val2014_000000004021.jpg', 'kb_source': 'conceptnet', 'fact': ['glove', 'is a', 'physical impact buff'], 'question_id': '812'}, '152': {'fact_surface': '[[saxophone]] is related to [[jazz blues]]', 'answer': 'jazz blue', 'question': 'What types of music does this instrument used to play?', 'img_file': 'ILSVRC2012_test_00027848.JPEG', 'kb_source': 'conceptnet', 'fact': ['saxophone', 'related to', 'jazz blue'], 'question_id': '813'}, '153': {'fact_surface': '[[cat]] is related to [[enemy dog]]', 'answer': 'cat', 'question': 'what object in this image is an enemy of dogs?', 'img_file': 'COCO_val2014_000000026768.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'related to', 'enemy dog'], 'question_id': '814'}, '154': {'fact_surface': '[[a boat]] is for [[moving across the water]]', 'answer': 'boat', 'question': 'Which object in this image is used for moving across water?', 'img_file': 'COCO_val2014_000000104629.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'used for', 'move across water'], 'question_id': '1700'}, '155': {'fact_surface': '[[boats]] are [[bouyant]]', 'answer': 'boat', 'question': 'Which object in this image is a bouyant?', 'img_file': 'COCO_val2014_000000104629.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'is a', 'bouyant'], 'question_id': '1701'}, '156': {'fact_surface': '[[sandwich]] belongs to the category of [[Cuisine]]', 'answer': 'sandwich', 'question': 'Which object in this image is a kind of cuisine?', 'img_file': 'COCO_val2014_000000112269.jpg', 'kb_source': 'dbpedia', 'fact': ['sandwich', 'belong to', 'cuisine'], 'question_id': '5265'}, '157': {'fact_surface': '[[orange]] is related to [[mandarin]]', 'answer': 'orange', 'question': 'Which fruit in this image is most similar to mandarin?', 'img_file': 'ILSVRC2012_test_00007382.JPEG', 'kb_source': 'conceptnet', 'fact': ['orange', 'related to', 'mandarin'], 'question_id': '5264'}, '158': {'fact_surface': '[[motorcycle]] may travel faster than [[traffic]]', 'answer': 'motorcycle', 'question': 'which object in this image is faster than traffic?', 'img_file': 'COCO_val2014_000000144795.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'fast', 'traffic'], 'question_id': '5268'}, '159': {'fact_surface': '[[computer]] can [[mine data]]', 'answer': 'computer', 'question': 'Which object in this image is capable of mining data?', 'img_file': 'ILSVRC2012_test_00057152.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'capable of', 'mine data'], 'question_id': '4574'}, '160': {'fact_surface': '[[computer]] has [[a monitor, a cpu box, a keyboard and a mouse]]', 'answer': 'computer', 'question': 'Which object in this image is a part of monitor cpu box keyboard and mouse?', 'img_file': 'ILSVRC2012_test_00057152.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'part of', 'monitor cpu box keyboard and mouse'], 'question_id': '4575'}, '161': {'fact_surface': 'A [[bus]] is a [[vehicle]]', 'answer': 'bus', 'question': 'Which object in this image belongs to vehicle?', 'img_file': 'COCO_val2014_000000024195.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'is a', 'vehicle'], 'question_id': '3959'}, '162': {'fact_surface': '[[train]] are often more expensive than [[bus]]', 'answer': 'train', 'question': 'which object in this image do we need to pay more for than bus ', 'img_file': 'ILSVRC2012_test_00002425.JPEG', 'kb_source': 'webchild', 'fact': ['train', 'expensive', 'bus'], 'question_id': '3029'}, '163': {'fact_surface': '[[train]] are usually faster than [[bus]]', 'answer': 'train', 'question': 'which object in this image is faster than shuttle bus?', 'img_file': 'ILSVRC2012_test_00002425.JPEG', 'kb_source': 'webchild', 'fact': ['train', 'fast', 'bus'], 'question_id': '3028'}, '164': {'fact_surface': '[[train]] are usually faster than [[bus]]', 'answer': 'train', 'question': 'which object in this image is faster than shuttle bus?', 'img_file': 'ILSVRC2012_test_00002425.JPEG', 'kb_source': 'webchild', 'fact': ['train', 'fast', 'bus'], 'question_id': '3027'}, '165': {'fact_surface': '[[tracks]] is related to [[trains]]', 'answer': 'train', 'question': 'Which object in this image uses tracks?', 'img_file': 'ILSVRC2012_test_00002425.JPEG', 'kb_source': 'conceptnet', 'fact': ['track', 'related to', 'train'], 'question_id': '3026'}, '166': {'fact_surface': '[[A French horn]] has [[three keys]]', 'answer': 'french horn', 'question': 'Which object in this image has three keys?', 'img_file': 'ILSVRC2012_test_00019551.JPEG', 'kb_source': 'conceptnet', 'fact': ['french horn', 'has a', 'three key'], 'question_id': '3025'}, '167': {'fact_surface': '[[pizza]] is a subclass of [[hot food or drink]]', 'answer': 'pizza', 'question': 'What is the hot food or drink item in this image?', 'img_file': 'COCO_val2014_000000140017.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'is a', 'hot food or drink'], 'question_id': '3024'}, '168': {'fact_surface': 'An activity [[a sheep]] can do is [[graze]]', 'answer': 'sheep', 'question': 'Which object in this image is capable of grazing?', 'img_file': 'COCO_val2014_000000109888.jpg', 'kb_source': 'conceptnet', 'fact': ['sheep', 'capable of', 'graze'], 'question_id': '3020'}, '169': {'fact_surface': 'Something you might find [[a bedroom]] is [[pillows]].', 'answer': 'pillows', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000100895.jpg', 'kb_source': 'conceptnet', 'fact': ['pillows', 'at location', 'bedroom'], 'question_id': '5671'}, '170': {'fact_surface': '[[children]] belongs to the category of [[Human]]', 'answer': 'child', 'question': 'Who are humans in this image?', 'img_file': 'COCO_val2014_000000100895.jpg', 'kb_source': 'dbpedia', 'fact': ['child', 'belong to', 'human'], 'question_id': '5672'}, '171': {'fact_surface': '[[a harp]] has [[strings]]', 'answer': 'harp', 'question': 'Which object in this image has a string', 'img_file': 'ILSVRC2012_test_00001209.JPEG', 'kb_source': 'conceptnet', 'fact': ['harp', 'has a', 'string'], 'question_id': '5673'}, '172': {'fact_surface': '[[a monitor]] can [[display images]].', 'answer': 'monitor', 'question': 'Which object in this image is used to display image?', 'img_file': 'ILSVRC2012_test_00059513.JPEG', 'kb_source': 'conceptnet', 'fact': ['monitor', 'capable of', 'display image'], 'question_id': '5678'}, '173': {'fact_surface': 'You are likely to find [[a monitor]] in [[an office]].', 'answer': 'monitor', 'question': \"what's shown in the top of the image\", 'img_file': 'ILSVRC2012_test_00059513.JPEG', 'kb_source': 'conceptnet', 'fact': ['monitor', 'at location', 'office'], 'question_id': '5679'}, '174': {'fact_surface': '[[a plunger]] is for [[the toilet]]', 'answer': 'plunger', 'question': 'What object in this image used for the toilet?', 'img_file': 'COCO_val2014_000000002388.jpg', 'kb_source': 'conceptnet', 'fact': ['plunger', 'used for', 'toilet'], 'question_id': '238'}, '175': {'fact_surface': '[[toilet]] is related to [[seat]]', 'answer': 'toilet', 'question': 'Which thing in the image has a seat?', 'img_file': 'COCO_val2014_000000002388.jpg', 'kb_source': 'conceptnet', 'fact': ['toilet', 'related to', 'seat'], 'question_id': '239'}, '176': {'fact_surface': '[[orange]] is related to [[round]]', 'answer': 'orange', 'question': 'Which fruit in the image is round?', 'img_file': 'COCO_val2014_000000016161.jpg', 'kb_source': 'conceptnet', 'fact': ['orange', 'related to', 'round'], 'question_id': '234'}, '177': {'fact_surface': '[[oranges]] are [[full of vitamin C]]', 'answer': 'orange', 'question': 'Which food in this image is full of vitamin C', 'img_file': 'COCO_val2014_000000016161.jpg', 'kb_source': 'conceptnet', 'fact': ['orange', 'has property', 'full of vitamin c'], 'question_id': '230'}, '178': {'fact_surface': '[[an orange]] is [[juicy]].', 'answer': 'orange', 'question': 'Which fruit in this image is juicy', 'img_file': 'COCO_val2014_000000016161.jpg', 'kb_source': 'conceptnet', 'fact': ['orange', 'has property', 'juicy'], 'question_id': '231'}, '179': {'fact_surface': '[[orange]] is related to [[lemon]]', 'answer': 'orange', 'question': 'Which food is the most related to lemon', 'img_file': 'COCO_val2014_000000016161.jpg', 'kb_source': 'conceptnet', 'fact': ['orange', 'related to', 'lemon'], 'question_id': '232'}, '180': {'fact_surface': '[[banana]] belongs to the category of [[Tropical fruit]]', 'answer': 'banana', 'question': 'Which one in the image belongs to the Tropical fruit?', 'img_file': 'COCO_val2014_000000016161.jpg', 'kb_source': 'dbpedia', 'fact': ['banana', 'belong to', 'tropical fruit'], 'question_id': '233'}, '181': {'fact_surface': '[[rain]] is related to [[water]]', 'answer': 'water', 'question': 'Which object in this image is related to rain?', 'img_file': 'COCO_val2014_000000004066.jpg', 'kb_source': 'conceptnet', 'fact': ['rain', 'related to', 'water'], 'question_id': '2536'}, '182': {'fact_surface': '[[surfboard]] is related to [[surf]]', 'answer': 'surfboard', 'question': 'which object in this image can we find to be related to surf', 'img_file': 'COCO_val2014_000000004066.jpg', 'kb_source': 'conceptnet', 'fact': ['surfboard', 'related to', 'surf'], 'question_id': '2537'}, '183': {'fact_surface': '[[Dragonfly]] is an instance of [[animal]]', 'answer': 'dragonfly', 'question': 'Which object in this image is a animal?', 'img_file': 'ILSVRC2012_test_00001551.JPEG', 'kb_source': 'conceptnet', 'fact': ['dragonfly', 'is a', 'animal'], 'question_id': '5070'}, '184': {'fact_surface': '[[a saxophone]] is used for [[playing music]]', 'answer': 'saxophone', 'question': 'What object in this image is used for playing music?', 'img_file': 'ILSVRC2012_test_00007902.JPEG', 'kb_source': 'conceptnet', 'fact': ['saxophone', 'used for', 'play music'], 'question_id': '938'}, '185': {'fact_surface': '[[boat]] is related to [[water vehicle]]', 'answer': 'boat', 'question': 'What water vehicle is depicted here?', 'img_file': 'COCO_val2014_000000023489.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'related to', 'water vehicle'], 'question_id': '931'}, '186': {'fact_surface': '[[snow]] belongs to the category of [[Cold]]', 'answer': 'cold', 'question': 'What can you feel in this weather?', 'img_file': 'COCO_val2014_000000106900.jpg', 'kb_source': 'dbpedia', 'fact': ['snow', 'belong to', 'cold'], 'question_id': '937'}, '187': {'fact_surface': '[[traffic light]] can [[stop cars]]', 'answer': 'traffic light', 'question': 'Which thing in the image stops the car?', 'img_file': 'COCO_val2014_000000128939.jpg', 'kb_source': 'conceptnet', 'fact': ['traffic light', 'capable of', 'stop car'], 'question_id': '936'}, '188': {'fact_surface': '(controller,/r/UsedFor,control TV)', 'answer': 'control tv', 'question': 'What is the device in the image used for>', 'img_file': 'COCO_val2014_000000101862.jpg', 'kb_source': 'conceptnet', 'fact': ['controller', 'used for', 'control tv'], 'question_id': '934'}, '189': {'fact_surface': '[[sheep]] is related to [[goat]]', 'answer': 'sheep', 'question': 'Which object in this image is related to goat?', 'img_file': 'COCO_val2014_000000003926.jpg', 'kb_source': 'conceptnet', 'fact': ['sheep', 'related to', 'goat'], 'question_id': '5380'}, '190': {'fact_surface': '[[lambskin]] is related to [[sheep]]', 'answer': 'sheep', 'question': 'Which animal in this image is related to lambskin?', 'img_file': 'COCO_val2014_000000003926.jpg', 'kb_source': 'conceptnet', 'fact': ['lambkin', 'related to', 'sheep'], 'question_id': '5381'}, '191': {'fact_surface': '[[sheep]] is related to [[woolly]]', 'answer': 'sheep', 'question': 'Which object in this image is related to  cream?', 'img_file': 'COCO_val2014_000000003926.jpg', 'kb_source': 'conceptnet', 'fact': ['sheep', 'related to', 'woolly'], 'question_id': '5382'}, '192': {'fact_surface': '[[shedhand]] is related to [[sheep]]', 'answer': 'sheep', 'question': 'what is it in this image is related to shedhand?', 'img_file': 'COCO_val2014_000000003926.jpg', 'kb_source': 'conceptnet', 'fact': ['shedhand', 'related to', 'sheep'], 'question_id': '5383'}, '193': {'fact_surface': 'Things that are often found together are [[computer]] and [[mouse]].', 'answer': 'computer', 'question': 'Which object in this image is related to mouse?', 'img_file': 'ILSVRC2012_test_00049049.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'related to', 'mouse'], 'question_id': '5387'}, '194': {'fact_surface': 'You can use [[a computer]] to [[write emails]]', 'answer': 'computer', 'question': 'Which object in this image can be used to write email?', 'img_file': 'ILSVRC2012_test_00049049.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'used for', 'write email'], 'question_id': '5388'}, '195': {'fact_surface': '[[laptop]] are typically more expensive than [[traditional desktop computer]]', 'answer': 'laptop', 'question': 'which object in this image is normally more expensive than desktop computer?', 'img_file': 'ILSVRC2012_test_00049049.JPEG', 'kb_source': 'webchild', 'fact': ['laptop', 'expensive', 'traditional desktop computer'], 'question_id': '5389'}, '196': {'fact_surface': '[[Wine]] is [[made from fermented grape juice]]', 'answer': 'wine', 'question': 'Which thing is made from fermented grape juice?', 'img_file': 'COCO_val2014_000000016382.jpg', 'kb_source': 'conceptnet', 'fact': ['wine', 'receives action', 'make from ferment grape juice'], 'question_id': '797'}, '197': {'fact_surface': '[[a frisbee]] is for [[the park]]', 'answer': 'park', 'question': 'normally where can you find this game?', 'img_file': 'COCO_val2014_000000122300.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'used for', 'park'], 'question_id': '796'}, '198': {'fact_surface': '[[Pineapple]] is [[grown in hawaii]]', 'answer': 'pineapple', 'question': 'Which object in this image is grown in hawaii', 'img_file': 'ILSVRC2012_test_00059970.JPEG', 'kb_source': 'conceptnet', 'fact': ['pineapple', 'receives action', 'grow in hawaii'], 'question_id': '795'}, '199': {'fact_surface': '[[pineapples]] are [[a sign of welcome in hawaii]]', 'answer': 'pineapple', 'question': 'Which object is a sign of welcome in hawaii', 'img_file': 'ILSVRC2012_test_00059970.JPEG', 'kb_source': 'conceptnet', 'fact': ['pineapple', 'is a', 'sign of welcome in hawaii'], 'question_id': '794'}, '200': {'fact_surface': '[[pineapple]] belongs to the category of [[Tropical flora]]', 'answer': 'pineapple', 'question': 'Which object in this image belongs to the category of tropical flora', 'img_file': 'ILSVRC2012_test_00059970.JPEG', 'kb_source': 'dbpedia', 'fact': ['pineapple', 'belong to', 'tropical flora'], 'question_id': '793'}, '201': {'fact_surface': '[[pineapple]] is related to [[hawaiian symbol]]', 'answer': 'pineapple', 'question': 'Which object in this image is related to hawaiian symbol', 'img_file': 'ILSVRC2012_test_00059970.JPEG', 'kb_source': 'conceptnet', 'fact': ['pineapple', 'related to', 'hawaiian symbol'], 'question_id': '792'}, '202': {'fact_surface': '[[Pineapples]] only [[grow in tropical or sub-tropical regions]]', 'answer': 'pineapple', 'question': 'Which food in this image can only grow in tropical or sub-tropical regions', 'img_file': 'ILSVRC2012_test_00059970.JPEG', 'kb_source': 'conceptnet', 'fact': ['pineapple', 'capable of', 'grow in tropical or sub tropical region'], 'question_id': '791'}, '203': {'fact_surface': '[[pineapple]] is related to [[spiky fruit]]', 'answer': 'pineapple', 'question': 'Which fruit in this image is spiky ', 'img_file': 'ILSVRC2012_test_00059970.JPEG', 'kb_source': 'conceptnet', 'fact': ['pineapple', 'related to', 'spiky fruit'], 'question_id': '790'}, '204': {'fact_surface': '[[plates]] belongs to the category of [[Kitchenware]]', 'answer': 'plate', 'question': 'Which object in this image belongs to the category Kitchenware?', 'img_file': 'ILSVRC2012_test_00044186.JPEG', 'kb_source': 'dbpedia', 'fact': ['plate', 'belong to', 'kitchenware'], 'question_id': '2145'}, '205': {'fact_surface': '[[a cello]] is [[like a violin but larger]]', 'answer': 'like violin but large', 'question': 'What is the difference between the instrument and the violin?', 'img_file': 'ILSVRC2012_test_00051257.JPEG', 'kb_source': 'conceptnet', 'fact': ['cello', 'has property', 'like violin but large'], 'question_id': '798'}, '206': {'fact_surface': '[[pomegranate]] belongs to the category of [[Fruit]]', 'answer': 'pomegranate', 'question': 'Which object in this image belongs to the category Fruit?', 'img_file': 'ILSVRC2012_test_00044186.JPEG', 'kb_source': 'dbpedia', 'fact': ['pomegranate', 'belong to', 'fruit'], 'question_id': '2144'}, '207': {'fact_surface': '[[pomegranate]] belongs to the category of [[Fruit]]', 'answer': 'pomegranate', 'question': 'Which object in this image belongs to the category Fruit?', 'img_file': 'ILSVRC2012_test_00044186.JPEG', 'kb_source': 'dbpedia', 'fact': ['pomegranate', 'belong to', 'fruit'], 'question_id': '2143'}, '208': {'fact_surface': '[[children]] belongs to the category of [[Humans]]', 'answer': 'child', 'question': 'Which small people in this image belong to the category Humans?', 'img_file': 'COCO_val2014_000000006954.jpg', 'kb_source': 'dbpedia', 'fact': ['child', 'belong to', 'human'], 'question_id': '1139'}, '209': {'fact_surface': '[[desk]] is related to [[office table]]', 'answer': 'desk', 'question': 'Which object in this image is a kind of office table?', 'img_file': 'ILSVRC2012_test_00020862.JPEG', 'kb_source': 'conceptnet', 'fact': ['desk', 'related to', 'office table'], 'question_id': '1133'}, '210': {'fact_surface': '[[a monitor]] can [[display images]].', 'answer': 'monitor', 'question': 'Which object in this image can display images?', 'img_file': 'ILSVRC2012_test_00020862.JPEG', 'kb_source': 'conceptnet', 'fact': ['monitor', 'capable of', 'display image'], 'question_id': '1132'}, '211': {'fact_surface': '[[Horse]] is an instance of [[living thing]]', 'answer': 'horse', 'question': 'Which object in this image is a live thing?', 'img_file': 'COCO_val2014_000000136285.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'is a', 'live thing'], 'question_id': '2419'}, '212': {'fact_surface': '[[baggage]] is related to [[luggage]]', 'answer': 'luggage', 'question': 'which object in this image is related to baggage?', 'img_file': 'COCO_val2014_000000115245.jpg', 'kb_source': 'conceptnet', 'fact': ['baggage', 'related to', 'luggage'], 'question_id': '4975'}, '213': {'fact_surface': '[[books]] contain [[written knowledge]]', 'answer': 'book', 'question': 'Which object in this image contains written knowledge?', 'img_file': 'COCO_val2014_000000008708.jpg', 'kb_source': 'conceptnet', 'fact': ['book', 'has a', 'write knowledge'], 'question_id': '1921'}, '214': {'fact_surface': '[[Books]] usually contain [[text]]', 'answer': 'book', 'question': 'Which object in this image usually contains text?', 'img_file': 'COCO_val2014_000000008708.jpg', 'kb_source': 'conceptnet', 'fact': ['book', 'has a', 'text'], 'question_id': '1922'}, '215': {'fact_surface': '[[wheel]] is part of [[a skateboard]]', 'answer': 'skateboard', 'question': 'Which object in this image has a wheel?', 'img_file': 'COCO_val2014_000000007977.jpg', 'kb_source': 'conceptnet', 'fact': ['wheel', 'part of', 'skateboard'], 'question_id': '4762'}, '216': {'fact_surface': '[[pineapples]] have [[spikey tops]]', 'answer': 'pineapple', 'question': 'Which object in this image has a spikey top', 'img_file': 'ILSVRC2012_test_00059970.JPEG', 'kb_source': 'conceptnet', 'fact': ['pineapple', 'has a', 'spikey top'], 'question_id': '4765'}, '217': {'fact_surface': '[[a luggage]] is used for [[carrying]]', 'answer': 'luggage', 'question': 'Which object in this image is used for carrying things?', 'img_file': 'COCO_val2014_000000130839.jpg', 'kb_source': 'conceptnet', 'fact': ['luggage', 'used for', 'carry'], 'question_id': '4766'}, '218': {'fact_surface': '[[bagage]] is related to [[luggage]]', 'answer': 'luggage', 'question': 'What object is related to bagage in this image?', 'img_file': 'COCO_val2014_000000137727.jpg', 'kb_source': 'conceptnet', 'fact': ['bagage', 'related to', 'luggage'], 'question_id': '4769'}, '219': {'fact_surface': '[[train]] are cheaper than [[flight]]', 'answer': 'train', 'question': 'Which object in this image usually  costs less than flight?', 'img_file': 'COCO_val2014_000000137727.jpg', 'kb_source': 'webchild', 'fact': ['train', 'cheap', 'flight'], 'question_id': '4768'}, '220': {'fact_surface': 'You are likely to find [[a keyboard]] in [[an office]]', 'answer': 'keyboard', 'question': 'What can be found in this office?', 'img_file': 'COCO_val2014_000000146805.jpg', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'at location', 'office'], 'question_id': '5809'}, '221': {'fact_surface': 'A [[desk]] is a [[modified table. tables are furniture]]', 'answer': 'desk', 'question': 'Which object in this image is a modify table for work?', 'img_file': 'COCO_val2014_000000146805.jpg', 'kb_source': 'conceptnet', 'fact': ['desk', 'is a', 'modify table table be furniture'], 'question_id': '5808'}, '222': {'fact_surface': '[[banana]] is a subclass of [[edible fruit]]', 'answer': 'banana', 'question': 'What object in this image is an edible fruit?', 'img_file': 'COCO_val2014_000000004749.jpg', 'kb_source': 'conceptnet', 'fact': ['banana', 'is a', 'edible fruit'], 'question_id': '5803'}, '223': {'fact_surface': '[[bowl]] belongs to the category of [[Kitchenware]]', 'answer': 'bowl', 'question': 'What item of kitchenware is in this image?', 'img_file': 'COCO_val2014_000000004749.jpg', 'kb_source': 'dbpedia', 'fact': ['bowl', 'belong to', 'kitchenware'], 'question_id': '5802'}, '224': {'fact_surface': '[[frisbee]] belongs to the category of [[Toy]]', 'answer': 'frisbee', 'question': 'Which object in this image belongs to the category Toy?', 'img_file': 'COCO_val2014_000000103579.jpg', 'kb_source': 'dbpedia', 'fact': ['frisbee', 'belong to', 'toy'], 'question_id': '5801'}, '225': {'fact_surface': '[[boomerang]] is related to [[frisbee]]', 'answer': 'frisbee', 'question': 'Which object in this image is related to boomerang?', 'img_file': 'COCO_val2014_000000103579.jpg', 'kb_source': 'conceptnet', 'fact': ['boomerang', 'related to', 'frisbee'], 'question_id': '5800'}, '226': {'fact_surface': '[[suit]] belongs to the category of [[Style]]', 'answer': 'suit', 'question': 'Which object in this image is related to style?', 'img_file': 'COCO_val2014_000000101948.jpg', 'kb_source': 'dbpedia', 'fact': ['suit', 'belong to', 'style'], 'question_id': '5807'}, '227': {'fact_surface': '[[suit]] is related to [[lawsuit]]', 'answer': 'suit', 'question': 'Which object in this image is related to lawsuit?', 'img_file': 'COCO_val2014_000000101948.jpg', 'kb_source': 'conceptnet', 'fact': ['suit', 'related to', 'lawsuit'], 'question_id': '5806'}, '228': {'fact_surface': '[[A person]] has [[emotional states]]', 'answer': 'person', 'question': 'Which object in this image has a emotional state', 'img_file': 'COCO_val2014_000000101948.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'has a', 'emotional state'], 'question_id': '5805'}, '229': {'fact_surface': '[[Frisbees]] are [[flat discs]]', 'answer': 'frisbee', 'question': 'What is the flat disc in this image called?', 'img_file': 'COCO_val2014_000000025057.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'is a', 'flat disc'], 'question_id': '5804'}, '230': {'fact_surface': '[[person]] can [[enjoy food]]', 'answer': 'person', 'question': 'Who in this image can enjoy food?', 'img_file': 'COCO_val2014_000000011449.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'enjoy food'], 'question_id': '1573'}, '231': {'fact_surface': '[[a harp]] is used for [[melody]]', 'answer': 'harp', 'question': 'Which object in this image can be used for melody?', 'img_file': 'ILSVRC2012_test_00050462.JPEG', 'kb_source': 'conceptnet', 'fact': ['harp', 'used for', 'melody'], 'question_id': '1577'}, '232': {'fact_surface': '[[people]] often [[carry suitcases when they travel]]', 'answer': 'person', 'question': 'Which object in this image often carries a suitcase when travelling?', 'img_file': 'ILSVRC2012_test_00000056.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'carry suitcase when they travel'], 'question_id': '4889'}, '233': {'fact_surface': '[[volleyball]] belongs to the category of [[Ball games]]', 'answer': 'volleyball', 'question': 'What types of Ball games is played in this image?', 'img_file': 'ILSVRC2012_test_00045885.JPEG', 'kb_source': 'dbpedia', 'fact': ['volleyball', 'belong to', 'ball games'], 'question_id': '2709'}, '234': {'fact_surface': '[[volleyball]] belongs to the category of [[Summer Olympic sports]]', 'answer': 'volleyball', 'question': 'What kind of action in Summer Olympic sports is depicted in this image', 'img_file': 'ILSVRC2012_test_00045885.JPEG', 'kb_source': 'dbpedia', 'fact': ['volleyball', 'belong to', 'summer olympic sports'], 'question_id': '2708'}, '235': {'fact_surface': '[[volleyball]] belongs to the category of [[Competitive games]]', 'answer': 'volleyball', 'question': 'Which object in this image belongs to the category Competitive games?', 'img_file': 'ILSVRC2012_test_00045885.JPEG', 'kb_source': 'dbpedia', 'fact': ['volleyball', 'belong to', 'competitive games'], 'question_id': '2706'}, '236': {'fact_surface': '[[A person]] may [[purchase an item using cash]]', 'answer': 'person', 'question': 'which object in this image is capable of purchasing an item with cash?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'purchase item use cash'], 'question_id': '2700'}, '237': {'fact_surface': '[[motorcycle]] belongs to the category of [[Electric vehicles]]', 'answer': 'motorcycle', 'question': 'Which object in this image belongs to the category Electric vehicles?', 'img_file': 'COCO_val2014_000000015596.jpg', 'kb_source': 'dbpedia', 'fact': ['motorcycle', 'belong to', 'electric vehicle'], 'question_id': '2703'}, '238': {'fact_surface': '[[Broccoli]] is [[green]]', 'answer': 'broccoli', 'question': 'What is the green vegetable on the plate?', 'img_file': 'ILSVRC2012_test_00000783.JPEG', 'kb_source': 'conceptnet', 'fact': ['broccoli', 'has property', 'green'], 'question_id': '475'}, '239': {'fact_surface': '[[lipstick]] is related to [[lip]]', 'answer': 'lipstick', 'question': 'Which object in this image is related to lip?', 'img_file': 'ILSVRC2012_test_00007810.JPEG', 'kb_source': 'conceptnet', 'fact': ['lipstick', 'related to', 'lip'], 'question_id': '3472'}, '240': {'fact_surface': '[[a piano]] can be used for [[playing music]]', 'answer': 'piano', 'question': 'Which thing is used for playing music?', 'img_file': 'ILSVRC2012_test_00030242.JPEG', 'kb_source': 'conceptnet', 'fact': ['piano', 'used for', 'play music'], 'question_id': '838'}, '241': {'fact_surface': 'A [[cat]] is a [[feline]]', 'answer': 'cat', 'question': 'which object in this image is a type of feline?', 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'is a', 'feline'], 'question_id': '5249'}, '242': {'fact_surface': '[[cats]] have [[sharp claws]]', 'answer': 'cat', 'question': 'which object in this image has sharp claws?', 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'has a', 'sharp claw'], 'question_id': '5248'}, '243': {'fact_surface': '[[motorcycle]] is related to [[ride]]', 'answer': 'motorcycle', 'question': 'Which object in this image can be ridden?', 'img_file': 'ILSVRC2012_test_00026467.JPEG', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'related to', 'ride'], 'question_id': '1729'}, '244': {'fact_surface': '[[Bows]] can be made by [[tying a certain knot]]', 'answer': 'bow', 'question': 'Which object in this image is created by tying a certain knot?', 'img_file': 'ILSVRC2012_test_00000208.JPEG', 'kb_source': 'conceptnet', 'fact': ['bow', 'created by', 'tie certain knot'], 'question_id': '1726'}, '245': {'fact_surface': 'A [[umbrella]] is a [[thing used to keep rain or sun off the person holding it]]', 'answer': 'umbrella', 'question': 'which object in this image is used to keep rain or sun off a person?', 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'is a', 'thing use to keep rain or sun off person hold it'], 'question_id': '5244'}, '246': {'fact_surface': '[[hair spray]] is a subclass of [[hair styling product]]', 'answer': 'hair spray', 'question': 'Which object in this image is a hair style product?', 'img_file': 'ILSVRC2012_test_00000208.JPEG', 'kb_source': 'conceptnet', 'fact': ['hair spray', 'is a', 'hair style product'], 'question_id': '1725'}, '247': {'fact_surface': '[[frisbee]] is for [[exercise]].', 'answer': 'frisbee', 'question': 'Which object in this image is for exercise?', 'img_file': 'COCO_val2014_000000128654.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'used for', 'exercise'], 'question_id': '1723'}, '248': {'fact_surface': '[[Zebras]] have [[stripes]]', 'answer': 'zebra', 'question': 'Which object in this image has stripes?', 'img_file': 'COCO_val2014_000000013948.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'stripe'], 'question_id': '1720'}, '249': {'fact_surface': '[[A pen]] can be used to [[create art]]', 'answer': 'pen', 'question': 'What in this image can be used to creat art?', 'img_file': 'ILSVRC2012_test_00016837.JPEG', 'kb_source': 'conceptnet', 'fact': ['pen', 'used for', 'create art'], 'question_id': '3001'}, '250': {'fact_surface': '[[wii]] belongs to the category of [[Electronic toys]]', 'answer': 'wii', 'question': 'Which object in the image  is an electronic toy?', 'img_file': 'COCO_val2014_000000109313.jpg', 'kb_source': 'dbpedia', 'fact': ['wii', 'belong to', 'electronic toys'], 'question_id': '1581'}, '251': {'fact_surface': 'You are likely to find [[rain]] in [[weather]].', 'answer': 'rain', 'question': 'What is the weather in the image?', 'img_file': 'COCO_val2014_000000007088.jpg', 'kb_source': 'conceptnet', 'fact': ['rain', 'at location', 'weather'], 'question_id': '1586'}, '252': {'fact_surface': '[[An umbrella]] is used to [[protect people from sun and rain]]', 'answer': 'umbrella', 'question': 'Which object in this image is used for protect person from rain?', 'img_file': 'COCO_val2014_000000007088.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'used for', 'protect person from sun and rain'], 'question_id': '1587'}, '253': {'fact_surface': '[[a luggage]] is for [[travelling]]', 'answer': 'luggage', 'question': 'what can we find on the desk', 'img_file': 'ILSVRC2012_test_00010551.JPEG', 'kb_source': 'conceptnet', 'fact': ['luggage', 'used for', 'travel'], 'question_id': '1584'}, '254': {'fact_surface': '[[backpack]] can be more comfortable than [[shoulder bag]]', 'answer': 'backpack', 'question': 'Which bag is more comfortable than a shoulder bag?', 'img_file': 'ILSVRC2012_test_00010551.JPEG', 'kb_source': 'webchild', 'fact': ['backpack', 'comfortable', 'shoulder bag'], 'question_id': '1585'}, '255': {'fact_surface': '[[Horses]] are [[faster than men]]', 'answer': 'horse', 'question': 'Which object in this image is faster than men?', 'img_file': 'COCO_val2014_000000020779.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'is a', 'fast than men'], 'question_id': '5658'}, '256': {'fact_surface': '[[horseriding]] is related to [[horse]]', 'answer': 'horse', 'question': 'which object in this image can you use to go horseriding?', 'img_file': 'COCO_val2014_000000020779.jpg', 'kb_source': 'conceptnet', 'fact': ['horseriding', 'related to', 'horse'], 'question_id': '5659'}, '257': {'fact_surface': '[[cars]] have [[seats in them]]', 'answer': 'car', 'question': 'What object has seats in them?', 'img_file': 'ILSVRC2012_test_00000912.JPEG', 'kb_source': 'conceptnet', 'fact': ['car', 'has a', 'seat in them'], 'question_id': '5656'}, '258': {'fact_surface': '[[parking lot]] absorb more solar radiation than [[grass]]', 'answer': 'grass', 'question': 'What absorbs less solar heat than the place shown in the image', 'img_file': 'ILSVRC2012_test_00000912.JPEG', 'kb_source': 'webchild', 'fact': ['parking lot', 'solar', 'grass'], 'question_id': '5657'}, '259': {'fact_surface': '[[bus]] still tends to be more common than [[rail]]', 'answer': 'bus', 'question': 'What mode of transport seen in this image is more common than rail?', 'img_file': 'COCO_val2014_000000105872.jpg', 'kb_source': 'webchild', 'fact': ['bus', 'common', 'rail'], 'question_id': '5654'}, '260': {'fact_surface': '[[bus]] is related to [[vehicle]]', 'answer': 'bus', 'question': 'What is the object in this image that is related to vehicles?', 'img_file': 'COCO_val2014_000000105872.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'related to', 'vehicle'], 'question_id': '5655'}, '261': {'fact_surface': '[[Cars]] usually have [[a spare tire]]', 'answer': 'car', 'question': 'What object in this image might have a spare tire?', 'img_file': 'COCO_val2014_000000108838.jpg', 'kb_source': 'conceptnet', 'fact': ['car', 'has a', 'spare tire'], 'question_id': '3287'}, '262': {'fact_surface': '(laptop,/r/CapableOf,browsing the internet)', 'answer': 'laptop', 'question': 'What object in this image is capable of browsing the internet?', 'img_file': 'COCO_val2014_000000106411.jpg', 'kb_source': 'conceptnet', 'fact': ['laptop', 'capable of', 'browsing the internet'], 'question_id': '216'}, '263': {'fact_surface': '[[umbrella]] is a kind of [[rain protection]]', 'answer': 'umbrella', 'question': 'What rain protection tool is used in the image?', 'img_file': 'COCO_val2014_000000007394.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'is a', 'rain protection'], 'question_id': '213'}, '264': {'fact_surface': '[[A bus]] can [[transport many people at once]]', 'answer': 'bus', 'question': 'What object in this image can transport multiple people at once?', 'img_file': 'COCO_val2014_000000101053.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'capable of', 'transport many person at once'], 'question_id': '210'}, '265': {'fact_surface': '[[bicycle]] has [[frame]].', 'answer': 'bicycle', 'question': 'Which object in this image has a frame?', 'img_file': 'COCO_val2014_000000108838.jpg', 'kb_source': 'conceptnet', 'fact': ['frame', 'part of', 'bicycle'], 'question_id': '3285'}, '266': {'fact_surface': '[[Apples]] can be [[red, yellow or green in color]]', 'answer': 'apple', 'question': 'Which object in this image has the color of red yellow or green?', 'img_file': 'COCO_val2014_000000104568.jpg', 'kb_source': 'conceptnet', 'fact': ['apple', 'has property', 'red yellow or green in color'], 'question_id': '3648'}, '267': {'fact_surface': '[[Cakes]] are often [[made for birthdays]]', 'answer': 'cake', 'question': 'Which food in this image is made for birthday?', 'img_file': 'COCO_val2014_000000150417.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'has property', 'make for birthday'], 'question_id': '3644'}, '268': {'fact_surface': '[[Dogs]] can [[smell food]]', 'answer': 'dog', 'question': 'Which object in this image is capable of smelling food?', 'img_file': 'COCO_val2014_000000125291.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'capable of', 'smell food'], 'question_id': '2550'}, '269': {'fact_surface': '[[a zebra]] has [[eyes]]', 'answer': 'zebra', 'question': 'what thing in this picture has eyes', 'img_file': 'COCO_val2014_000000009548.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'eye'], 'question_id': '2554'}, '270': {'fact_surface': '[[zebra]] belongs to the category of [[Animals]]', 'answer': 'zebra', 'question': 'Which object in this image belongs to the category Animals?', 'img_file': 'COCO_val2014_000000009548.jpg', 'kb_source': 'dbpedia', 'fact': ['zebra', 'belong to', 'animal'], 'question_id': '2555'}, '271': {'fact_surface': '[[Zebras]] have [[black and white stripes]]', 'answer': 'zebra', 'question': 'Which animals in this image have black and white stripes?', 'img_file': 'COCO_val2014_000000009548.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'black and white stripe'], 'question_id': '2556'}, '272': {'fact_surface': 'You are likely to find [[a cello]] in [[an orchestra]]', 'answer': 'cello', 'question': 'Which object in this image can be found in an orchestra?', 'img_file': 'ILSVRC2012_test_00005137.JPEG', 'kb_source': 'conceptnet', 'fact': ['cello', 'at location', 'orchestra'], 'question_id': '2557'}, '273': {'fact_surface': '[[A cello]] is like [[a big violin]]', 'answer': 'cello', 'question': 'Which object in this image is like a big violin?', 'img_file': 'ILSVRC2012_test_00005137.JPEG', 'kb_source': 'conceptnet', 'fact': ['cello', 'is a', 'big violin'], 'question_id': '2558'}, '274': {'fact_surface': '[[cello]] is a kind of [[stringed instrument]]', 'answer': 'cello', 'question': 'Which object in this image is a string instrument?', 'img_file': 'ILSVRC2012_test_00005137.JPEG', 'kb_source': 'conceptnet', 'fact': ['cello', 'is a', 'string instrument'], 'question_id': '2559'}, '275': {'fact_surface': '[[a saxophone]] is [[a common instrunment in jazz]]', 'answer': 'saxophone', 'question': 'Which object in this image is a common instrument in jazz?', 'img_file': 'ILSVRC2012_test_00000321.JPEG', 'kb_source': 'conceptnet', 'fact': ['saxophone', 'is a', 'common instrunment in jazz'], 'question_id': '5010'}, '276': {'fact_surface': '[[a saxophone]] is used for [[playing music]]', 'answer': 'saxophone', 'question': 'Which object in this image is used for playing music?', 'img_file': 'ILSVRC2012_test_00000321.JPEG', 'kb_source': 'conceptnet', 'fact': ['saxophone', 'used for', 'play music'], 'question_id': '5011'}, '277': {'fact_surface': '[[a car]] is [[heavier than a horse]]', 'answer': 'car', 'question': 'Which object in this image is heavier than a horse ?', 'img_file': 'COCO_val2014_000000124462.jpg', 'kb_source': 'conceptnet', 'fact': ['car', 'is a', 'heavy than horse'], 'question_id': '5014'}, '278': {'fact_surface': '*Something you find on [[the surface of the earth]] is [[sand]]', 'answer': 'sand', 'question': 'What can be found on the surface of the earth?', 'img_file': 'ILSVRC2012_test_00008428.JPEG', 'kb_source': 'conceptnet', 'fact': ['sand', 'at location', 'surface of earth'], 'question_id': '5017'}, '279': {'fact_surface': '[[sand]] is [[difficult to walk in]]', 'answer': 'sand', 'question': 'What surface in the image difficult to walk in?', 'img_file': 'ILSVRC2012_test_00008428.JPEG', 'kb_source': 'conceptnet', 'fact': ['sand', 'has property', 'difficult to walk in'], 'question_id': '5018'}, '280': {'fact_surface': '[[A banana]] has [[a peel]]', 'answer': 'banana', 'question': 'What in this image has peel?', 'img_file': 'COCO_val2014_000000130875.jpg', 'kb_source': 'conceptnet', 'fact': ['banana', 'has a', 'peel'], 'question_id': '5019'}, '281': {'fact_surface': '[[horses]] may be [[dangerous]]', 'answer': 'horse', 'question': 'which object in this image may be dangerous to human', 'img_file': 'COCO_val2014_000000132554.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'has property', 'dangerous'], 'question_id': '4417'}, '282': {'fact_surface': '[[horses]] like to [[graze in pastures]]', 'answer': 'horse', 'question': 'Which object in this image likes to graze in pasture?', 'img_file': 'COCO_val2014_000000132554.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'desires', 'graze in pasture'], 'question_id': '4416'}, '283': {'fact_surface': '[[a bowl]] is used for [[eating soup]]', 'answer': 'bowl', 'question': 'which object in this image can we used for eating soup', 'img_file': 'COCO_val2014_000000101456.jpg', 'kb_source': 'conceptnet', 'fact': ['bowl', 'used for', 'eat soup'], 'question_id': '4412'}, '284': {'fact_surface': '[[camel]] belongs to the category of [[Islamism]]', 'answer': 'camel', 'question': 'Which animal in the image is highly related to Islamism?', 'img_file': 'ILSVRC2012_test_00017725.JPEG', 'kb_source': 'dbpedia', 'fact': ['camel', 'belong to', 'islamism'], 'question_id': '918'}, '285': {'fact_surface': '[[Broccoli]] is [[a green vegetable]]', 'answer': 'broccoli', 'question': 'What green vegetable is in this picture?', 'img_file': 'COCO_val2014_000000106150.jpg', 'kb_source': 'conceptnet', 'fact': ['broccoli', 'is a', 'green vegetable'], 'question_id': '914'}, '286': {'fact_surface': 'You are likely to find [[a camel]] in [[the desert]]', 'answer': 'desert', 'question': 'Where you can find the animal in this image?', 'img_file': 'ILSVRC2012_test_00017725.JPEG', 'kb_source': 'conceptnet', 'fact': ['camel', 'at location', 'desert'], 'question_id': '917'}, '287': {'fact_surface': '[[an airport]] is for [[airplanes]]', 'answer': 'airplane', 'question': 'What is this place used for?', 'img_file': 'COCO_val2014_000000006864.jpg', 'kb_source': 'conceptnet', 'fact': ['airport', 'used for', 'airplane'], 'question_id': '916'}, '288': {'fact_surface': '[[trombone]] is related to [[long]]', 'answer': 'trombone', 'question': 'Which object in this image is related to long?', 'img_file': 'ILSVRC2012_test_00000499.JPEG', 'kb_source': 'conceptnet', 'fact': ['trombone', 'related to', 'long'], 'question_id': '910'}, '289': {'fact_surface': '[[squirrels]] can [[store nuts]]', 'answer': 'squirrel', 'question': 'Which animal in this image is able to store nuts', 'img_file': 'COCO_val2014_000000015070.jpg', 'kb_source': 'conceptnet', 'fact': ['squirrel', 'capable of', 'store nut'], 'question_id': '630'}, '290': {'fact_surface': '[[squirrels]] can [[store nuts for the winter]]', 'answer': 'squirrel', 'question': 'Which animal is capable of storing nuts for the winter', 'img_file': 'COCO_val2014_000000015070.jpg', 'kb_source': 'conceptnet', 'fact': ['squirrel', 'capable of', 'store nut for winter'], 'question_id': '631'}, '291': {'fact_surface': '*Something you find in [[a forest]] is [[a squirrel]]', 'answer': 'squirrel', 'question': 'Which animal in this image can be found in a forest', 'img_file': 'COCO_val2014_000000015070.jpg', 'kb_source': 'conceptnet', 'fact': ['squirrel', 'at location', 'forest'], 'question_id': '633'}, '292': {'fact_surface': 'A [[bread]] is a [[type of food]].', 'answer': 'bread', 'question': 'Which object in this image is a type of food?', 'img_file': 'COCO_val2014_000000131841.jpg', 'kb_source': 'conceptnet', 'fact': ['bread', 'is a', 'type of food'], 'question_id': '1111'}, '293': {'fact_surface': 'A [[bread]] is a [[type of food]].', 'answer': 'bread', 'question': 'Which object in this image is a type of food?', 'img_file': 'COCO_val2014_000000131841.jpg', 'kb_source': 'conceptnet', 'fact': ['bread', 'is a', 'type of food'], 'question_id': '1110'}, '294': {'fact_surface': 'A [[bread]] is a [[type of food]].', 'answer': 'bread', 'question': 'Which object in this image is a type of food?', 'img_file': 'COCO_val2014_000000131841.jpg', 'kb_source': 'conceptnet', 'fact': ['bread', 'is a', 'type of food'], 'question_id': '1113'}, '295': {'fact_surface': 'A [[bread]] is a [[type of food]].', 'answer': 'bread', 'question': 'Which object in this image is a type of food?', 'img_file': 'COCO_val2014_000000131841.jpg', 'kb_source': 'conceptnet', 'fact': ['bread', 'is a', 'type of food'], 'question_id': '1112'}, '296': {'fact_surface': '[[forks]] can be used for [[eating solid food]]', 'answer': 'fork', 'question': 'Which object in this image is used for eating?', 'img_file': 'COCO_val2014_000000131841.jpg', 'kb_source': 'conceptnet', 'fact': ['fork', 'used for', 'eat solid food'], 'question_id': '1115'}, '297': {'fact_surface': 'A [[bread]] is a [[type of food]].', 'answer': 'bread', 'question': 'Which object in this image is a type of food?', 'img_file': 'COCO_val2014_000000131841.jpg', 'kb_source': 'conceptnet', 'fact': ['bread', 'is a', 'type of food'], 'question_id': '1114'}, '298': {'fact_surface': 'Kinds of [[pastry]] : [[cake]]', 'answer': 'cake', 'question': 'Which object in this image is a kind of pastry?', 'img_file': 'COCO_val2014_000000131841.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'is a', 'pastry'], 'question_id': '1116'}, '299': {'fact_surface': '[[a helmet]] is used to [[protect your head]]', 'answer': 'helmet', 'question': \"￼Which object in this image is used for protecting one's head?\", 'img_file': 'COCO_val2014_000000004021.jpg', 'kb_source': 'conceptnet', 'fact': ['helmet', 'used for', 'protect your head'], 'question_id': '4859'}, '300': {'fact_surface': 'You can use [[a frisbee]] to [[catch and throw back]]', 'answer': 'frisbee', 'question': 'Which object in this image is used for catching and throwing?', 'img_file': 'COCO_val2014_000000134459.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'used for', 'catch and throw back'], 'question_id': '4857'}, '301': {'fact_surface': '[[Frisbee]] is related to [[boomerang]]', 'answer': 'frisbee', 'question': 'Which object in this image is related to boomerang?', 'img_file': 'COCO_val2014_000000134459.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'related to', 'boomerang'], 'question_id': '4856'}, '302': {'fact_surface': '[[a frisbee]] is [[an aerodynamic toy disc]]', 'answer': 'frisbee', 'question': 'Which object in this image is an aerodynamic toy disc?', 'img_file': 'COCO_val2014_000000134459.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'is a', 'aerodynamic toy disc'], 'question_id': '4855'}, '303': {'fact_surface': '[[snowmobile]] belongs to the category of [[Vehicles by type]]', 'answer': 'snowmobile', 'question': 'What vehicle is shown in this image?', 'img_file': 'ILSVRC2012_test_00004836.JPEG', 'kb_source': 'dbpedia', 'fact': ['snowmobile', 'belong to', 'vehicles by type'], 'question_id': '2009'}, '304': {'fact_surface': '[[broccoli]] belongs to the category of [[Food and drink]]', 'answer': 'broccoli', 'question': 'What object in this image is used for food?', 'img_file': 'COCO_val2014_000000142500.jpg', 'kb_source': 'dbpedia', 'fact': ['broccoli', 'belong to', 'food and drink'], 'question_id': '4853'}, '305': {'fact_surface': '[[lemon]] belongs to the category of [[Citrus]]', 'answer': 'lemon', 'question': 'Which citrus fruit can you see in this image?', 'img_file': 'ILSVRC2012_test_00027003.JPEG', 'kb_source': 'dbpedia', 'fact': ['lemon', 'belong to', 'citrus'], 'question_id': '4724'}, '306': {'fact_surface': '[[x ray]] are more energetic than [[microwave]]', 'answer': 'microwave', 'question': 'which object in this image is less energetic than x ray?', 'img_file': 'ILSVRC2012_test_00054961.JPEG', 'kb_source': 'webchild', 'fact': ['x ray', 'energetic', 'microwave'], 'question_id': '2307'}, '307': {'fact_surface': '[[bus]] are a little slower than [[car]]', 'answer': 'bus', 'question': 'which object in this image is slower than car?', 'img_file': 'COCO_val2014_000000138601.jpg', 'kb_source': 'webchild', 'fact': ['bus', 'slow', 'car'], 'question_id': '5821'}, '308': {'fact_surface': '[[bus]] may be slower than [[plane]]', 'answer': 'plane', 'question': 'Which vehicle is faster than the object on the right of this image?', 'img_file': 'COCO_val2014_000000138601.jpg', 'kb_source': 'webchild', 'fact': ['bus', 'slow', 'plane'], 'question_id': '5820'}, '309': {'fact_surface': '[[banjo]] belongs to the category of [[Music]]', 'answer': 'banjo', 'question': 'Which object is related to music?', 'img_file': 'ILSVRC2012_test_00056081.JPEG', 'kb_source': 'dbpedia', 'fact': ['banjo', 'belong to', 'music'], 'question_id': '1182'}, '310': {'fact_surface': '[[fire hydrant]] belongs to the category of [[Streets]]', 'answer': 'street', 'question': 'Normally where can you find the object in the middle?', 'img_file': 'COCO_val2014_000000147338.jpg', 'kb_source': 'dbpedia', 'fact': ['fire hydrant', 'belong to', 'street'], 'question_id': '197'}, '311': {'fact_surface': '[[A unicycle]] only has [[one wheel]]', 'answer': 'unicycle', 'question': 'Which object in this image only has one wheel', 'img_file': 'ILSVRC2012_test_00035105.JPEG', 'kb_source': 'conceptnet', 'fact': ['unicycle', 'has a', 'one wheel'], 'question_id': '191'}, '312': {'fact_surface': '[[accordion]] belongs to the category of [[Musical instrument]]', 'answer': 'accordion', 'question': 'Tell me the name of the musical instrument shown in this image', 'img_file': 'ILSVRC2012_test_00040602.JPEG', 'kb_source': 'dbpedia', 'fact': ['accordion', 'belong to', 'musical instrument'], 'question_id': '190'}, '313': {'fact_surface': '[[scissors]] belongs to the category of [[Cutting]]', 'answer': 'cut', 'question': 'Why the man is holding a scissor?', 'img_file': 'COCO_val2014_000000013783.jpg', 'kb_source': 'dbpedia', 'fact': ['scissors', 'belong to', 'cut'], 'question_id': '193'}, '314': {'fact_surface': '[[sheep]] is related to [[like cloud]]', 'answer': 'sheep', 'question': 'What thing in the image looks like cloud?', 'img_file': 'COCO_val2014_000000139512.jpg', 'kb_source': 'conceptnet', 'fact': ['sheep', 'related to', 'like cloud'], 'question_id': '192'}, '315': {'fact_surface': '[[chair]] is related to [[sit]]', 'answer': 'chair', 'question': 'Which object in this image is for sitting?', 'img_file': 'COCO_val2014_000000117899.jpg', 'kb_source': 'conceptnet', 'fact': ['chair', 'related to', 'it'], 'question_id': '1183'}, '316': {'fact_surface': '[[teddy bears]] can be used to [[please little children]]', 'answer': 'teddy bear', 'question': 'Which object in this image can please little children?', 'img_file': 'COCO_val2014_000000017769.jpg', 'kb_source': 'conceptnet', 'fact': ['teddy bear', 'used for', 'please little child'], 'question_id': '3453'}, '317': {'fact_surface': '[[skateboarding]] is related to [[skateboarder]]', 'answer': 'skateboard', 'question': 'what is the skatboarder in this image doing?', 'img_file': 'COCO_val2014_000000008589.jpg', 'kb_source': 'conceptnet', 'fact': ['skateboard', 'related to', 'skateboard'], 'question_id': '3451'}, '318': {'fact_surface': '[[Oceans]] contain [[salt water]]', 'answer': 'water', 'question': 'which thing does the place shown in this image have as a part?', 'img_file': 'ILSVRC2012_test_00002037.JPEG', 'kb_source': 'conceptnet', 'fact': ['ocean', 'has a', 'water'], 'question_id': '3456'}, '319': {'fact_surface': '[[driving]] is more accurate than [[drunk driving]]', 'answer': 'driving', 'question': 'Which link is less accurate than the action shown in this image', 'img_file': 'ILSVRC2012_test_00002037.JPEG', 'kb_source': 'webchild', 'fact': ['driving', 'accurate', 'drunk driving'], 'question_id': '3457'}, '320': {'fact_surface': 'You are likely to find [[ocean]] in [[New York]].', 'answer': 'ocean', 'question': 'what can you find in this image?', 'img_file': 'ILSVRC2012_test_00002037.JPEG', 'kb_source': 'conceptnet', 'fact': ['ocean', 'at location', 'new york'], 'question_id': '3454'}, '321': {'fact_surface': '[[water]] is so much heavier than [[air]]', 'answer': 'water', 'question': 'what  is heavier than air in this image', 'img_file': 'ILSVRC2012_test_00002037.JPEG', 'kb_source': 'webchild', 'fact': ['water', 'heavy', 'air'], 'question_id': '3455'}, '322': {'fact_surface': '[[water]] is thicker than [[door]]', 'answer': 'water', 'question': 'what in this image is thicker than door?', 'img_file': 'ILSVRC2012_test_00002037.JPEG', 'kb_source': 'webchild', 'fact': ['water', 'thick', 'door'], 'question_id': '3458'}, '323': {'fact_surface': '[[glue]] is thicker than [[water]]', 'answer': 'water', 'question': 'what in this image is less thick than glue?', 'img_file': 'ILSVRC2012_test_00002037.JPEG', 'kb_source': 'webchild', 'fact': ['glue', 'thick', 'water'], 'question_id': '3459'}, '324': {'fact_surface': '[[A tree]] has [[roots]]', 'answer': 'tree', 'question': 'Which things in this image have roots?', 'img_file': 'COCO_val2014_000000025747.jpg', 'kb_source': 'conceptnet', 'fact': ['tree', 'has a', 'root'], 'question_id': '6'}, '325': {'fact_surface': '[[position]] work better than [[standing]]', 'answer': 'position', 'question': 'Which action is better than the action shown in this image', 'img_file': 'COCO_val2014_000000009175.jpg', 'kb_source': 'webchild', 'fact': ['position', 'good', 'standing'], 'question_id': '5223'}, '326': {'fact_surface': '[[position]] work better than [[standing]]', 'answer': 'position', 'question': 'Which action is better than the action shown in this image', 'img_file': 'COCO_val2014_000000009175.jpg', 'kb_source': 'webchild', 'fact': ['position', 'good', 'standing'], 'question_id': '5222'}, '327': {'fact_surface': '*Something you find at [[sea]] is [[dolphins]]', 'answer': 'dolphin', 'question': 'What can be found in this place?', 'img_file': 'ILSVRC2012_test_00000352.JPEG', 'kb_source': 'conceptnet', 'fact': ['dolphin', 'at location', 'sea'], 'question_id': '5225'}, '328': {'fact_surface': 'An [[cell phone]] can [[make a call]].', 'answer': 'cell phone', 'question': '￼Which object in this image can be used to make a call?', 'img_file': 'COCO_val2014_000000009729.jpg', 'kb_source': 'conceptnet', 'fact': ['cell phone', 'capable of', 'make call'], 'question_id': '5224'}, '329': {'fact_surface': 'Somewhere [[a dog]] can be is [[the floor]].', 'answer': 'dog', 'question': 'Which object in this image can be found in floor?', 'img_file': 'ILSVRC2012_test_00055801.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'at location', 'floor'], 'question_id': '3067'}, '330': {'fact_surface': 'Somewhere [[a dog]] can be is [[the floor]].', 'answer': 'dog', 'question': 'Which object in this image can be found in floor?', 'img_file': 'ILSVRC2012_test_00055801.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'at location', 'floor'], 'question_id': '3066'}, '331': {'fact_surface': 'Somewhere [[a dog]] can be is [[the floor]].', 'answer': 'dog', 'question': 'Which object in this image can be found in floor?', 'img_file': 'ILSVRC2012_test_00055801.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'at location', 'floor'], 'question_id': '3065'}, '332': {'fact_surface': '[[backpack]] is related to [[strap]]', 'answer': 'backpack', 'question': 'What object in this image has straps?', 'img_file': 'ILSVRC2012_test_00000449.JPEG', 'kb_source': 'conceptnet', 'fact': ['backpack', 'related to', 'trap'], 'question_id': '3064'}, '333': {'fact_surface': 'Somewhere [[a dog]] can be is [[the floor]].', 'answer': 'dog', 'question': 'Which object in this image can be found in floor?', 'img_file': 'ILSVRC2012_test_00055801.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'at location', 'floor'], 'question_id': '3069'}, '334': {'fact_surface': 'Somewhere [[a dog]] can be is [[the floor]].', 'answer': 'dog', 'question': 'Which object in this image can be found in floor?', 'img_file': 'ILSVRC2012_test_00055801.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'at location', 'floor'], 'question_id': '3068'}, '335': {'fact_surface': 'Kinds of [[animals]] : [[elephant]]', 'answer': 'elephant', 'question': 'what is the name of the animal in this image?', 'img_file': 'COCO_val2014_000000002315.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'is a', 'animal'], 'question_id': '1304'}, '336': {'fact_surface': '[[kitchen]] has [[light]].', 'answer': 'light', 'question': 'what can you often find in the place shown in this picture', 'img_file': 'ILSVRC2012_test_00028847.JPEG', 'kb_source': 'conceptnet', 'fact': ['light', 'part of', 'kitchen'], 'question_id': '1305'}, '337': {'fact_surface': '[[bell pepper]] belongs to the category of [[Spices]]', 'answer': 'bell pepper', 'question': 'Which object in this image belongs to the category Spices?', 'img_file': 'ILSVRC2012_test_00043794.JPEG', 'kb_source': 'dbpedia', 'fact': ['bell pepper', 'belong to', 'spice'], 'question_id': '1307'}, '338': {'fact_surface': '[[elephant]] are slower than [[horse]]', 'answer': 'horse', 'question': 'what animal is faster than the animal in this image', 'img_file': 'COCO_val2014_000000002315.jpg', 'kb_source': 'webchild', 'fact': ['elephant', 'slow', 'horse'], 'question_id': '1303'}, '339': {'fact_surface': '[[Bell pepper]] is an instance of [[greenery]]', 'answer': 'bell pepper', 'question': 'Which object in this image belongs to greenery?', 'img_file': 'ILSVRC2012_test_00043794.JPEG', 'kb_source': 'conceptnet', 'fact': ['bell pepper', 'is a', 'greenery'], 'question_id': '1308'}, '340': {'fact_surface': '[[soccer balls]] are [[spherical]]', 'answer': 'soccer ball', 'question': 'Which object in this image is spherical?', 'img_file': 'ILSVRC2012_test_00042528.JPEG', 'kb_source': 'conceptnet', 'fact': ['soccer ball', 'has property', 'spherical'], 'question_id': '1309'}, '341': {'fact_surface': 'Something you might find [[a bedroom]] is [[lamp]].', 'answer': 'lamp', 'question': 'what object in this image can be found in a bedroom?', 'img_file': 'COCO_val2014_000000122954.jpg', 'kb_source': 'conceptnet', 'fact': ['lamp', 'at location', 'bedroom'], 'question_id': '498'}, '342': {'fact_surface': 'A [[refrigerator]] is a [[machine that keeps food cold]]', 'answer': 'refrigerator', 'question': 'Which device in the image can keeps things cold?', 'img_file': 'COCO_val2014_000000122954.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'is a', 'machine that keep food cold'], 'question_id': '499'}, '343': {'fact_surface': '(scooter,/r/UsedFor,ride)', 'answer': 'ride', 'question': 'What is a scooter used for', 'img_file': 'ILSVRC2012_test_00045346.JPEG', 'kb_source': 'conceptnet', 'fact': ['scooter', 'used for', 'ride'], 'question_id': '496'}, '344': {'fact_surface': 'You can use [[a frisbee]] to [[play with your dog]]', 'answer': 'dog', 'question': 'Normally you play this game with your?', 'img_file': 'COCO_val2014_000000100238.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'used for', 'dog'], 'question_id': '490'}, '345': {'fact_surface': '[[teddy bear]] is a subclass of [[stuffed animal]]', 'answer': 'teddy bear', 'question': 'What is the stuffed animal in the middle?', 'img_file': 'COCO_val2014_000000134688.jpg', 'kb_source': 'conceptnet', 'fact': ['teddy bear', 'is a', 'stuff animal'], 'question_id': '491'}, '346': {'fact_surface': '[[Broccoli]] is [[a green vegetable]]', 'answer': 'broccoli', 'question': 'What is the green vegetable in the bowl?', 'img_file': 'COCO_val2014_000000123321.jpg', 'kb_source': 'conceptnet', 'fact': ['broccoli', 'is a', 'green vegetable'], 'question_id': '493'}, '347': {'fact_surface': '[[skis]] belongs to the category of [[Outdoor recreation]]', 'answer': 'ski', 'question': 'Which object in this image belongs to the category Outdoor recreation?', 'img_file': 'COCO_val2014_000000104453.jpg', 'kb_source': 'dbpedia', 'fact': ['ski', 'belong to', 'outdoor recreation'], 'question_id': '3935'}, '348': {'fact_surface': '[[human]] live a lot longer than [[dog]]', 'answer': 'dog', 'question': 'which object in this image is less long than human?', 'img_file': 'COCO_val2014_000000121443.jpg', 'kb_source': 'webchild', 'fact': ['human', 'long', 'dog'], 'question_id': '3931'}, '349': {'fact_surface': '[[bicycles]] are for [[having races]]', 'answer': 'bicycle', 'question': 'Which object in this image might be used for having races?', 'img_file': 'COCO_val2014_000000017244.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'is a', 'have race'], 'question_id': '3930'}, '350': {'fact_surface': '[[laptop]] are more convenient than [[desktop]]', 'answer': 'laptop', 'question': 'Which object in this image is more convenient than a desktop computer?', 'img_file': 'COCO_val2014_000000021361.jpg', 'kb_source': 'webchild', 'fact': ['laptop', 'convenient', 'desktop'], 'question_id': '3933'}, '351': {'fact_surface': '[[teddy bears]] are [[a popular toy]]', 'answer': 'teddy bear', 'question': 'Which object in this image is a popular toy?', 'img_file': 'COCO_val2014_000000021361.jpg', 'kb_source': 'conceptnet', 'fact': ['teddy bear', 'is a', 'popular toy'], 'question_id': '3932'}, '352': {'fact_surface': 'You are likely to find [[sofa]] on [[a living room]].', 'answer': 'sofa', 'question': 'what in this image can be found in live room?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'at location', 'live room'], 'question_id': '1241'}, '353': {'fact_surface': '[[Airports]] have [[runways]]', 'answer': 'runway', 'question': 'What thing does the place shown in this image have as a part?', 'img_file': 'COCO_val2014_000000126659.jpg', 'kb_source': 'conceptnet', 'fact': ['airport', 'has a', 'runway'], 'question_id': '3265'}, '354': {'fact_surface': '[[pizza]] belongs to the category of [[Italian design]]', 'answer': 'pizza', 'question': 'Which object in this image is of Italian design?', 'img_file': 'ILSVRC2012_test_00019587.JPEG', 'kb_source': 'dbpedia', 'fact': ['pizza', 'belong to', 'italian design'], 'question_id': '3665'}, '355': {'fact_surface': '[[water]] is obviously less expensive than [[beef]]', 'answer': 'water', 'question': 'which object in this image is less expensive than beef?', 'img_file': 'COCO_val2014_000000021588.jpg', 'kb_source': 'webchild', 'fact': ['water', 'expensive', 'beef'], 'question_id': '3667'}, '356': {'fact_surface': '[[pizza]] belongs to the category of [[Foods]]', 'answer': 'pizza', 'question': 'Which round object in the images belongs to the category food?', 'img_file': 'ILSVRC2012_test_00019587.JPEG', 'kb_source': 'dbpedia', 'fact': ['pizza', 'belong to', 'food'], 'question_id': '3666'}, '357': {'fact_surface': '[[a person]] can [[butter his morning toast]]', 'answer': 'person', 'question': 'Which object in this image is capable of buttering his morning toast?', 'img_file': 'ILSVRC2012_test_00058260.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'butter his morning toast'], 'question_id': '3661'}, '358': {'fact_surface': '[[wine glass]] is related to [[glass]]', 'answer': 'wine glass', 'question': 'which object in this image is related to glass?', 'img_file': 'COCO_val2014_000000003595.jpg', 'kb_source': 'conceptnet', 'fact': ['wine glass', 'related to', 'glass'], 'question_id': '3660'}, '359': {'fact_surface': '[[Cats]] like to [[jump up on furniture and explore]]', 'answer': 'cat', 'question': 'What thing, shown in this image, often likes to jump up on furniture and explore?', 'img_file': 'COCO_val2014_000000009807.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'desires', 'jump up on furniture and explore'], 'question_id': '3663'}, '360': {'fact_surface': '[[racquet]] belongs to the category of [[Tennis]]', 'answer': 'racquet', 'question': 'Which object in this image belongs to the category Tennis?', 'img_file': 'ILSVRC2012_test_00058260.JPEG', 'kb_source': 'dbpedia', 'fact': ['racquet', 'belong to', 'tennis'], 'question_id': '3662'}, '361': {'fact_surface': '[[motorcycle]] are lighter than [[car]]', 'answer': 'motorcycle', 'question': 'Which one is lighter? Car or the vehicle in the image?', 'img_file': 'COCO_val2014_000000102497.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'light', 'car'], 'question_id': '3669'}, '362': {'fact_surface': '[[helmet]] is related to [[head]]', 'answer': 'helmet', 'question': 'Which object in this image is related to head?', 'img_file': 'COCO_val2014_000000102497.jpg', 'kb_source': 'conceptnet', 'fact': ['helmet', 'related to', 'head'], 'question_id': '3668'}, '363': {'fact_surface': '[[truck]] is [[a vehicle type]]', 'answer': 'truck', 'question': 'what object in this image is a type of vehicle?', 'img_file': 'COCO_val2014_000000149364.jpg', 'kb_source': 'conceptnet', 'fact': ['truck', 'is a', 'vehicle type'], 'question_id': '3593'}, '364': {'fact_surface': '[[truck]] is [[a vehicle type]]', 'answer': 'truck', 'question': 'what object in this image is a type of vehicle?', 'img_file': 'COCO_val2014_000000149364.jpg', 'kb_source': 'conceptnet', 'fact': ['truck', 'is a', 'vehicle type'], 'question_id': '3592'}, '365': {'fact_surface': '[[Trucks]] can [[deliver computers]]', 'answer': 'truck', 'question': 'what object in this image can deliver computers?', 'img_file': 'COCO_val2014_000000149364.jpg', 'kb_source': 'conceptnet', 'fact': ['truck', 'capable of', 'deliver computer'], 'question_id': '3591'}, '366': {'fact_surface': '[[rugby ball]] belongs to the category of [[Sports originating in England]]', 'answer': 'rugby ball', 'question': 'Which object in this image belongs to the category Sports originating in England?', 'img_file': 'ILSVRC2012_test_00025041.JPEG', 'kb_source': 'dbpedia', 'fact': ['rugby ball', 'belong to', 'sports originating in england'], 'question_id': '3590'}, '367': {'fact_surface': '[[horse]] walk faster than [[cow]]', 'answer': 'cow', 'question': 'Which animal in this image is slower than a horse?', 'img_file': 'ILSVRC2012_test_00057899.JPEG', 'kb_source': 'webchild', 'fact': ['horse', 'fast', 'cow'], 'question_id': '3597'}, '368': {'fact_surface': '[[goat]] are smaller than [[cow]]', 'answer': 'cow', 'question': 'which animal in this image is less small than goat?', 'img_file': 'ILSVRC2012_test_00057899.JPEG', 'kb_source': 'webchild', 'fact': ['goat', 'small', 'cow'], 'question_id': '3596'}, '369': {'fact_surface': '[[goat]] are smaller than [[cow]]', 'answer': 'cow', 'question': 'which animal in this image is less small than goat?', 'img_file': 'ILSVRC2012_test_00057899.JPEG', 'kb_source': 'webchild', 'fact': ['goat', 'small', 'cow'], 'question_id': '3595'}, '370': {'fact_surface': '[[truck]] belongs to the category of [[Commercial vehicles]]', 'answer': 'truck', 'question': 'Which object in this image belongs to the category Commercial vehicles? ', 'img_file': 'COCO_val2014_000000149364.jpg', 'kb_source': 'dbpedia', 'fact': ['truck', 'belong to', 'commercial vehicles'], 'question_id': '3594'}, '371': {'fact_surface': '[[a hotel room]] can be used for [[temporary residence]]', 'answer': 'temporary residence', 'question': 'What is this place used for?', 'img_file': 'COCO_val2014_000000132121.jpg', 'kb_source': 'conceptnet', 'fact': ['hotel room', 'used for', 'temporary residence'], 'question_id': '5034'}, '372': {'fact_surface': '[[Bedrooms]] usually have [[beds]]', 'answer': 'bed', 'question': \"what's shown in the left part of the image\", 'img_file': 'COCO_val2014_000000132121.jpg', 'kb_source': 'conceptnet', 'fact': ['bedroom', 'has a', 'bed'], 'question_id': '5035'}, '373': {'fact_surface': '[[a bottle]] is used for [[storing liquid]]', 'answer': 'bottle', 'question': 'What is used for storing liquid in this image?', 'img_file': 'COCO_val2014_000000008876.jpg', 'kb_source': 'conceptnet', 'fact': ['bottle', 'used for', 'store liquid'], 'question_id': '4437'}, '374': {'fact_surface': '[[giraffe]] is [[long-necked]].', 'answer': 'giraffe', 'question': 'Which animal in the image has a long neck?', 'img_file': 'COCO_val2014_000000138821.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'has property', 'long neck'], 'question_id': '4430'}, '375': {'fact_surface': 'When you want to [[program]], you will use [[computer]].', 'answer': 'computer', 'question': 'What do you need to program?', 'img_file': 'ILSVRC2012_test_00021967.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'used for', 'program'], 'question_id': '4439'}, '376': {'fact_surface': '[[wine]] is related to [[colour]]', 'answer': 'wine', 'question': 'Which object in this image is related to colour?', 'img_file': 'COCO_val2014_000000008876.jpg', 'kb_source': 'conceptnet', 'fact': ['wine', 'related to', 'colour'], 'question_id': '4438'}, '377': {'fact_surface': '[[pencil box]] belongs to the category of [[Containers]]', 'answer': 'pencil box', 'question': 'What is the container in this image', 'img_file': 'ILSVRC2012_test_00049153.JPEG', 'kb_source': 'dbpedia', 'fact': ['pencil box', 'belong to', 'container'], 'question_id': '976'}, '378': {'fact_surface': 'You are likely to find [[a bowl]] in [[a kitchen]]', 'answer': 'kitchen', 'question': 'Where can people find bowls', 'img_file': 'ILSVRC2012_test_00027426.JPEG', 'kb_source': 'conceptnet', 'fact': ['bowl', 'at location', 'kitchen'], 'question_id': '972'}, '379': {'fact_surface': '[[A rubber eraser]] can be used to [[erase pencil]]', 'answer': 'rubber eraser', 'question': 'Which object in this image can be used to erase pencil', 'img_file': 'COCO_val2014_000000151790.jpg', 'kb_source': 'conceptnet', 'fact': ['rubber eraser', 'used for', 'erase pencil'], 'question_id': '970'}, '380': {'fact_surface': '[[teddy bear]] is a subclass of [[stuffed animal]]', 'answer': 'teddy bear', 'question': 'what is the stuffed animal on the right?', 'img_file': 'COCO_val2014_000000145020.jpg', 'kb_source': 'conceptnet', 'fact': ['teddy bear', 'is a', 'stuff animal'], 'question_id': '978'}, '381': {'fact_surface': '[[a sofa]] is for [[lying on]]', 'answer': 'sofa', 'question': 'What in this image is used for lie on?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'used for', 'lie on'], 'question_id': '1243'}, '382': {'fact_surface': '[[chair]] is related to [[furniture]]', 'answer': 'chair', 'question': 'Which object in this image is a furniture ?', 'img_file': 'ILSVRC2012_test_00010196.JPEG', 'kb_source': 'conceptnet', 'fact': ['chair', 'related to', 'furniture'], 'question_id': '5411'}, '383': {'fact_surface': '[[fig]] belongs to the category of [[Tree]]', 'answer': 'fig', 'question': 'What object in the center belongs to the category tree?', 'img_file': 'ILSVRC2012_test_00042247.JPEG', 'kb_source': 'dbpedia', 'fact': ['fig', 'belong to', 'tree'], 'question_id': '1689'}, '384': {'fact_surface': '[[surfboard]] belongs to the category of [[Surfing equipment]]', 'answer': 'surfboard', 'question': 'What surfing equipment is used in this image ?', 'img_file': 'COCO_val2014_000000111788.jpg', 'kb_source': 'dbpedia', 'fact': ['surfboard', 'belong to', 'surfing equipment'], 'question_id': '1465'}, '385': {'fact_surface': '[[donut]] belongs to the category of [[Snack foods]]', 'answer': 'donut', 'question': 'What object in this image is a type of snack food?', 'img_file': 'COCO_val2014_000000007107.jpg', 'kb_source': 'dbpedia', 'fact': ['donut', 'belong to', 'snack food'], 'question_id': '4239'}, '386': {'fact_surface': '[[Berliner]] is related to [[doughnut]]', 'answer': 'doughnut', 'question': 'What object in this image is related to a berliner?', 'img_file': 'COCO_val2014_000000007107.jpg', 'kb_source': 'conceptnet', 'fact': ['berliner', 'related to', 'doughnut'], 'question_id': '4238'}, '387': {'fact_surface': '[[donut]] belongs to the category of [[Dessert]]', 'answer': 'donut', 'question': 'What dessert is in this image?', 'img_file': 'COCO_val2014_000000007107.jpg', 'kb_source': 'dbpedia', 'fact': ['donut', 'belong to', 'dessert'], 'question_id': '4237'}, '388': {'fact_surface': '[[donut]] belongs to the category of [[Cooking]]', 'answer': 'donut', 'question': 'What in this image is made by cooking?', 'img_file': 'COCO_val2014_000000007107.jpg', 'kb_source': 'dbpedia', 'fact': ['donut', 'belong to', 'cooking'], 'question_id': '4236'}, '389': {'fact_surface': '[[buildings]] belongs to the category of [[Construction]]', 'answer': 'build', 'question': 'Which object in this image belongs to the category of Constructions?', 'img_file': 'ILSVRC2012_test_00022897.JPEG', 'kb_source': 'dbpedia', 'fact': ['build', 'belong to', 'construction'], 'question_id': '4235'}, '390': {'fact_surface': '[[horse]] are more muscular than [[cow]]', 'answer': 'cow', 'question': 'which animal in this image is less muscular than a horse?', 'img_file': 'COCO_val2014_000000140542.jpg', 'kb_source': 'webchild', 'fact': ['horse', 'muscular', 'cow'], 'question_id': '4234'}, '391': {'fact_surface': '[[clop]] is related to [[horse]]', 'answer': 'horse', 'question': 'Which object in this image is related to clop?', 'img_file': 'COCO_val2014_000000140542.jpg', 'kb_source': 'conceptnet', 'fact': ['clop', 'related to', 'horse'], 'question_id': '4233'}, '392': {'fact_surface': '[[horses]] are used for [[riding]].', 'answer': 'horse', 'question': 'What in this image can be used for riding on?', 'img_file': 'COCO_val2014_000000140542.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'used for', 'ride'], 'question_id': '4232'}, '393': {'fact_surface': '[[A tennis ball]] is often [[yellow]]', 'answer': 'tennis ball', 'question': 'Which object in this image is often yellow?', 'img_file': 'COCO_val2014_000000020965.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis ball', 'has property', 'yellow'], 'question_id': '4231'}, '394': {'fact_surface': '[[watercraft]] is related to [[boat]]', 'answer': 'boat', 'question': 'What kind of watercraft is shown in this image ?', 'img_file': 'COCO_val2014_000000129175.jpg', 'kb_source': 'conceptnet', 'fact': ['watercraft', 'related to', 'boat'], 'question_id': '4230'}, '395': {'fact_surface': '[[monitor]] belongs to the category of [[Display technology]]', 'answer': 'monitor', 'question': 'Which object is related to display technology?', 'img_file': 'COCO_val2014_000000144162.jpg', 'kb_source': 'dbpedia', 'fact': ['monitor', 'belong to', 'display technology'], 'question_id': '5590'}, '396': {'fact_surface': '[[weddings]] can be [[costly]]', 'answer': 'wedding', 'question': 'What property does the scenario in this image have?', 'img_file': 'ILSVRC2012_test_00000082.JPEG', 'kb_source': 'conceptnet', 'fact': ['wedding', 'has property', 'costly'], 'question_id': '5593'}, '397': {'fact_surface': '[[Weddings]] are [[expensive]]', 'answer': 'expensive', 'question': 'What property does the event in this image have?', 'img_file': 'ILSVRC2012_test_00000082.JPEG', 'kb_source': 'conceptnet', 'fact': ['wedding', 'has property', 'expensive'], 'question_id': '5595'}, '398': {'fact_surface': '[[weddings]] are [[happy for the bride and groom]]', 'answer': 'happy for bride and groom', 'question': 'What property does the event in this image have?', 'img_file': 'ILSVRC2012_test_00000082.JPEG', 'kb_source': 'conceptnet', 'fact': ['wedding', 'has property', 'happy for bride and groom'], 'question_id': '5594'}, '399': {'fact_surface': '[[weddings]] can be [[costly]]', 'answer': 'costly', 'question': 'What property does the event in this image have?', 'img_file': 'ILSVRC2012_test_00000082.JPEG', 'kb_source': 'conceptnet', 'fact': ['wedding', 'has property', 'costly'], 'question_id': '5596'}, '400': {'fact_surface': '[[an oven]] can be used to [[cook dinner]]', 'answer': 'oven', 'question': 'What object in this image can cook dinner?', 'img_file': 'ILSVRC2012_test_00007217.JPEG', 'kb_source': 'conceptnet', 'fact': ['oven', 'used for', 'cook dinner'], 'question_id': '319'}, '401': {'fact_surface': '[[tv]] is a kind of [[media]].', 'answer': 'tv', 'question': 'Which object in this image is a kind of media', 'img_file': 'ILSVRC2012_test_00032881.JPEG', 'kb_source': 'conceptnet', 'fact': ['tv', 'is a', 'medium'], 'question_id': '313'}, '402': {'fact_surface': '[[hats]] can [[go on a hat rack]]', 'answer': 'hat', 'question': 'What thin in the image can block the sunlight from your eyes?', 'img_file': 'ILSVRC2012_test_00000957.JPEG', 'kb_source': 'conceptnet', 'fact': ['hat', 'capable of', 'go on hat rack'], 'question_id': '311'}, '403': {'fact_surface': '[[a bookshelf]] can be used for [[storing books]]', 'answer': 'bookshelf', 'question': 'What thing is used for storing books', 'img_file': 'ILSVRC2012_test_00032881.JPEG', 'kb_source': 'conceptnet', 'fact': ['bookshelf', 'used for', 'store book'], 'question_id': '317'}, '404': {'fact_surface': '[[A bookshelf]] contains [[books]]', 'answer': 'book', 'question': 'What does the right large object contain?', 'img_file': 'ILSVRC2012_test_00032881.JPEG', 'kb_source': 'conceptnet', 'fact': ['bookshelf', 'has a', 'book'], 'question_id': '316'}, '405': {'fact_surface': 'You can use [[a tv]] to [[watch movies]]', 'answer': 'tv', 'question': 'What thing in this image can be used to watch movies', 'img_file': 'ILSVRC2012_test_00032881.JPEG', 'kb_source': 'conceptnet', 'fact': ['tv', 'used for', 'watch movie'], 'question_id': '315'}, '406': {'fact_surface': '[[a TV]] can [[display images]].', 'answer': 'tv', 'question': 'Which object can be used to display images', 'img_file': 'ILSVRC2012_test_00032881.JPEG', 'kb_source': 'conceptnet', 'fact': ['tv', 'capable of', 'display image'], 'question_id': '314'}, '407': {'fact_surface': '[[a court]] is for [[playing tennis]]', 'answer': 'play tennis', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000109370.jpg', 'kb_source': 'conceptnet', 'fact': ['court', 'used for', 'play tennis'], 'question_id': '4213'}, '408': {'fact_surface': '[[A tv]] is used to [[display a transmitted image]]', 'answer': 'tv', 'question': 'Which object in this image is used to display transmitted images?', 'img_file': 'ILSVRC2012_test_00023491.JPEG', 'kb_source': 'conceptnet', 'fact': ['tv', 'used for', 'display transmit image'], 'question_id': '4212'}, '409': {'fact_surface': '[[teddy bear]] belongs to the category of [[1902 introductions]]', 'answer': 'teddy bear', 'question': 'When the toy in the centre is introduced?', 'img_file': 'COCO_val2014_000000100343.jpg', 'kb_source': 'dbpedia', 'fact': ['teddy bear', 'belong to', '1902 introductions'], 'question_id': '442'}, '410': {'fact_surface': '[[Fish]] can [[swim]]', 'answer': 'swim', 'question': 'What do fish can', 'img_file': 'ILSVRC2012_test_00052304.JPEG', 'kb_source': 'conceptnet', 'fact': ['fish', 'capable of', 'swim'], 'question_id': '441'}, '411': {'fact_surface': 'You can use [[cell phone]] to [[call]].', 'answer': 'cell phone', 'question': 'Which electronic appliance can be used to call someone', 'img_file': 'ILSVRC2012_test_00023514.JPEG', 'kb_source': 'conceptnet', 'fact': ['cell phone', 'used for', 'call'], 'question_id': '445'}, '412': {'fact_surface': '[[the flute]] is [[an instrument of music]]', 'answer': 'flute', 'question': 'Which object in this image is a instrument of music?', 'img_file': 'ILSVRC2012_test_00002224.JPEG', 'kb_source': 'conceptnet', 'fact': ['flute', 'is a', 'instrument of music'], 'question_id': '2295'}, '413': {'fact_surface': '[[People]] want to [[meditate]]', 'answer': 'person', 'question': 'Which thing in this image can sometimes like to meditate?', 'img_file': 'ILSVRC2012_test_00002224.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'meditate'], 'question_id': '2294'}, '414': {'fact_surface': '[[grind]] is related to [[skateboard]]', 'answer': 'skateboard', 'question': 'Which object in this image is related to grind?', 'img_file': 'COCO_val2014_000000137622.jpg', 'kb_source': 'conceptnet', 'fact': ['grind', 'related to', 'skateboard'], 'question_id': '5190'}, '415': {'fact_surface': '[[a refrigerator]] is for [[cold food storage]]', 'answer': 'refrigerator', 'question': 'Which object in this image is used for storing cold food?', 'img_file': 'COCO_val2014_000000122954.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'used for', 'cold food storage'], 'question_id': '3431'}, '416': {'fact_surface': '[[a couch]] can be used for [[sitting down]]', 'answer': 'couch', 'question': 'Which object in this image is used for sit down?', 'img_file': 'COCO_val2014_000000122954.jpg', 'kb_source': 'conceptnet', 'fact': ['couch', 'used for', 'sit down'], 'question_id': '3433'}, '417': {'fact_surface': '[[A baseball bat]] can [[hit a baseball]]', 'answer': 'baseball bat', 'question': 'Which equipment in this image is used to hit baseball?', 'img_file': 'COCO_val2014_000000129945.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball bat', 'capable of', 'hit baseball'], 'question_id': '3434'}, '418': {'fact_surface': '[[unicycle]] belongs to the category of [[Cycling]]', 'answer': 'unicycle', 'question': 'what object int his image is used for cycling?', 'img_file': 'ILSVRC2012_test_00019930.JPEG', 'kb_source': 'dbpedia', 'fact': ['unicycle', 'belong to', 'cycling'], 'question_id': '873'}, '419': {'fact_surface': '[[An elephant]] has [[a nose]]', 'answer': 'elephant', 'question': 'which object in this image is a animal that has nose', 'img_file': 'ILSVRC2012_test_00037716.JPEG', 'kb_source': 'conceptnet', 'fact': ['elephant', 'has a', 'nose'], 'question_id': '2741'}, '420': {'fact_surface': '[[blade]] is related to [[grass]]', 'answer': 'grass', 'question': 'Which object in this image is related to blade?', 'img_file': 'ILSVRC2012_test_00037716.JPEG', 'kb_source': 'conceptnet', 'fact': ['blade', 'related to', 'grass'], 'question_id': '2740'}, '421': {'fact_surface': '[[hot dog]] belongs to the category of [[North American cuisine]]', 'answer': 'hot dog', 'question': 'Which food in this image comes from North America?', 'img_file': 'COCO_val2014_000000113905.jpg', 'kb_source': 'dbpedia', 'fact': ['hot dog', 'belong to', 'north american cuisine'], 'question_id': '2743'}, '422': {'fact_surface': '[[Hot dogs]] are [[a favorite fast food]]', 'answer': 'hot dog', 'question': 'Which object in this image is a favorite fast food?', 'img_file': 'COCO_val2014_000000113905.jpg', 'kb_source': 'conceptnet', 'fact': ['hot dog', 'is a', 'favorite fast food'], 'question_id': '2742'}, '423': {'fact_surface': '[[fruits]] belongs to the category of [[Food]]', 'answer': 'fruit', 'question': 'Which oject belongs to the Food category?', 'img_file': 'ILSVRC2012_test_00007770.JPEG', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'food'], 'question_id': '2030'}, '424': {'fact_surface': '[[flow]] is related to [[water]]', 'answer': 'water', 'question': 'Which object in this image is related to flow?', 'img_file': 'COCO_val2014_000000118401.jpg', 'kb_source': 'conceptnet', 'fact': ['flow', 'related to', 'water'], 'question_id': '4847'}, '425': {'fact_surface': '[[tuner]] is related to [[piano]]', 'answer': 'piano', 'question': 'Which object in this image might need a tuner?', 'img_file': 'ILSVRC2012_test_00022418.JPEG', 'kb_source': 'conceptnet', 'fact': ['tuner', 'related to', 'piano'], 'question_id': '4840'}, '426': {'fact_surface': '[[key]] is related to [[piano]]', 'answer': 'piano', 'question': 'Which object in this image has keys?', 'img_file': 'ILSVRC2012_test_00022418.JPEG', 'kb_source': 'conceptnet', 'fact': ['key', 'related to', 'piano'], 'question_id': '4841'}, '427': {'fact_surface': '[[the beach]] is [[sandy]]', 'answer': 'beach', 'question': 'What property does the place in this image have?', 'img_file': 'COCO_val2014_000000108130.jpg', 'kb_source': 'conceptnet', 'fact': ['beach', 'has property', 'sandy'], 'question_id': '2038'}, '428': {'fact_surface': '[[carrot cake]] is related to [[cake]]', 'answer': 'cake', 'question': 'Which object in this image is related to carrot cake?', 'img_file': 'COCO_val2014_000000136270.jpg', 'kb_source': 'conceptnet', 'fact': ['carrot cake', 'related to', 'cake'], 'question_id': '5201'}, '429': {'fact_surface': '[[a cake]] is for [[a wedding]]', 'answer': 'cake', 'question': 'Which object in this image is used for wedding?', 'img_file': 'COCO_val2014_000000136270.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'used for', 'wed'], 'question_id': '5200'}, '430': {'fact_surface': '[[punnet]] is related to [[strawberries]]', 'answer': 'strawberry', 'question': 'Which object in this image might be bought by the punnet?', 'img_file': 'COCO_val2014_000000118607.jpg', 'kb_source': 'conceptnet', 'fact': ['punnet', 'related to', 'strawberry'], 'question_id': '5203'}, '431': {'fact_surface': '[[carrot cake]] is related to [[cake]]', 'answer': 'cake', 'question': 'Which object in this image is related to carrot cake?', 'img_file': 'COCO_val2014_000000136270.jpg', 'kb_source': 'conceptnet', 'fact': ['carrot cake', 'related to', 'cake'], 'question_id': '5202'}, '432': {'fact_surface': '[[strawberries]] is a kind of [[fruit]]', 'answer': 'strawberry', 'question': 'Which object in this image is a fruit?', 'img_file': 'COCO_val2014_000000118607.jpg', 'kb_source': 'conceptnet', 'fact': ['strawberry', 'is a', 'fruit'], 'question_id': '5204'}, '433': {'fact_surface': '*Something you find [[at the beach]] is [[a volleyball]]', 'answer': 'volleyball', 'question': 'what object in this image can be found at a beach?', 'img_file': 'ILSVRC2012_test_00008641.JPEG', 'kb_source': 'conceptnet', 'fact': ['volleyball', 'at location', 'at beach'], 'question_id': '3049'}, '434': {'fact_surface': '[[volleyball]] is softer than [[basketball]]', 'answer': 'volleyball', 'question': 'which sport equipment in this image is softer than basketball?', 'img_file': 'ILSVRC2012_test_00008641.JPEG', 'kb_source': 'webchild', 'fact': ['volleyball', 'soft', 'basketball'], 'question_id': '3048'}, '435': {'fact_surface': '[[suits]] are [[formal clothes]]', 'answer': 'suit', 'question': 'Which object in this image is formal clothing?', 'img_file': 'COCO_val2014_000000115571.jpg', 'kb_source': 'conceptnet', 'fact': ['suit', 'is a', 'formal clothe'], 'question_id': '3045'}, '436': {'fact_surface': 'You can use [[a bus]] to [[commute to work]]', 'answer': 'bus', 'question': 'Which object in this image is used for commute to work?', 'img_file': 'COCO_val2014_000000115571.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'used for', 'commute to work'], 'question_id': '3044'}, '437': {'fact_surface': '[[restaurant]] are a bit more expensive than [[cafe]]', 'answer': 'cafe', 'question': 'What can be less expensive than the place shown on the left?', 'img_file': 'COCO_val2014_000000139969.jpg', 'kb_source': 'webchild', 'fact': ['restaurant', 'expensive', 'cafe'], 'question_id': '3047'}, '438': {'fact_surface': '[[bus]] is [[a form of public transportation]]', 'answer': 'bus', 'question': 'Which object in this image is a form of public transportation?', 'img_file': 'COCO_val2014_000000109819.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'is a', 'form of public transportation'], 'question_id': '1097'}, '439': {'fact_surface': '[[teddy bear]] is a subclass of [[stuffed animal]]', 'answer': 'teddy bear', 'question': 'Which object in this image is a stuffed animal?', 'img_file': 'COCO_val2014_000000135975.jpg', 'kb_source': 'conceptnet', 'fact': ['teddy bear', 'is a', 'stuff animal'], 'question_id': '1093'}, '440': {'fact_surface': '[[bus]] is [[a form of public transportation]]', 'answer': 'bus', 'question': 'Which object in this image is a form of public transportation?', 'img_file': 'COCO_val2014_000000109819.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'is a', 'form of public transportation'], 'question_id': '1098'}, '441': {'fact_surface': '[[musth]] is related to [[elephant]]', 'answer': 'elephant', 'question': 'Which object in this image is related to musth?', 'img_file': 'COCO_val2014_000000109819.jpg', 'kb_source': 'conceptnet', 'fact': ['musth', 'related to', 'elephant'], 'question_id': '1099'}, '442': {'fact_surface': '[[chairs]] is a kind of [[furniture]]', 'answer': 'chair', 'question': 'Which of the objects in this image is a type of furniture?', 'img_file': 'COCO_val2014_000000008708.jpg', 'kb_source': 'conceptnet', 'fact': ['chair', 'is a', 'furniture'], 'question_id': '1915'}, '443': {'fact_surface': '[[motorcycle]] is a type of [[motor vehicle]].', 'answer': 'motorcycle', 'question': 'Which object in this image belongs to a motor vehicle?', 'img_file': 'COCO_val2014_000000005205.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'is a', 'motor vehicle'], 'question_id': '1322'}, '444': {'fact_surface': '[[A car]] has [[four tyres]]', 'answer': 'car', 'question': 'Which object in this image has a four tyres?', 'img_file': 'COCO_val2014_000000005205.jpg', 'kb_source': 'conceptnet', 'fact': ['car', 'has a', 'four tyre'], 'question_id': '1323'}, '445': {'fact_surface': '[[motorcycle]] are much less protected than [[car]]', 'answer': 'motorcycle', 'question': 'which object in this image is less protected than car?', 'img_file': 'COCO_val2014_000000005205.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'protected', 'car'], 'question_id': '1320'}, '446': {'fact_surface': '[[A motorcycle]] has [[two wheels and can go fast]]', 'answer': 'motorcycle', 'question': 'Which object in this image can go fast and has two wheels?', 'img_file': 'COCO_val2014_000000005205.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'has a', 'two wheel and can go fast'], 'question_id': '1321'}, '447': {'fact_surface': '[[a road]] is used for [[travelers]]', 'answer': 'road', 'question': 'What is the place in this image used for moving?', 'img_file': 'COCO_val2014_000000123555.jpg', 'kb_source': 'conceptnet', 'fact': ['road', 'used for', 'travel'], 'question_id': '1326'}, '448': {'fact_surface': '[[children]] belongs to the category of [[Human]]', 'answer': 'child', 'question': 'Which object in this image belongs to the category Human?', 'img_file': 'COCO_val2014_000000025804.jpg', 'kb_source': 'dbpedia', 'fact': ['child', 'belong to', 'human'], 'question_id': '1327'}, '449': {'fact_surface': '[[paper]] is related to [[book]]', 'answer': 'book', 'question': 'Which of these objects is related to paper?', 'img_file': 'COCO_val2014_000000008708.jpg', 'kb_source': 'conceptnet', 'fact': ['paper', 'related to', 'book'], 'question_id': '1914'}, '450': {'fact_surface': '[[motorcycle]] is related to [[ride]]', 'answer': 'motorcycle', 'question': 'Which object in this image can you ride on?', 'img_file': 'COCO_val2014_000000005205.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'related to', 'ride'], 'question_id': '1325'}, '451': {'fact_surface': '[[elephant]] is bigger than [[horse]]', 'answer': 'elephant', 'question': 'which object in this image is bigger than horse?', 'img_file': 'COCO_val2014_000000025804.jpg', 'kb_source': 'webchild', 'fact': ['elephant', 'big', 'horse'], 'question_id': '1328'}, '452': {'fact_surface': '[[Glasses]] have [[a frame and two lenses]]', 'answer': 'glass', 'question': 'Which object in this image has a frame and two lenses?', 'img_file': 'COCO_val2014_000000008708.jpg', 'kb_source': 'conceptnet', 'fact': ['glass', 'has a', 'frame and two lense'], 'question_id': '1917'}, '453': {'fact_surface': '[[A teddy bear]] is for [[cuddling]]', 'answer': 'teddy bear', 'question': 'Which object in this image might be used for cuddling?', 'img_file': 'COCO_val2014_000000008708.jpg', 'kb_source': 'conceptnet', 'fact': ['teddy bear', 'used for', 'cuddle'], 'question_id': '1916'}, '454': {'fact_surface': '[[bus]] are cheaper than [[taxi]]', 'answer': 'bus', 'question': 'which object in this image costs less money than taxi?', 'img_file': 'COCO_val2014_000000024195.jpg', 'kb_source': 'webchild', 'fact': ['bus', 'cheap', 'taxi'], 'question_id': '3958'}, '455': {'fact_surface': 'You are likely to find [[a bus]] in [[the street]]', 'answer': 'street', 'question': 'Where can the object in the middle of this image be found?', 'img_file': 'COCO_val2014_000000024195.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'at location', 'street'], 'question_id': '3953'}, '456': {'fact_surface': '[[living room]] can be warmer than [[bedroom]]', 'answer': 'bedroom', 'question': 'Which place is less warm than the place shown in this image?', 'img_file': 'ILSVRC2012_test_00009787.JPEG', 'kb_source': 'webchild', 'fact': ['living room', 'warm', 'bedroom'], 'question_id': '3952'}, '457': {'fact_surface': '[[bus]] is [[a form of public transportation]]', 'answer': 'bus', 'question': 'Which object in this image is a form of public transportation?', 'img_file': 'COCO_val2014_000000024195.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'is a', 'form of public transportation'], 'question_id': '3957'}, '458': {'fact_surface': '[[Buses]] are used to [[go from place to place]]', 'answer': 'bus', 'question': 'Which object in this image can be used for go from place to place?', 'img_file': 'COCO_val2014_000000024195.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'used for', 'go from place to place'], 'question_id': '3956'}, '459': {'fact_surface': '[[bus]] still tends to be more common than [[rail]]', 'answer': 'bus', 'question': 'which object in this image is more common than rail?', 'img_file': 'COCO_val2014_000000024195.jpg', 'kb_source': 'webchild', 'fact': ['bus', 'common', 'rail'], 'question_id': '3955'}, '460': {'fact_surface': '[[roads]] can be used for [[transport]]', 'answer': 'transport', 'question': 'What can this place in the image be used for?', 'img_file': 'COCO_val2014_000000024195.jpg', 'kb_source': 'conceptnet', 'fact': ['road', 'used for', 'transport'], 'question_id': '3954'}, '461': {'fact_surface': '[[Bears]] can [[eat most types of food]]', 'answer': 'bear', 'question': 'Which object in this image is capable of eat most types of food?', 'img_file': 'COCO_val2014_000000008401.jpg', 'kb_source': 'conceptnet', 'fact': ['bear', 'capable of', 'eat most type of food'], 'question_id': '4062'}, '462': {'fact_surface': '[[A bear]] can [[winter in a cave]]', 'answer': 'bear', 'question': 'Which object in this image can winter in a cave?', 'img_file': 'COCO_val2014_000000008401.jpg', 'kb_source': 'conceptnet', 'fact': ['bear', 'capable of', 'winter in cave'], 'question_id': '4063'}, '463': {'fact_surface': '[[bears]] are [[dangerous animals]]', 'answer': 'bear', 'question': 'What can maul you to death?', 'img_file': 'COCO_val2014_000000008401.jpg', 'kb_source': 'conceptnet', 'fact': ['bear', 'is a', 'dangerous animal'], 'question_id': '4060'}, '464': {'fact_surface': '[[bears]] have [[fur]]', 'answer': 'bear', 'question': 'Which object in this image has fur?', 'img_file': 'COCO_val2014_000000008401.jpg', 'kb_source': 'conceptnet', 'fact': ['bear', 'has a', 'fur'], 'question_id': '4061'}, '465': {'fact_surface': 'A [[bear]] is a [[large, strong, intelligent animal with big claws and teeth that lives in cold climates]]', 'answer': 'bear', 'question': 'Which object in this image is a large strong intelligent animal with big claws and teeth that lives in cold climates?', 'img_file': 'COCO_val2014_000000008401.jpg', 'kb_source': 'conceptnet', 'fact': ['bear', 'is a', 'large strong intelligent animal with big claw and tooth that life in cold climate'], 'question_id': '4064'}, '466': {'fact_surface': '[[tennis racket]] belongs to the category of [[Sport]]', 'answer': 'tennis racket', 'question': 'Which equipment in this image belongs to sports?', 'img_file': 'ILSVRC2012_test_00035548.JPEG', 'kb_source': 'dbpedia', 'fact': ['tennis racket', 'belong to', 'sport'], 'question_id': '4065'}, '467': {'fact_surface': '[[Lizards]] have [[a tail]]', 'answer': 'lizard', 'question': 'Which object in this image has a tail?', 'img_file': 'ILSVRC2012_test_00000767.JPEG', 'kb_source': 'conceptnet', 'fact': ['lizard', 'has a', 'tail'], 'question_id': '5780'}, '468': {'fact_surface': '[[Lizards]] have [[four legs]]', 'answer': 'lizard', 'question': 'Which object in this image has a four legs?', 'img_file': 'ILSVRC2012_test_00000767.JPEG', 'kb_source': 'conceptnet', 'fact': ['lizard', 'has a', 'four leg'], 'question_id': '5781'}, '469': {'fact_surface': 'You are likely to find [[a lizard]] in [[rocky places]]', 'answer': 'lizard', 'question': 'which object in this image can live in the rocky place', 'img_file': 'ILSVRC2012_test_00000767.JPEG', 'kb_source': 'conceptnet', 'fact': ['lizard', 'at location', 'rocky place'], 'question_id': '5782'}, '470': {'fact_surface': '[[a horse]] can [[pull a cart]]', 'answer': 'horse', 'question': 'Which object in this image can pull a cart?', 'img_file': 'COCO_val2014_000000101013.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'capable of', 'pull cart'], 'question_id': '3607'}, '471': {'fact_surface': '[[iPod]] belongs to the category of [[Electronics manufacturing]]', 'answer': 'ipod', 'question': 'Which object in the image is an electronic gadget?', 'img_file': 'ILSVRC2012_test_00000923.JPEG', 'kb_source': 'dbpedia', 'fact': ['ipod', 'belong to', 'electronics manufacturing'], 'question_id': '3609'}, '472': {'fact_surface': '[[A remote]] can [[control a TV]]', 'answer': 'remote', 'question': 'Which object in this image can be used to control a tv?', 'img_file': 'ILSVRC2012_test_00000923.JPEG', 'kb_source': 'conceptnet', 'fact': ['remote', 'capable of', 'control tv'], 'question_id': '3608'}, '473': {'fact_surface': 'A [[turtle]] is a [[reptile]]', 'answer': 'turtle', 'question': 'What is the reptile in this image?', 'img_file': 'ILSVRC2012_test_00034257.JPEG', 'kb_source': 'conceptnet', 'fact': ['turtle', 'is a', 'reptile'], 'question_id': '4453'}, '474': {'fact_surface': 'You are likely to find [[a boy]] in [[a playground]]', 'answer': 'boy', 'question': 'which object can we find in this place shown in the image', 'img_file': 'COCO_val2014_000000105448.jpg', 'kb_source': 'conceptnet', 'fact': ['boy', 'at location', 'playground'], 'question_id': '4452'}, '475': {'fact_surface': '[[track]] are more expensive than [[tire]]', 'answer': 'track', 'question': 'Which place is more expensive than the place shown in this image', 'img_file': 'COCO_val2014_000000105448.jpg', 'kb_source': 'webchild', 'fact': ['track', 'expensive', 'tire'], 'question_id': '4451'}, '476': {'fact_surface': '[[skateboard]] is related to [[wheel]]', 'answer': 'skateboard', 'question': 'Which object in this image has wheels?', 'img_file': 'COCO_val2014_000000105448.jpg', 'kb_source': 'conceptnet', 'fact': ['skateboard', 'related to', 'wheel'], 'question_id': '4450'}, '477': {'fact_surface': '[[rugby ball]] belongs to the category of [[Sports equipment]]', 'answer': 'rugby ball', 'question': 'Which object in this image belongs to the category Sports equipment?', 'img_file': 'ILSVRC2012_test_00033964.JPEG', 'kb_source': 'dbpedia', 'fact': ['rugby ball', 'belong to', 'sports equipment'], 'question_id': '4457'}, '478': {'fact_surface': '[[bathroom]] has [[toilet]].', 'answer': 'toilet', 'question': 'What can be seen in this image?', 'img_file': 'COCO_val2014_000000144062.jpg', 'kb_source': 'conceptnet', 'fact': ['toilet', 'part of', 'bathroom'], 'question_id': '4455'}, '479': {'fact_surface': 'You are likely to find [[toilet paper]] on [[the bathroom]].', 'answer': 'toilet paper', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000144062.jpg', 'kb_source': 'conceptnet', 'fact': ['toilet paper', 'at location', 'bathroom'], 'question_id': '4454'}, '480': {'fact_surface': '[[tire]] is part of [[a car]].', 'answer': 'car', 'question': 'Which vehicle in this image has tires?', 'img_file': 'COCO_val2014_000000104381.jpg', 'kb_source': 'conceptnet', 'fact': ['tire', 'part of', 'car'], 'question_id': '4459'}, '481': {'fact_surface': '[[sand]] is related to [[deserts]]', 'answer': 'sand', 'question': 'Which object in this image could also be related to deserts?', 'img_file': 'ILSVRC2012_test_00033964.JPEG', 'kb_source': 'conceptnet', 'fact': ['sand', 'related to', 'desert'], 'question_id': '4458'}, '482': {'fact_surface': '(monitor,/r/UsedFor,watching)', 'answer': 'watch', 'question': 'What is monitor used for?', 'img_file': 'ILSVRC2012_test_00059513.JPEG', 'kb_source': 'conceptnet', 'fact': ['monitor', 'used for', 'watch'], 'question_id': '959'}, '483': {'fact_surface': 'You can use [[cell phone]] to [[call]].', 'answer': 'phone', 'question': 'Which device on the table can be used to call?', 'img_file': 'ILSVRC2012_test_00017039.JPEG', 'kb_source': 'conceptnet', 'fact': ['phone', 'used for', 'call'], 'question_id': '958'}, '484': {'fact_surface': '[[drum]] belongs to the category of [[Musical instruments]]', 'answer': 'drum', 'question': 'Tell me the musical instrument in this image?', 'img_file': 'ILSVRC2012_test_00014861.JPEG', 'kb_source': 'dbpedia', 'fact': ['drum', 'belong to', 'musical instrument'], 'question_id': '953'}, '485': {'fact_surface': '[[apple]] belongs to the category of [[Crops originating from China]]', 'answer': 'apple', 'question': 'Which fruit in this image is crop originating from China', 'img_file': 'ILSVRC2012_test_00017039.JPEG', 'kb_source': 'dbpedia', 'fact': ['apple', 'belong to', 'crops originating from china'], 'question_id': '957'}, '486': {'fact_surface': '[[laptop]] are much more convenient than [[desktop computer]]', 'answer': 'laptop', 'question': 'what object in this image is more convenient than a desktop computer', 'img_file': 'ILSVRC2012_test_00021967.JPEG', 'kb_source': 'webchild', 'fact': ['laptop', 'convenient', 'desktop computer'], 'question_id': '717'}, '487': {'fact_surface': '[[Bagels]] are [[good with cream cheese]]', 'answer': 'bagel', 'question': 'Which object in this image is good with cream cheese?', 'img_file': 'ILSVRC2012_test_00017846.JPEG', 'kb_source': 'conceptnet', 'fact': ['bagel', 'has property', 'good with cream cheese'], 'question_id': '2178'}, '488': {'fact_surface': '[[dining table]] belongs to the category of [[Furniture]]', 'answer': 'dining table', 'question': 'Which round object in the center of this image belongs to the category Furniture?', 'img_file': 'ILSVRC2012_test_00001283.JPEG', 'kb_source': 'dbpedia', 'fact': ['dining table', 'belong to', 'furniture'], 'question_id': '1669'}, '489': {'fact_surface': '[[banana split]] is related to [[banana]]', 'answer': 'banana', 'question': 'Which object in the center of the image is related to banana split?', 'img_file': 'ILSVRC2012_test_00037882.JPEG', 'kb_source': 'conceptnet', 'fact': ['banana split', 'related to', 'banana'], 'question_id': '1668'}, '490': {'fact_surface': '[[banana]] is a more specific symbol than [[fruit]]', 'answer': 'banana', 'question': 'which object in this image is more specific than fruit?', 'img_file': 'ILSVRC2012_test_00037882.JPEG', 'kb_source': 'webchild', 'fact': ['banana', 'specific', 'fruit'], 'question_id': '1667'}, '491': {'fact_surface': '[[banana]] is [[peelable]].', 'answer': 'banana', 'question': 'Which object in this image is peelable?', 'img_file': 'ILSVRC2012_test_00037882.JPEG', 'kb_source': 'conceptnet', 'fact': ['banana', 'has property', 'peelable'], 'question_id': '1666'}, '492': {'fact_surface': '[[orange]] is [[a color]]', 'answer': 'orange', 'question': 'Which object in this image has a name that is also a colour?', 'img_file': 'ILSVRC2012_test_00037882.JPEG', 'kb_source': 'conceptnet', 'fact': ['orange', 'is a', 'color'], 'question_id': '1665'}, '493': {'fact_surface': '[[bell pepper]] belongs to the category of [[Capsicum]]', 'answer': 'bell pepper', 'question': 'Which object in this image belongs to the category Capsicum?', 'img_file': 'ILSVRC2012_test_00045779.JPEG', 'kb_source': 'dbpedia', 'fact': ['bell pepper', 'belong to', 'capsicum'], 'question_id': '1664'}, '494': {'fact_surface': '[[vegetables]] belongs to the category of [[Foods]]', 'answer': 'vegetable', 'question': 'Which object in this image can be cateroried to Foods?', 'img_file': 'ILSVRC2012_test_00045779.JPEG', 'kb_source': 'dbpedia', 'fact': ['vegetable', 'belong to', 'food'], 'question_id': '1663'}, '495': {'fact_surface': '[[cow]] belongs to the category of [[Mammals with sequenced genomes]]', 'answer': 'cow', 'question': 'what is it  in this image belongs to the category Mammals with sequenced genomes?', 'img_file': 'COCO_val2014_000000149832.jpg', 'kb_source': 'dbpedia', 'fact': ['cow', 'belong to', 'mammals with sequenced genomes'], 'question_id': '1662'}, '496': {'fact_surface': '[[cow]] belongs to the category of [[Mammals with sequenced genomes]]', 'answer': 'cow', 'question': 'what is it  in this image belongs to the category Mammals with sequenced genomes?', 'img_file': 'COCO_val2014_000000149832.jpg', 'kb_source': 'dbpedia', 'fact': ['cow', 'belong to', 'mammals with sequenced genomes'], 'question_id': '1661'}, '497': {'fact_surface': '[[cow]] belongs to the category of [[Mammals with sequenced genomes]]', 'answer': 'cow', 'question': 'what is it  in this image belongs to the category Mammals with sequenced genomes?', 'img_file': 'COCO_val2014_000000149832.jpg', 'kb_source': 'dbpedia', 'fact': ['cow', 'belong to', 'mammals with sequenced genomes'], 'question_id': '1660'}, '498': {'fact_surface': '[[the camel]] can [[work for days without water]]', 'answer': 'work for day without water', 'question': 'What is the animal famous for?', 'img_file': 'ILSVRC2012_test_00008993.JPEG', 'kb_source': 'conceptnet', 'fact': ['camel', 'capable of', 'work for day without water'], 'question_id': '591'}, '499': {'fact_surface': '[[camel]] is related to [[hump]]', 'answer': 'hump', 'question': 'What is on the back of the animal?', 'img_file': 'ILSVRC2012_test_00008993.JPEG', 'kb_source': 'conceptnet', 'fact': ['camel', 'related to', 'hump'], 'question_id': '593'}, '500': {'fact_surface': '[[camel]] are a lot taller than [[horse]]', 'answer': 'camel', 'question': 'Which one is taller? horse or the animal in the image?', 'img_file': 'ILSVRC2012_test_00008993.JPEG', 'kb_source': 'webchild', 'fact': ['camel', 'tall', 'horse'], 'question_id': '592'}, '501': {'fact_surface': '*Something you find on [[the street]] is [[traffic light]]', 'answer': 'street', 'question': 'Normally where can you find this thing?', 'img_file': 'ILSVRC2012_test_00007890.JPEG', 'kb_source': 'conceptnet', 'fact': ['traffic light', 'at location', 'street'], 'question_id': '599'}, '502': {'fact_surface': '[[trains]] can [[carry freight]].', 'answer': 'train', 'question': 'What thing in this image is able to carry freight', 'img_file': 'COCO_val2014_000000026226.jpg', 'kb_source': 'conceptnet', 'fact': ['train', 'capable of', 'carry freight'], 'question_id': '598'}, '503': {'fact_surface': '[[forks]] have [[tines]]', 'answer': 'fork', 'question': 'Which object in this image has a tine?', 'img_file': 'COCO_val2014_000000100132.jpg', 'kb_source': 'conceptnet', 'fact': ['fork', 'has a', 'tine'], 'question_id': '2824'}, '504': {'fact_surface': '[[bread]] is for [[making toast]]', 'answer': 'bread', 'question': 'Which object in this image could be used to make toast?', 'img_file': 'COCO_val2014_000000100132.jpg', 'kb_source': 'conceptnet', 'fact': ['bread', 'used for', 'make toast'], 'question_id': '2825'}, '505': {'fact_surface': 'Somewhere [[a sandwich]] can be is [[in the fridge]]', 'answer': 'fridge', 'question': 'Where does the objects shown in this image can be found?', 'img_file': 'COCO_val2014_000000100132.jpg', 'kb_source': 'conceptnet', 'fact': ['sandwich', 'at location', 'fridge'], 'question_id': '2822'}, '506': {'fact_surface': '[[bread ]] is for [[eating]]', 'answer': 'bread', 'question': 'Which object in this image is used for eat?', 'img_file': 'COCO_val2014_000000100132.jpg', 'kb_source': 'conceptnet', 'fact': ['bread', 'used for', 'eat'], 'question_id': '2823'}, '507': {'fact_surface': '[[An elephant]] is [[larger than a breadbox]]', 'answer': 'elephant', 'question': 'Which object in this image is larger than a breadbox?', 'img_file': 'COCO_val2014_000000001869.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'is a', 'large than breadbox'], 'question_id': '5417'}, '508': {'fact_surface': '[[hamburger]] is [[a very fatty food]]', 'answer': 'hamburger', 'question': 'Which object in this image is very fatty ?', 'img_file': 'COCO_val2014_000000121826.jpg', 'kb_source': 'conceptnet', 'fact': ['hamburger', 'is a', 'very fatty food'], 'question_id': '3382'}, '509': {'fact_surface': '[[Lettuce]] is part of [[a salad]]', 'answer': 'salad', 'question': 'Which object in this image cotains lettuce?', 'img_file': 'COCO_val2014_000000121826.jpg', 'kb_source': 'conceptnet', 'fact': ['lettuce', 'part of', 'salad'], 'question_id': '3383'}, '510': {'fact_surface': '*Something you find at [[a fast-food restaurant]] is [[a hamburger]]', 'answer': 'hamburger', 'question': 'Which object in this image can be found in a fast food restaurant?', 'img_file': 'COCO_val2014_000000121826.jpg', 'kb_source': 'conceptnet', 'fact': ['hamburger', 'at location', 'fast food restaurant'], 'question_id': '3380'}, '511': {'fact_surface': '[[fesh vegtables]] is part of [[a salad]].', 'answer': 'fesh vegtables', 'question': 'What is the healthier food in the image ?', 'img_file': 'COCO_val2014_000000121826.jpg', 'kb_source': 'conceptnet', 'fact': ['fesh vegtables', 'part of', 'salad'], 'question_id': '3381'}, '512': {'fact_surface': '[[an elephant]] has [[a long nose called \"trunk\"]]', 'answer': 'elephant', 'question': 'Which object has a long nose', 'img_file': 'COCO_val2014_000000001869.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'has a', 'long nose call trunk'], 'question_id': '5418'}, '513': {'fact_surface': '[[A frisbee]] is [[round, flying disc]]', 'answer': 'frisbee', 'question': 'What is the round, disc-like stuff?', 'img_file': 'COCO_val2014_000000108327.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'is a', 'round fly disc'], 'question_id': '1409'}, '514': {'fact_surface': '[[A frisbee]] is [[a toy that you throw]]', 'answer': 'frisbee', 'question': 'Which object in this image is a toy that you throw?', 'img_file': 'COCO_val2014_000000108327.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'is a', 'toy that you throw'], 'question_id': '1408'}, '515': {'fact_surface': 'You are likely to find [[a bathroom]] with [[toilet in a residence]]', 'answer': 'toilet', 'question': 'What is the place used for?', 'img_file': 'COCO_val2014_000000108548.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'at location', 'toilet'], 'question_id': '1403'}, '516': {'fact_surface': '[[a bathroom]] is for [[washing your hands]]', 'answer': 'wash your hand', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000108548.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'used for', 'wash your hand'], 'question_id': '1402'}, '517': {'fact_surface': '[[jellyfish]] is related to [[transparent]]', 'answer': 'jellyfish', 'question': 'Which object in this image is transparent?', 'img_file': 'ILSVRC2012_test_00008683.JPEG', 'kb_source': 'conceptnet', 'fact': ['jellyfish', 'related to', 'transparent'], 'question_id': '1400'}, '518': {'fact_surface': '[[zebra]] is a kind of [[animal]].', 'answer': 'zebra', 'question': 'Which object in this image is an animal?', 'img_file': 'COCO_val2014_000000011760.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'is a', 'animal'], 'question_id': '1405'}, '519': {'fact_surface': '[[a bathroom]] is for [[washing your hands]]', 'answer': 'wash your hand', 'question': 'what is the place in this image used for?', 'img_file': 'COCO_val2014_000000108548.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'used for', 'wash your hand'], 'question_id': '1404'}, '520': {'fact_surface': '[[cow]] belongs to the category of [[Mammal]]', 'answer': 'cow', 'question': 'What mammals can be seen in this image?', 'img_file': 'COCO_val2014_000000119961.jpg', 'kb_source': 'dbpedia', 'fact': ['cow', 'belong to', 'mammal'], 'question_id': '4215'}, '521': {'fact_surface': 'You are likely to find [[a cow]] in [[a pasture]]', 'answer': 'cow', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000119961.jpg', 'kb_source': 'conceptnet', 'fact': ['cow', 'at location', 'pasture'], 'question_id': '4214'}, '522': {'fact_surface': '[[tree]] has [[roots]].', 'answer': 'tree', 'question': 'What in this image has roots?', 'img_file': 'COCO_val2014_000000004069.jpg', 'kb_source': 'conceptnet', 'fact': ['root', 'part of', 'tree'], 'question_id': '4217'}, '523': {'fact_surface': '[[drove]] is related to [[cattle]]', 'answer': 'cattle', 'question': 'Which object in this image is related to drive?', 'img_file': 'COCO_val2014_000000119961.jpg', 'kb_source': 'conceptnet', 'fact': ['drive', 'related to', 'cattle'], 'question_id': '4216'}, '524': {'fact_surface': '[[a tv]] is used for [[brainwashing people into buying stuff]]', 'answer': 'tv', 'question': 'Which thing in this image is used for brainwashing people into buying stuff?', 'img_file': 'ILSVRC2012_test_00023491.JPEG', 'kb_source': 'conceptnet', 'fact': ['tv', 'used for', 'brainwash person into buy stuff'], 'question_id': '4211'}, '525': {'fact_surface': '[[a tv]] is for [[watching]]', 'answer': 'tv', 'question': 'What thing in this image is for watching?', 'img_file': 'ILSVRC2012_test_00023491.JPEG', 'kb_source': 'conceptnet', 'fact': ['tv', 'used for', 'watch'], 'question_id': '4210'}, '526': {'fact_surface': '[[zebra]] is a kind of [[animal]].', 'answer': 'zebra', 'question': 'Which animal can be seen in this picture?', 'img_file': 'COCO_val2014_000000017089.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'is a', 'animal'], 'question_id': '693'}, '527': {'fact_surface': '[[Forest roads]] are [[inspirational]]', 'answer': 'forest road', 'question': 'What property does the place in this image have?', 'img_file': 'COCO_val2014_000000004069.jpg', 'kb_source': 'conceptnet', 'fact': ['forest road', 'has property', 'inspirational'], 'question_id': '4218'}, '528': {'fact_surface': '[[A dog]] can [[learn how to beg]]', 'answer': 'dog', 'question': 'Which object in this image can learn how to beg?', 'img_file': 'COCO_val2014_000000125405.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'capable of', 'learn how to beg'], 'question_id': '1542'}, '529': {'fact_surface': '[[Dogs]] usually [[play outside]]', 'answer': 'dog', 'question': 'Which animal in this image likes to play outside?', 'img_file': 'COCO_val2014_000000125405.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'capable of', 'play outside'], 'question_id': '1543'}, '530': {'fact_surface': '[[a frisbee]] is [[an aerodynamic toy disc]]', 'answer': 'frisbee', 'question': 'Which object in this image is a aerodynamic toy disc?', 'img_file': 'COCO_val2014_000000145734.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'is a', 'aerodynamic toy disc'], 'question_id': '5579'}, '531': {'fact_surface': '[[elephants]] are [[large]]', 'answer': 'elephant', 'question': 'Which animal in this image is large?', 'img_file': 'ILSVRC2012_test_00043882.JPEG', 'kb_source': 'conceptnet', 'fact': ['elephant', 'has property', 'large'], 'question_id': '5576'}, '532': {'fact_surface': '[[elephants]] are [[our largest land animal]]', 'answer': 'elephant', 'question': 'Which object in this image is the largest land animal?', 'img_file': 'ILSVRC2012_test_00043882.JPEG', 'kb_source': 'conceptnet', 'fact': ['elephant', 'is a', 'our large land animal'], 'question_id': '5575'}, '533': {'fact_surface': '[[Bathrooms]] have [[sinks]]', 'answer': 'sink', 'question': 'Which object in this image is a part of bathroom?', 'img_file': 'COCO_val2014_000000007214.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'has a', 'sink'], 'question_id': '5798'}, '534': {'fact_surface': '[[a runway]] is for [[landing airplanes]]', 'answer': 'land airplane', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000126659.jpg', 'kb_source': 'conceptnet', 'fact': ['runway', 'used for', 'land airplane'], 'question_id': '3264'}, '535': {'fact_surface': '[[oranges]] are [[sweet, juicy fruit]]', 'answer': 'sweet and juicy', 'question': 'What is the taste of the fruit in the image?', 'img_file': 'ILSVRC2012_test_00028372.JPEG', 'kb_source': 'conceptnet', 'fact': ['orange', 'is a', 'sweet and juicy'], 'question_id': '335'}, '536': {'fact_surface': '[[knife]] is used for [[ cut something]].', 'answer': 'knife', 'question': 'What thing in the image can be used for cutting?', 'img_file': 'ILSVRC2012_test_00028372.JPEG', 'kb_source': 'conceptnet', 'fact': ['knife', 'used for', 'cut something'], 'question_id': '334'}, '537': {'fact_surface': 'You can use [[a toilet]] to [[poop]]', 'answer': 'toilet', 'question': 'Which thing you have to use if you want to poop?', 'img_file': 'COCO_val2014_000000104837.jpg', 'kb_source': 'conceptnet', 'fact': ['toilet', 'used for', 'poop'], 'question_id': '337'}, '538': {'fact_surface': '[[toaster]] is related to [[browning bread]]', 'answer': 'toaster', 'question': 'Which thing in the image is used to browning bread?', 'img_file': 'ILSVRC2012_test_00028372.JPEG', 'kb_source': 'conceptnet', 'fact': ['toaster', 'related to', 'brown bread'], 'question_id': '333'}, '539': {'fact_surface': '[[bottle]] is related to [[wine container]]', 'answer': 'wine', 'question': 'What is in the bottle?', 'img_file': 'ILSVRC2012_test_00022929.JPEG', 'kb_source': 'conceptnet', 'fact': ['bottle', 'related to', 'wine'], 'question_id': '332'}, '540': {'fact_surface': 'A [[harp]] is a [[musical instrument]]', 'answer': 'harp', 'question': 'Which object in this image is a musical instrument?', 'img_file': 'ILSVRC2012_test_00016538.JPEG', 'kb_source': 'conceptnet', 'fact': ['harp', 'is a', 'musical instrument'], 'question_id': '3269'}, '541': {'fact_surface': 'You are likely to find [[a stove]] in [[the kitchen]].', 'answer': 'stove', 'question': 'What thing is likely to be found in this place', 'img_file': 'COCO_val2014_000000117788.jpg', 'kb_source': 'conceptnet', 'fact': ['stove', 'at location', 'kitchen'], 'question_id': '5125'}, '542': {'fact_surface': '[[A bear]] has [[claws]]', 'answer': 'bear', 'question': 'which object has claws', 'img_file': 'COCO_val2014_000000006871.jpg', 'kb_source': 'conceptnet', 'fact': ['bear', 'has a', 'claw'], 'question_id': '5126'}, '543': {'fact_surface': '[[cargo bin]] is related to [[luggage]]', 'answer': 'luggage', 'question': 'What seen here may be placed in a cargo bin?', 'img_file': 'COCO_val2014_000000112022.jpg', 'kb_source': 'conceptnet', 'fact': ['cargo bin', 'related to', 'luggage'], 'question_id': '3195'}, '544': {'fact_surface': 'A [[monitor]] is a [[name for a type of computer screen]]', 'answer': 'monitor', 'question': 'Which object in this image is used for output by a computer?', 'img_file': 'COCO_val2014_000000150320.jpg', 'kb_source': 'conceptnet', 'fact': ['monitor', 'is a', 'name for type of computer screen'], 'question_id': '3416'}, '545': {'fact_surface': 'You can use [[a desk]] to [[work sitting down]]', 'answer': 'desk', 'question': 'Which furniture in this image is used for work sit down?', 'img_file': 'COCO_val2014_000000150320.jpg', 'kb_source': 'conceptnet', 'fact': ['desk', 'used for', 'work sit down'], 'question_id': '3417'}, '546': {'fact_surface': '[[computer]] belongs to the category of [[Office supplies]]', 'answer': 'computer', 'question': 'Which equipment in this image belongs to the category Office supplies?', 'img_file': 'COCO_val2014_000000150320.jpg', 'kb_source': 'dbpedia', 'fact': ['computer', 'belong to', 'office supplies'], 'question_id': '3414'}, '547': {'fact_surface': 'A [[keyboard]] is a [[input device]].', 'answer': 'keyboard', 'question': 'Which electronic device in this image is a input device?', 'img_file': 'COCO_val2014_000000150320.jpg', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'is a', 'input device'], 'question_id': '3415'}, '548': {'fact_surface': '[[pointer]] is related to [[mouse]]', 'answer': 'mouse', 'question': 'Which object in this image is related to a pointer?', 'img_file': 'COCO_val2014_000000150320.jpg', 'kb_source': 'conceptnet', 'fact': ['point', 'related to', 'mouse'], 'question_id': '3418'}, '549': {'fact_surface': '[[desk]] is a kind of [[furniture]]', 'answer': 'desk', 'question': 'Which object in this image is a kind of fuiniture?', 'img_file': 'COCO_val2014_000000150320.jpg', 'kb_source': 'conceptnet', 'fact': ['desk', 'is a', 'furniture'], 'question_id': '3419'}, '550': {'fact_surface': 'A [[kitten]] is a [[young cat]]', 'answer': 'kitten', 'question': 'Which object in this image is a young cat?', 'img_file': 'COCO_val2014_000000026768.jpg', 'kb_source': 'conceptnet', 'fact': ['kitten', 'is a', 'young cat'], 'question_id': '4869'}, '551': {'fact_surface': '[[iBook]] is related to [[laptop]]', 'answer': 'laptop', 'question': 'which object in this picture can connect with an ibook', 'img_file': 'ILSVRC2012_test_00060109.JPEG', 'kb_source': 'conceptnet', 'fact': ['ibook', 'related to', 'laptop'], 'question_id': '4862'}, '552': {'fact_surface': '[[teddy bear]] belongs to the category of [[Stuffed toys]]', 'answer': 'teddy bear', 'question': 'which object in this image is a type of stuffed toy?', 'img_file': 'COCO_val2014_000000135572.jpg', 'kb_source': 'dbpedia', 'fact': ['teddy bear', 'belong to', 'stuffed toys'], 'question_id': '4860'}, '553': {'fact_surface': 'You are likely to find [[a human]] in [[room]]', 'answer': 'human', 'question': 'what can we find in the place shown in this image', 'img_file': 'COCO_val2014_000000120747.jpg', 'kb_source': 'conceptnet', 'fact': ['human', 'at location', 'room'], 'question_id': '2011'}, '554': {'fact_surface': 'You are likely to find [[a wall]] in [[a room]]', 'answer': 'wall', 'question': 'What can you find in this place?', 'img_file': 'COCO_val2014_000000120747.jpg', 'kb_source': 'conceptnet', 'fact': ['wall', 'at location', 'room'], 'question_id': '2010'}, '555': {'fact_surface': '[[train]] moved no faster than [[pedestrian]]', 'answer': 'train', 'question': 'which object in this image could run faster than pedestrian', 'img_file': 'COCO_val2014_000000028526.jpg', 'kb_source': 'webchild', 'fact': ['train', 'fast', 'pedestrian'], 'question_id': '4864'}, '556': {'fact_surface': '[[a guitar]] is for [[playing chords]]', 'answer': 'guitar', 'question': 'Which object seen here is used for playing chords?', 'img_file': 'ILSVRC2012_test_00038723.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'used for', 'play chord'], 'question_id': '4865'}, '557': {'fact_surface': '[[pretzel]] is a subclass of [[snack food]]', 'answer': 'pretzel', 'question': 'Which object in this image is a snack food?', 'img_file': 'ILSVRC2012_test_00000056.JPEG', 'kb_source': 'conceptnet', 'fact': ['pretzel', 'is a', 'snack food'], 'question_id': '4890'}, '558': {'fact_surface': '[[laptop]] belongs to the category of [[Mobile technology]]', 'answer': 'laptop', 'question': 'Which object in this image is a kind of Mobile technology?', 'img_file': 'COCO_val2014_000000141278.jpg', 'kb_source': 'dbpedia', 'fact': ['laptop', 'belong to', 'mobile technology'], 'question_id': '1349'}, '559': {'fact_surface': '[[window desktop laptop]] are largely cheaper than [[apple]]', 'answer': 'cheap', 'question': 'Whether the laptop in the image is cheaper or more expensive than a apple mac?', 'img_file': 'COCO_val2014_000000116405.jpg', 'kb_source': 'webchild', 'fact': ['window desktop laptop', 'cheap', 'cheap'], 'question_id': '452'}, '560': {'fact_surface': '[[reishi]] is related to [[mushroom]]', 'answer': 'mushroom', 'question': 'which object in this picture shows similar property as reishi', 'img_file': 'ILSVRC2012_test_00010194.JPEG', 'kb_source': 'conceptnet', 'fact': ['reishi', 'related to', 'mushroom'], 'question_id': '1343'}, '561': {'fact_surface': '[[skis]] belongs to the category of [[Outdoor recreation]]', 'answer': 'ski', 'question': 'which kind of outdoor recreation are shown in this image', 'img_file': 'COCO_val2014_000000138975.jpg', 'kb_source': 'dbpedia', 'fact': ['ski', 'belong to', 'outdoor recreation'], 'question_id': '1346'}, '562': {'fact_surface': '[[a person]] can [[lose his keys]]', 'answer': 'person', 'question': 'Which object in this image is capable of losing keys?', 'img_file': 'COCO_val2014_000000004765.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'lose his key'], 'question_id': '4008'}, '563': {'fact_surface': '[[surfing]] is related to [[surfboard]]', 'answer': 'surfboard', 'question': 'Which object in this image is for surfing?', 'img_file': 'COCO_val2014_000000004765.jpg', 'kb_source': 'conceptnet', 'fact': ['surf', 'related to', 'surfboard'], 'question_id': '4009'}, '564': {'fact_surface': '[[cow]] belongs to the category of [[Bovinae]]', 'answer': 'cow', 'question': 'Which object in this image belongs to the category Bovinae?', 'img_file': 'COCO_val2014_000000105367.jpg', 'kb_source': 'dbpedia', 'fact': ['cow', 'belong to', 'bovinae'], 'question_id': '4007'}, '565': {'fact_surface': 'Things that are often found together are [[keyboard]] and [[mouse]].', 'answer': 'keyboard', 'question': 'What object in this image is often found with a mouse?', 'img_file': 'COCO_val2014_000000118108.jpg', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'related to', 'mouse'], 'question_id': '3977'}, '566': {'fact_surface': '[[mouse]] belongs to the category of [[Computing]]', 'answer': 'mouse', 'question': 'What object in this image is related to computing?', 'img_file': 'COCO_val2014_000000118108.jpg', 'kb_source': 'dbpedia', 'fact': ['mouse', 'belong to', 'computing'], 'question_id': '3976'}, '567': {'fact_surface': '[[A keyboard]] is used for [[entering text]]', 'answer': 'keyboard', 'question': 'What object in this image is used for entering text?', 'img_file': 'COCO_val2014_000000118108.jpg', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'used for', 'enter text'], 'question_id': '3978'}, '568': {'fact_surface': 'You can use [[refrigerator]] to [[keep food fresh]].', 'answer': 'refrigerator', 'question': 'Which object in this image is used for keeping food fresh?', 'img_file': 'COCO_val2014_000000126983.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'used for', 'keep food fresh'], 'question_id': '3621'}, '569': {'fact_surface': '[[refrigerators]] can [[cool warm food]]', 'answer': 'refrigerator', 'question': 'Which object in this image is capable of cooling warm food?', 'img_file': 'COCO_val2014_000000126983.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'capable of', 'cool warm food'], 'question_id': '3620'}, '570': {'fact_surface': '[[a refrigerator]] is for [[making ice]]', 'answer': 'refrigerator', 'question': 'Which object in this image can be used for making ice?', 'img_file': 'COCO_val2014_000000126983.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'used for', 'make ice'], 'question_id': '3623'}, '571': {'fact_surface': '[[a refrigerator]] is used for [[chilling food]]', 'answer': 'refrigerator', 'question': 'Which object in this image is used for chilling food?', 'img_file': 'COCO_val2014_000000126983.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'used for', 'chill food'], 'question_id': '3622'}, '572': {'fact_surface': '[[a luggage]] is for [[carrying your clothing and personal items]]', 'answer': 'luggage', 'question': 'Which object in this image is used for carry your personal item?', 'img_file': 'COCO_val2014_000000020632.jpg', 'kb_source': 'conceptnet', 'fact': ['luggage', 'used for', 'carry your clothe and personal item'], 'question_id': '4479'}, '573': {'fact_surface': 'You can use [[a luggage]] to [[transport clothing while on a trip]]', 'answer': 'luggage', 'question': 'Which object in this image is used for transport clothe while on trip?', 'img_file': 'COCO_val2014_000000020632.jpg', 'kb_source': 'conceptnet', 'fact': ['luggage', 'used for', 'transport clothe while on trip'], 'question_id': '4478'}, '574': {'fact_surface': '[[A pen]] is [[a writing or drawing tool]]', 'answer': 'pen', 'question': 'Which object in this image is a writing or drawing tool?', 'img_file': 'ILSVRC2012_test_00029179.JPEG', 'kb_source': 'conceptnet', 'fact': ['pen', 'is a', 'write or draw tool'], 'question_id': '4470'}, '575': {'fact_surface': '[[cake]] is related to [[birthday party]]', 'answer': 'cake', 'question': 'Which object in this image is related to a birthday party?', 'img_file': 'COCO_val2014_000000114184.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'related to', 'birthday party'], 'question_id': '4473'}, '576': {'fact_surface': '[[Chocolate]] can [[make someone happy]]', 'answer': 'chocolate', 'question': 'Which thing in this image can make people happy?', 'img_file': 'COCO_val2014_000000114184.jpg', 'kb_source': 'conceptnet', 'fact': ['chocolate', 'capable of', 'make someone happy'], 'question_id': '4472'}, '577': {'fact_surface': '[[plates]] belongs to the category of [[Kitchenware]]', 'answer': 'plate', 'question': 'What object in this image belongs to the kitchenware?', 'img_file': 'COCO_val2014_000000114184.jpg', 'kb_source': 'dbpedia', 'fact': ['plate', 'belong to', 'kitchenware'], 'question_id': '4474'}, '578': {'fact_surface': '[[dog]] is related to [[pet animal]]', 'answer': 'dog', 'question': 'Which animal in this image is a pet?', 'img_file': 'COCO_val2014_000000115912.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'related to', 'pet animal'], 'question_id': '2464'}, '579': {'fact_surface': '[[A dog]] can [[please its master]]', 'answer': 'dog', 'question': 'Which animal in this image is capable of please it master?', 'img_file': 'COCO_val2014_000000115912.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'capable of', 'please it master'], 'question_id': '2461'}, '580': {'fact_surface': '[[dog]] is related to [[barking]]', 'answer': 'dog', 'question': 'What in this image can bark?', 'img_file': 'COCO_val2014_000000115912.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'related to', 'bark'], 'question_id': '2462'}, '581': {'fact_surface': '[[dog]] is related to [[pet animal]]', 'answer': 'dog', 'question': 'Which animal in this image is a pet?', 'img_file': 'COCO_val2014_000000115912.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'related to', 'pet animal'], 'question_id': '2463'}, '582': {'fact_surface': '[[trombone]] belongs to the category of [[Jazz]]', 'answer': 'trombone', 'question': 'Which object is related to jazz in this image?', 'img_file': 'ILSVRC2012_test_00000499.JPEG', 'kb_source': 'dbpedia', 'fact': ['trombone', 'belong to', 'jazz'], 'question_id': '5346'}, '583': {'fact_surface': '[[blanketing]] is related to [[cloth]]', 'answer': 'blanket', 'question': 'What in this image is related to cloth?', 'img_file': 'COCO_val2014_000000119581.jpg', 'kb_source': 'conceptnet', 'fact': ['blanket', 'related to', 'cloth'], 'question_id': '5340'}, '584': {'fact_surface': '[[people]] can [[wear pairs of pants]]', 'answer': 'person', 'question': 'Which objects are wearing pairs of pants in this image?', 'img_file': 'ILSVRC2012_test_00000499.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'wear pair of pant'], 'question_id': '5341'}, '585': {'fact_surface': '[[trombone]] is related to [[brass]]', 'answer': 'trombone', 'question': 'What is the brass object in this image?', 'img_file': 'ILSVRC2012_test_00000499.JPEG', 'kb_source': 'conceptnet', 'fact': ['trombone', 'related to', 'brass'], 'question_id': '5343'}, '586': {'fact_surface': '[[A wave]] is part of [[an ocean]]', 'answer': 'wave', 'question': 'What is a part of an ocean?', 'img_file': 'COCO_val2014_000000006028.jpg', 'kb_source': 'conceptnet', 'fact': ['wave', 'part of', 'ocean'], 'question_id': '5348'}, '587': {'fact_surface': '[[hat with a wide brim]] belongs to the category of [[1950s]]', 'answer': 'hat with a wide brim', 'question': 'Which object in this image belongs to the 1950s?', 'img_file': 'ILSVRC2012_test_00027726.JPEG', 'kb_source': 'dbpedia', 'fact': ['hat with a wide brim', 'belong to', '1950s'], 'question_id': '1028'}, '588': {'fact_surface': '[[trucks]] can [[move heavy loads]]', 'answer': 'truck', 'question': 'What object can move heavy load?', 'img_file': 'COCO_val2014_000000008646.jpg', 'kb_source': 'conceptnet', 'fact': ['truck', 'capable of', 'move heavy load'], 'question_id': '1649'}, '589': {'fact_surface': '[[Table tennis]] is also [[called ping-pong]]', 'answer': 'ping pong', 'question': 'What is the another name of this game?', 'img_file': 'ILSVRC2012_test_00029063.JPEG', 'kb_source': 'conceptnet', 'fact': ['table tennis', 'is a', 'ping pong'], 'question_id': '579'}, '590': {'fact_surface': '[[couch]] is related to [[chair]]', 'answer': 'couch', 'question': 'What thing in this image is most similar to chair', 'img_file': 'COCO_val2014_000000153685.jpg', 'kb_source': 'conceptnet', 'fact': ['couch', 'related to', 'chair'], 'question_id': '571'}, '591': {'fact_surface': '[[A pizza]] contains [[mostly dough, cheese, and tomato]]', 'answer': 'pizza', 'question': 'Which food is mostly dough, cheese and tomato?', 'img_file': 'COCO_val2014_000000144959.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'has a', 'mostly dough cheese and tomato'], 'question_id': '576'}, '592': {'fact_surface': 'You can use [[a frisbee]] to [[entertain a dog]]', 'answer': 'frisbee', 'question': 'Which animal you can entertain by using this game?', 'img_file': 'COCO_val2014_000000147259.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'used for', 'entertain dog'], 'question_id': '575'}, '593': {'fact_surface': '[[Turtles]] are [[similar to tortoises]]', 'answer': 'turtle', 'question': 'Which object in this image is similar to a tortoise?', 'img_file': 'ILSVRC2012_test_00011888.JPEG', 'kb_source': 'conceptnet', 'fact': ['turtle', 'has property', 'similar to tortoise'], 'question_id': '2801'}, '594': {'fact_surface': '[[windows]] belongs to the category of [[Architectural elements]]', 'answer': 'window', 'question': 'What is one prominent architectural element pictured here?', 'img_file': 'COCO_val2014_000000100848.jpg', 'kb_source': 'dbpedia', 'fact': ['window', 'belong to', 'architectural elements'], 'question_id': '5432'}, '595': {'fact_surface': '[[bagels]] are [[shaped like doughnuts]]', 'answer': 'bagel', 'question': 'Which object in this image has the property of being shaped like a doughnut?', 'img_file': 'ILSVRC2012_test_00002238.JPEG', 'kb_source': 'conceptnet', 'fact': ['bagel', 'has property', 'shape like doughnut'], 'question_id': '5433'}, '596': {'fact_surface': '[[living room]] can be warmer than [[bedroom]]', 'answer': 'living room', 'question': 'Which place is less warm than the place shown in this image', 'img_file': 'COCO_val2014_000000100848.jpg', 'kb_source': 'webchild', 'fact': ['living room', 'warm', 'bedroom'], 'question_id': '5431'}, '597': {'fact_surface': '[[bagel]] belongs to the category of [[Baked goods]]', 'answer': 'bagel', 'question': \"which object in this image belongs to the category 'baked goods'?\", 'img_file': 'ILSVRC2012_test_00002238.JPEG', 'kb_source': 'dbpedia', 'fact': ['bagel', 'belong to', 'baked goods'], 'question_id': '5436'}, '598': {'fact_surface': '[[Bread]] is generally [[made from grain]]', 'answer': 'bread', 'question': 'which object in this image is made of grain', 'img_file': 'ILSVRC2012_test_00002238.JPEG', 'kb_source': 'conceptnet', 'fact': ['bread', 'has property', 'make from grain'], 'question_id': '5437'}, '599': {'fact_surface': '[[a bagel]] is [[a roll]]', 'answer': 'bagel', 'question': 'What kind of roll can one see here?', 'img_file': 'ILSVRC2012_test_00002238.JPEG', 'kb_source': 'conceptnet', 'fact': ['bagel', 'is a', 'roll'], 'question_id': '5434'}, '600': {'fact_surface': '[[bagel]] is [[a doughnut shaped roll]]', 'answer': 'bagel', 'question': 'which object in this image is a donut shaped roll?', 'img_file': 'ILSVRC2012_test_00002238.JPEG', 'kb_source': 'conceptnet', 'fact': ['bagel', 'is a', 'doughnut shape roll'], 'question_id': '5435'}, '601': {'fact_surface': '[[frisbees]] are [[toys]]', 'answer': 'frisbee', 'question': 'What object in this image is a toy?', 'img_file': 'COCO_val2014_000000100238.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'is a', 'toy'], 'question_id': '3364'}, '602': {'fact_surface': '[[handbag]] belongs to the category of [[Containers]]', 'answer': 'handbag', 'question': 'What object in this image is a container?', 'img_file': 'COCO_val2014_000000100238.jpg', 'kb_source': 'dbpedia', 'fact': ['handbag', 'belong to', 'container'], 'question_id': '3365'}, '603': {'fact_surface': '[[a frisbee]] is for [[the park]]', 'answer': 'frisbee', 'question': 'What object in this image is used at a park?', 'img_file': 'COCO_val2014_000000100238.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'used for', 'park'], 'question_id': '3367'}, '604': {'fact_surface': '[[plate]] is related to [[frisbee]]', 'answer': 'frisbee', 'question': 'Which object in this image is like a plate?', 'img_file': 'COCO_val2014_000000100238.jpg', 'kb_source': 'conceptnet', 'fact': ['plate', 'related to', 'frisbee'], 'question_id': '3361'}, '605': {'fact_surface': '[[frisbee]] belongs to the category of [[Sports equipment]]', 'answer': 'frisbee', 'question': 'What object in this image is a type of sports equipment?', 'img_file': 'COCO_val2014_000000100238.jpg', 'kb_source': 'dbpedia', 'fact': ['flying disc', 'belong to', 'frisbee'], 'question_id': '3362'}, '606': {'fact_surface': '[[frisbees]] are [[fun]]', 'answer': 'frisbee', 'question': 'What object in this image is fun?', 'img_file': 'COCO_val2014_000000100238.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'has property', 'fun'], 'question_id': '3363'}, '607': {'fact_surface': 'You are likely to find [[a snake]] in [[a nightmare]]', 'answer': 'snake', 'question': 'Which object in this image might occur in a nightmare?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'at location', 'nightmare'], 'question_id': '4273'}, '608': {'fact_surface': '[[a motorcycle]] has [[two wheels]]', 'answer': 'motorcycle', 'question': 'Which object in this image has a two wheel', 'img_file': 'COCO_val2014_000000121430.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'has a', 'two wheel'], 'question_id': '4271'}, '609': {'fact_surface': '[[grass]] can [[stain your pants]]', 'answer': 'grass', 'question': 'Which object in this image is capable of staining your pants?', 'img_file': 'COCO_val2014_000000121430.jpg', 'kb_source': 'conceptnet', 'fact': ['grass', 'capable of', 'stain your pant'], 'question_id': '4270'}, '610': {'fact_surface': 'You are likely to find [[a snake]] in [[outside, in the grass]]', 'answer': 'snake', 'question': 'Which object in this image can be found in grass?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'at location', 'outside in grass'], 'question_id': '4277'}, '611': {'fact_surface': '[[snake]] is related to [[legless]]', 'answer': 'snake', 'question': 'Which object in this image is legless?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'related to', 'legless'], 'question_id': '4276'}, '612': {'fact_surface': 'An [[snake]] can [[bite]].', 'answer': 'snake', 'question': 'Which object in this image can bite?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'capable of', 'bite'], 'question_id': '4275'}, '613': {'fact_surface': 'A [[snake]] is a [[reptile with a long, narrow body and no legs]]', 'answer': 'snake', 'question': 'Which object in this image is a reptile with long narrow body and no leg?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'is a', 'reptile with long narrow body and no leg'], 'question_id': '4274'}, '614': {'fact_surface': 'You are likely to find [[a snake]] in [[the rainforest]]', 'answer': 'snake', 'question': 'Which animal in this image can be found in rainforest?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'at location', 'rainforest'], 'question_id': '4279'}, '615': {'fact_surface': 'You are likely to find [[a snake]] in [[tall, moist grass [New England species]]]', 'answer': 'snake', 'question': 'What in this image can be found in tall moist grass new england specie?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'at location', 'tall moist grass new england specie'], 'question_id': '4278'}, '616': {'fact_surface': '*Something you find at [[a street corner]] is [[a fire hydrant]]', 'answer': 'fire hydrant', 'question': 'Which object in this image can be found at street corners?', 'img_file': 'COCO_val2014_000000125829.jpg', 'kb_source': 'conceptnet', 'fact': ['fire hydrant', 'at location', 'street corner'], 'question_id': '5557'}, '617': {'fact_surface': '[[bicycle]] is a kind of [[two-wheeled vehicle]].', 'answer': 'bicycle', 'question': 'What particular two wheeled vehicle is seen here?', 'img_file': 'COCO_val2014_000000125829.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'is a', 'two wheel vehicle'], 'question_id': '5556'}, '618': {'fact_surface': '[[donut]] are better than [[peanut]]', 'answer': 'donut', 'question': 'which object in this image is better than peanut?', 'img_file': 'ILSVRC2012_test_00023567.JPEG', 'kb_source': 'webchild', 'fact': ['donut', 'good', 'peanut'], 'question_id': '5550'}, '619': {'fact_surface': '[[bus]] are slower than [[train]]', 'answer': 'train', 'question': 'What object in this image is faster than bus?', 'img_file': 'COCO_val2014_000000028526.jpg', 'kb_source': 'webchild', 'fact': ['bus', 'slow', 'train'], 'question_id': '4863'}, '620': {'fact_surface': '[[bicycles]] are [[human powered]]', 'answer': 'bicycle', 'question': 'Which object in this image is human powered?', 'img_file': 'COCO_val2014_000000125829.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'has property', 'human power'], 'question_id': '5559'}, '621': {'fact_surface': 'A [[person]] can [[talk]].', 'answer': 'person', 'question': 'which object in this image can talk', 'img_file': 'ILSVRC2012_test_00008027.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'talk'], 'question_id': '2017'}, '622': {'fact_surface': '[[iBook]] is related to [[laptop]]', 'answer': 'laptop', 'question': 'which object in this picture can connect with an ibook', 'img_file': 'ILSVRC2012_test_00060109.JPEG', 'kb_source': 'conceptnet', 'fact': ['ibook', 'related to', 'laptop'], 'question_id': '4861'}, '623': {'fact_surface': '[[guitar]] belongs to the category of [[Arts in Spain]]', 'answer': 'guitar', 'question': 'What object belongs to art of Spain?', 'img_file': 'ILSVRC2012_test_00038723.JPEG', 'kb_source': 'dbpedia', 'fact': ['guitar', 'belong to', 'arts in spain'], 'question_id': '4866'}, '624': {'fact_surface': '[[A person]] can [[hear the radio]]', 'answer': 'person', 'question': 'which object in this image can hear the radio for news', 'img_file': 'ILSVRC2012_test_00027848.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'hear radio'], 'question_id': '4867'}, '625': {'fact_surface': '[[tree]] is related to [[wood]]', 'answer': 'tree', 'question': 'Which object in this image is related to wood?', 'img_file': 'COCO_val2014_000000016704.jpg', 'kb_source': 'conceptnet', 'fact': ['tree', 'related to', 'wood'], 'question_id': '5883'}, '626': {'fact_surface': '[[an elephant]] has [[a long nose called \"trunk\"]]', 'answer': 'elephant', 'question': 'Which object in this image has a long nose called a trunk?', 'img_file': 'COCO_val2014_000000016704.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'has a', 'long nose call trunk'], 'question_id': '5882'}, '627': {'fact_surface': '[[A dog]] can [[follow its master]]', 'answer': 'dog', 'question': 'What animal in the image can follow its master?', 'img_file': 'COCO_val2014_000000106356.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'capable of', 'follow it master'], 'question_id': '5881'}, '628': {'fact_surface': '[[vegetables]] belongs to the category of [[Food]]', 'answer': 'vegetable', 'question': 'Which object in this image belongs to the category Food?', 'img_file': 'COCO_val2014_000000135256.jpg', 'kb_source': 'dbpedia', 'fact': ['vegetable', 'belong to', 'food'], 'question_id': '5887'}, '629': {'fact_surface': '[[soccer ball]] belongs to the category of [[Game equipment]]', 'answer': 'soccer ball', 'question': 'what object in this image is game equipment?', 'img_file': 'ILSVRC2012_test_00000641.JPEG', 'kb_source': 'dbpedia', 'fact': ['soccer ball', 'belong to', 'game equipment'], 'question_id': '351'}, '630': {'fact_surface': '[[A remote]] can [[control a TV]]', 'answer': 'control tv', 'question': 'What can the object in this image do?', 'img_file': 'ILSVRC2012_test_00045390.JPEG', 'kb_source': 'conceptnet', 'fact': ['remote', 'capable of', 'control tv'], 'question_id': '350'}, '631': {'fact_surface': '[[children]] belongs to the category of [[Hominini]]', 'answer': 'child', 'question': 'What in this image belongs to the category Hominini?', 'img_file': 'COCO_val2014_000000134459.jpg', 'kb_source': 'dbpedia', 'fact': ['child', 'belong to', 'hominini'], 'question_id': '4854'}, '632': {'fact_surface': '[[A motorcycle]] is used for [[transportation]]', 'answer': 'motorcycle', 'question': 'Which object in this image is used for transportation?', 'img_file': 'COCO_val2014_000000015827.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'used for', 'transportation'], 'question_id': '2190'}, '633': {'fact_surface': 'You can use [[a baseball field]] to [[play]]', 'answer': 'play', 'question': 'What activity is the place used for?', 'img_file': 'COCO_val2014_000000005388.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball field', 'used for', 'play'], 'question_id': '2259'}, '634': {'fact_surface': 'You are likely to find [[a baseball]] in [[baseball field]]', 'answer': 'baseball', 'question': 'Which objects do you expect to find in a baseball field?', 'img_file': 'COCO_val2014_000000005388.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'at location', 'baseball field'], 'question_id': '2258'}, '635': {'fact_surface': '[[Baseball]] is [[a popular sport in America]]', 'answer': 'baseball', 'question': 'What popular sport in America is in this image?', 'img_file': 'COCO_val2014_000000005388.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'is a', 'popular sport in america'], 'question_id': '2257'}, '636': {'fact_surface': '[[cheese]] is used for [[cooking]].', 'answer': 'cheese', 'question': 'What can you cook with ?', 'img_file': 'COCO_val2014_000000119677.jpg', 'kb_source': 'conceptnet', 'fact': ['cheese', 'used for', 'cook'], 'question_id': '4637'}, '637': {'fact_surface': '[[ping-pong ball]] belongs to the category of [[Indoor sports]]', 'answer': 'ping pong ball', 'question': 'Which kind of indoor sports are they playing?', 'img_file': 'ILSVRC2012_test_00002577.JPEG', 'kb_source': 'dbpedia', 'fact': ['table tennis', 'belong to', 'ping pong ball'], 'question_id': '2255'}, '638': {'fact_surface': '[[hand]] has [[a wrist]].', 'answer': 'hand', 'question': 'Which object in this image has a wrist?', 'img_file': 'ILSVRC2012_test_00002577.JPEG', 'kb_source': 'conceptnet', 'fact': ['wrist', 'part of', 'hand'], 'question_id': '2254'}, '639': {'fact_surface': '[[flowers]] belongs to the category of [[Plants]]', 'answer': 'flower', 'question': 'Which object in this image belongs to the category Plants?', 'img_file': 'COCO_val2014_000000101059.jpg', 'kb_source': 'dbpedia', 'fact': ['flower', 'belong to', 'plant'], 'question_id': '2253'}, '640': {'fact_surface': '[[a vase]] can [[holds flowers]]', 'answer': 'vase', 'question': 'Where should flowers be placed in this image?', 'img_file': 'COCO_val2014_000000101059.jpg', 'kb_source': 'conceptnet', 'fact': ['vase', 'capable of', 'hold flower'], 'question_id': '2252'}, '641': {'fact_surface': 'You are likely to find [[snow]] in [[winter]].', 'answer': 'snow', 'question': 'What object can be found in winter?', 'img_file': 'COCO_val2014_000000102329.jpg', 'kb_source': 'conceptnet', 'fact': ['snow', 'at location', 'winter'], 'question_id': '2251'}, '642': {'fact_surface': '[[cell phone]] belongs to the category of [[Mobile telephony]]', 'answer': 'cell phone', 'question': 'Which object in this image belongs to the class Mobile telephony?', 'img_file': 'COCO_val2014_000000027517.jpg', 'kb_source': 'dbpedia', 'fact': ['cell phone', 'belong to', 'mobile telephony'], 'question_id': '4634'}, '643': {'fact_surface': '[[snow]] is [[falling from the sku]].', 'answer': 'snow', 'question': 'What object is falling from sky?', 'img_file': 'COCO_val2014_000000020972.jpg', 'kb_source': 'conceptnet', 'fact': ['snow', 'has property', 'fall from sku'], 'question_id': '3227'}, '644': {'fact_surface': '[[sand]] is used for [[hourglasses]]', 'answer': 'sand', 'question': 'Which thing in this image is used in an hourglass?', 'img_file': 'COCO_val2014_000000124599.jpg', 'kb_source': 'conceptnet', 'fact': ['sand', 'used for', 'hourglass'], 'question_id': '4804'}, '645': {'fact_surface': '[[motorcycle]] can be lighter than [[car]]', 'answer': 'motorcycle', 'question': 'which object in this image is lighter than car?', 'img_file': 'COCO_val2014_000000104647.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'light', 'car'], 'question_id': '2789'}, '646': {'fact_surface': '[[A motorcycle]] has [[two wheels and can go fast]]', 'answer': 'motorcycle', 'question': 'Which object in this image has two wheels and can go fast?', 'img_file': 'COCO_val2014_000000104647.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'has a', 'two wheel and can go fast'], 'question_id': '2788'}, '647': {'fact_surface': '[[luggage]] is used to [[carry clothing on vacation]]', 'answer': 'luggage', 'question': 'Which object in this image is used for carrying clothing on vacation?', 'img_file': 'COCO_val2014_000000006864.jpg', 'kb_source': 'conceptnet', 'fact': ['luggage', 'used for', 'carry clothe on vacation'], 'question_id': '5371'}, '648': {'fact_surface': '[[Cars]] have [[four wheels]]', 'answer': 'car', 'question': 'Which object in this image has four wheels?', 'img_file': 'COCO_val2014_000000146701.jpg', 'kb_source': 'conceptnet', 'fact': ['car', 'has a', 'four wheel'], 'question_id': '4399'}, '649': {'fact_surface': '[[People]] like to [[watch tv]]', 'answer': 'person', 'question': 'which object in this image likes watching TV?', 'img_file': 'ILSVRC2012_test_00044361.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'watch tv'], 'question_id': '4390'}, '650': {'fact_surface': '[[a person]] can [[plant a tree]]', 'answer': 'person', 'question': 'which object in this image is capable of planting a tree?', 'img_file': 'ILSVRC2012_test_00044361.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'plant tree'], 'question_id': '4391'}, '651': {'fact_surface': '[[A person]] can [[laugh at other people]]', 'answer': 'person', 'question': 'which object in this image is capable of laughing at others?', 'img_file': 'ILSVRC2012_test_00044361.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'laugh at other person'], 'question_id': '4392'}, '652': {'fact_surface': '[[A person]] can [[view a picture]]', 'answer': 'person', 'question': 'which object in this image is capable of viewing a picture?', 'img_file': 'ILSVRC2012_test_00044361.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'view picture'], 'question_id': '4393'}, '653': {'fact_surface': '[[A person]] can [[learn to read]]', 'answer': 'person', 'question': 'which object in this image can learn to read?', 'img_file': 'ILSVRC2012_test_00044361.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'learn to read'], 'question_id': '4394'}, '654': {'fact_surface': '[[A person]] can [[make a purchase with cash]]', 'answer': 'person', 'question': 'which object in this image is capable of purchasing an item with cash?', 'img_file': 'ILSVRC2012_test_00044361.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'make purchase with cash'], 'question_id': '4395'}, '655': {'fact_surface': 'You can use [[a luggage]] to [[carry your things while travelling]]', 'answer': 'luggage', 'question': 'Which object in this image is used for carry your thing while travel?', 'img_file': 'COCO_val2014_000000112022.jpg', 'kb_source': 'conceptnet', 'fact': ['luggage', 'used for', 'carry your thing while travel'], 'question_id': '3194'}, '656': {'fact_surface': '[[a suitcase]] can be used for [[packing clothes for a trip]]', 'answer': 'suitcase', 'question': 'Which object in this image is used for packing clothes for a trip?', 'img_file': 'COCO_val2014_000000112022.jpg', 'kb_source': 'conceptnet', 'fact': ['suitcase', 'used for', 'pack clothe for trip'], 'question_id': '3192'}, '657': {'fact_surface': '[[knives]] can [[be both tools and weapons]]', 'answer': 'knife', 'question': 'Which object in the image can be both tools and weapons?', 'img_file': 'ILSVRC2012_test_00000783.JPEG', 'kb_source': 'conceptnet', 'fact': ['knife', 'capable of', 'be both tool and weapon'], 'question_id': '474'}, '658': {'fact_surface': 'You can use [[a luggage]] to [[carry your things while travelling]]', 'answer': 'luggage', 'question': 'Which object in this image is used to carry your things while travelling?', 'img_file': 'COCO_val2014_000000112022.jpg', 'kb_source': 'conceptnet', 'fact': ['luggage', 'used for', 'carry your thing while travel'], 'question_id': '3190'}, '659': {'fact_surface': '[[a cat]] likes to [[chase birds]]', 'answer': 'cat', 'question': 'What thing in the image likes to chase birds?', 'img_file': 'COCO_val2014_000000131131.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'desires', 'chase bird'], 'question_id': '479'}, '660': {'fact_surface': '[[piano]] has [[white and black keys]]', 'answer': 'piano', 'question': 'What object has white and black keys?', 'img_file': 'COCO_val2014_000000117530.jpg', 'kb_source': 'conceptnet', 'fact': ['piano', 'part of', 'white and black key'], 'question_id': '4020'}, '661': {'fact_surface': '*Something you find at [[your house]] is [[a home office]]', 'answer': 'your house', 'question': 'where can we find the place shown in this image', 'img_file': 'COCO_val2014_000000117530.jpg', 'kb_source': 'conceptnet', 'fact': ['home office', 'at location', 'your house'], 'question_id': '4021'}, '662': {'fact_surface': '[[bed]] is related to [[rest place]]', 'answer': 'bed', 'question': 'What object in the image is used for rest.', 'img_file': 'COCO_val2014_000000116678.jpg', 'kb_source': 'conceptnet', 'fact': ['bed', 'related to', 'rest place'], 'question_id': '3994'}, '663': {'fact_surface': '[[bedroom]] is for [[sleeping]]', 'answer': 'sleep', 'question': 'What can this place in the image be used for?', 'img_file': 'COCO_val2014_000000116678.jpg', 'kb_source': 'conceptnet', 'fact': ['bedroom', 'used for', 'sleep'], 'question_id': '3993'}, '664': {'fact_surface': '[[bus]] are cheaper than [[train]]', 'answer': 'train', 'question': 'which transport in this image is less cheap than bus?', 'img_file': 'COCO_val2014_000000129135.jpg', 'kb_source': 'webchild', 'fact': ['bus', 'cheap', 'train'], 'question_id': '3991'}, '665': {'fact_surface': '[[climate change]] is seven times greater than [[train]]', 'answer': 'train', 'question': 'which tranport in this image is less great than climate change?', 'img_file': 'COCO_val2014_000000129135.jpg', 'kb_source': 'webchild', 'fact': ['climate change', 'great', 'train'], 'question_id': '3990'}, '666': {'fact_surface': '[[plantain]] be firmer than [[banana]]', 'answer': 'banana', 'question': 'Which food shown here is softer than a plantain?', 'img_file': 'ILSVRC2012_test_00040162.JPEG', 'kb_source': 'webchild', 'fact': ['plantain', 'firm', 'banana'], 'question_id': '298'}, '667': {'fact_surface': '[[apple]] is related to [[red fruit]]', 'answer': 'apple', 'question': 'What red fruit is in this image?', 'img_file': 'ILSVRC2012_test_00040162.JPEG', 'kb_source': 'conceptnet', 'fact': ['apple', 'related to', 'red fruit'], 'question_id': '299'}, '668': {'fact_surface': '[[an apple]] is for [[keeping the doctor away]]', 'answer': 'apple', 'question': 'What object in this image is used for keeping the doctor away?', 'img_file': 'ILSVRC2012_test_00040162.JPEG', 'kb_source': 'conceptnet', 'fact': ['apple', 'used for', 'keep doctor away'], 'question_id': '297'}, '669': {'fact_surface': '[[vases]] can be used to [[hold cut flowers]]', 'answer': 'vase', 'question': 'What object in this image is used to hold flowers?', 'img_file': 'COCO_val2014_000000101059.jpg', 'kb_source': 'conceptnet', 'fact': ['vase', 'used for', 'hold cut flower'], 'question_id': '293'}, '670': {'fact_surface': 'A [[motorcycle]] is a [[two wheeled vehicle]].', 'answer': 'two', 'question': 'How many wheels do these vehicle have?', 'img_file': 'COCO_val2014_000000135666.jpg', 'kb_source': 'conceptnet', 'fact': ['two', 'is a', 'two wheel vehicle'], 'question_id': '290'}, '671': {'fact_surface': '*Something you find at [[crossroads]] is [[traffic lights]]', 'answer': 'traffic light', 'question': 'which object in this image  often occurs in the crossroad', 'img_file': 'COCO_val2014_000000128939.jpg', 'kb_source': 'conceptnet', 'fact': ['traffic light', 'at location', 'crossroad'], 'question_id': '5487'}, '672': {'fact_surface': '[[a bus]] can [[carry passengers]]', 'answer': 'bus', 'question': 'which object in this image is often used for carrying passenger', 'img_file': 'ILSVRC2012_test_00058790.JPEG', 'kb_source': 'conceptnet', 'fact': ['bus', 'capable of', 'carry passenger'], 'question_id': '2446'}, '673': {'fact_surface': '[[Buses]] can be [[crowded during rush hour]]', 'answer': 'bus', 'question': 'Which vehicles have the property of crowd during rush hour?', 'img_file': 'ILSVRC2012_test_00058790.JPEG', 'kb_source': 'conceptnet', 'fact': ['bus', 'has property', 'crowd during rush hour'], 'question_id': '2447'}, '674': {'fact_surface': 'You can use [[a bus]] to [[travel around town]]', 'answer': 'bus', 'question': 'Which object in this image is used for travel around town?', 'img_file': 'ILSVRC2012_test_00058790.JPEG', 'kb_source': 'conceptnet', 'fact': ['bus', 'used for', 'travel around town'], 'question_id': '2444'}, '675': {'fact_surface': '[[buses]] are [[a common type fo public transportation]]', 'answer': 'bus', 'question': 'Which vehicles in this image is a common type for public transportation?', 'img_file': 'ILSVRC2012_test_00058790.JPEG', 'kb_source': 'conceptnet', 'fact': ['bus', 'is a', 'common type fo public transportation'], 'question_id': '2445'}, '676': {'fact_surface': '[[a bowl]] can [[keep water in it]]', 'answer': 'bowl', 'question': 'Which object in this image can keep water in it?', 'img_file': 'COCO_val2014_000000002759.jpg', 'kb_source': 'conceptnet', 'fact': ['bowl', 'capable of', 'keep water in it'], 'question_id': '1436'}, '677': {'fact_surface': '[[Broccoli]] is [[green]]', 'answer': 'broccoli', 'question': 'Which object in this image is green?', 'img_file': 'COCO_val2014_000000002759.jpg', 'kb_source': 'conceptnet', 'fact': ['broccoli', 'has property', 'green'], 'question_id': '1434'}, '678': {'fact_surface': '[[bowl]] is a kind of [[vessel]]', 'answer': 'bowl', 'question': 'Which object in this image is a vessel?', 'img_file': 'COCO_val2014_000000002759.jpg', 'kb_source': 'conceptnet', 'fact': ['bowl', 'is a', 'vessel'], 'question_id': '1432'}, '679': {'fact_surface': 'You can use [[a spoon]] for [[stirring]].', 'answer': 'spoon', 'question': 'Which object in this image can be used for stirring?', 'img_file': 'COCO_val2014_000000002759.jpg', 'kb_source': 'conceptnet', 'fact': ['spoon', 'used for', 'stir'], 'question_id': '1433'}, '680': {'fact_surface': '[[Wii]] is a kind of [[Gaming System]].', 'answer': 'wii', 'question': 'Which gaming system are the person playing in this image?', 'img_file': 'COCO_val2014_000000146487.jpg', 'kb_source': 'conceptnet', 'fact': ['wii', 'is a', 'game system'], 'question_id': '1627'}, '681': {'fact_surface': '[[ballast]] is related to [[ship]]', 'answer': 'ship', 'question': 'Which object in this image is related to ballast?', 'img_file': 'ILSVRC2012_test_00059915.JPEG', 'kb_source': 'conceptnet', 'fact': ['ballast', 'related to', 'ship'], 'question_id': '1626'}, '682': {'fact_surface': '*Something you find [[in the ocean]] is [[ships]]', 'answer': 'ship', 'question': 'Which object in this image can be found in the ocean?', 'img_file': 'ILSVRC2012_test_00059915.JPEG', 'kb_source': 'conceptnet', 'fact': ['ship', 'at location', 'in ocean'], 'question_id': '1625'}, '683': {'fact_surface': '[[tv]] is a kind of [[media]].', 'answer': 'tv', 'question': 'What kind of media is shown in this image ?', 'img_file': 'COCO_val2014_000000146487.jpg', 'kb_source': 'conceptnet', 'fact': ['tv', 'is a', 'medium'], 'question_id': '1629'}, '684': {'fact_surface': '[[tv]] is a kind of [[media]].', 'answer': 'tv', 'question': 'What kind of media is shown in this image ?', 'img_file': 'COCO_val2014_000000146487.jpg', 'kb_source': 'conceptnet', 'fact': ['tv', 'is a', 'medium'], 'question_id': '1628'}, '685': {'fact_surface': 'You are likely to find [[a horse]] in [[a racecourse]]', 'answer': 'horse', 'question': 'What can be found in this racecourse?', 'img_file': 'COCO_val2014_000000019032.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'at location', 'racecourse'], 'question_id': '2863'}, '686': {'fact_surface': '[[An umbrella]] is used to [[protect people from sun and rain]]', 'answer': 'umbrella', 'question': 'Which object in this image is used to protect people from sun and rain', 'img_file': 'COCO_val2014_000000137573.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'used for', 'protect person from sun and rain'], 'question_id': '559'}, '687': {'fact_surface': '[[Umbrellas]] are [[used on rainy days]]', 'answer': 'umbrella', 'question': 'Which object in this image is used on rainy days', 'img_file': 'COCO_val2014_000000137573.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'receives action', 'use on rainy day'], 'question_id': '558'}, '688': {'fact_surface': '[[teddy bear]] is a subclass of [[stuffed animal]]', 'answer': 'teddy bear', 'question': 'What stuffed animal is seen here?', 'img_file': 'COCO_val2014_000000108484.jpg', 'kb_source': 'conceptnet', 'fact': ['teddy bear', 'is a', 'stuff animal'], 'question_id': '554'}, '689': {'fact_surface': '[[an umbrella]] is for [[bad weather]]', 'answer': 'umbrella', 'question': 'Which object in this image is used for bad weather?', 'img_file': 'COCO_val2014_000000137573.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'used for', 'bad weather'], 'question_id': '557'}, '690': {'fact_surface': '[[teddy bear]] belongs to the category of [[Toy]]', 'answer': 'teddy bear', 'question': 'Tell me the name of the toy in this image?', 'img_file': 'COCO_val2014_000000108484.jpg', 'kb_source': 'dbpedia', 'fact': ['teddy bear', 'belong to', 'toy'], 'question_id': '553'}, '691': {'fact_surface': '[[the beach]] is [[sandy]]', 'answer': 'sandy', 'question': 'What property does the place in this image have?', 'img_file': 'COCO_val2014_000000151524.jpg', 'kb_source': 'conceptnet', 'fact': ['beach', 'has property', 'sandy'], 'question_id': '1438'}, '692': {'fact_surface': '[[balance beam]] is a subclass of [[gymnastics apparatus]]', 'answer': 'beam', 'question': 'Which object in this image is a gymnastics apparatus?', 'img_file': 'ILSVRC2012_test_00054727.JPEG', 'kb_source': 'conceptnet', 'fact': ['beam', 'is a', 'gymnastics apparatus'], 'question_id': '5055'}, '693': {'fact_surface': '[[goldfish]] are [[common aquatic pets]]', 'answer': 'goldfish', 'question': 'Which object in this image is a common aquatic pet?', 'img_file': 'ILSVRC2012_test_00042680.JPEG', 'kb_source': 'conceptnet', 'fact': ['goldfish', 'is a', 'common aquatic pet'], 'question_id': '1199'}, '694': {'fact_surface': '*Something you find [[in the water]] is [[a fish]]', 'answer': 'fish', 'question': 'Which object in this image is typically found in water?', 'img_file': 'ILSVRC2012_test_00042680.JPEG', 'kb_source': 'conceptnet', 'fact': ['fish', 'at location', 'in water'], 'question_id': '1198'}, '695': {'fact_surface': '[[eating]] was more important than [[music]]', 'answer': 'eat', 'question': 'In this image, which action is less significant than the action shown?', 'img_file': 'COCO_val2014_000000106909.jpg', 'kb_source': 'webchild', 'fact': ['eat', 'important', 'music'], 'question_id': '3349'}, '696': {'fact_surface': 'Somewhere [[skiiers]] can be is on [[a ski slope]]', 'answer': 'skiiers', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000115243.jpg', 'kb_source': 'conceptnet', 'fact': ['skiiers', 'at location', 'ski slope'], 'question_id': '5451'}, '697': {'fact_surface': '[[moto-cross]] is related to [[motorcycle]]', 'answer': 'motorcycle', 'question': 'Which object in this image is related to moto cross?', 'img_file': 'COCO_val2014_000000100896.jpg', 'kb_source': 'conceptnet', 'fact': ['moto cross', 'related to', 'motorcycle'], 'question_id': '4259'}, '698': {'fact_surface': '[[banana]] is [[delicious]].', 'answer': 'banana', 'question': 'Which object in this image is delicious?', 'img_file': 'COCO_val2014_000000008844.jpg', 'kb_source': 'conceptnet', 'fact': ['banana', 'has property', 'delicious'], 'question_id': '4253'}, '699': {'fact_surface': '[[A banana]] is [[good to eat]]', 'answer': 'banana', 'question': 'Which object in this image is good to eat?', 'img_file': 'COCO_val2014_000000008844.jpg', 'kb_source': 'conceptnet', 'fact': ['banana', 'has property', 'good to eat'], 'question_id': '4252'}, '700': {'fact_surface': '[[a person]] wants [[love, money and respect]]', 'answer': 'person', 'question': 'Which object in this image wants love, money and respect?', 'img_file': 'COCO_val2014_000000008844.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'love money and respect'], 'question_id': '4254'}, '701': {'fact_surface': '[[children]] belongs to the category of [[Humans]]', 'answer': 'child', 'question': 'Which object in this image belongs to the category Humans?', 'img_file': 'ILSVRC2012_test_00003469.JPEG', 'kb_source': 'dbpedia', 'fact': ['child', 'belong to', 'human'], 'question_id': '5532'}, '702': {'fact_surface': 'Somewhere [[trains]] can be is [[a station]].', 'answer': 'station', 'question': 'Where does the vehicle in the middle of this image can be found in?', 'img_file': 'ILSVRC2012_test_00015539.JPEG', 'kb_source': 'conceptnet', 'fact': ['train', 'at location', 'station'], 'question_id': '5531'}, '703': {'fact_surface': 'Somewhere [[trains]] can be is [[a station]].', 'answer': 'station', 'question': 'Where does the vehicle in the middle of this image can be found in?', 'img_file': 'ILSVRC2012_test_00015539.JPEG', 'kb_source': 'conceptnet', 'fact': ['train', 'at location', 'station'], 'question_id': '5530'}, '704': {'fact_surface': 'Somewhere [[skiiers]] can be is on [[a ski slope]]', 'answer': 'skiiers', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000138975.jpg', 'kb_source': 'conceptnet', 'fact': ['skiiers', 'at location', 'ski slope'], 'question_id': '1344'}, '705': {'fact_surface': '[[The crust]] is part of [[a pizza]]', 'answer': 'pizza', 'question': 'Which object in this image has a crust', 'img_file': 'ILSVRC2012_test_00004362.JPEG', 'kb_source': 'conceptnet', 'fact': ['crust', 'part of', 'pizza'], 'question_id': '3838'}, '706': {'fact_surface': '[[skis]] belongs to the category of [[Outdoor recreation]]', 'answer': 'ski', 'question': 'which kind of outdoor recreation are shown in this image', 'img_file': 'COCO_val2014_000000138975.jpg', 'kb_source': 'dbpedia', 'fact': ['ski', 'belong to', 'outdoor recreation'], 'question_id': '1345'}, '707': {'fact_surface': '[[A banjo]] is [[a stringed instrumetnt]]', 'answer': 'banjo', 'question': 'What stringed instrument is seen here?', 'img_file': 'ILSVRC2012_test_00001251.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'is a', 'string instrumetnt'], 'question_id': '370'}, '708': {'fact_surface': '[[Babies]] are [[young]]', 'answer': 'baby', 'question': 'what object in this image is very young?', 'img_file': 'ILSVRC2012_test_00038324.JPEG', 'kb_source': 'conceptnet', 'fact': ['baby', 'has property', 'young'], 'question_id': '373'}, '709': {'fact_surface': '[[kite]] is related to [[string]]', 'answer': 'kite', 'question': 'What do you need in your hand if you want to fly this thing?', 'img_file': 'COCO_val2014_000000004688.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'related to', 'string'], 'question_id': '375'}, '710': {'fact_surface': '(cellphone,/r/IsA,modern device)', 'answer': 'modern device', 'question': 'What kind is a cellphone belongs', 'img_file': 'COCO_val2014_000000119026.jpg', 'kb_source': 'conceptnet', 'fact': ['cellphone', 'is a', 'modern device'], 'question_id': '377'}, '711': {'fact_surface': '[[sheep]] is related to [[woolly livestock]]', 'answer': 'sheep', 'question': 'What is the woolly livestock?', 'img_file': 'COCO_val2014_000000024207.jpg', 'kb_source': 'conceptnet', 'fact': ['sheep', 'related to', 'woolly livestock'], 'question_id': '376'}, '712': {'fact_surface': '[[a computer]] is for [[doing calculations]]', 'answer': 'computer', 'question': 'Which object in this image can do calculation', 'img_file': 'ILSVRC2012_test_00000930.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'used for', 'do calculation'], 'question_id': '2275'}, '713': {'fact_surface': 'You are likely to find [[a keyboard]] in [[an office]]', 'answer': 'keyboard', 'question': 'What can be found at an office computer?', 'img_file': 'ILSVRC2012_test_00000930.JPEG', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'at location', 'office'], 'question_id': '2274'}, '714': {'fact_surface': '[[bee]] are less aggressive than [[wasp]]', 'answer': 'bee', 'question': 'what thing is less aggressive than wasp in this image?', 'img_file': 'ILSVRC2012_test_00000177.JPEG', 'kb_source': 'webchild', 'fact': ['bee', 'aggressive', 'wasp'], 'question_id': '2277'}, '715': {'fact_surface': 'A [[computer]] is a [[machine that can run program at very fast speed]].', 'answer': 'computer', 'question': 'Which object in this image can run programs rapidly?', 'img_file': 'ILSVRC2012_test_00000930.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'is a', 'machine that can run program at very fast speed'], 'question_id': '2276'}, '716': {'fact_surface': '[[Artichokes]] are a kind of [[vegetables]]', 'answer': 'artichoke', 'question': 'Which object in this image is a vegetable?', 'img_file': 'ILSVRC2012_test_00038877.JPEG', 'kb_source': 'conceptnet', 'fact': ['artichoke', 'is a', 'vegetable'], 'question_id': '2271'}, '717': {'fact_surface': 'A [[artichoke]] is a [[green, spiny vegetable]]', 'answer': 'artichoke', 'question': 'What is the green, spiny vegetable in this image?', 'img_file': 'ILSVRC2012_test_00038877.JPEG', 'kb_source': 'conceptnet', 'fact': ['artichoke', 'is a', 'green spiny vegetable'], 'question_id': '2270'}, '718': {'fact_surface': '[[lemon]] belongs to the category of [[Cocktail garnishes]]', 'answer': 'lemon', 'question': 'Which object in this image might be used as a cocktail garnish?', 'img_file': 'ILSVRC2012_test_00038877.JPEG', 'kb_source': 'dbpedia', 'fact': ['lemon', 'belong to', 'cocktail garnishes'], 'question_id': '2272'}, '719': {'fact_surface': '[[visual display unit]] is related to [[monitor]]', 'answer': 'monitor', 'question': 'Which object in this image is related to visual display unit?', 'img_file': 'ILSVRC2012_test_00052797.JPEG', 'kb_source': 'conceptnet', 'fact': ['visual display unit', 'related to', 'monitor'], 'question_id': '2279'}, '720': {'fact_surface': '[[A desk]] may contain [[drawers]]', 'answer': 'desk', 'question': 'Which object in this image has drawers?', 'img_file': 'ILSVRC2012_test_00052797.JPEG', 'kb_source': 'conceptnet', 'fact': ['desk', 'has a', 'drawer'], 'question_id': '2278'}, '721': {'fact_surface': '[[bakery]] is a more human place than [[most bakery]]', 'answer': 'bakery', 'question': 'Which place is more human than the place shown in this image', 'img_file': 'COCO_val2014_000000149444.jpg', 'kb_source': 'webchild', 'fact': ['bakery', 'human', 'most bakery'], 'question_id': '2051'}, '722': {'fact_surface': '[[donut]] belongs to the category of [[Cuisine of the Americas]]', 'answer': 'donut', 'question': 'Which object in this image is a kind of American Cuisine ?', 'img_file': 'COCO_val2014_000000149444.jpg', 'kb_source': 'dbpedia', 'fact': ['donut', 'belong to', 'cuisine of the americas'], 'question_id': '2050'}, '723': {'fact_surface': '[[goldfish]] are [[good pets]]', 'answer': 'goldfish', 'question': 'Which object in this image is a good pet?', 'img_file': 'ILSVRC2012_test_00053220.JPEG', 'kb_source': 'conceptnet', 'fact': ['goldfish', 'is a', 'good pet'], 'question_id': '2059'}, '724': {'fact_surface': '[[a goldfish]] is [[a carp]]', 'answer': 'goldfish', 'question': 'Which object in this image is a carp?', 'img_file': 'ILSVRC2012_test_00053220.JPEG', 'kb_source': 'conceptnet', 'fact': ['goldfish', 'is a', 'carp'], 'question_id': '2058'}, '725': {'fact_surface': '[[horse]] walk faster than [[cow]]', 'answer': 'horse', 'question': 'Which animal walks faster than the animal shown in this image?', 'img_file': 'ILSVRC2012_test_00008031.JPEG', 'kb_source': 'webchild', 'fact': ['horse', 'fast', 'cow'], 'question_id': '4824'}, '726': {'fact_surface': '[[laptop]] are much more convenient than [[desktop computer]]', 'answer': 'laptop', 'question': 'which object in this image is more convenient than desktop computer?', 'img_file': 'COCO_val2014_000000136718.jpg', 'kb_source': 'webchild', 'fact': ['laptop', 'convenient', 'desktop computer'], 'question_id': '4821'}, '727': {'fact_surface': '[[oranges]] have [[seed]]', 'answer': 'seed', 'question': 'Whether the fruit in the image has seed or not?', 'img_file': 'ILSVRC2012_test_00027435.JPEG', 'kb_source': 'conceptnet', 'fact': ['orange', 'has a', 'seed'], 'question_id': '414'}, '728': {'fact_surface': '[[accordion]] is related to [[fold up]]', 'answer': 'accordion', 'question': 'Which instrument in this image can be fold up?', 'img_file': 'ILSVRC2012_test_00048637.JPEG', 'kb_source': 'conceptnet', 'fact': ['accordion', 'related to', 'fold up'], 'question_id': '415'}, '729': {'fact_surface': '[[A guitar]] has [[strings]]', 'answer': 'guitar', 'question': 'Which instrument in this image has strings?', 'img_file': 'ILSVRC2012_test_00048637.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'has a', 'string'], 'question_id': '416'}, '730': {'fact_surface': '[[sheep]] is related to [[a lamp]]', 'answer': 'lamp', 'question': 'What is the meat of the animal called?', 'img_file': 'COCO_val2014_000000109888.jpg', 'kb_source': 'conceptnet', 'fact': ['sheep', 'related to', 'lamp'], 'question_id': '417'}, '731': {'fact_surface': '[[Stop signs]] are [[eight-sided objects]]', 'answer': 'stop sign', 'question': 'What is the eight-sided object in this image?', 'img_file': 'ILSVRC2012_test_00004200.JPEG', 'kb_source': 'conceptnet', 'fact': ['stop sign', 'is a', 'eight side object'], 'question_id': '1388'}, '732': {'fact_surface': '[[a drum]] is used for [[banging out rhythms]]', 'answer': 'drum', 'question': 'Which object is used for banging out rhythms in this image?', 'img_file': 'ILSVRC2012_test_00022927.JPEG', 'kb_source': 'conceptnet', 'fact': ['drum', 'used for', 'bang out rhythm'], 'question_id': '411'}, '733': {'fact_surface': '[[A tree]] can [[grow a branch]]', 'answer': 'tree', 'question': 'Which object in this image is capable of grow branch?', 'img_file': 'ILSVRC2012_test_00004200.JPEG', 'kb_source': 'conceptnet', 'fact': ['tree', 'capable of', 'grow branch'], 'question_id': '1387'}, '734': {'fact_surface': '[[a train]] are used to [[go to a distant place]].', 'answer': 'train', 'question': 'What object in this image is used to go to a distant place?', 'img_file': 'COCO_val2014_000000004980.jpg', 'kb_source': 'conceptnet', 'fact': ['train', 'used for', 'go to distant place'], 'question_id': '1380'}, '735': {'fact_surface': '[[a train]] are used to [[go to a distant place]].', 'answer': 'train', 'question': 'What object in this image is used to go to a distant place?', 'img_file': 'COCO_val2014_000000004980.jpg', 'kb_source': 'conceptnet', 'fact': ['train', 'used for', 'go to distant place'], 'question_id': '1381'}, '736': {'fact_surface': '[[a suitcase]] is for [[packing]]', 'answer': 'suitcase', 'question': 'Which object in this image is used for pack?', 'img_file': 'COCO_val2014_000000004980.jpg', 'kb_source': 'conceptnet', 'fact': ['suitcase', 'used for', 'pack'], 'question_id': '1382'}, '737': {'fact_surface': 'You can use [[a handbag]] to [[put your stuff]]', 'answer': 'handbag', 'question': 'What object in the image is used to store stuff?', 'img_file': 'COCO_val2014_000000004980.jpg', 'kb_source': 'conceptnet', 'fact': ['handbag', 'used for', 'put your stuff'], 'question_id': '1383'}, '738': {'fact_surface': '[[knives]] can be used to [[cut flesh]]', 'answer': 'knife', 'question': 'Which object is used for cut flesh in this image?', 'img_file': 'COCO_val2014_000000107831.jpg', 'kb_source': 'conceptnet', 'fact': ['knife', 'used for', 'cut flesh'], 'question_id': '1777'}, '739': {'fact_surface': '[[A banjo]] has [[strings]]', 'answer': 'banjo', 'question': 'Which object in this image has strings?', 'img_file': 'ILSVRC2012_test_00006983.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'has a', 'string'], 'question_id': '5277'}, '740': {'fact_surface': '[[A banjo]] is [[a musical instrument]]', 'answer': 'banjo', 'question': 'Which object in this image is a musical instrument?', 'img_file': 'ILSVRC2012_test_00006983.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'is a', 'musical instrument'], 'question_id': '5273'}, '741': {'fact_surface': '[[a fork]] is used for [[eating pie]]', 'answer': 'fork', 'question': 'Which object in this image is used for eat pie?', 'img_file': 'COCO_val2014_000000009050.jpg', 'kb_source': 'conceptnet', 'fact': ['fork', 'used for', 'eat pie'], 'question_id': '1814'}, '742': {'fact_surface': '[[Horses]] can [[carry riders]]', 'answer': 'horse', 'question': 'Which animal in this image is able to carry goods?', 'img_file': 'COCO_val2014_000000109403.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'capable of', 'carry rider'], 'question_id': '1815'}, '743': {'fact_surface': '[[horses]] are [[strong enough to carry peopl]]', 'answer': 'horse', 'question': 'Which object in this image is strong enough to carry people?', 'img_file': 'COCO_val2014_000000109403.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'has property', 'strong enough to carry peopl'], 'question_id': '1816'}, '744': {'fact_surface': '[[horses]] are [[very trainable animals]]', 'answer': 'horse', 'question': 'Which object in this image is a very trainable animal?', 'img_file': 'COCO_val2014_000000109403.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'is a', 'very trainable animal'], 'question_id': '1817'}, '745': {'fact_surface': '[[strawberry]] are sweeter than [[banana]]', 'answer': 'banana', 'question': 'which object in this image is less sweet than strawberry?', 'img_file': 'COCO_val2014_000000103490.jpg', 'kb_source': 'webchild', 'fact': ['strawberry', 'sweet', 'banana'], 'question_id': '1811'}, '746': {'fact_surface': '[[A person]] can [[feel happy]]', 'answer': 'person', 'question': 'Is there any object in the image capable of feeling happy?', 'img_file': 'ILSVRC2012_test_00040602.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'feel happy'], 'question_id': '1813'}, '747': {'fact_surface': '[[Horses]] Can [[run faster than most humans]]', 'answer': 'horse', 'question': 'Which object in this image is capable of running faster than most humans?', 'img_file': 'COCO_val2014_000000109403.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'capable of', 'run fast than most human'], 'question_id': '1818'}, '748': {'fact_surface': '[[wii]] belongs to the category of [[Toy]]', 'answer': 'wii', 'question': 'Which object in this image belongs to the category Toy?', 'img_file': 'COCO_val2014_000000007320.jpg', 'kb_source': 'dbpedia', 'fact': ['wii', 'belong to', 'toy'], 'question_id': '1819'}, '749': {'fact_surface': '[[living room]] can be warmer than [[bedroom]]', 'answer': 'bedroom', 'question': 'Which place is less warm than the place shown in this image', 'img_file': 'COCO_val2014_000000127585.jpg', 'kb_source': 'webchild', 'fact': ['living room', 'warm', 'bedroom'], 'question_id': '2165'}, '750': {'fact_surface': '[[cow]] are stronger than [[horse]]', 'answer': 'cow', 'question': 'which object in this image is stronger than horse?', 'img_file': 'ILSVRC2012_test_00015413.JPEG', 'kb_source': 'webchild', 'fact': ['cow', 'strong', 'horse'], 'question_id': '2164'}, '751': {'fact_surface': '[[a guitar]] is [[a stringed muscial instrument]]', 'answer': 'guitar', 'question': 'Which object in this image is a stringed musical instrument?', 'img_file': 'ILSVRC2012_test_00042369.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'is a', 'string muscial instrument'], 'question_id': '1609'}, '752': {'fact_surface': '*Something you find in [[a room]] is [[furniture]]', 'answer': 'furniture', 'question': 'what can we observe in the place shown in this image', 'img_file': 'COCO_val2014_000000127585.jpg', 'kb_source': 'conceptnet', 'fact': ['furniture', 'at location', 'room'], 'question_id': '2166'}, '753': {'fact_surface': 'You are likely to find [[motorcycle]] in [[a street corner]].', 'answer': 'motorcycle', 'question': 'Which vehicle in this image can be found in street corner?', 'img_file': 'COCO_val2014_000000116061.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'at location', 'street corner'], 'question_id': '3228'}, '754': {'fact_surface': 'A [[guitar]] is a [[stringed musical instrument]]', 'answer': 'guitar', 'question': 'Which object in this image is a stringed musical instrument?', 'img_file': 'ILSVRC2012_test_00010154.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'is a', 'string musical instrument'], 'question_id': '4955'}, '755': {'fact_surface': '[[nose ring]] is related to [[cattle]]', 'answer': 'cattle', 'question': 'What objects in this image might have nose rings?', 'img_file': 'COCO_val2014_000000001083.jpg', 'kb_source': 'conceptnet', 'fact': ['nose ring', 'related to', 'cattle'], 'question_id': '2844'}, '756': {'fact_surface': '[[cow]] belongs to the category of [[Herbivorous animals]]', 'answer': 'cow', 'question': 'Which object in this image is a Herbivorous animal?', 'img_file': 'COCO_val2014_000000001083.jpg', 'kb_source': 'dbpedia', 'fact': ['cow', 'belong to', 'herbivorous animals'], 'question_id': '2845'}, '757': {'fact_surface': 'You are likely to find [[a heifer]] in [[a pasture]]', 'answer': 'heifer', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000001083.jpg', 'kb_source': 'conceptnet', 'fact': ['heifer', 'at location', 'pasture'], 'question_id': '2843'}, '758': {'fact_surface': '[[barn]] is related to [[cattle]]', 'answer': 'cattle', 'question': 'What objects in this image might live in a barn?', 'img_file': 'COCO_val2014_000000001083.jpg', 'kb_source': 'conceptnet', 'fact': ['barn', 'related to', 'cattle'], 'question_id': '2840'}, '759': {'fact_surface': '[[cow]] are stronger than [[horse]]', 'answer': 'cow', 'question': 'What object in this image is stronger than a horse?', 'img_file': 'COCO_val2014_000000001083.jpg', 'kb_source': 'webchild', 'fact': ['cow', 'strong', 'horse'], 'question_id': '2841'}, '760': {'fact_surface': '[[keel]] is related to [[ship]]', 'answer': 'ship', 'question': 'Which object in this image has a keel?', 'img_file': 'ILSVRC2012_test_00001992.JPEG', 'kb_source': 'conceptnet', 'fact': ['keel', 'related to', 'ship'], 'question_id': '5473'}, '761': {'fact_surface': '[[primate]] is related to [[monkey]]', 'answer': 'monkey', 'question': 'Which object in this image is a primate?', 'img_file': 'ILSVRC2012_test_00027686.JPEG', 'kb_source': 'conceptnet', 'fact': ['primate', 'related to', 'monkey'], 'question_id': '3326'}, '762': {'fact_surface': 'You are likely to find [[a monkey]] in [[the zoo or tropical forest]]', 'answer': 'monkey', 'question': 'Which object in this image can be found in a zoo or tropical forest?', 'img_file': 'ILSVRC2012_test_00027686.JPEG', 'kb_source': 'conceptnet', 'fact': ['monkey', 'at location', 'zoo or tropical forest'], 'question_id': '3327'}, '763': {'fact_surface': '[[a monkey]] can [[use a tool]]', 'answer': 'monkey', 'question': 'Which object in this image is capable of using tools?', 'img_file': 'ILSVRC2012_test_00027686.JPEG', 'kb_source': 'conceptnet', 'fact': ['monkey', 'capable of', 'use tool'], 'question_id': '3328'}, '764': {'fact_surface': 'You are likely to find [[a monkey]] in [[the treetop]]', 'answer': 'monkey', 'question': 'Which object in this image can be found in the treetops?', 'img_file': 'ILSVRC2012_test_00027686.JPEG', 'kb_source': 'conceptnet', 'fact': ['monkey', 'at location', 'treetop'], 'question_id': '3329'}, '765': {'fact_surface': '*[[dog]] has [[legs]]', 'answer': 'dog', 'question': 'Which object in this image has four legs', 'img_file': 'COCO_val2014_000000027617.jpg', 'kb_source': 'conceptnet', 'fact': ['leg', 'part of', 'dog'], 'question_id': '5519'}, '766': {'fact_surface': '[[dog]] age faster than [[humanoid]]', 'answer': 'dog', 'question': 'which object in this image is faster than humanoid?', 'img_file': 'COCO_val2014_000000027617.jpg', 'kb_source': 'webchild', 'fact': ['dog', 'fast', 'humanoid'], 'question_id': '5518'}, '767': {'fact_surface': '[[sauce]] is related to [[tomato]]', 'answer': 'tomato', 'question': 'Which object in this image is related to sauce?', 'img_file': 'COCO_val2014_000000105014.jpg', 'kb_source': 'conceptnet', 'fact': ['sauce', 'related to', 'tomato'], 'question_id': '5511'}, '768': {'fact_surface': '[[bloody mary]] is related to [[tomato]]', 'answer': 'tomato', 'question': 'Which object in this image is used in a bloody mary?', 'img_file': 'COCO_val2014_000000105014.jpg', 'kb_source': 'conceptnet', 'fact': ['bloody mary', 'related to', 'tomato'], 'question_id': '5510'}, '769': {'fact_surface': 'A [[dog]] is a [[pet]]', 'answer': 'dog', 'question': 'Which animal in this image is a pet?', 'img_file': 'COCO_val2014_000000027617.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'is a', 'pet'], 'question_id': '5515'}, '770': {'fact_surface': '[[A dog]] likes to [[play frisbee]]', 'answer': 'dog', 'question': 'Which thing in this image likes to play frisbee?', 'img_file': 'COCO_val2014_000000027617.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'desires', 'play frisbee'], 'question_id': '5517'}, '771': {'fact_surface': '[[dogs]] can [[detect odors better than humans can]]', 'answer': 'dog', 'question': 'Which object in this image is capable of detect odor much better than human can?', 'img_file': 'COCO_val2014_000000027617.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'capable of', 'detect odor good than human can'], 'question_id': '5516'}, '772': {'fact_surface': '[[table tennis]] is [[popular in China]]', 'answer': 'china', 'question': 'This game is most populate in which country?', 'img_file': 'ILSVRC2012_test_00048422.JPEG', 'kb_source': 'conceptnet', 'fact': ['table tennis', 'has property', 'china'], 'question_id': '535'}, '773': {'fact_surface': '[[A stop sign]] has [[eight sides]]', 'answer': 'stop sign', 'question': 'What eight-sided object is visible in this image?', 'img_file': 'COCO_val2014_000000027441.jpg', 'kb_source': 'conceptnet', 'fact': ['stop sign', 'has a', 'eight side'], 'question_id': '539'}, '774': {'fact_surface': '[[an oven]] can be used for [[cooking]]', 'answer': 'cooking', 'question': 'What is the metal thing is used for?', 'img_file': 'COCO_val2014_000000104568.jpg', 'kb_source': 'conceptnet', 'fact': ['oven', 'used for', 'cooking'], 'question_id': '538'}, '775': {'fact_surface': '[[sandpainting]] is related to [[sand]]', 'answer': 'sand', 'question': 'What in the image is used for sandpainting?', 'img_file': 'ILSVRC2012_test_00000549.JPEG', 'kb_source': 'conceptnet', 'fact': ['sandpainting', 'related to', 'sand'], 'question_id': '1908'}, '776': {'fact_surface': '[[a knife]] can be used to [[cut things]]', 'answer': 'knife', 'question': 'Which object in this image is used for cutting things?', 'img_file': 'ILSVRC2012_test_00002544.JPEG', 'kb_source': 'conceptnet', 'fact': ['knife', 'used for', 'cut thing'], 'question_id': '1905'}, '777': {'fact_surface': '[[The ocean]] has [[tides]]', 'answer': 'ocean', 'question': 'What thing does the place shown in this image have as a part?', 'img_file': 'COCO_val2014_000000152582.jpg', 'kb_source': 'conceptnet', 'fact': ['ocean', 'has a', 'tide'], 'question_id': '3290'}, '778': {'fact_surface': '[[a violin]] is used for [[making lovely music]]', 'answer': 'violin', 'question': 'Which object in this image is used for making lovely music?', 'img_file': 'ILSVRC2012_test_00024564.JPEG', 'kb_source': 'conceptnet', 'fact': ['violin', 'used for', 'make lovely music'], 'question_id': '1901'}, '779': {'fact_surface': '[[flowers]] belongs to the category of [[Botany]]', 'answer': 'flowers', 'question': 'Which object in this image belongs to the category Botany?', 'img_file': 'COCO_val2014_000000025286.jpg', 'kb_source': 'dbpedia', 'fact': ['flowers', 'belong to', 'botany'], 'question_id': '3812'}, '780': {'fact_surface': '*Something you find at [[an intersection]] is [[traffic lights]]', 'answer': 'traffic light', 'question': 'Which object in this image can be found at an intersection?', 'img_file': 'COCO_val2014_000000021202.jpg', 'kb_source': 'conceptnet', 'fact': ['traffic light', 'at location', 'intersection'], 'question_id': '3813'}, '781': {'fact_surface': '[[a vase]] can [[holds flowers]]', 'answer': 'vase', 'question': 'Which object in this image can hold flowers?', 'img_file': 'COCO_val2014_000000025286.jpg', 'kb_source': 'conceptnet', 'fact': ['vase', 'capable of', 'hold flower'], 'question_id': '3810'}, '782': {'fact_surface': '[[a vase]] is [[a container]]', 'answer': 'vase', 'question': 'Which container is shown in this image ?', 'img_file': 'COCO_val2014_000000025286.jpg', 'kb_source': 'conceptnet', 'fact': ['vase', 'is a', 'container'], 'question_id': '3811'}, '783': {'fact_surface': '[[stop sign]] belongs to the category of [[Syntactic entities]]', 'answer': 'stop sign', 'question': 'What in this image belongs to the category Syntactic entities?', 'img_file': 'COCO_val2014_000000021202.jpg', 'kb_source': 'dbpedia', 'fact': ['stop sign', 'belong to', 'syntactic entities'], 'question_id': '3816'}, '784': {'fact_surface': '[[stop sign]] belongs to the category of [[Syntactic entities]]', 'answer': 'stop sign', 'question': 'What in this image belongs to the category Syntactic entities?', 'img_file': 'COCO_val2014_000000021202.jpg', 'kb_source': 'dbpedia', 'fact': ['stop sign', 'belong to', 'syntactic entities'], 'question_id': '3817'}, '785': {'fact_surface': '[[yellow light]] is related to [[traffic light]]', 'answer': 'traffic light', 'question': 'Which object in this image is related to yellow light?', 'img_file': 'COCO_val2014_000000021202.jpg', 'kb_source': 'conceptnet', 'fact': ['yellow light', 'related to', 'traffic light'], 'question_id': '3814'}, '786': {'fact_surface': 'Kinds of [[machines]] : [[traffic light]]', 'answer': 'traffic light', 'question': 'What in this image is a machine?', 'img_file': 'COCO_val2014_000000021202.jpg', 'kb_source': 'conceptnet', 'fact': ['traffic light', 'is a', 'machine'], 'question_id': '3815'}, '787': {'fact_surface': '[[traffic light]] belongs to the category of [[Land transport]]', 'answer': 'traffic light', 'question': 'What in this image belongs to the category Land transport?', 'img_file': 'COCO_val2014_000000021202.jpg', 'kb_source': 'dbpedia', 'fact': ['traffic light', 'belong to', 'land transport'], 'question_id': '3818'}, '788': {'fact_surface': '[[camel]] belongs to the category of [[Animal]]', 'answer': 'camel', 'question': 'What category of animal is in the image?', 'img_file': 'ILSVRC2012_test_00008993.JPEG', 'kb_source': 'dbpedia', 'fact': ['camel', 'belong to', 'animal'], 'question_id': '3819'}, '789': {'fact_surface': '[[a couch]] is for [[sleeping on]]', 'answer': 'couch', 'question': 'What object in this image can be used to sleep on?', 'img_file': 'COCO_val2014_000000138204.jpg', 'kb_source': 'conceptnet', 'fact': ['couch', 'used for', 'sleep on'], 'question_id': '4512'}, '790': {'fact_surface': '[[living room]] can be warmer than [[bedroom]]', 'answer': 'living room', 'question': 'Which place is less warm than the place shown in this image', 'img_file': 'COCO_val2014_000000103558.jpg', 'kb_source': 'webchild', 'fact': ['living room', 'warm', 'bedroom'], 'question_id': '4510'}, '791': {'fact_surface': '[[A blanket]] is [[a large piece of cloth]]', 'answer': 'blanket', 'question': 'Which object in this image is a large piece of cloth?', 'img_file': 'COCO_val2014_000000138204.jpg', 'kb_source': 'conceptnet', 'fact': ['blanket', 'is a', 'large piece of cloth'], 'question_id': '4511'}, '792': {'fact_surface': '[[ride]] is related to [[bicycle]]', 'answer': 'bicycle', 'question': 'What is the name of the vehicle in the middle of the image', 'img_file': 'COCO_val2014_000000103499.jpg', 'kb_source': 'conceptnet', 'fact': ['ride', 'related to', 'bicycle'], 'question_id': '5288'}, '793': {'fact_surface': '[[hammer]] is related to [[cut]]', 'answer': 'cut', 'question': 'What is the metal thing in the image used for?', 'img_file': 'ILSVRC2012_test_00002767.JPEG', 'kb_source': 'conceptnet', 'fact': ['hammer', 'related to', 'cut'], 'question_id': '1014'}, '794': {'fact_surface': '(volleyball,/r/UsedFor,play)', 'answer': 'play', 'question': 'What is volleyball used for', 'img_file': 'ILSVRC2012_test_00004234.JPEG', 'kb_source': 'conceptnet', 'fact': ['volleyball', 'used for', 'play'], 'question_id': '1011'}, '795': {'fact_surface': 'You are likely to find [[whale]] in [[a beach]].', 'answer': 'beach', 'question': 'Where the animal is laying on?', 'img_file': 'ILSVRC2012_test_00003730.JPEG', 'kb_source': 'conceptnet', 'fact': ['whale', 'at location', 'beach'], 'question_id': '1013'}, '796': {'fact_surface': '[[Refrigerators]] can [[keep food cold]]', 'answer': 'refrigerator', 'question': 'Which object in this image can keep food cold?', 'img_file': 'ILSVRC2012_test_00007262.JPEG', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'capable of', 'keep food cold'], 'question_id': '4358'}, '797': {'fact_surface': '[[a microwave]] can be used to [[heat food]]', 'answer': 'microwave', 'question': 'Which object in this image is used for heating food?', 'img_file': 'ILSVRC2012_test_00007262.JPEG', 'kb_source': 'conceptnet', 'fact': ['microwave', 'used for', 'heat food'], 'question_id': '4354'}, '798': {'fact_surface': '[[a microwave]] is for [[cooking food fast]]', 'answer': 'microwave', 'question': 'Which object in this image is used for cooking food fast?', 'img_file': 'ILSVRC2012_test_00007262.JPEG', 'kb_source': 'conceptnet', 'fact': ['microwave', 'used for', 'cook food fast'], 'question_id': '4355'}, '799': {'fact_surface': '[[A microwave]] can [[warm up your coffee]]', 'answer': 'microwave', 'question': 'Which object in this image can warm up your coffee?', 'img_file': 'ILSVRC2012_test_00007262.JPEG', 'kb_source': 'conceptnet', 'fact': ['microwave', 'capable of', 'warm up your coffee'], 'question_id': '4356'}, '800': {'fact_surface': '[[a refrigerator]] is for [[freezing food]]', 'answer': 'refrigerator', 'question': 'Which object in this image is used for freezing food?', 'img_file': 'ILSVRC2012_test_00007262.JPEG', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'used for', 'freeze food'], 'question_id': '4357'}, '801': {'fact_surface': '[[toilet]] belongs to the category of [[Public services]]', 'answer': 'toilet', 'question': 'What belongs to public services?', 'img_file': 'COCO_val2014_000000120157.jpg', 'kb_source': 'dbpedia', 'fact': ['toilet', 'belong to', 'public services'], 'question_id': '4350'}, '802': {'fact_surface': '[[snow]] is related to [[fluffy white]]', 'answer': 'snow', 'question': 'What is the fluffy white things in the image?', 'img_file': 'COCO_val2014_000000105053.jpg', 'kb_source': 'conceptnet', 'fact': ['snow', 'related to', 'fluffy white'], 'question_id': '437'}, '803': {'fact_surface': '[[keyboard]] is used to [[enter data to computer]]', 'answer': 'keyboard', 'question': 'Which object is used for data entry?', 'img_file': 'ILSVRC2012_test_00000014.JPEG', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'used for', 'enter data to computer'], 'question_id': '435'}, '804': {'fact_surface': '[[bicycles]] are [[human powered transports]]', 'answer': 'bicycle', 'question': 'which object in this image is a form of human powered transportation?', 'img_file': 'ILSVRC2012_test_00003927.JPEG', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'is a', 'human power transport'], 'question_id': '5708'}, '805': {'fact_surface': '*Something you find on [[a pizza]] is [[mushrooms]]', 'answer': 'mushroom', 'question': 'Which vegetable in this image can be found on a pizza?', 'img_file': 'COCO_val2014_000000131557.jpg', 'kb_source': 'conceptnet', 'fact': ['mushroom', 'at location', 'pizza'], 'question_id': '5709'}, '806': {'fact_surface': '[[Bicycles]] usually have [[2 wheels]]', 'answer': 'bicycle', 'question': 'which object in this image has two wheels?', 'img_file': 'ILSVRC2012_test_00003927.JPEG', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'has a', '2 wheel'], 'question_id': '5704'}, '807': {'fact_surface': '[[people]] can [[paint pictures]]', 'answer': 'person', 'question': 'which object in this image is capable of painting a picture?', 'img_file': 'ILSVRC2012_test_00003927.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'paint picture'], 'question_id': '5705'}, '808': {'fact_surface': '[[people]] can [[draw pictures]]', 'answer': 'person', 'question': 'which object in this image is capable of drawing a picture?', 'img_file': 'ILSVRC2012_test_00003927.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'draw picture'], 'question_id': '5706'}, '809': {'fact_surface': '[[bicycle]] belongs to the category of [[Cycling equipment]]', 'answer': 'bicycle', 'question': \"which object in this image belong to the category 'cycling equipment'?\", 'img_file': 'ILSVRC2012_test_00003927.JPEG', 'kb_source': 'dbpedia', 'fact': ['bicycle', 'belong to', 'cycling equipment'], 'question_id': '5707'}, '810': {'fact_surface': 'You can use [[refrigerator]] to [[keep food fresh]].', 'answer': 'refrigerator', 'question': 'Which kitchen appliance in this image is used to keep food fresh?', 'img_file': 'ILSVRC2012_test_00020753.JPEG', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'used for', 'keep food fresh'], 'question_id': '5700'}, '811': {'fact_surface': '[[boats]] can [[travel over water]]', 'answer': 'boat', 'question': 'Which vehicle in this image is capable of travel over water?', 'img_file': 'COCO_val2014_000000102466.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'capable of', 'travel over water'], 'question_id': '5701'}, '812': {'fact_surface': '[[A dog]] can [[sense danger]]', 'answer': 'dog', 'question': 'Which object in this image is capable of sensing danger?', 'img_file': 'ILSVRC2012_test_00001757.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'capable of', 'sense danger'], 'question_id': '5702'}, '813': {'fact_surface': '[[a bicycle]] is [[a two wheeled method of transportation]]', 'answer': 'bicycle', 'question': 'which object in this image is a two wheeled method of transport?', 'img_file': 'ILSVRC2012_test_00003927.JPEG', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'is a', 'two wheel method of transportation'], 'question_id': '5703'}, '814': {'fact_surface': '[[fleece]] is related to [[sheep]]', 'answer': 'sheep', 'question': \"which object in this image is related to 'fleece'?\", 'img_file': 'COCO_val2014_000000027438.jpg', 'kb_source': 'conceptnet', 'fact': ['fleece', 'related to', 'sheep'], 'question_id': '1050'}, '815': {'fact_surface': '[[sheep]] belongs to the category of [[Livestock]]', 'answer': 'sheep', 'question': \"which object in this image belongs to the category 'livestock'?\", 'img_file': 'COCO_val2014_000000027438.jpg', 'kb_source': 'dbpedia', 'fact': ['sheep', 'belong to', 'livestock'], 'question_id': '1051'}, '816': {'fact_surface': '[[sheep]] are [[animals]]', 'answer': 'sheep', 'question': 'which object in this image in an animal?', 'img_file': 'COCO_val2014_000000027438.jpg', 'kb_source': 'conceptnet', 'fact': ['sheep', 'is a', 'animal'], 'question_id': '1052'}, '817': {'fact_surface': \"[[a spoon]] is used for [[eating food that isn't very solid]]\", 'answer': 'spoon', 'question': \"Which object in this image is used for eating food that isn't very solid?\", 'img_file': 'COCO_val2014_000000002759.jpg', 'kb_source': 'conceptnet', 'fact': ['spoon', 'used for', \"eat food that isn't very solid\"], 'question_id': '1430'}, '818': {'fact_surface': '[[a fuel tank]] is part of [[an airplane]].', 'answer': 'airplane', 'question': 'which object in this image has a fuel tank?', 'img_file': 'COCO_val2014_000000100404.jpg', 'kb_source': 'conceptnet', 'fact': ['fuel tank', 'part of', 'airplane'], 'question_id': '5354'}, '819': {'fact_surface': '[[rugby balls]] are [[oval shaped]].', 'answer': 'rugby ball', 'question': 'Which object in this image is oval shaped?', 'img_file': 'ILSVRC2012_test_00025206.JPEG', 'kb_source': 'conceptnet', 'fact': ['rugby ball', 'has property', 'oval shape'], 'question_id': '1054'}, '820': {'fact_surface': '[[zebras]] are [[black and white]].', 'answer': 'zebra', 'question': 'Which object in this image has the property of black and white?', 'img_file': 'COCO_val2014_000000004754.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has property', 'black and white'], 'question_id': '1055'}, '821': {'fact_surface': '[[zebra]] belongs to the category of [[Mammal families]]', 'answer': 'zebra', 'question': 'Which object in this image belongs to the category Mammal families?', 'img_file': 'COCO_val2014_000000004754.jpg', 'kb_source': 'dbpedia', 'fact': ['zebra', 'belong to', 'mammal families'], 'question_id': '1056'}, '822': {'fact_surface': '[[Zebras]] have [[black and white stripes]]', 'answer': 'zebra', 'question': 'Which animal in the front of the image has black and white stripes?', 'img_file': 'COCO_val2014_000000004754.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'black and white stripe'], 'question_id': '1057'}, '823': {'fact_surface': 'You can use [[a bowl]] to [[hold soup]]', 'answer': 'bowl', 'question': 'Which object in this image is used for holding soup?', 'img_file': 'COCO_val2014_000000002759.jpg', 'kb_source': 'conceptnet', 'fact': ['bowl', 'used for', 'hold soup'], 'question_id': '1431'}, '824': {'fact_surface': '[[Forest roads]] are [[inspirational]]', 'answer': 'forest road', 'question': 'What objects in this image are inspirational', 'img_file': 'ILSVRC2012_test_00035105.JPEG', 'kb_source': 'conceptnet', 'fact': ['forest road', 'has property', 'inspirational'], 'question_id': '1832'}, '825': {'fact_surface': '[[Forest roads]] are [[inspirational]]', 'answer': 'forest road', 'question': 'What objects in this image are inspirational', 'img_file': 'ILSVRC2012_test_00035105.JPEG', 'kb_source': 'conceptnet', 'fact': ['forest road', 'has property', 'inspirational'], 'question_id': '1833'}, '826': {'fact_surface': '[[Forest roads]] are [[inspirational]]', 'answer': 'forest road', 'question': 'What objects in this image are inspirational', 'img_file': 'ILSVRC2012_test_00035105.JPEG', 'kb_source': 'conceptnet', 'fact': ['forest road', 'has property', 'inspirational'], 'question_id': '1830'}, '827': {'fact_surface': '[[Forest roads]] are [[inspirational]]', 'answer': 'forest road', 'question': 'What objects in this image are inspirational', 'img_file': 'ILSVRC2012_test_00035105.JPEG', 'kb_source': 'conceptnet', 'fact': ['forest road', 'has property', 'inspirational'], 'question_id': '1831'}, '828': {'fact_surface': '[[Forest roads]] are [[inspirational]]', 'answer': 'forest road', 'question': 'What objects in this image are inspirational', 'img_file': 'ILSVRC2012_test_00035105.JPEG', 'kb_source': 'conceptnet', 'fact': ['forest road', 'has property', 'inspirational'], 'question_id': '1834'}, '829': {'fact_surface': '[[rugby ball]] belongs to the category of [[Balls]]', 'answer': 'rugby ball', 'question': 'In this image, which object belongs to the category Balls?', 'img_file': 'ILSVRC2012_test_00002362.JPEG', 'kb_source': 'dbpedia', 'fact': ['rugby ball', 'belong to', 'ball'], 'question_id': '1838'}, '830': {'fact_surface': '[[A French horn]] has [[three keys]]', 'answer': 'french horn', 'question': 'Which object in this image has three keys?', 'img_file': 'ILSVRC2012_test_00031269.JPEG', 'kb_source': 'conceptnet', 'fact': ['french horn', 'has a', 'three key'], 'question_id': '3791'}, '831': {'fact_surface': '[[motorcycle]] belongs to the category of [[Vehicle]]', 'answer': 'motorcycle', 'question': 'Which vehicle is included in this image?', 'img_file': 'COCO_val2014_000000121162.jpg', 'kb_source': 'dbpedia', 'fact': ['motorcycle', 'belong to', 'vehicle'], 'question_id': '3793'}, '832': {'fact_surface': '[[French horn]] is related to [[trumpet]]', 'answer': 'french horn', 'question': 'Which object in this image is related to trumpet?', 'img_file': 'ILSVRC2012_test_00031269.JPEG', 'kb_source': 'conceptnet', 'fact': ['french horn', 'related to', 'trumpet'], 'question_id': '3792'}, '833': {'fact_surface': 'You are likely to find [[a kitchenette]] in [[a house]]', 'answer': 'house', 'question': 'Where does this place in the image can be found?', 'img_file': 'COCO_val2014_000000135071.jpg', 'kb_source': 'conceptnet', 'fact': ['kitchenette', 'at location', 'house'], 'question_id': '4985'}, '834': {'fact_surface': '[[An oven]] can [[heat a meal]]', 'answer': 'oven', 'question': 'Which object in this image is able to heat meal?', 'img_file': 'COCO_val2014_000000135071.jpg', 'kb_source': 'conceptnet', 'fact': ['oven', 'capable of', 'heat meal'], 'question_id': '4987'}, '835': {'fact_surface': 'A [[artichoke]] is a [[green, spiny vegetable]]', 'answer': 'artichoke', 'question': 'Which object in this image is a green spiny vegetable?', 'img_file': 'ILSVRC2012_test_00003419.JPEG', 'kb_source': 'conceptnet', 'fact': ['artichoke', 'is a', 'green spiny vegetable'], 'question_id': '2153'}, '836': {'fact_surface': '[[skis]] belongs to the category of [[Winter sports]]', 'answer': 'ski', 'question': 'Which object in this image belongs to the category snow sports？', 'img_file': 'COCO_val2014_000000005032.jpg', 'kb_source': 'dbpedia', 'fact': ['ski', 'belong to', 'winter sports'], 'question_id': '4989'}, '837': {'fact_surface': '[[a person]] wants [[life and liberty]]', 'answer': 'person', 'question': 'Which thing in this image desires life and liberty?', 'img_file': 'COCO_val2014_000000005032.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'life and liberty'], 'question_id': '4988'}, '838': {'fact_surface': '[[A cat]] has [[a nose]]', 'answer': 'cat', 'question': '￼Which object in this image has a nose?', 'img_file': 'COCO_val2014_000000122213.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'has a', 'nose'], 'question_id': '1955'}, '839': {'fact_surface': 'Somewhere [[a rice cooker]] can be is [[a kitchen]].', 'answer': 'rice cooker', 'question': 'What can be found in this place?', 'img_file': 'ILSVRC2012_test_00007959.JPEG', 'kb_source': 'conceptnet', 'fact': ['rice cooker', 'at location', 'kitchen'], 'question_id': '1957'}, '840': {'fact_surface': '[[Cats]] have [[excellent balance]]', 'answer': 'cat', 'question': 'Which animal in this image has an excellent balance?', 'img_file': 'COCO_val2014_000000122213.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'has a', 'excellent balance'], 'question_id': '1956'}, '841': {'fact_surface': '[[A banjo]] has [[strings]]', 'answer': 'banjo', 'question': 'Which object in this image has strings?', 'img_file': 'ILSVRC2012_test_00028677.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'has a', 'string'], 'question_id': '3243'}, '842': {'fact_surface': '[[A banjo]] is [[a musical instrument]]', 'answer': 'banjo', 'question': 'Which object in this image is a musical instrument?', 'img_file': 'ILSVRC2012_test_00028677.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'is a', 'musical instrument'], 'question_id': '3242'}, '843': {'fact_surface': 'You can use [[a banjo]] to [[play bluegrass music]]', 'answer': 'banjo', 'question': 'Which object in this image is used for playing bluegrass music?', 'img_file': 'ILSVRC2012_test_00028677.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'used for', 'play bluegrass music'], 'question_id': '3241'}, '844': {'fact_surface': 'You can use [[a banjo]] to [[play bluegrass music]]', 'answer': 'banjo', 'question': 'Which object in this image is used for playing bluegrass music?', 'img_file': 'ILSVRC2012_test_00028677.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'used for', 'play bluegrass music'], 'question_id': '3240'}, '845': {'fact_surface': '[[cell phone]] belongs to the category of [[Communication]]', 'answer': 'cell phone', 'question': 'Which object in this image is used for Communication?', 'img_file': 'COCO_val2014_000000114453.jpg', 'kb_source': 'dbpedia', 'fact': ['cell phone', 'belong to', 'communication'], 'question_id': '1480'}, '846': {'fact_surface': '[[dog]] are more trustworthy than [[human]]', 'answer': 'dog', 'question': 'which object in the image is more trustworthy than humans', 'img_file': 'COCO_val2014_000000123964.jpg', 'kb_source': 'webchild', 'fact': ['dog', 'trustworthy', 'human'], 'question_id': '5498'}, '847': {'fact_surface': '[[a baseball]] is for [[hitting]]', 'answer': 'baseball', 'question': 'What is used for hit in this image?', 'img_file': 'COCO_val2014_000000123964.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'used for', 'hit'], 'question_id': '5499'}, '848': {'fact_surface': '[[Water]] contains [[hydrogen and oxygen atoms]]', 'answer': 'ye', 'question': 'Is there water here?', 'img_file': 'COCO_val2014_000000101088.jpg', 'kb_source': 'conceptnet', 'fact': ['ye', 'has a', 'hydrogen and oxygen atom'], 'question_id': '1485'}, '849': {'fact_surface': '[[car]] are slower than [[airplane]]', 'answer': 'airplane', 'question': 'Which object in this image is faster than a car?', 'img_file': 'COCO_val2014_000000101088.jpg', 'kb_source': 'webchild', 'fact': ['car', 'slow', 'airplane'], 'question_id': '1484'}, '850': {'fact_surface': 'You are likely to find [[an elephant]] in [[a circus]].', 'answer': 'elephant', 'question': 'Which object in this image can be found in in circus?', 'img_file': 'COCO_val2014_000000018896.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'at location', 'in circus'], 'question_id': '3300'}, '851': {'fact_surface': 'Somewhere [[tourists]] can be is in [[a zoo]]', 'answer': 'tourist', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000018896.jpg', 'kb_source': 'conceptnet', 'fact': ['tourist', 'at location', 'zoo'], 'question_id': '3301'}, '852': {'fact_surface': 'A [[plant]] is a [[living being]]', 'answer': 'plant', 'question': 'What is the living being in the image?', 'img_file': 'COCO_val2014_000000013300.jpg', 'kb_source': 'conceptnet', 'fact': ['plant', 'is a', 'live be'], 'question_id': '610'}, '853': {'fact_surface': '[[A tree]] can [[grow new branches]]', 'answer': 'tree', 'question': 'Which object in this image is capable of growing new branches?', 'img_file': 'COCO_val2014_000000021613.jpg', 'kb_source': 'conceptnet', 'fact': ['tree', 'capable of', 'grow new branch'], 'question_id': '1273'}, '854': {'fact_surface': '[[goldfish]] are [[popular pets]]', 'answer': 'goldfish', 'question': 'Which object in this image is a popular pet?', 'img_file': 'ILSVRC2012_test_00053220.JPEG', 'kb_source': 'conceptnet', 'fact': ['goldfish', 'is a', 'popular pet'], 'question_id': '2060'}, '855': {'fact_surface': '[[a bathroom]] is for [[Cleaning your teeth in]]', 'answer': 'clean your tooth in', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000011727.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'used for', 'clean your tooth in'], 'question_id': '2793'}, '856': {'fact_surface': '(laptop,/r/UsedFor,watch movie)', 'answer': 'laptop', 'question': 'What thing in the image can be used for watching movie?', 'img_file': 'ILSVRC2012_test_00022120.JPEG', 'kb_source': 'conceptnet', 'fact': ['laptop', 'used for', 'watch movie'], 'question_id': '615'}, '857': {'fact_surface': '[[a bathroom]] is for [[washing up in]]', 'answer': 'bathroom', 'question': 'Where is this place?', 'img_file': 'COCO_val2014_000000002388.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'used for', 'wash up in'], 'question_id': '2063'}, '858': {'fact_surface': '[[the ocean]] contains [[salt]]', 'answer': 'ocean', 'question': 'What thing shown in this image has salt?', 'img_file': 'COCO_val2014_000000106411.jpg', 'kb_source': 'conceptnet', 'fact': ['ocean', 'has a', 'salt'], 'question_id': '1994'}, '859': {'fact_surface': '[[a sofa]] is for [[lying on]]', 'answer': 'sofa', 'question': 'Which furniture in the image can I lie on? ', 'img_file': 'COCO_val2014_000000100187.jpg', 'kb_source': 'conceptnet', 'fact': ['sofa', 'used for', 'lie on'], 'question_id': '513'}, '860': {'fact_surface': '[[snow]] is [[slippery to drive on]]', 'answer': 'slippery', 'question': 'What property does the place in this image have?', 'img_file': 'COCO_val2014_000000002867.jpg', 'kb_source': 'conceptnet', 'fact': ['snow', 'has property', 'slippery'], 'question_id': '1224'}, '861': {'fact_surface': 'Somewhere [[skiiers]] can be is on [[a ski slope]]', 'answer': 'skiiers', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000002867.jpg', 'kb_source': 'conceptnet', 'fact': ['skiiers', 'at location', 'ski slope'], 'question_id': '1223'}, '862': {'fact_surface': '[[suitcase]] is a subclass of [[box]]', 'answer': 'suitcase', 'question': 'What object in the image is a subclass of box?', 'img_file': 'COCO_val2014_000000108408.jpg', 'kb_source': 'conceptnet', 'fact': ['suitcase', 'is a', 'box'], 'question_id': '1221'}, '863': {'fact_surface': '[[suitcase]] is related to [[luggage]]', 'answer': 'suitcase', 'question': 'which object in this image can be used for moving luggage', 'img_file': 'COCO_val2014_000000108408.jpg', 'kb_source': 'conceptnet', 'fact': ['suitcase', 'related to', 'luggage'], 'question_id': '1220'}, '864': {'fact_surface': '[[squirrel]] is related to [[collecting nuts]]', 'answer': 'squirrel', 'question': 'Which animal in this image is the most related to collecting nuts', 'img_file': 'COCO_val2014_000000015070.jpg', 'kb_source': 'conceptnet', 'fact': ['squirrel', 'related to', 'collect nut'], 'question_id': '629'}, '865': {'fact_surface': '[[squirrel]] is related to [[big tail]]', 'answer': 'squirrel', 'question': 'Which animal in this image is the most related to big tail', 'img_file': 'COCO_val2014_000000015070.jpg', 'kb_source': 'conceptnet', 'fact': ['squirrel', 'related to', 'big tail'], 'question_id': '628'}, '866': {'fact_surface': '[[fencing]] is for [[keeping animals out of a garden]]', 'answer': 'fence', 'question': 'What thing in the image can be used for keeping animals out of a garden?', 'img_file': 'COCO_val2014_000000022589.jpg', 'kb_source': 'conceptnet', 'fact': ['fence', 'used for', 'keep animal out of garden'], 'question_id': '4167'}, '867': {'fact_surface': '[[People]] have [[feet]]', 'answer': 'person', 'question': 'which object in this image has feet?', 'img_file': 'ILSVRC2012_test_00044335.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'has a', 'foot'], 'question_id': '4166'}, '868': {'fact_surface': '[[a person]] can [[hear noises]]', 'answer': 'person', 'question': 'which object in this image is capable of hearing noises?', 'img_file': 'ILSVRC2012_test_00044335.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'hear noise'], 'question_id': '4165'}, '869': {'fact_surface': '[[people]] have [[ears]]', 'answer': 'person', 'question': 'which object in this image has ears?', 'img_file': 'ILSVRC2012_test_00044335.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'has a', 'ear'], 'question_id': '4164'}, '870': {'fact_surface': '[[People]] have [[muscles in their body]]', 'answer': 'person', 'question': 'which object in this image has muscles in their body?', 'img_file': 'ILSVRC2012_test_00044335.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'has a', 'muscle in their body'], 'question_id': '4163'}, '871': {'fact_surface': '[[people]] can [[stand on two feet]]', 'answer': 'person', 'question': 'which object in this image is capable of standing on two feet?', 'img_file': 'ILSVRC2012_test_00044335.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'stand on two foot'], 'question_id': '4162'}, '872': {'fact_surface': '[[a typical livingroom]] contains [[a sofa]]', 'answer': 'sofa', 'question': 'Which object in this image is a part of a typical livingroom?', 'img_file': 'COCO_val2014_000000003145.jpg', 'kb_source': 'conceptnet', 'fact': ['typical livingroom', 'has a', 'sofa'], 'question_id': '4161'}, '873': {'fact_surface': '[[an electric fan]] is for [[cooling]]', 'answer': 'electric fan', 'question': 'Waht object in this image is used for cooling?', 'img_file': 'COCO_val2014_000000003145.jpg', 'kb_source': 'conceptnet', 'fact': ['electric fan', 'used for', 'cool'], 'question_id': '4160'}, '874': {'fact_surface': '[[surfboard]] is related to [[longboard]]', 'answer': 'surfboard', 'question': 'What kind of longboard is shown in this image ?', 'img_file': 'COCO_val2014_000000109537.jpg', 'kb_source': 'conceptnet', 'fact': ['surfboard', 'related to', 'longboard'], 'question_id': '4169'}, '875': {'fact_surface': '[[sheep]] is related to [[wool source]]', 'answer': 'sheep', 'question': 'Which animal in this image is related to wool source?', 'img_file': 'COCO_val2014_000000022589.jpg', 'kb_source': 'conceptnet', 'fact': ['sheep', 'related to', 'wool source'], 'question_id': '4168'}, '876': {'fact_surface': '[[a wall]] is [[a side of a building]]', 'answer': 'wall', 'question': 'What thing which you can see here is the side of a building?', 'img_file': 'COCO_val2014_000000022004.jpg', 'kb_source': 'conceptnet', 'fact': ['wall', 'is a', 'side of build'], 'question_id': '2238'}, '877': {'fact_surface': '[[An elephant]] has [[four legs]]', 'answer': 'elephant', 'question': 'Which object in this image has a four leg?', 'img_file': 'COCO_val2014_000000108338.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'has a', 'four leg'], 'question_id': '2231'}, '878': {'fact_surface': '[[An elephant]] has [[four legs]]', 'answer': 'elephant', 'question': 'Which object in this image has four legs?', 'img_file': 'COCO_val2014_000000108338.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'has a', 'four leg'], 'question_id': '2230'}, '879': {'fact_surface': '[[distantness]] is related to [[remote]]', 'answer': 'remote', 'question': 'Which object in this image is related to distantness?', 'img_file': 'ILSVRC2012_test_00008552.JPEG', 'kb_source': 'conceptnet', 'fact': ['distantness', 'related to', 'remote'], 'question_id': '2237'}, '880': {'fact_surface': '[[dog]] are more loyal than [[cat]]', 'answer': 'cat', 'question': 'What in the image is less loyal than a dog?', 'img_file': 'COCO_val2014_000000022892.jpg', 'kb_source': 'webchild', 'fact': ['dog', 'loyal', 'cat'], 'question_id': '4608'}, '881': {'fact_surface': '[[train]] are more dependable than [[car]]', 'answer': 'train', 'question': 'which object in this image is more dependable than car?', 'img_file': 'COCO_val2014_000000101145.jpg', 'kb_source': 'webchild', 'fact': ['train', 'dependable', 'car'], 'question_id': '3496'}, '882': {'fact_surface': '[[hotplate]] is related to [[stove]]', 'answer': 'stove', 'question': 'Which object in this image is like a hotplate?', 'img_file': 'COCO_val2014_000000136466.jpg', 'kb_source': 'conceptnet', 'fact': ['hotplate', 'related to', 'stove'], 'question_id': '3494'}, '883': {'fact_surface': '[[stoves]] can also [[cook food]]', 'answer': 'stove', 'question': 'Which object in this image can be used to cook food?', 'img_file': 'COCO_val2014_000000136466.jpg', 'kb_source': 'conceptnet', 'fact': ['stove', 'capable of', 'cook food'], 'question_id': '3495'}, '884': {'fact_surface': '[[baking tray]] is related to [[oven]]', 'answer': 'oven', 'question': 'What object in this image is related to a baking tray?', 'img_file': 'COCO_val2014_000000136466.jpg', 'kb_source': 'conceptnet', 'fact': ['bake tray', 'related to', 'oven'], 'question_id': '3492'}, '885': {'fact_surface': '[[An oven]] is [[very hot]]', 'answer': 'oven', 'question': 'Which object in this image is very hot?', 'img_file': 'COCO_val2014_000000136466.jpg', 'kb_source': 'conceptnet', 'fact': ['oven', 'has property', 'very hot'], 'question_id': '3493'}, '886': {'fact_surface': '[[Most homes]] contain [[an oven]]', 'answer': 'oven', 'question': 'What object in this image is in most homes?', 'img_file': 'COCO_val2014_000000136466.jpg', 'kb_source': 'conceptnet', 'fact': ['most home', 'has a', 'oven'], 'question_id': '3490'}, '887': {'fact_surface': 'You can use [[oven]] to [[bake]].', 'answer': 'oven', 'question': 'What object in this image is used for baking?', 'img_file': 'COCO_val2014_000000136466.jpg', 'kb_source': 'conceptnet', 'fact': ['oven', 'used for', 'bake'], 'question_id': '3491'}, '888': {'fact_surface': 'You are likely to find [[human]] in [[bedroom]].', 'answer': 'human', 'question': 'which can we often see in the place shown in this image', 'img_file': 'COCO_val2014_000000106793.jpg', 'kb_source': 'conceptnet', 'fact': ['human', 'at location', 'bedroom'], 'question_id': '2091'}, '889': {'fact_surface': '[[a computer]] is for [[calculating data]]', 'answer': 'computer', 'question': 'Which object in this image can be used for calculate data?', 'img_file': 'ILSVRC2012_test_00057152.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'used for', 'calculate data'], 'question_id': '4576'}, '890': {'fact_surface': '[[hot dog]] belongs to the category of [[Fast food]]', 'answer': 'hot dog', 'question': 'Which object in this image belongs to the category Fast food?', 'img_file': 'ILSVRC2012_test_00015545.JPEG', 'kb_source': 'dbpedia', 'fact': ['hot dog', 'belong to', 'fast food'], 'question_id': '2099'}, '891': {'fact_surface': 'You are likely to find [[a kite]] in [[the sky]]', 'answer': 'kite', 'question': 'Which object can you find in the sky in this image?', 'img_file': 'COCO_val2014_000000153865.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'at location', 'sky'], 'question_id': '4605'}, '892': {'fact_surface': \"You are likely to find [[a cat]] in [[a catlover's home]]\", 'answer': 'cat', 'question': \"Which object in this image can be found in catlover's home?\", 'img_file': 'COCO_val2014_000000131131.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'at location', \"catlover's home\"], 'question_id': '3333'}, '893': {'fact_surface': '[[cow]] belongs to the category of [[Animals]]', 'answer': 'cow', 'question': 'what kind of animal is this in the image', 'img_file': 'COCO_val2014_000000149832.jpg', 'kb_source': 'dbpedia', 'fact': ['cow', 'belong to', 'animal'], 'question_id': '1655'}, '894': {'fact_surface': '[[telecommunications]] is related to [[cell phone]]', 'answer': 'cell phone', 'question': 'Which object in this image is related to telecommunication?', 'img_file': 'COCO_val2014_000000129707.jpg', 'kb_source': 'conceptnet', 'fact': ['telecommunication', 'related to', 'cell phone'], 'question_id': '1038'}, '895': {'fact_surface': '[[Stop signs]] are [[red octagons]]', 'answer': 'stop sign', 'question': 'Which object in this image is a red octagon?', 'img_file': 'COCO_val2014_000000129957.jpg', 'kb_source': 'conceptnet', 'fact': ['stop sign', 'is a', 'red octagon'], 'question_id': '1032'}, '896': {'fact_surface': '[[Stop signs]] are [[red and white]]', 'answer': 'stop sign', 'question': 'Which object in this image is red and white?', 'img_file': 'COCO_val2014_000000129957.jpg', 'kb_source': 'conceptnet', 'fact': ['stop sign', 'has property', 'red and white'], 'question_id': '1033'}, '897': {'fact_surface': '[[a bird]] can [[learn to fly]]', 'answer': 'bird', 'question': 'Which object in this image is capable of learning to fly?', 'img_file': 'ILSVRC2012_test_00021551.JPEG', 'kb_source': 'conceptnet', 'fact': ['bird', 'capable of', 'learn to fly'], 'question_id': '1030'}, '898': {'fact_surface': '[[pineapple]] belongs to the category of [[Hawaii]]', 'answer': 'pineapple', 'question': 'Which fruit in the background is associated with Hawaii?', 'img_file': 'ILSVRC2012_test_00021551.JPEG', 'kb_source': 'dbpedia', 'fact': ['pineapple', 'belong to', 'hawaii'], 'question_id': '1031'}, '899': {'fact_surface': '[[A cat]] can be [[difficult to wash in the bath]]', 'answer': 'cat', 'question': 'Which object in this image can be difficult to bathe?', 'img_file': 'COCO_val2014_000000005617.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'has property', 'difficult to wash in bath'], 'question_id': '4372'}, '900': {'fact_surface': '[[A cat]] can [[clean itself often]]', 'answer': 'cat', 'question': 'Which object in this image is capable of cleaning itself?', 'img_file': 'COCO_val2014_000000005617.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'clean itself often'], 'question_id': '4373'}, '901': {'fact_surface': '[[bedroom]] is for [[sleeping]]', 'answer': 'sleep', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000005617.jpg', 'kb_source': 'conceptnet', 'fact': ['bedroom', 'used for', 'sleep'], 'question_id': '4370'}, '902': {'fact_surface': '[[A cat]] has [[claws]]', 'answer': 'cat', 'question': 'Which object in this image has claws?', 'img_file': 'COCO_val2014_000000005617.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'has a', 'claw'], 'question_id': '4371'}, '903': {'fact_surface': '[[a cat]] can [[hunt for mice]]', 'answer': 'cat', 'question': 'Which animal in this image is capable of hunting for mouse?', 'img_file': 'COCO_val2014_000000005617.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'hunt for mouse'], 'question_id': '4374'}, '904': {'fact_surface': '[[the beach]] is [[romantic]]', 'answer': 'romantic', 'question': 'What property does the place in this image have?', 'img_file': 'COCO_val2014_000000014494.jpg', 'kb_source': 'conceptnet', 'fact': ['beach', 'has property', 'romantic'], 'question_id': '4081'}, '905': {'fact_surface': '*Something you find at [[beach]] is [[pretty girls]]', 'answer': 'pretty girl', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000014494.jpg', 'kb_source': 'conceptnet', 'fact': ['pretty girl', 'at location', 'beach'], 'question_id': '4082'}, '906': {'fact_surface': '[[Snails]] can [[wave their antennae]]', 'answer': 'nail', 'question': 'Which things in this image can wave their antennae?', 'img_file': 'ILSVRC2012_test_00003143.JPEG', 'kb_source': 'conceptnet', 'fact': ['nail', 'capable of', 'wave their antenna'], 'question_id': '4087'}, '907': {'fact_surface': '[[slime]] is related to [[snail]]', 'answer': 'nail', 'question': 'Which object in this image is associated with slime?', 'img_file': 'ILSVRC2012_test_00003143.JPEG', 'kb_source': 'conceptnet', 'fact': ['lime', 'related to', 'nail'], 'question_id': '4088'}, '908': {'fact_surface': '[[escargot]] is related to [[snail]]', 'answer': 'nail', 'question': 'Which object in this image is used in escargot?', 'img_file': 'ILSVRC2012_test_00003143.JPEG', 'kb_source': 'conceptnet', 'fact': ['escargot', 'related to', 'nail'], 'question_id': '4089'}, '909': {'fact_surface': '[[Trains]] usually [[require a boarding pass]]', 'answer': 'train', 'question': 'Which object in this image might require a boarding pass?', 'img_file': 'COCO_val2014_000000006789.jpg', 'kb_source': 'conceptnet', 'fact': ['train', 'capable of', 'require board pass'], 'question_id': '5728'}, '910': {'fact_surface': '[[train]] are actually more efficient than [[car]]', 'answer': 'car', 'question': 'Which object in this image is less efficient than a train?', 'img_file': 'COCO_val2014_000000006789.jpg', 'kb_source': 'webchild', 'fact': ['train', 'efficient', 'car'], 'question_id': '5729'}, '911': {'fact_surface': '[[Keyboards]] are [[a way to enter information]]', 'answer': 'keyboard', 'question': 'What object the person is using to enter information?g', 'img_file': 'COCO_val2014_000000025846.jpg', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'is a', 'way to enter information'], 'question_id': '5722'}, '912': {'fact_surface': '[[e-mail]] is related to [[computer]]', 'answer': 'computer', 'question': 'Which object in this image is related to e mail?', 'img_file': 'COCO_val2014_000000025846.jpg', 'kb_source': 'conceptnet', 'fact': ['e mail', 'related to', 'computer'], 'question_id': '5721'}, '913': {'fact_surface': 'You are likely to find [[a bus]] in [[the street]]', 'answer': 'street', 'question': 'Where does the object at the bottom of the image can be found in?', 'img_file': 'COCO_val2014_000000026501.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'at location', 'street'], 'question_id': '5726'}, '914': {'fact_surface': '[[A bus]] can [[transport many people at once]]', 'answer': 'bus', 'question': 'Which object in this image is capable of transporting many people at once?', 'img_file': 'COCO_val2014_000000026501.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'capable of', 'transport many person at once'], 'question_id': '5725'}, '915': {'fact_surface': 'The order of [[giraffe]] is [[Even-toed ungulate]]', 'answer': 'even toed ungulate', 'question': 'What is the order of the animal shown in this image?', 'img_file': 'COCO_val2014_000000006005.jpg', 'kb_source': 'dbpedia', 'fact': ['giraffe', 'animal order', 'even toed ungulate'], 'question_id': '2394'}, '916': {'fact_surface': 'You are likely to find [[giraffes]] in [[the zoo]].', 'answer': 'giraffe', 'question': 'Which object in this image can be found in zoo?', 'img_file': 'COCO_val2014_000000006005.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'at location', 'zoo'], 'question_id': '2395'}, '917': {'fact_surface': '[[balance beam]] belongs to the category of [[Gymnastics]]', 'answer': 'balance beam', 'question': 'Which object in this image belongs to the category Gymnastics?', 'img_file': 'ILSVRC2012_test_00008843.JPEG', 'kb_source': 'dbpedia', 'fact': ['balance beam', 'belong to', 'gymnastics'], 'question_id': '2390'}, '918': {'fact_surface': '[[pizza]] is made with [[dough, tomato sauce and mozzarella cheese]]', 'answer': 'pizza', 'question': 'Which object in this image can be created with dough, tomato sauce and mozzarella cheese?', 'img_file': 'COCO_val2014_000000146489.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'created by', 'dough tomato sauce and mozzarella cheese'], 'question_id': '2399'}, '919': {'fact_surface': 'You can use [[a frisbee]] to [[play with your dog]]', 'answer': 'frisbee', 'question': 'Which object in this image is used for play with your pet?', 'img_file': 'COCO_val2014_000000103227.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'used for', 'play with your dog'], 'question_id': '1858'}, '920': {'fact_surface': 'You can use [[a frisbee]] to [[catch and throw back]]', 'answer': 'frisbee', 'question': 'Which object in this image is used for catch and throw back?', 'img_file': 'COCO_val2014_000000103227.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'used for', 'catch and throw back'], 'question_id': '1859'}, '921': {'fact_surface': 'You are likely to find [[a trumpet]] in [[a brass band]]', 'answer': 'trumpet', 'question': 'Which object in this image can be found in a brass band?', 'img_file': 'ILSVRC2012_test_00037498.JPEG', 'kb_source': 'conceptnet', 'fact': ['trumpet', 'at location', 'brass band'], 'question_id': '1850'}, '922': {'fact_surface': '[[pizza]] belongs to the category of [[Convenience foods]]', 'answer': 'pizza', 'question': 'Which object in this image belongs to the category Convenience foods?', 'img_file': 'COCO_val2014_000000016733.jpg', 'kb_source': 'dbpedia', 'fact': ['pizza', 'belong to', 'convenience foods'], 'question_id': '1851'}, '923': {'fact_surface': '[[oranges]] are [[full of vitamin C]]', 'answer': 'orange', 'question': 'What shown here is full of vitamin C?', 'img_file': 'COCO_val2014_000000013145.jpg', 'kb_source': 'conceptnet', 'fact': ['orange', 'has property', 'full of vitamin c'], 'question_id': '1852'}, '924': {'fact_surface': '[[orange]] are less green than [[avocado]]', 'answer': 'orange', 'question': 'which fruit in this image is greener than avocado?', 'img_file': 'COCO_val2014_000000013145.jpg', 'kb_source': 'webchild', 'fact': ['orange', 'green', 'avocado'], 'question_id': '1853'}, '925': {'fact_surface': '[[horse]] belongs to the category of [[Working animal]]', 'answer': 'horse', 'question': 'which object in this image is such kind of animal than can work for human', 'img_file': 'COCO_val2014_000000026386.jpg', 'kb_source': 'dbpedia', 'fact': ['horse', 'belong to', 'working animal'], 'question_id': '1855'}, '926': {'fact_surface': '[[children]] belongs to the category of [[Kinship]]', 'answer': 'child', 'question': 'Which object in this image belongs to the category Kinship?', 'img_file': 'COCO_val2014_000000103227.jpg', 'kb_source': 'dbpedia', 'fact': ['child', 'belong to', 'kinship'], 'question_id': '1856'}, '927': {'fact_surface': '[[frisbee]] is [[a game]]', 'answer': 'frisbee', 'question': 'Which object in this image is a sport?', 'img_file': 'COCO_val2014_000000103227.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'is a', 'game'], 'question_id': '1857'}, '928': {'fact_surface': '[[racquets]] is related to [[game]]', 'answer': 'racquet', 'question': 'What is the person holding to play this game ?', 'img_file': 'ILSVRC2012_test_00020186.JPEG', 'kb_source': 'conceptnet', 'fact': ['racquet', 'related to', 'game'], 'question_id': '2172'}, '929': {'fact_surface': '[[ping-pong ball]] belongs to the category of [[Games of physical skill]]', 'answer': 'ping pong', 'question': 'Which game of physical skill is shown here?', 'img_file': 'ILSVRC2012_test_00020186.JPEG', 'kb_source': 'dbpedia', 'fact': ['ping pong', 'belong to', 'games of physical skill'], 'question_id': '2173'}, '930': {'fact_surface': '[[Lemons]] are [[yellow colored]]', 'answer': 'lemon', 'question': 'Which object in this image is yellow?', 'img_file': 'ILSVRC2012_test_00009113.JPEG', 'kb_source': 'conceptnet', 'fact': ['lemon', 'has property', 'yellow color'], 'question_id': '2171'}, '931': {'fact_surface': '[[bagels]] are [[round with holes in them]]', 'answer': 'bagel', 'question': 'Which objects in this image are round with holes in them?', 'img_file': 'ILSVRC2012_test_00017846.JPEG', 'kb_source': 'conceptnet', 'fact': ['bagel', 'has property', 'round with hole in them'], 'question_id': '2176'}, '932': {'fact_surface': '[[bagels]] are [[popular breakfast foods]]', 'answer': 'bagel', 'question': 'Which object in this image is a popular breakfast food?', 'img_file': 'ILSVRC2012_test_00017846.JPEG', 'kb_source': 'conceptnet', 'fact': ['bagel', 'is a', 'popular breakfast food'], 'question_id': '2177'}, '933': {'fact_surface': 'You are likely to find [[animals]] in [[a zoo ]].', 'answer': 'animal', 'question': 'What is likely to be found in this place?', 'img_file': 'COCO_val2014_000000111819.jpg', 'kb_source': 'conceptnet', 'fact': ['animal', 'at location', 'zoo'], 'question_id': '2174'}, '934': {'fact_surface': '[[baby bed]] belongs to the category of [[Child safety]]', 'answer': 'baby bed', 'question': 'Which object in this image considers Child safety?', 'img_file': 'ILSVRC2012_test_00011476.JPEG', 'kb_source': 'dbpedia', 'fact': ['baby bed', 'belong to', 'child safety'], 'question_id': '2175'}, '935': {'fact_surface': '[[bagel]] belongs to the category of [[Jewish cuisine]]', 'answer': 'bagel', 'question': 'Which object in this image is a Jewish cuisine?', 'img_file': 'ILSVRC2012_test_00017846.JPEG', 'kb_source': 'dbpedia', 'fact': ['bagel', 'belong to', 'jewish cuisine'], 'question_id': '2179'}, '936': {'fact_surface': '[[train]] are far more efficient than [[car]]', 'answer': 'car', 'question': 'what is less efficient than the object in the left with red strip in this image', 'img_file': 'COCO_val2014_000000026226.jpg', 'kb_source': 'webchild', 'fact': ['train', 'efficient', 'car'], 'question_id': '3844'}, '937': {'fact_surface': '[[bow tie]] belongs to the category of [[Clothing]]', 'answer': 'bow tie', 'question': 'What is one object in this image belonging to the category Clothing?', 'img_file': 'COCO_val2014_000000116017.jpg', 'kb_source': 'dbpedia', 'fact': ['bow tie', 'belong to', 'clothing'], 'question_id': '5694'}, '938': {'fact_surface': '[[a bicycle]] is for [[transportation]]', 'answer': 'bicycle', 'question': 'Which object in this image is used for transportation?', 'img_file': 'ILSVRC2012_test_00043918.JPEG', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'used for', 'transportation'], 'question_id': '5695'}, '939': {'fact_surface': '[[donut]] belongs to the category of [[Snack food]]', 'answer': 'donut', 'question': 'Which object in this image belongs to the category Snack food?', 'img_file': 'COCO_val2014_000000142487.jpg', 'kb_source': 'dbpedia', 'fact': ['donut', 'belong to', 'snack food'], 'question_id': '1933'}, '940': {'fact_surface': '[[donut]] belongs to the category of [[Food]]', 'answer': 'donut', 'question': 'Which object in this image belongs to the category Food?', 'img_file': 'COCO_val2014_000000142487.jpg', 'kb_source': 'dbpedia', 'fact': ['donut', 'belong to', 'food'], 'question_id': '1932'}, '941': {'fact_surface': '[[donut]] belongs to the category of [[Sweet breads]]', 'answer': 'donut', 'question': 'What is the sweet breads in the image?', 'img_file': 'COCO_val2014_000000142487.jpg', 'kb_source': 'dbpedia', 'fact': ['donut', 'belong to', 'sweet breads'], 'question_id': '1931'}, '942': {'fact_surface': '[[Tennis balls]] are [[hollow]]', 'answer': 'tennis ball', 'question': 'Which round object that you cannot see in this image has the property of hollow?', 'img_file': 'COCO_val2014_000000104166.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis ball', 'has property', 'hollow'], 'question_id': '1934'}, '943': {'fact_surface': '[[horses]] are [[fast animals]]', 'answer': 'horse', 'question': 'Which fast animal is shown in this image ?', 'img_file': 'COCO_val2014_000000004211.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'is a', 'fast animal'], 'question_id': '5124'}, '944': {'fact_surface': '[[unicycle]] are lighter than [[bicycle]]', 'answer': 'unicycle', 'question': 'Which vehicle in the image is usually lighter than a bicycle?', 'img_file': 'ILSVRC2012_test_00019930.JPEG', 'kb_source': 'webchild', 'fact': ['unicycle', 'light', 'bicycle'], 'question_id': '5120'}, '945': {'fact_surface': '[[hot dog]] belongs to the category of [[Foods]]', 'answer': 'hot dog', 'question': 'Can you identify any type of food in this image?', 'img_file': 'ILSVRC2012_test_00013759.JPEG', 'kb_source': 'dbpedia', 'fact': ['hot dog', 'belong to', 'food'], 'question_id': '5121'}, '946': {'fact_surface': '[[hot dog]] belongs to the category of [[North American culture]]', 'answer': 'hot dog', 'question': 'Which object in this image belongs to the category North American culture?', 'img_file': 'ILSVRC2012_test_00013759.JPEG', 'kb_source': 'dbpedia', 'fact': ['hot dog', 'belong to', 'north american culture'], 'question_id': '5122'}, '947': {'fact_surface': '[[grass]] is related to [[spring]]', 'answer': 'grass', 'question': 'Which object in this image can be related to spring?', 'img_file': 'COCO_val2014_000000004211.jpg', 'kb_source': 'conceptnet', 'fact': ['grass', 'related to', 'spring'], 'question_id': '5123'}, '948': {'fact_surface': '[[Bears]] can [[stand on their hind legs]]', 'answer': 'bear', 'question': 'Which object in the image is capable of standing on their hind legs?', 'img_file': 'COCO_val2014_000000016776.jpg', 'kb_source': 'conceptnet', 'fact': ['bear', 'capable of', 'stand on their hind leg'], 'question_id': '1427'}, '949': {'fact_surface': '[[tree]] has [[trunk]].', 'answer': 'tree', 'question': 'Which object in this image has a trunk?', 'img_file': 'COCO_val2014_000000016776.jpg', 'kb_source': 'conceptnet', 'fact': ['trunk', 'part of', 'tree'], 'question_id': '1428'}, '950': {'fact_surface': 'You can use [[a handbag]] to [[keep things in]]', 'answer': 'handbag', 'question': 'What object in this image is used to keep things in?', 'img_file': 'COCO_val2014_000000100238.jpg', 'kb_source': 'conceptnet', 'fact': ['handbag', 'used for', 'keep thing in'], 'question_id': '3366'}, '951': {'fact_surface': '[[snow]] is related to [[white frozen]]', 'answer': 'snow', 'question': 'What is the white frozen thing in the image? ', 'img_file': 'COCO_val2014_000000102159.jpg', 'kb_source': 'conceptnet', 'fact': ['snow', 'related to', 'white freeze'], 'question_id': '605'}, '952': {'fact_surface': 'A [[mushroom]] is a [[fungus]]', 'answer': 'mushroom', 'question': 'What is the fungus in the image?', 'img_file': 'COCO_val2014_000000140664.jpg', 'kb_source': 'conceptnet', 'fact': ['mushroom', 'is a', 'fungus'], 'question_id': '607'}, '953': {'fact_surface': '[[A frisbee]] can [[fly]].', 'answer': 'frisbee', 'question': 'What thing in the image can fly?', 'img_file': 'COCO_val2014_000000153971.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'capable of', 'fly'], 'question_id': '606'}, '954': {'fact_surface': '[[an umbrella]] can [[shade a table]]', 'answer': 'shade table', 'question': 'What the umbrella in the image is used for?', 'img_file': 'COCO_val2014_000000121506.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'capable of', 'shade table'], 'question_id': '601'}, '955': {'fact_surface': '[[bowl]] is related to [[serving soup]]', 'answer': 'bowl', 'question': 'what object in this image can be used to serve soup?', 'img_file': 'ILSVRC2012_test_00046892.JPEG', 'kb_source': 'conceptnet', 'fact': ['bowl', 'related to', 'serve soup'], 'question_id': '600'}, '956': {'fact_surface': '[[cabinets]] belongs to the category of [[Furniture]]', 'answer': 'cabinets', 'question': 'In this image, which object belongs to the category Furniture?', 'img_file': 'COCO_val2014_000000124601.jpg', 'kb_source': 'dbpedia', 'fact': ['cabinets', 'belong to', 'furniture'], 'question_id': '1204'}, '957': {'fact_surface': '[[cabinets]] belongs to the category of [[Woodworking]]', 'answer': 'cabinets', 'question': 'Which object in this image belongs to the category of woodwork?', 'img_file': 'COCO_val2014_000000124601.jpg', 'kb_source': 'dbpedia', 'fact': ['cabinets', 'belong to', 'woodworking'], 'question_id': '1203'}, '958': {'fact_surface': '[[A bear]] is a kind of [[carnivore]].', 'answer': 'bear', 'question': 'Who is a carnivore in this image?', 'img_file': 'COCO_val2014_000000127955.jpg', 'kb_source': 'conceptnet', 'fact': ['bear', 'is a', 'carnivore'], 'question_id': '1353'}, '959': {'fact_surface': '[[a computer]] can [[stream media]]', 'answer': 'computer', 'question': 'Which object in this image is capable of streaming media?', 'img_file': 'COCO_val2014_000000141278.jpg', 'kb_source': 'conceptnet', 'fact': ['computer', 'capable of', 'stream media'], 'question_id': '1350'}, '960': {'fact_surface': '[[saxophones]] are [[made out of metal]]', 'answer': 'metal', 'question': 'What is the instrument made out of?', 'img_file': 'ILSVRC2012_test_00000761.JPEG', 'kb_source': 'conceptnet', 'fact': ['saxophone', 'receives action', 'metal'], 'question_id': '461'}, '961': {'fact_surface': '[[a car]] is [[a people mover]]', 'answer': 'car', 'question': 'which object in this image can help people move', 'img_file': 'ILSVRC2012_test_00023289.JPEG', 'kb_source': 'conceptnet', 'fact': ['car', 'is a', 'person mover'], 'question_id': '5554'}, '962': {'fact_surface': '[[a person]] wants [[a haircut]]', 'answer': 'person', 'question': 'Which object in this image desires haircut?', 'img_file': 'COCO_val2014_000000000962.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'haircut'], 'question_id': '4149'}, '963': {'fact_surface': '[[tennis racket]] is related to [[strike]]', 'answer': 'tennis racket', 'question': 'What can you see in this image is related to strike?', 'img_file': 'COCO_val2014_000000000962.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis racket', 'related to', 'strike'], 'question_id': '4148'}, '964': {'fact_surface': 'You are likely to find [[a cat]] in [[the litterbox]]', 'answer': 'cat', 'question': 'Which object in this image can sometimes be found in a litterbox?', 'img_file': 'ILSVRC2012_test_00001487.JPEG', 'kb_source': 'conceptnet', 'fact': ['cat', 'at location', 'litterbox'], 'question_id': '4145'}, '965': {'fact_surface': '[[desk]] belongs to the category of [[Living arrangements]]', 'answer': 'desk', 'question': 'what does the cat sit on?', 'img_file': 'ILSVRC2012_test_00010630.JPEG', 'kb_source': 'dbpedia', 'fact': ['desk', 'belong to', 'living arrangements'], 'question_id': '4144'}, '966': {'fact_surface': '[[kittens]] have [[fur]]', 'answer': 'kitten', 'question': 'What can you see in the image that has fur?', 'img_file': 'ILSVRC2012_test_00010630.JPEG', 'kb_source': 'conceptnet', 'fact': ['kitten', 'has a', 'fur'], 'question_id': '4141'}, '967': {'fact_surface': '[[snowboard]] belongs to the category of [[Snow]]', 'answer': 'snowboard', 'question': 'Which sport is related to snow?', 'img_file': 'COCO_val2014_000000132510.jpg', 'kb_source': 'dbpedia', 'fact': ['snowboard', 'belong to', 'snow'], 'question_id': '4140'}, '968': {'fact_surface': '[[kitten]] belongs to the category of [[Cat]]', 'answer': 'kitten', 'question': 'What animal in the picture belongs to the category cat?', 'img_file': 'ILSVRC2012_test_00010630.JPEG', 'kb_source': 'dbpedia', 'fact': ['kitten', 'belong to', 'cat'], 'question_id': '4143'}, '969': {'fact_surface': '[[Kittens]] are [[soft and furry]]', 'answer': 'kitten', 'question': 'What in the image is soft and furry?', 'img_file': 'ILSVRC2012_test_00010630.JPEG', 'kb_source': 'conceptnet', 'fact': ['kitten', 'has property', 'soft and furry'], 'question_id': '4142'}, '970': {'fact_surface': '[[frisbee]] belongs to the category of [[Toy]]', 'answer': 'frisbee', 'question': 'Which object in this image belongs to the category Toy?', 'img_file': 'COCO_val2014_000000153971.jpg', 'kb_source': 'dbpedia', 'fact': ['frisbee', 'belong to', 'toy'], 'question_id': '3859'}, '971': {'fact_surface': '[[AstroTurf]] is related to [[grass]]', 'answer': 'grass', 'question': 'Which object in this image could be related to astroturf?', 'img_file': 'COCO_val2014_000000019447.jpg', 'kb_source': 'conceptnet', 'fact': ['astroturf', 'related to', 'grass'], 'question_id': '5910'}, '972': {'fact_surface': '[[vegetables]] belongs to the category of [[Plants]]', 'answer': 'vegetable', 'question': \"What's in the bowl that you can eat?\", 'img_file': 'COCO_val2014_000000004936.jpg', 'kb_source': 'dbpedia', 'fact': ['vegetable', 'belong to', 'plant'], 'question_id': '4556'}, '973': {'fact_surface': '[[Hippopotamus]] is an instance of [[mammal]]', 'answer': 'hippopotamus', 'question': 'Which object in this image is a mammal?', 'img_file': 'ILSVRC2012_test_00000775.JPEG', 'kb_source': 'conceptnet', 'fact': ['hippopotamus', 'is a', 'mammal'], 'question_id': '4555'}, '974': {'fact_surface': '[[monitor]] is a subclass of [[computer display]]', 'answer': 'monitor', 'question': 'Which device in this image is a computer display?', 'img_file': 'ILSVRC2012_test_00006633.JPEG', 'kb_source': 'conceptnet', 'fact': ['monitor', 'is a', 'computer display'], 'question_id': '4550'}, '975': {'fact_surface': '[[Zebras]] have [[stripes]]', 'answer': 'zebra', 'question': 'Which object in this image has stripes?', 'img_file': 'COCO_val2014_000000107814.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'stripe'], 'question_id': '1184'}, '976': {'fact_surface': '[[violins]] have [[four strings]]', 'answer': 'violin', 'question': 'Which object in this image has four strings?', 'img_file': 'ILSVRC2012_test_00053657.JPEG', 'kb_source': 'conceptnet', 'fact': ['violin', 'has a', 'four string'], 'question_id': '743'}, '977': {'fact_surface': 'A [[violin]] is a [[musical string instrument]]', 'answer': 'violin', 'question': 'Which object in this image is a musical string instrument?', 'img_file': 'ILSVRC2012_test_00053657.JPEG', 'kb_source': 'conceptnet', 'fact': ['violin', 'is a', 'musical string instrument'], 'question_id': '744'}, '978': {'fact_surface': '[[violin]] is related to [[music]]', 'answer': 'violin', 'question': 'Which object in this image is related to music', 'img_file': 'ILSVRC2012_test_00053657.JPEG', 'kb_source': 'conceptnet', 'fact': ['violin', 'related to', 'music'], 'question_id': '745'}, '979': {'fact_surface': '[[Zebra]] is an instance of [[mammal]]', 'answer': 'zebra', 'question': 'Which object in this image is a mammal?', 'img_file': 'COCO_val2014_000000107814.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'is a', 'mammal'], 'question_id': '1185'}, '980': {'fact_surface': '[[a baseball field]] can be used for [[playing baseball]]', 'answer': 'play baseball', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000106331.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball field', 'used for', 'play baseball'], 'question_id': '2949'}, '981': {'fact_surface': '[[A baseball bat]] can [[hit a baseball]]', 'answer': 'baseball bat', 'question': 'Which object in this image can be used to hit a baseball?', 'img_file': 'COCO_val2014_000000106331.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball bat', 'capable of', 'hit baseball'], 'question_id': '2948'}, '982': {'fact_surface': '[[a person]] can [[drive a lorry]]', 'answer': 'person', 'question': 'Which object in this image could potentially drive a lorry?', 'img_file': 'ILSVRC2012_test_00006954.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'drive lorry'], 'question_id': '2942'}, '983': {'fact_surface': '[[airplane]] are far safer than [[automobile]]', 'answer': 'airplane', 'question': 'which vehicle in this image is safer than automobile?', 'img_file': 'COCO_val2014_000000107582.jpg', 'kb_source': 'webchild', 'fact': ['airplane', 'safe', 'automobile'], 'question_id': '5357'}, '984': {'fact_surface': '[[An airplane]] can [[circle an airfield]]', 'answer': 'airplane', 'question': 'What seen here might circle an airfield?', 'img_file': 'COCO_val2014_000000107582.jpg', 'kb_source': 'conceptnet', 'fact': ['airplane', 'capable of', 'circle airfield'], 'question_id': '5356'}, '985': {'fact_surface': '[[an airplane]] is used for [[air transportation]]', 'answer': 'airplane', 'question': 'which object in this image is used for air transportation?', 'img_file': 'COCO_val2014_000000100404.jpg', 'kb_source': 'conceptnet', 'fact': ['airplane', 'used for', 'air transportation'], 'question_id': '5355'}, '986': {'fact_surface': '[[wool]] is related to [[sheep]]', 'answer': 'sheep', 'question': \"which object in this image is related to 'wool'?\", 'img_file': 'COCO_val2014_000000027438.jpg', 'kb_source': 'conceptnet', 'fact': ['wool', 'related to', 'sheep'], 'question_id': '1053'}, '987': {'fact_surface': '[[an airplane]] is for [[transportation]]', 'answer': 'airplane', 'question': 'which object in this image is used for transportation?', 'img_file': 'COCO_val2014_000000100404.jpg', 'kb_source': 'conceptnet', 'fact': ['airplane', 'used for', 'transportation'], 'question_id': '5353'}, '988': {'fact_surface': '[[airplane]] belongs to the category of [[Aerospace]]', 'answer': 'airplane', 'question': \"which object in this image belongs to the category 'aerospace'?\", 'img_file': 'COCO_val2014_000000100404.jpg', 'kb_source': 'dbpedia', 'fact': ['airplane', 'belong to', 'aerospace'], 'question_id': '5352'}, '989': {'fact_surface': '[[airplane]] belongs to the category of [[Flight]]', 'answer': 'airplane', 'question': \"which object in this image belong to the category of 'flight'?\", 'img_file': 'COCO_val2014_000000100404.jpg', 'kb_source': 'dbpedia', 'fact': ['airplane', 'belong to', 'flight'], 'question_id': '5351'}, '990': {'fact_surface': '[[A computer]] has [[a keyboard]]', 'answer': 'keyboard', 'question': 'Which object in this image belongs to a part of computer?', 'img_file': 'ILSVRC2012_test_00031261.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'has a', 'keyboard'], 'question_id': '5350'}, '991': {'fact_surface': '[[A railroad track]] is used for [[transporting people]]', 'answer': 'transport person', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000025747.jpg', 'kb_source': 'conceptnet', 'fact': ['railroad track', 'used for', 'transport person'], 'question_id': '1058'}, '992': {'fact_surface': 'A [[train]] is a [[longh vehicle composed of many cars linked together]]', 'answer': 'train', 'question': 'Which object in this image is a longh vehicle compose of many car link together?', 'img_file': 'COCO_val2014_000000025747.jpg', 'kb_source': 'conceptnet', 'fact': ['train', 'is a', 'longh vehicle compose of many car link together'], 'question_id': '1059'}, '993': {'fact_surface': '[[wing]] is related to [[airplane]]', 'answer': 'airplane', 'question': 'Which vehicle in this image has wings?', 'img_file': 'COCO_val2014_000000107582.jpg', 'kb_source': 'conceptnet', 'fact': ['wing', 'related to', 'airplane'], 'question_id': '5359'}, '994': {'fact_surface': '[[airplane]] belongs to the category of [[Vehicle]]', 'answer': 'airplane', 'question': 'What stuff in the image belongs to vehicle?', 'img_file': 'COCO_val2014_000000107582.jpg', 'kb_source': 'dbpedia', 'fact': ['airplane', 'belong to', 'vehicle'], 'question_id': '5358'}, '995': {'fact_surface': 'You can use [[a suitcase]] to [[carry your clothes]]', 'answer': 'suitcase', 'question': 'what thing is this image can be used to carry your clothes?', 'img_file': 'COCO_val2014_000000141882.jpg', 'kb_source': 'conceptnet', 'fact': ['suitcase', 'used for', 'carry your clothe'], 'question_id': '4317'}, '996': {'fact_surface': '*Something you find [[at an airport]] is [[luggage]]', 'answer': 'luggage', 'question': 'Which object in this image can be found in at airport?', 'img_file': 'COCO_val2014_000000141882.jpg', 'kb_source': 'conceptnet', 'fact': ['luggage', 'at location', 'at airport'], 'question_id': '4318'}, '997': {'fact_surface': '[[cats]] are [[usually furry]]', 'answer': 'cat', 'question': 'Which object in this image is usually furry?', 'img_file': 'COCO_val2014_000000127477.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'has property', 'usually furry'], 'question_id': '4319'}, '998': {'fact_surface': '[[hot dog]] belongs to the category of [[Sausages]]', 'answer': 'hot dog', 'question': 'What object in the image typically contains a sausage?', 'img_file': 'COCO_val2014_000000130438.jpg', 'kb_source': 'dbpedia', 'fact': ['hot dog', 'belong to', 'sausage'], 'question_id': '1180'}, '999': {'fact_surface': '[[hands]] has [[fingernails]].', 'answer': 'hand', 'question': 'What visible here has fingernails?', 'img_file': 'COCO_val2014_000000153563.jpg', 'kb_source': 'conceptnet', 'fact': ['fingernail', 'part of', 'hand'], 'question_id': '3119'}, '1000': {'fact_surface': '[[a computer]] is for [[doing work]]', 'answer': 'computer', 'question': 'Which object in this image is used for do work in office?', 'img_file': 'ILSVRC2012_test_00032169.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'used for', 'do work'], 'question_id': '3116'}, '1001': {'fact_surface': '[[a computer]] is for [[doing work]]', 'answer': 'computer', 'question': 'Which object in this image is used for do work in office?', 'img_file': 'ILSVRC2012_test_00032169.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'used for', 'do work'], 'question_id': '3115'}, '1002': {'fact_surface': '[[car]] belongs to the category of [[Private transport]]', 'answer': 'car', 'question': 'Which object in this image belongs to the category Private transport?', 'img_file': 'COCO_val2014_000000010363.jpg', 'kb_source': 'dbpedia', 'fact': ['car', 'belong to', 'private transport'], 'question_id': '3113'}, '1003': {'fact_surface': '[[A cat]] can [[be a very good companion]]', 'answer': 'cat', 'question': 'Which object in this image is capable of being a very good companion?', 'img_file': 'COCO_val2014_000000010363.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'be very good companion'], 'question_id': '3112'}, '1004': {'fact_surface': '[[canoe]] is related to [[boat]]', 'answer': 'boat', 'question': 'Which object in this image is related to canoe?', 'img_file': 'COCO_val2014_000000107548.jpg', 'kb_source': 'conceptnet', 'fact': ['canoe', 'related to', 'boat'], 'question_id': '3110'}, '1005': {'fact_surface': '[[roads]] can be [[confusing]]', 'answer': 'road', 'question': 'What property does the place in this image have?', 'img_file': 'COCO_val2014_000000024243.jpg', 'kb_source': 'conceptnet', 'fact': ['road', 'has property', 'confuse'], 'question_id': '5795'}, '1006': {'fact_surface': 'A [[banjo]] is a [[guitar-like musical instrument]]', 'answer': 'banjo', 'question': 'Which object in this image is a guitar-like musical instrument?', 'img_file': 'ILSVRC2012_test_00056081.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'is a', 'guitar like musical instrument'], 'question_id': '1181'}, '1007': {'fact_surface': '[[a refrigerator]] is for [[keeping food from decaying quickly]]', 'answer': 'refrigerator', 'question': 'Which object in this image is used for keeping food from decaying quickly?', 'img_file': 'ILSVRC2012_test_00001244.JPEG', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'used for', 'keep food from decay quickly'], 'question_id': '5740'}, '1008': {'fact_surface': 'You can use [[a refrigerator]] to [[cool things]]', 'answer': 'refrigerator', 'question': 'Which object in this image is used for cooling things?', 'img_file': 'ILSVRC2012_test_00001244.JPEG', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'used for', 'cool thing'], 'question_id': '5741'}, '1009': {'fact_surface': '[[an oven]] can be used to [[cook food.]]', 'answer': 'oven', 'question': 'Which object in this image is used for cooking food?', 'img_file': 'ILSVRC2012_test_00001244.JPEG', 'kb_source': 'conceptnet', 'fact': ['oven', 'used for', 'cook food'], 'question_id': '5742'}, '1010': {'fact_surface': '[[pedal]] is related to [[bicycle]]', 'answer': 'bicycle', 'question': 'Which object in this image is related to pedalling?', 'img_file': 'COCO_val2014_000000020342.jpg', 'kb_source': 'conceptnet', 'fact': ['pedal', 'related to', 'bicycle'], 'question_id': '5743'}, '1011': {'fact_surface': '[[a bicycle]] has [[2 tires]]', 'answer': 'bicycle', 'question': 'Which object in this image has 2 tires?', 'img_file': 'COCO_val2014_000000020342.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'has a', '2 tire'], 'question_id': '5744'}, '1012': {'fact_surface': '[[a bicycle]] has [[two peddles]]', 'answer': 'bicycle', 'question': 'Which object in this image has two pedals?', 'img_file': 'COCO_val2014_000000020342.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'has a', 'two peddle'], 'question_id': '5745'}, '1013': {'fact_surface': '[[bicycle]] belongs to the category of [[Transport]]', 'answer': 'bicycle', 'question': 'Which object in this image belongs to the category Transport?', 'img_file': 'COCO_val2014_000000020342.jpg', 'kb_source': 'dbpedia', 'fact': ['bicycle', 'belong to', 'transport'], 'question_id': '5746'}, '1014': {'fact_surface': '[[A person]] can [[train a dog]]', 'answer': 'person', 'question': 'Which object in this image is capable of training a dog?', 'img_file': 'COCO_val2014_000000148392.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'train dog'], 'question_id': '5747'}, '1015': {'fact_surface': '[[bark]] is related to [[tree]]', 'answer': 'tree', 'question': 'Which object in this image is related to bark?', 'img_file': 'COCO_val2014_000000148392.jpg', 'kb_source': 'conceptnet', 'fact': ['bark', 'related to', 'tree'], 'question_id': '5748'}, '1016': {'fact_surface': '[[Fire hydrants]] are [[important to fire fighters]]', 'answer': 'fire hydrant', 'question': 'Which object in this image is important to fire fighters?', 'img_file': 'COCO_val2014_000000148392.jpg', 'kb_source': 'conceptnet', 'fact': ['fire hydrant', 'has property', 'important to fire fighter'], 'question_id': '5749'}, '1017': {'fact_surface': '[[motorcycle]] are far far more dangerous than [[automobile]]', 'answer': 'motorcycle', 'question': 'which object in this image is more dangerous than automobile?', 'img_file': 'COCO_val2014_000000144795.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'dangerous', 'automobile'], 'question_id': '5267'}, '1018': {'fact_surface': '[[a toilet]] is used for [[depositing human waste]]', 'answer': 'toilet', 'question': 'Which object in this image is used for depositing human waste?', 'img_file': 'COCO_val2014_000000107123.jpg', 'kb_source': 'conceptnet', 'fact': ['toilet', 'used for', 'deposit human waste'], 'question_id': '5260'}, '1019': {'fact_surface': '[[pizza]] is a kind of [[food]].', 'answer': 'pizza', 'question': 'Which object in this image belongs to food?', 'img_file': 'COCO_val2014_000000114586.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'is a', 'food'], 'question_id': '2136'}, '1020': {'fact_surface': '[[Pizza]] can have [[mushrooms on it]]', 'answer': 'pizza', 'question': 'Which object in this image has a mushroom on it?', 'img_file': 'COCO_val2014_000000114586.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'has a', 'mushroom on it'], 'question_id': '2137'}, '1021': {'fact_surface': '[[trains]] can [[carry freight]].', 'answer': 'train', 'question': 'Which object in this image can be used to carry freight?', 'img_file': 'COCO_val2014_000000025747.jpg', 'kb_source': 'conceptnet', 'fact': ['train', 'capable of', 'carry freight'], 'question_id': '7'}, '1022': {'fact_surface': '[[Pizzas]] are [[flat and round]]', 'answer': 'pizza', 'question': 'Which object in this image is flat and round?', 'img_file': 'COCO_val2014_000000114586.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'has property', 'flat and round'], 'question_id': '2135'}, '1023': {'fact_surface': 'You can use [[computer]] to [[...store information]]', 'answer': 'computer', 'question': 'Which object in this image can be used for storing information?', 'img_file': 'COCO_val2014_000000117701.jpg', 'kb_source': 'conceptnet', 'fact': ['computer', 'used for', 'store information'], 'question_id': '2379'}, '1024': {'fact_surface': '[[a frisbee]] is for [[having fun]]', 'answer': 'frisbee', 'question': 'Which sport device in this image is used for have fun?', 'img_file': 'COCO_val2014_000000001987.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'used for', 'have fun'], 'question_id': '2374'}, '1025': {'fact_surface': '[[hydrography]] is related to [[waters]]', 'answer': 'water', 'question': 'Which object in this image is related to hydrography?', 'img_file': 'COCO_val2014_000000001987.jpg', 'kb_source': 'conceptnet', 'fact': ['hydrography', 'related to', 'water'], 'question_id': '2375'}, '1026': {'fact_surface': '[[People]] like to [[play games]]', 'answer': 'person', 'question': 'Which thing in this image is playing game?', 'img_file': 'ILSVRC2012_test_00029467.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'play game'], 'question_id': '2376'}, '1027': {'fact_surface': 'You can use [[a frisbee]] to [[play]]', 'answer': 'frisbee', 'question': 'what object is used for playing in this image?', 'img_file': 'COCO_val2014_000000001987.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'used for', 'play'], 'question_id': '2372'}, '1028': {'fact_surface': '[[frisbee]] is for [[relaxation]].', 'answer': 'frisbee', 'question': 'Which sport in this image is used for relaxation?', 'img_file': 'COCO_val2014_000000001987.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'used for', 'relaxation'], 'question_id': '2373'}, '1029': {'fact_surface': 'You are likely to find [[a flute]] in [[the woodwind section]]', 'answer': 'flute', 'question': 'Which object in this image can be found in the woodwind section?', 'img_file': 'ILSVRC2012_test_00010575.JPEG', 'kb_source': 'conceptnet', 'fact': ['flute', 'at location', 'woodwind section'], 'question_id': '1876'}, '1030': {'fact_surface': '*Something you find at [[a zoo]] is [[a zebra]]', 'answer': 'zebra', 'question': 'Which object in this image can be found in zoo?', 'img_file': 'COCO_val2014_000000006688.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'at location', 'zoo'], 'question_id': '1872'}, '1031': {'fact_surface': '[[children]] belongs to the category of [[Human]]', 'answer': 'child', 'question': 'What in this image belongs to the category Human?', 'img_file': 'COCO_val2014_000000120767.jpg', 'kb_source': 'dbpedia', 'fact': ['child', 'belong to', 'human'], 'question_id': '1870'}, '1032': {'fact_surface': '[[zebra]] belongs to the category of [[Animal]]', 'answer': 'zebra', 'question': 'Which object in this image belongs to the category Animal?', 'img_file': 'COCO_val2014_000000006688.jpg', 'kb_source': 'dbpedia', 'fact': ['zebra', 'belong to', 'animal'], 'question_id': '1871'}, '1033': {'fact_surface': '[[Pizza]] is [[a disc-shaped food item]]', 'answer': 'pizza', 'question': 'Which object in this image is food？', 'img_file': 'COCO_val2014_000000114586.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'is a', 'disc shape food item'], 'question_id': '2133'}, '1034': {'fact_surface': 'Kinds of [[keyboard instrument]] : [[piano]]', 'answer': 'piano', 'question': 'What object in this image belongs to a keyboard instrument?', 'img_file': 'ILSVRC2012_test_00030242.JPEG', 'kb_source': 'conceptnet', 'fact': ['piano', 'is a', 'keyboard instrument'], 'question_id': '4942'}, '1035': {'fact_surface': '[[helmet]] belongs to the category of [[Protective gear]]', 'answer': 'helmet', 'question': 'What item of protective gear is in this image?', 'img_file': 'ILSVRC2012_test_00005133.JPEG', 'kb_source': 'dbpedia', 'fact': ['helmet', 'belong to', 'protective gear'], 'question_id': '2118'}, '1036': {'fact_surface': '[[fencing]] is for [[For keeping animals or people in]]', 'answer': 'fence', 'question': 'Which object in this image is used for for keeping animals in?', 'img_file': 'COCO_val2014_000000003932.jpg', 'kb_source': 'conceptnet', 'fact': ['fence', 'used for', 'for keep animal or person in'], 'question_id': '2119'}, '1037': {'fact_surface': '[[yeast]] is related to [[bread]]', 'answer': 'bread', 'question': 'Which object in this image is related to yeast?', 'img_file': 'COCO_val2014_000000152340.jpg', 'kb_source': 'conceptnet', 'fact': ['yeast', 'related to', 'bread'], 'question_id': '2113'}, '1038': {'fact_surface': '[[spinifex]] is related to [[grass]]', 'answer': 'grass', 'question': 'Which object in this image is related to spinifex?', 'img_file': 'ILSVRC2012_test_00005133.JPEG', 'kb_source': 'conceptnet', 'fact': ['spinifex', 'related to', 'grass'], 'question_id': '2114'}, '1039': {'fact_surface': '*Something you find [[on the surface of the earth]] is [[grass]]', 'answer': 'grass', 'question': 'What can you see on the surface of the earth?', 'img_file': 'ILSVRC2012_test_00005133.JPEG', 'kb_source': 'conceptnet', 'fact': ['grass', 'at location', 'on surface of earth'], 'question_id': '2115'}, '1040': {'fact_surface': '[[helmets]] can be used for [[protection]]', 'answer': 'helmet', 'question': 'Which object in this image is used to void injury?', 'img_file': 'ILSVRC2012_test_00005133.JPEG', 'kb_source': 'conceptnet', 'fact': ['helmet', 'used for', 'protection'], 'question_id': '2116'}, '1041': {'fact_surface': '[[a helmet]] ought to be [[hard]]', 'answer': 'helmet', 'question': 'Which object used to prevent injury is hard?', 'img_file': 'ILSVRC2012_test_00005133.JPEG', 'kb_source': 'conceptnet', 'fact': ['helmet', 'has property', 'hard'], 'question_id': '2117'}, '1042': {'fact_surface': '[[books]] are [[a source of information]]', 'answer': 'book', 'question': 'Which object in this image is a source of information?', 'img_file': 'COCO_val2014_000000008708.jpg', 'kb_source': 'conceptnet', 'fact': ['book', 'is a', 'source of information'], 'question_id': '1919'}, '1043': {'fact_surface': '[[glasses]] have [[two lenses]]', 'answer': 'glass', 'question': 'Which object in this image has two lenses?', 'img_file': 'COCO_val2014_000000008708.jpg', 'kb_source': 'conceptnet', 'fact': ['glass', 'has a', 'two lense'], 'question_id': '1918'}, '1044': {'fact_surface': '[[bicycles]] are [[a mechanized form of transport]]', 'answer': 'bicycle', 'question': 'Which object in this image is a mechanized form of transport?', 'img_file': 'ILSVRC2012_test_00002886.JPEG', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'is a', 'mechanize form of transport'], 'question_id': '5108'}, '1045': {'fact_surface': '[[bicycle]] has [[wheels]].', 'answer': 'bicycle', 'question': 'Which object in this image has wheels?', 'img_file': 'ILSVRC2012_test_00002886.JPEG', 'kb_source': 'conceptnet', 'fact': ['wheel', 'part of', 'bicycle'], 'question_id': '5109'}, '1046': {'fact_surface': '[[pizza]] is [[a good food]]', 'answer': 'pizza', 'question': 'Which object in this image is a good food?', 'img_file': 'COCO_val2014_000000114586.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'is a', 'good food'], 'question_id': '2131'}, '1047': {'fact_surface': '[[helmet]] is a subclass of [[protective garment]]', 'answer': 'helmet', 'question': 'What object in this image is a type of protective garment?', 'img_file': 'COCO_val2014_000000108838.jpg', 'kb_source': 'conceptnet', 'fact': ['helmet', 'is a', 'protective garment'], 'question_id': '3288'}, '1048': {'fact_surface': '[[hot dog]] belongs to the category of [[Smoked meat]]', 'answer': 'hot dog', 'question': 'Which object in this image belongs to the category Smoked meat?', 'img_file': 'ILSVRC2012_test_00001635.JPEG', 'kb_source': 'dbpedia', 'fact': ['hot dog', 'belong to', 'smoked meat'], 'question_id': '5106'}, '1049': {'fact_surface': '[[tie]] belongs to the category of [[Neckwear]]', 'answer': 'tie', 'question': 'Which object does the man have as a neckwear?', 'img_file': 'COCO_val2014_000000118124.jpg', 'kb_source': 'dbpedia', 'fact': ['tie', 'belong to', 'neckwear'], 'question_id': '3282'}, '1050': {'fact_surface': '[[hot dog]] is a subclass of [[sausage]]', 'answer': 'hot dog', 'question': 'Which object in this image is a subclass of sausage?', 'img_file': 'ILSVRC2012_test_00001635.JPEG', 'kb_source': 'conceptnet', 'fact': ['hot dog', 'is a', 'sausage'], 'question_id': '5105'}, '1051': {'fact_surface': '[[a motorcycle]] has [[two wheels]]', 'answer': 'motorcycle', 'question': 'What object in this image has two wheels?', 'img_file': 'COCO_val2014_000000013177.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'has a', 'two wheel'], 'question_id': '885'}, '1052': {'fact_surface': '[[cake]] is related to [[delicious]]', 'answer': 'cake', 'question': 'Which object in this image is related to delicious', 'img_file': 'COCO_val2014_000000136270.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'related to', 'delicious'], 'question_id': '889'}, '1053': {'fact_surface': '[[a kitchen]] is used for [[cook food]]', 'answer': 'cook food', 'question': 'What is the room in the image for?', 'img_file': 'COCO_val2014_000000106351.jpg', 'kb_source': 'conceptnet', 'fact': ['kitchen', 'used for', 'cook food'], 'question_id': '888'}, '1054': {'fact_surface': '[[an umbrella]] is used to [[shield a person from rain]]', 'answer': 'umbrella', 'question': 'which object in this image is used to shield a preson from the rain?', 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'used for', 'shield person from rain'], 'question_id': '5245'}, '1055': {'fact_surface': 'When you think about [[sleeping]], [[sofa]] also comes to mind.', 'answer': 'sofa', 'question': 'Which object in this image is connected with  sleep?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sleep', 'related to', 'sofa'], 'question_id': '1269'}, '1056': {'fact_surface': '[[a sofa]] is for [[watching television]]', 'answer': 'sofa', 'question': 'Which object in this image is used for watch tv?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'used for', 'watch television'], 'question_id': '1268'}, '1057': {'fact_surface': '[[lobster]] is related to [[crab]]', 'answer': 'lobster', 'question': 'Which object is the most related to crab', 'img_file': 'ILSVRC2012_test_00042670.JPEG', 'kb_source': 'conceptnet', 'fact': ['lobster', 'related to', 'crab'], 'question_id': '668'}, '1058': {'fact_surface': '[[snails]] are [[slow]]', 'answer': 'low', 'question': 'What is the significant property of the animal in this image', 'img_file': 'ILSVRC2012_test_00003143.JPEG', 'kb_source': 'conceptnet', 'fact': ['nail', 'has property', 'low'], 'question_id': '666'}, '1059': {'fact_surface': '[[sofa]] belongs to the category of [[Conservation and restoration]]', 'answer': 'sofa', 'question': 'What in this image belongs to the category Conservation and restoration?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'dbpedia', 'fact': ['sofa', 'belong to', 'conservation and restoration'], 'question_id': '1267'}, '1060': {'fact_surface': '[[day bed]] is related to [[sofa]]', 'answer': 'sofa', 'question': 'Which object in this image is related to rest?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['day bed', 'related to', 'sofa'], 'question_id': '1265'}, '1061': {'fact_surface': '*Something you find in [[bed]] is [[a teddy bear]]', 'answer': 'teddy bear', 'question': 'Which of the objects in this image might be found in a bed?', 'img_file': 'COCO_val2014_000000008708.jpg', 'kb_source': 'conceptnet', 'fact': ['teddy bear', 'at location', 'bed'], 'question_id': '1913'}, '1062': {'fact_surface': '[[A bicycle]] is [[a vehicle with two wheels]]', 'answer': 'bicycle', 'question': 'Which object in this image has two wheels?', 'img_file': 'COCO_val2014_000000108838.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'is a', 'vehicle with two wheel'], 'question_id': '3284'}, '1063': {'fact_surface': '[[bicycle]] are lighter than [[car]]', 'answer': 'bicycle', 'question': 'Which object in this image is lighter than a car?', 'img_file': 'COCO_val2014_000000108838.jpg', 'kb_source': 'webchild', 'fact': ['bicycle', 'light', 'car'], 'question_id': '3283'}, '1064': {'fact_surface': '[[a helmet]] can [[protect a head from impact]]', 'answer': 'helmet', 'question': 'Which object in this image can protect the head from impact?', 'img_file': 'ILSVRC2012_test_00002886.JPEG', 'kb_source': 'conceptnet', 'fact': ['helmet', 'capable of', 'protect head from impact'], 'question_id': '5107'}, '1065': {'fact_surface': '[[saxophone]] is used for [[music]].', 'answer': 'music', 'question': 'What is the object in the centre of this image used for?', 'img_file': 'ILSVRC2012_test_00000761.JPEG', 'kb_source': 'conceptnet', 'fact': ['saxophone', 'used for', 'music'], 'question_id': '3280'}, '1066': {'fact_surface': '[[Hot dogs]] are [[good for lunch]]', 'answer': 'hot dog', 'question': 'Which object in this image is good for lunch?', 'img_file': 'ILSVRC2012_test_00018817.JPEG', 'kb_source': 'conceptnet', 'fact': ['hot dog', 'has property', 'good for lunch'], 'question_id': '4129'}, '1067': {'fact_surface': '[[Hot dogs]] can have [[many different toppings]]', 'answer': 'hot dog', 'question': 'Which object in this image can have many different toppings?', 'img_file': 'ILSVRC2012_test_00018817.JPEG', 'kb_source': 'conceptnet', 'fact': ['hot dog', 'has a', 'many different topping'], 'question_id': '4128'}, '1068': {'fact_surface': '[[A keyboard]] is for [[data entry]]', 'answer': 'keyboard', 'question': 'What is used for data entry?', 'img_file': 'COCO_val2014_000000116252.jpg', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'used for', 'data entry'], 'question_id': '4122'}, '1069': {'fact_surface': '[[A keyboard]] is for [[data entry]]', 'answer': 'keyboard', 'question': 'What is used for data entry?', 'img_file': 'COCO_val2014_000000116252.jpg', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'used for', 'data entry'], 'question_id': '4121'}, '1070': {'fact_surface': '[[keyboard]] is used for [[typing letters onto the windows]]', 'answer': 'keyboard', 'question': 'Which object in this image is used for input onto a monitor?', 'img_file': 'COCO_val2014_000000116252.jpg', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'used for', 'type letter onto window'], 'question_id': '4120'}, '1071': {'fact_surface': '[[room]] are more important than [[parking space]]', 'answer': 'park space', 'question': 'What place is less important than the place in the image?', 'img_file': 'COCO_val2014_000000138070.jpg', 'kb_source': 'webchild', 'fact': ['room', 'important', 'park space'], 'question_id': '4126'}, '1072': {'fact_surface': '[[a boat]] is for [[floating]]', 'answer': 'boat', 'question': 'Which object in this image is used for float?', 'img_file': 'COCO_val2014_000000135846.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'used for', 'float'], 'question_id': '4125'}, '1073': {'fact_surface': '[[a boat]] can [[take you to an island]]', 'answer': 'boat', 'question': 'Which object in this image can take you to an island', 'img_file': 'COCO_val2014_000000135846.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'capable of', 'take you to island'], 'question_id': '4124'}, '1074': {'fact_surface': '[[horse]] is related to [[zebra]]', 'answer': 'zebra', 'question': 'Which object in this image is related to horse', 'img_file': 'ILSVRC2012_test_00010048.JPEG', 'kb_source': 'conceptnet', 'fact': ['horse', 'related to', 'zebra'], 'question_id': '5689'}, '1075': {'fact_surface': '[[a tree]] is [[made of wood]].', 'answer': 'tree', 'question': 'Which object in this image is made of wood?', 'img_file': 'COCO_val2014_000000129812.jpg', 'kb_source': 'conceptnet', 'fact': ['tree', 'has property', 'make of wood'], 'question_id': '5688'}, '1076': {'fact_surface': '[[cell phone]] belongs to the category of [[History of communication]]', 'answer': 'cell phone', 'question': 'Which object in this image belongs to the category History of communication?', 'img_file': 'COCO_val2014_000000101622.jpg', 'kb_source': 'dbpedia', 'fact': ['cell phone', 'belong to', 'history of communication'], 'question_id': '5685'}, '1077': {'fact_surface': '[[a basketball]] is [[bigger than a baseball]]', 'answer': 'basketball', 'question': 'What ball in this image is bigger than baseball?', 'img_file': 'ILSVRC2012_test_00049700.JPEG', 'kb_source': 'conceptnet', 'fact': ['basketball', 'is a', 'big than baseball'], 'question_id': '5684'}, '1078': {'fact_surface': 'You are likely to find [[a heifer]] in [[a pasture]]', 'answer': 'heifer', 'question': 'What can likely be found in this place?', 'img_file': 'ILSVRC2012_test_00034575.JPEG', 'kb_source': 'conceptnet', 'fact': ['heifer', 'at location', 'pasture'], 'question_id': '5687'}, '1079': {'fact_surface': '[[truck]] belongs to the category of [[Vehicle]]', 'answer': 'truck', 'question': 'What kind of vehicle is in this image?', 'img_file': 'COCO_val2014_000000007178.jpg', 'kb_source': 'dbpedia', 'fact': ['truck', 'belong to', 'vehicle'], 'question_id': '5686'}, '1080': {'fact_surface': '[[boxen]] is related to [[computer]]', 'answer': 'computer', 'question': 'What in this image is related to boxen?', 'img_file': 'ILSVRC2012_test_00059513.JPEG', 'kb_source': 'conceptnet', 'fact': ['boxen', 'related to', 'computer'], 'question_id': '5680'}, '1081': {'fact_surface': \"You are likely to find [[an accordion]] in [[weird al's videos]]\", 'answer': 'accordion', 'question': \"Which instrument in the foreground can be found in weird al's video\", 'img_file': 'ILSVRC2012_test_00022018.JPEG', 'kb_source': 'conceptnet', 'fact': ['accordion', 'at location', \"weird al's video\"], 'question_id': '5683'}, '1082': {'fact_surface': '[[computers]] are [[very useful]]', 'answer': 'computer', 'question': 'What in this image has the property of very useful?', 'img_file': 'ILSVRC2012_test_00059513.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'has property', 'very useful'], 'question_id': '5682'}, '1083': {'fact_surface': 'Kinds of [[food]] : [[hamburger]]', 'answer': 'hamburger', 'question': 'What is the food on the left called?', 'img_file': 'COCO_val2014_000000100083.jpg', 'kb_source': 'conceptnet', 'fact': ['hamburger', 'is a', 'food'], 'question_id': '5368'}, '1084': {'fact_surface': '[[a person]] can [[butter toast]]', 'answer': 'person', 'question': 'which object in this image is capable of buttering toast?', 'img_file': 'ILSVRC2012_test_00005014.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'butter toast'], 'question_id': '2587'}, '1085': {'fact_surface': '[[people]] can [[buy a car]]', 'answer': 'person', 'question': 'what object in this image is capable of buying a car?', 'img_file': 'ILSVRC2012_test_00005014.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'buy car'], 'question_id': '2586'}, '1086': {'fact_surface': '[[People]] can [[swim in water]]', 'answer': 'person', 'question': 'What object in this image is capable of swimming in water?', 'img_file': 'ILSVRC2012_test_00005014.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'swim in water'], 'question_id': '2585'}, '1087': {'fact_surface': '[[People]] can [[speak words]]', 'answer': 'person', 'question': 'what object in this image can speak?', 'img_file': 'ILSVRC2012_test_00005014.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'speak word'], 'question_id': '2584'}, '1088': {'fact_surface': '[[a person]] wants [[happy times]]', 'answer': 'person', 'question': \"What object in this image appears 'happy'?\", 'img_file': 'ILSVRC2012_test_00005014.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'happy time'], 'question_id': '2583'}, '1089': {'fact_surface': '[[An airplane]] is for [[traversing the skies]]', 'answer': 'airplane', 'question': 'What object can fly in the sky?', 'img_file': 'ILSVRC2012_test_00006479.JPEG', 'kb_source': 'conceptnet', 'fact': ['airplane', 'used for', 'traverse sky'], 'question_id': '2582'}, '1090': {'fact_surface': '[[an airplane]] can [[arrive at the airport]]', 'answer': 'airplane', 'question': 'Which object in this image might arrive at an airport?', 'img_file': 'ILSVRC2012_test_00006479.JPEG', 'kb_source': 'conceptnet', 'fact': ['airplane', 'capable of', 'arrive at airport'], 'question_id': '2581'}, '1091': {'fact_surface': '[[living room]] can be warmer than [[bedroom]]', 'answer': 'bedroom', 'question': 'Which place may be less warm than the place shown in this image?', 'img_file': 'ILSVRC2012_test_00029351.JPEG', 'kb_source': 'webchild', 'fact': ['living room', 'warm', 'bedroom'], 'question_id': '2580'}, '1092': {'fact_surface': '[[people]] can [[taste food]]', 'answer': 'person', 'question': 'what object in this image is capable of eating food?', 'img_file': 'ILSVRC2012_test_00005014.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'taste food'], 'question_id': '2589'}, '1093': {'fact_surface': '[[A person]] can [[look angry]]', 'answer': 'person', 'question': 'what object in this image is capable of getting angry?', 'img_file': 'ILSVRC2012_test_00005014.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'look angry'], 'question_id': '2588'}, '1094': {'fact_surface': '[[vegetables]] belongs to the category of [[Food]]', 'answer': 'vegetable', 'question': 'Which object in this image belongs to the category Food?', 'img_file': 'COCO_val2014_000000116206.jpg', 'kb_source': 'dbpedia', 'fact': ['vegetable', 'belong to', 'food'], 'question_id': '3544'}, '1095': {'fact_surface': '[[vegetables]] belongs to the category of [[Food]]', 'answer': 'vegetable', 'question': 'What is chopped in this image and belongs to the category food?', 'img_file': 'COCO_val2014_000000116206.jpg', 'kb_source': 'dbpedia', 'fact': ['vegetable', 'belong to', 'food'], 'question_id': '3545'}, '1096': {'fact_surface': '[[helmets]] can [[prevent head injuries]]', 'answer': 'helmet', 'question': 'Which object in this image is capable of preventing head injury?', 'img_file': 'COCO_val2014_000000125404.jpg', 'kb_source': 'conceptnet', 'fact': ['helmet', 'capable of', 'prevent head injury'], 'question_id': '2965'}, '1097': {'fact_surface': '[[wine]] is for [[Selling]]', 'answer': 'wine', 'question': 'Which object in this image is sold', 'img_file': 'COCO_val2014_000000126429.jpg', 'kb_source': 'conceptnet', 'fact': ['wine', 'used for', 'sell'], 'question_id': '2964'}, '1098': {'fact_surface': '[[honesty]] is better than [[book]]', 'answer': 'book', 'question': 'which object in this image is not  good than honesty?', 'img_file': 'ILSVRC2012_test_00057322.JPEG', 'kb_source': 'webchild', 'fact': ['honesty', 'good', 'book'], 'question_id': '2967'}, '1099': {'fact_surface': 'A [[helmet]] is a [[roughly spherical hard shell that you can wear around your head to protect it from injury]]', 'answer': 'helmet', 'question': 'Which object in this image is a roughly spherical hard shell that you can wear around your head to protect it from injury?', 'img_file': 'COCO_val2014_000000125404.jpg', 'kb_source': 'conceptnet', 'fact': ['helmet', 'is a', 'roughly spherical hard shell that you can wear around your head to protect it from injury'], 'question_id': '2966'}, '1100': {'fact_surface': '[[bottle]] belongs to the category of [[Liquid containers]]', 'answer': 'bottle', 'question': 'What object in this image is liquid container?', 'img_file': 'COCO_val2014_000000126429.jpg', 'kb_source': 'dbpedia', 'fact': ['bottle', 'belong to', 'liquid containers'], 'question_id': '2961'}, '1101': {'fact_surface': '[[A bottle]] can [[store wine]]', 'answer': 'bottle', 'question': 'Which object in this image can store wine?', 'img_file': 'COCO_val2014_000000126429.jpg', 'kb_source': 'conceptnet', 'fact': ['bottle', 'capable of', 'store wine'], 'question_id': '2960'}, '1102': {'fact_surface': '[[Wine]] contains [[alcohol]]', 'answer': 'wine', 'question': 'Which object in this image contains alcohol?', 'img_file': 'COCO_val2014_000000126429.jpg', 'kb_source': 'conceptnet', 'fact': ['wine', 'has a', 'alcohol'], 'question_id': '2963'}, '1103': {'fact_surface': '[[Wine]] is [[drunk by people]]', 'answer': 'wine', 'question': 'Which object in this image can be drunk by person?', 'img_file': 'COCO_val2014_000000126429.jpg', 'kb_source': 'conceptnet', 'fact': ['wine', 'has property', 'drunk by person'], 'question_id': '2962'}, '1104': {'fact_surface': '[[A stethoscope]] is [[a medical instrument]]', 'answer': 'stethoscope', 'question': 'What medical instrument does the boy have?', 'img_file': 'ILSVRC2012_test_00040213.JPEG', 'kb_source': 'conceptnet', 'fact': ['stethoscope', 'is a', 'medical instrument'], 'question_id': '763'}, '1105': {'fact_surface': '[[tennis ball]] belongs to the category of [[Summer Olympic sports]]', 'answer': 'summer', 'question': 'Whether this game belongs to the Summer Olympic or the Winter Olympic?', 'img_file': 'ILSVRC2012_test_00000992.JPEG', 'kb_source': 'dbpedia', 'fact': ['tennis ball', 'belong to', 'summer'], 'question_id': '760'}, '1106': {'fact_surface': '[[Broccoli]] is [[green]]', 'answer': 'broccoli', 'question': 'Which object in this image is green?', 'img_file': 'COCO_val2014_000000104612.jpg', 'kb_source': 'conceptnet', 'fact': ['broccoli', 'has property', 'green'], 'question_id': '2969'}, '1107': {'fact_surface': '[[broccoli]] is a kind of [[vegetable]].', 'answer': 'broccoli', 'question': 'Which object in this image is a vegetable?', 'img_file': 'COCO_val2014_000000104612.jpg', 'kb_source': 'conceptnet', 'fact': ['broccoli', 'is a', 'vegetable'], 'question_id': '2968'}, '1108': {'fact_surface': '[[dog]] seem more active than [[cat]]', 'answer': 'dog', 'question': 'Which animal in the image is more active?', 'img_file': 'COCO_val2014_000000022892.jpg', 'kb_source': 'webchild', 'fact': ['dog', 'active', 'cat'], 'question_id': '765'}, '1109': {'fact_surface': '[[camel]] is related to [[dromedary]]', 'answer': 'camel', 'question': 'Which object in this image is a dromedary?', 'img_file': 'ILSVRC2012_test_00017725.JPEG', 'kb_source': 'conceptnet', 'fact': ['camel', 'related to', 'dromedary'], 'question_id': '5379'}, '1110': {'fact_surface': '[[camel]] is related to [[dromedary]]', 'answer': 'camel', 'question': 'Which object in this image is a dromedary?', 'img_file': 'ILSVRC2012_test_00017725.JPEG', 'kb_source': 'conceptnet', 'fact': ['camel', 'related to', 'dromedary'], 'question_id': '5378'}, '1111': {'fact_surface': '[[Baseball]] is [[a sport]]', 'answer': 'baseball', 'question': 'What sport this image describes?', 'img_file': 'ILSVRC2012_test_00003646.JPEG', 'kb_source': 'conceptnet', 'fact': ['baseball', 'is a', 'sport'], 'question_id': '1078'}, '1112': {'fact_surface': '[[a helmet]] is a type of [[hat]]', 'answer': 'helmet', 'question': 'Which object in this image is a hat?', 'img_file': 'ILSVRC2012_test_00003646.JPEG', 'kb_source': 'conceptnet', 'fact': ['helmet', 'is a', 'hat'], 'question_id': '1076'}, '1113': {'fact_surface': 'A [[helmet]] is a [[hat that protects your head]]', 'answer': 'helmet', 'question': 'Which object in this image is a hat that protect your head?', 'img_file': 'ILSVRC2012_test_00003646.JPEG', 'kb_source': 'conceptnet', 'fact': ['helmet', 'is a', 'hat that protect your head'], 'question_id': '1075'}, '1114': {'fact_surface': '[[snail]] belongs to the category of [[Mollusc products]]', 'answer': 'nail', 'question': 'What mollusc is in this image?', 'img_file': 'ILSVRC2012_test_00001734.JPEG', 'kb_source': 'dbpedia', 'fact': ['nail', 'belong to', 'mollusc products'], 'question_id': '1072'}, '1115': {'fact_surface': '[[Airplanes]] have [[wings]]', 'answer': 'airplane', 'question': 'Which object in this image has wings?', 'img_file': 'COCO_val2014_000000008016.jpg', 'kb_source': 'conceptnet', 'fact': ['airplane', 'has a', 'wing'], 'question_id': '4339'}, '1116': {'fact_surface': '[[computers]] are [[one of the most powerful technologies ever invented by humans]]', 'answer': 'computer', 'question': 'Which object in this image is a one of most powerful technology ever invent by human?', 'img_file': 'ILSVRC2012_test_00012291.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'is a', 'one of most powerful technology ever invent by human'], 'question_id': '4333'}, '1117': {'fact_surface': '[[a river]] is for [[swimming]]', 'answer': 'swimming', 'question': 'What can the place in this image be used for?', 'img_file': 'COCO_val2014_000000120248.jpg', 'kb_source': 'conceptnet', 'fact': ['river', 'used for', 'swimming'], 'question_id': '3135'}, '1118': {'fact_surface': '[[tromboner]] is related to [[trombone]]', 'answer': 'trombone', 'question': 'Which object in this image is related to tromboner?', 'img_file': 'ILSVRC2012_test_00000655.JPEG', 'kb_source': 'conceptnet', 'fact': ['tromboner', 'related to', 'trombone'], 'question_id': '3136'}, '1119': {'fact_surface': 'You can use [[a boat]] to [[travel across water]]', 'answer': 'travel across water', 'question': 'what is the large object in the center of the image used for?', 'img_file': 'COCO_val2014_000000120248.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'used for', 'travel across water'], 'question_id': '3131'}, '1120': {'fact_surface': '[[ferry]] is related to [[boat]]', 'answer': 'boat', 'question': 'which object in this image is related to a ferry?', 'img_file': 'COCO_val2014_000000120248.jpg', 'kb_source': 'conceptnet', 'fact': ['ferry', 'related to', 'boat'], 'question_id': '3130'}, '1121': {'fact_surface': '[[A boat]] is [[a mode of transportation]]', 'answer': 'boat', 'question': 'which object in this image is a means of transportation?', 'img_file': 'COCO_val2014_000000120248.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'is a', 'mode of transportation'], 'question_id': '3133'}, '1122': {'fact_surface': 'You can use [[a boat]] to [[travel across water]]', 'answer': 'travel across water', 'question': 'what is the large object in the center of the image used for?', 'img_file': 'COCO_val2014_000000120248.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'used for', 'travel across water'], 'question_id': '3132'}, '1123': {'fact_surface': \"You are likely to find [[a banana]] in [[a monkey's hand]]\", 'answer': 'banana', 'question': \"Which object in this image can be found in monkey's hand?\", 'img_file': 'COCO_val2014_000000100343.jpg', 'kb_source': 'conceptnet', 'fact': ['banana', 'at location', \"monkey's hand\"], 'question_id': '3139'}, '1124': {'fact_surface': '[[Grass]] is often [[wet in the morning from dew]]', 'answer': 'grass', 'question': 'Which object in this image is often wet in morning from dew?', 'img_file': 'COCO_val2014_000000012543.jpg', 'kb_source': 'conceptnet', 'fact': ['grass', 'has property', 'wet in morning from dew'], 'question_id': '1532'}, '1125': {'fact_surface': '[[cup]] belongs to the category of [[Kitchen]]', 'answer': 'cup', 'question': 'Which object in this image belongs to the category of kitchen items?', 'img_file': 'ILSVRC2012_test_00047461.JPEG', 'kb_source': 'dbpedia', 'fact': ['cup', 'belong to', 'kitchen'], 'question_id': '5768'}, '1126': {'fact_surface': '[[Cups]] are used to [[drink from]]', 'answer': 'cup', 'question': 'Which kitchen item in this image may contain a drink?', 'img_file': 'ILSVRC2012_test_00047461.JPEG', 'kb_source': 'conceptnet', 'fact': ['cup', 'used for', 'drink from'], 'question_id': '5769'}, '1127': {'fact_surface': 'The class of [[goldfish]] is [[Actinopterygii]]', 'answer': 'actinopterygii', 'question': 'What is the class of the animal in this image?', 'img_file': 'ILSVRC2012_test_00042080.JPEG', 'kb_source': 'dbpedia', 'fact': ['goldfish', 'animal class', 'actinopterygii'], 'question_id': '5764'}, '1128': {'fact_surface': '[[wall]] is related to [[rope]]', 'answer': 'wall', 'question': 'what in this image is related to rope?', 'img_file': 'ILSVRC2012_test_00000048.JPEG', 'kb_source': 'conceptnet', 'fact': ['wall', 'related to', 'rope'], 'question_id': '5760'}, '1129': {'fact_surface': '[[dishes]] belongs to the category of [[Kitchenware]]', 'answer': 'dishes', 'question': 'What thing in this image belongs to the category Kitchenware?', 'img_file': 'COCO_val2014_000000106351.jpg', 'kb_source': 'dbpedia', 'fact': ['tableware', 'belong to', 'dishes'], 'question_id': '5186'}, '1130': {'fact_surface': '[[ping-pong ball]] belongs to the category of [[Indoor sports]]', 'answer': 'ping pong ball', 'question': 'Which kind of indoor sports are they playing?', 'img_file': 'ILSVRC2012_test_00002577.JPEG', 'kb_source': 'dbpedia', 'fact': ['table tennis', 'belong to', 'ping pong ball'], 'question_id': '2256'}, '1131': {'fact_surface': '[[snowboarding]] is [[a sport]]', 'answer': 'snowboard', 'question': 'What sport is shown in this image?', 'img_file': 'COCO_val2014_000000102329.jpg', 'kb_source': 'conceptnet', 'fact': ['snowboard', 'is a', 'sport'], 'question_id': '2250'}, '1132': {'fact_surface': 'An activity [[a cat]] can do is [[nap]].', 'answer': 'cat', 'question': 'Which object in this image is capable of napping?', 'img_file': 'COCO_val2014_000000023731.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'nap'], 'question_id': '5184'}, '1133': {'fact_surface': '[[ship]] belongs to the category of [[Watercraft]]', 'answer': 'ship', 'question': 'Which object in this image belongs to the category Watercraft?', 'img_file': 'ILSVRC2012_test_00059915.JPEG', 'kb_source': 'dbpedia', 'fact': ['ship', 'belong to', 'watercraft'], 'question_id': '1624'}, '1134': {'fact_surface': 'Kinds of [[musical instrument]] : [[french horn]]', 'answer': 'french horn', 'question': 'Which object in this image is a musical instrument?', 'img_file': 'ILSVRC2012_test_00049070.JPEG', 'kb_source': 'conceptnet', 'fact': ['french horn', 'is a', 'musical instrument'], 'question_id': '2974'}, '1135': {'fact_surface': '[[broccoli]] belongs to the category of [[Edible plants]]', 'answer': 'broccoli', 'question': 'Which object in this image belongs to the category Edible plants?', 'img_file': 'COCO_val2014_000000106150.jpg', 'kb_source': 'dbpedia', 'fact': ['broccoli', 'belong to', 'edible plants'], 'question_id': '5360'}, '1136': {'fact_surface': '[[Broccoli]] is [[green]]', 'answer': 'broccoli', 'question': 'Which object in this image is green?', 'img_file': 'COCO_val2014_000000106150.jpg', 'kb_source': 'conceptnet', 'fact': ['broccoli', 'has property', 'green'], 'question_id': '5361'}, '1137': {'fact_surface': '[[laptop]] belongs to the category of [[Computer hardware]]', 'answer': 'laptop', 'question': 'Which object in this image belongs to Computer hardware?', 'img_file': 'COCO_val2014_000000134112.jpg', 'kb_source': 'dbpedia', 'fact': ['laptop', 'belong to', 'computer hardware'], 'question_id': '5366'}, '1138': {'fact_surface': '[[dogs]] are [[hairy]]', 'answer': 'dog', 'question': 'Which object in this image has hair?', 'img_file': 'COCO_val2014_000000134112.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'has property', 'hairy'], 'question_id': '5367'}, '1139': {'fact_surface': '[[laptop]] belongs to the category of [[Mobile technology]]', 'answer': 'laptop', 'question': 'Which object in this image belongs to the category Mobile technology?', 'img_file': 'COCO_val2014_000000134112.jpg', 'kb_source': 'dbpedia', 'fact': ['laptop', 'belong to', 'mobile technology'], 'question_id': '5364'}, '1140': {'fact_surface': '[[laptop]] is related to [[desktop]]', 'answer': 'laptop', 'question': 'Which object in this image is similar to desktop?', 'img_file': 'COCO_val2014_000000134112.jpg', 'kb_source': 'conceptnet', 'fact': ['laptop', 'related to', 'desktop'], 'question_id': '5365'}, '1141': {'fact_surface': '[[cup]] is related to [[brassiere]]', 'answer': 'brassiere', 'question': 'Which object in this image has cups?', 'img_file': 'ILSVRC2012_test_00018779.JPEG', 'kb_source': 'conceptnet', 'fact': ['cup', 'related to', 'brassiere'], 'question_id': '2358'}, '1142': {'fact_surface': '[[brassiere]] is related to [[underwear]]', 'answer': 'brassiere', 'question': 'Which object in this image is related to underwear?', 'img_file': 'ILSVRC2012_test_00018779.JPEG', 'kb_source': 'conceptnet', 'fact': ['brassiere', 'related to', 'underwear'], 'question_id': '2359'}, '1143': {'fact_surface': '[[tennis]] is related to [[racquet]]', 'answer': 'racquet', 'question': 'Which object in this image is related to tennis?', 'img_file': 'ILSVRC2012_test_00016347.JPEG', 'kb_source': 'conceptnet', 'fact': ['tennis', 'related to', 'racquet'], 'question_id': '2352'}, '1144': {'fact_surface': '[[snowboard]] belongs to the category of [[Winter Olympic Games]]', 'answer': 'snowboard', 'question': 'Which object in this image belongs to the category Winter Olympic Games?', 'img_file': 'COCO_val2014_000000142346.jpg', 'kb_source': 'dbpedia', 'fact': ['snowboard', 'belong to', 'winter olympic games'], 'question_id': '2353'}, '1145': {'fact_surface': '[[a motorcycle]] is [[faster than a bicycle]]', 'answer': 'motorcycle', 'question': 'Which object in this image is faster than a bicycle?', 'img_file': 'COCO_val2014_000000116712.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'is a', 'fast than bicycle'], 'question_id': '2350'}, '1146': {'fact_surface': '[[people]] can [[wave \"hello\"]]', 'answer': 'person', 'question': 'Which object in this image is capable of waving hello?', 'img_file': 'ILSVRC2012_test_00016347.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'wave hello'], 'question_id': '2351'}, '1147': {'fact_surface': 'A [[guitar]] is a [[stringed musical instrument]]', 'answer': 'guitar', 'question': 'What can you found in this image is a string musical instrument?', 'img_file': 'ILSVRC2012_test_00006301.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'is a', 'string musical instrument'], 'question_id': '2354'}, '1148': {'fact_surface': '[[Baseball]] is [[one of the favourite American sports]]', 'answer': 'baseball', 'question': 'Which object in this image is one of the most favourite american sport?', 'img_file': 'COCO_val2014_000000133042.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'has property', 'one of favourite american sport'], 'question_id': '1898'}, '1149': {'fact_surface': '[[Baseball]] is [[one of the favourite American sports]]', 'answer': 'baseball', 'question': 'Which object in this image is one of the most favourite american sport?', 'img_file': 'COCO_val2014_000000133042.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'has property', 'one of favourite american sport'], 'question_id': '1899'}, '1150': {'fact_surface': '[[An umbrella]] is used to [[protect people from sun and rain]]', 'answer': 'protect person from sun and rain', 'question': 'What is the object on the right part of this image used for?', 'img_file': 'COCO_val2014_000000137573.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'used for', 'protect person from sun and rain'], 'question_id': '3735'}, '1151': {'fact_surface': '[[umbrellas]] are [[used when it rains]]', 'answer': 'umbrella', 'question': 'Which object in this image is used when it rains?', 'img_file': 'COCO_val2014_000000137573.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'is a', 'use when it rain'], 'question_id': '3734'}, '1152': {'fact_surface': 'You are likely to find [[a drum]] in [[a rock band]]', 'answer': 'drum', 'question': 'Which object in this image can be found in rock band?', 'img_file': 'ILSVRC2012_test_00002185.JPEG', 'kb_source': 'conceptnet', 'fact': ['drum', 'at location', 'rock band'], 'question_id': '3733'}, '1153': {'fact_surface': '[[a kitchen]] is for [[Cooking in]]', 'answer': 'cooking', 'question': 'What do people use the place in this image for?', 'img_file': 'COCO_val2014_000000009236.jpg', 'kb_source': 'conceptnet', 'fact': ['kitchen', 'used for', 'cooking'], 'question_id': '4691'}, '1154': {'fact_surface': 'You are likely to find [[a door]] as [[a part of a wall]]', 'answer': 'door', 'question': 'Which object in this image can be found as a part of the wall?', 'img_file': 'COCO_val2014_000000009236.jpg', 'kb_source': 'conceptnet', 'fact': ['door', 'at location', 'part of wall'], 'question_id': '4690'}, '1155': {'fact_surface': '[[fruits]] belongs to the category of [[Edible plants]]', 'answer': 'fruit', 'question': 'Which object in this image belongs to the category Edible plants?', 'img_file': 'ILSVRC2012_test_00025208.JPEG', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'edible plants'], 'question_id': '4692'}, '1156': {'fact_surface': '[[bathroom]] has [[toilet]].', 'answer': 'toilet', 'question': 'What thing does the place shown in this image have as a part?', 'img_file': 'COCO_val2014_000000024845.jpg', 'kb_source': 'conceptnet', 'fact': ['toilet', 'part of', 'bathroom'], 'question_id': '4697'}, '1157': {'fact_surface': '[[a bathroom]] is for [[washing your hands]]', 'answer': 'wash your hand', 'question': 'What does the place in the image can be used for?', 'img_file': 'COCO_val2014_000000024845.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'used for', 'wash your hand'], 'question_id': '4696'}, '1158': {'fact_surface': '[[cups]] is for [[holding drinks]]', 'answer': 'cup', 'question': 'What object in this image can hold drink?', 'img_file': 'COCO_val2014_000000115776.jpg', 'kb_source': 'conceptnet', 'fact': ['cup', 'used for', 'hold drink'], 'question_id': '5160'}, '1159': {'fact_surface': '[[a fork]] can be used to [[eat a steak]]', 'answer': 'fork', 'question': 'What object can be used to eat steak?', 'img_file': 'COCO_val2014_000000115776.jpg', 'kb_source': 'conceptnet', 'fact': ['fork', 'used for', 'eat steak'], 'question_id': '5161'}, '1160': {'fact_surface': '[[milk]] is related to [[cheese]]', 'answer': 'cheese', 'question': 'Which object in this image  is made of milk?', 'img_file': 'COCO_val2014_000000136911.jpg', 'kb_source': 'conceptnet', 'fact': ['milk', 'related to', 'cheese'], 'question_id': '5162'}, '1161': {'fact_surface': '[[people]] can [[read newspapers]]', 'answer': 'person', 'question': 'What in this image is capable of reading a newspaper?', 'img_file': 'ILSVRC2012_test_00012985.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'read newspaper'], 'question_id': '5163'}, '1162': {'fact_surface': '[[motorcycle]] are much smaller than [[car]]', 'answer': 'motorcycle', 'question': 'Which vehicle on the left of the image is smaller than a car?', 'img_file': 'COCO_val2014_000000013177.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'small', 'car'], 'question_id': '5165'}, '1163': {'fact_surface': '[[a person]] can [[sprint]].', 'answer': 'person', 'question': 'What thing shown in this image is capable of sprinting?', 'img_file': 'ILSVRC2012_test_00031079.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'print'], 'question_id': '5167'}, '1164': {'fact_surface': '[[Hair]] is on [[top of the head]]', 'answer': 'hair', 'question': 'which object in this image is on the top of head', 'img_file': 'ILSVRC2012_test_00031079.JPEG', 'kb_source': 'conceptnet', 'fact': ['hair', 'has property', 'top of head'], 'question_id': '5168'}, '1165': {'fact_surface': '[[Snow]] is [[cold and slippery]]', 'answer': 'cold', 'question': 'What property does the place in this image have?', 'img_file': 'ILSVRC2012_test_00026134.JPEG', 'kb_source': 'conceptnet', 'fact': ['snow', 'has property', 'cold'], 'question_id': '5169'}, '1166': {'fact_surface': 'A [[helmet]] is a [[hat that protects your head]]', 'answer': 'helmet', 'question': 'Which object in this image is a hat that protect your head?', 'img_file': 'COCO_val2014_000000104647.jpg', 'kb_source': 'conceptnet', 'fact': ['helmet', 'is a', 'hat that protect your head'], 'question_id': '2787'}, '1167': {'fact_surface': 'You can use [[sand]] to [[create glass]]', 'answer': 'sand', 'question': 'Which object in this image could be used to make glass?', 'img_file': 'COCO_val2014_000000124599.jpg', 'kb_source': 'conceptnet', 'fact': ['sand', 'used for', 'create glass'], 'question_id': '4803'}, '1168': {'fact_surface': '[[sofa]] are considered to be more expensive than [[couch]]', 'answer': 'sofa', 'question': 'which object in this image is more senior than couch?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'webchild', 'fact': ['sofa', 'expensive', 'couch'], 'question_id': '1263'}, '1169': {'fact_surface': 'Things that are often found together are [[sofa]] and [[a cup of  tea]].', 'answer': 'sofa', 'question': 'Which object in this image is connected with cup of tea?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'related to', 'cup of tea'], 'question_id': '1262'}, '1170': {'fact_surface': '[[Sofas]] are [[larger than chairs]]', 'answer': 'sofa', 'question': 'Which object in this image is a heavy than chair?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'is a', 'large than chair'], 'question_id': '1261'}, '1171': {'fact_surface': '[[cart]] belongs to the category of [[Horse driving]]', 'answer': 'cart', 'question': 'Which object in this image belongs to the category Horse driving?', 'img_file': 'COCO_val2014_000000106794.jpg', 'kb_source': 'dbpedia', 'fact': ['cart', 'belong to', 'horse driving'], 'question_id': '1798'}, '1172': {'fact_surface': '[[person]] wants [[a chance to show their hidden talents]]', 'answer': 'person', 'question': 'Which object in this image desires chance to show their hidden talents?', 'img_file': 'COCO_val2014_000000128704.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'chance to show their hide talent'], 'question_id': '1790'}, '1173': {'fact_surface': '[[Horses]] sometimes [[pull carriages]]', 'answer': 'horse', 'question': 'Which object in this image can pull carriage?', 'img_file': 'COCO_val2014_000000106794.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'capable of', 'pull carriage'], 'question_id': '1797'}, '1174': {'fact_surface': '[[laptop]] belongs to the category of [[Consumer goods]]', 'answer': 'laptop', 'question': 'which kind of consumer goods can we find in this image', 'img_file': 'COCO_val2014_000000149783.jpg', 'kb_source': 'dbpedia', 'fact': ['laptop', 'belong to', 'consumer goods'], 'question_id': '1795'}, '1175': {'fact_surface': '[[computers]] are [[electronic devices]]', 'answer': 'computer', 'question': 'What is an example of an electronic device in this image?', 'img_file': 'COCO_val2014_000000149783.jpg', 'kb_source': 'conceptnet', 'fact': ['computer', 'is a', 'electronic device'], 'question_id': '1794'}, '1176': {'fact_surface': '[[armchair]] is related to [[sofa]]', 'answer': 'sofa', 'question': 'Which object in this image is similar to armchair?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['armchair', 'related to', 'sofa'], 'question_id': '1264'}, '1177': {'fact_surface': '[[a trombone]] is used for [[playing music]]', 'answer': 'play music', 'question': \"What is the object in the person's hands used for?\", 'img_file': 'ILSVRC2012_test_00000499.JPEG', 'kb_source': 'conceptnet', 'fact': ['trombone', 'used for', 'play music'], 'question_id': '5344'}, '1178': {'fact_surface': '[[tromboner]] is related to [[trombone]]', 'answer': 'trombone', 'question': 'What object in this image is used by a tromboner?', 'img_file': 'ILSVRC2012_test_00000499.JPEG', 'kb_source': 'conceptnet', 'fact': ['tromboner', 'related to', 'trombone'], 'question_id': '5345'}, '1179': {'fact_surface': '[[a sofa]] is [[usually to sit or lie on]]', 'answer': 'sofa', 'question': 'What in this image is a usually to sit or lie on?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'is a', 'usually to sit or lie on'], 'question_id': '1244'}, '1180': {'fact_surface': 'You are likely to find [[a gift]] in [[a gift shop]]', 'answer': 'gift shop', 'question': 'Where are you likely to find a gift?', 'img_file': 'ILSVRC2012_test_00000015.JPEG', 'kb_source': 'conceptnet', 'fact': ['gift', 'at location', 'gift shop'], 'question_id': '3094'}, '1181': {'fact_surface': '[[settee]] is related to [[sofa]]', 'answer': 'sofa', 'question': 'What in this image is related to settee?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['settee', 'related to', 'sofa'], 'question_id': '1249'}, '1182': {'fact_surface': '[[a sofa]] may have [[a bed in it]]', 'answer': 'sofa', 'question': 'Which object in this image has a bolster in it', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'has a', 'bed in it'], 'question_id': '1248'}, '1183': {'fact_surface': '[[an elephant]] has [[a trunk]]', 'answer': 'elephant', 'question': 'Which object in this image has a trunk?', 'img_file': 'COCO_val2014_000000015599.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'has a', 'trunk'], 'question_id': '4101'}, '1184': {'fact_surface': 'Something you might find [[in a zoo]] is [[an elephant]].', 'answer': 'elephant', 'question': 'Which object in this image might be found in a zoo?', 'img_file': 'COCO_val2014_000000015599.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'at location', 'in zoo'], 'question_id': '4100'}, '1185': {'fact_surface': 'You are likely to find [[elephants]] in [[zoos]]', 'answer': 'elephant', 'question': 'Which object in this image is likely to be found in zoo?', 'img_file': 'COCO_val2014_000000015599.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'at location', 'zoo'], 'question_id': '4103'}, '1186': {'fact_surface': '[[elephants]] are [[large, gray mammals]]', 'answer': 'elephant', 'question': 'What is the large gray mammal shown in this image ?', 'img_file': 'COCO_val2014_000000015599.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'is a', 'large gray mammal'], 'question_id': '4102'}, '1187': {'fact_surface': '[[boats]] can be used for [[transport]]', 'answer': 'boat', 'question': 'What object in this image is a means of water transport?', 'img_file': 'COCO_val2014_000000024921.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'used for', 'transport'], 'question_id': '3898'}, '1188': {'fact_surface': '*Something you find [[at a bus stop]] is [[a bus]]', 'answer': 'bus', 'question': 'What object in this image can be found at a bus stop?', 'img_file': 'COCO_val2014_000000138040.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'at location', 'at bus stop'], 'question_id': '3899'}, '1189': {'fact_surface': '[[A car]] can [[seat people]]', 'answer': 'car', 'question': 'Which object in this image is capable of seating people?', 'img_file': 'COCO_val2014_000000013414.jpg', 'kb_source': 'conceptnet', 'fact': ['car', 'capable of', 'seat person'], 'question_id': '3897'}, '1190': {'fact_surface': '[[a banjo]] is used for [[playing folk music]]', 'answer': 'banjo', 'question': 'Which object in this image is used for playing folk music?', 'img_file': 'ILSVRC2012_test_00021564.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'used for', 'play folk music'], 'question_id': '3038'}, '1191': {'fact_surface': '[[Tennis balls]] are [[spherical in shape]]', 'answer': 'tennis ball', 'question': 'what objects in this image are a spherical shape?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis ball', 'has property', 'spherical in shape'], 'question_id': '2659'}, '1192': {'fact_surface': '[[a tennis ball]] is for [[playing tennis with]]', 'answer': 'tennis ball', 'question': 'what small round object in this image is used for playing tennis?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis ball', 'used for', 'play tennis with'], 'question_id': '2658'}, '1193': {'fact_surface': '[[watermelon]] are bigger than [[orange]]', 'answer': 'orange', 'question': 'which kind of fruit in this image is smaller than watermellon', 'img_file': 'COCO_val2014_000000019167.jpg', 'kb_source': 'webchild', 'fact': ['watermelon', 'big', 'orange'], 'question_id': '2657'}, '1194': {'fact_surface': '[[An orange]] can [[taste sour]]', 'answer': 'orange', 'question': 'Which object in this image is capable of taste sour?', 'img_file': 'COCO_val2014_000000019167.jpg', 'kb_source': 'conceptnet', 'fact': ['orange', 'capable of', 'taste sour'], 'question_id': '2656'}, '1195': {'fact_surface': '[[pizza]] is a kind of [[food]].', 'answer': 'pizza', 'question': 'Which food can you see in this image?', 'img_file': 'COCO_val2014_000000121632.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'is a', 'food'], 'question_id': '2655'}, '1196': {'fact_surface': '[[fork]] is related to [[prong]]', 'answer': 'fork', 'question': 'Which object in this image has prongs?', 'img_file': 'COCO_val2014_000000121632.jpg', 'kb_source': 'conceptnet', 'fact': ['fork', 'related to', 'prong'], 'question_id': '2654'}, '1197': {'fact_surface': '[[a horse]] is generally [[larger than a person]]', 'answer': 'horse', 'question': 'What is the animal in this image that is larger than a person?', 'img_file': 'COCO_val2014_000000112349.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'has property', 'large than person'], 'question_id': '1452'}, '1198': {'fact_surface': '[[zebra]] is a kind of [[animal]].', 'answer': 'zebra', 'question': 'Which object in this image is a animal?', 'img_file': 'COCO_val2014_000000116589.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'is a', 'animal'], 'question_id': '3562'}, '1199': {'fact_surface': '[[horse]] is related to [[zebra]]', 'answer': 'zebra', 'question': 'Which object in this image is related to horse?', 'img_file': 'COCO_val2014_000000116589.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'related to', 'zebra'], 'question_id': '3563'}, '1200': {'fact_surface': '[[A dog]] can [[come to its master]]', 'answer': 'dog', 'question': 'Which object in this image is capable of come to it master?', 'img_file': 'ILSVRC2012_test_00006252.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'capable of', 'come to it master'], 'question_id': '3560'}, '1201': {'fact_surface': 'A [[dog]] is a [[faithful companion]]', 'answer': 'dog', 'question': 'Which animal in this image is a faithful companion?', 'img_file': 'ILSVRC2012_test_00006252.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'is a', 'faithful companion'], 'question_id': '3561'}, '1202': {'fact_surface': '[[cart]] belongs to the category of [[Animal-powered transport]]', 'answer': 'cart', 'question': 'Which object in this image belongs to the category Animal-powered transport?', 'img_file': 'ILSVRC2012_test_00002725.JPEG', 'kb_source': 'dbpedia', 'fact': ['cart', 'belong to', 'animal powered transport'], 'question_id': '3567'}, '1203': {'fact_surface': '[[wii]] belongs to the category of [[Nintendo hardware]]', 'answer': 'wii', 'question': 'Which object in this image belongs to the category Nintendo hardware?', 'img_file': 'COCO_val2014_000000112065.jpg', 'kb_source': 'dbpedia', 'fact': ['wii', 'belong to', 'nintendo hardware'], 'question_id': '3564'}, '1204': {'fact_surface': '[[wii]] belongs to the category of [[Wii hardware]]', 'answer': 'wii', 'question': 'Which object in this image held by the person in the middle belongs to the category Wii hardware?', 'img_file': 'COCO_val2014_000000112065.jpg', 'kb_source': 'dbpedia', 'fact': ['wii', 'belong to', 'wii hardware'], 'question_id': '3565'}, '1205': {'fact_surface': '[[fencing]] is for [[marking a boundary]]', 'answer': 'fence', 'question': 'Which object in this image is used for mark boundary?', 'img_file': 'COCO_val2014_000000104002.jpg', 'kb_source': 'conceptnet', 'fact': ['fence', 'used for', 'mark boundary'], 'question_id': '2903'}, '1206': {'fact_surface': 'The family of [[cow]] is [[Bovidae]]', 'answer': 'bovidae', 'question': 'What is the family of the animal in this image?', 'img_file': 'COCO_val2014_000000104002.jpg', 'kb_source': 'dbpedia', 'fact': ['cattle', 'animal family', 'bovidae'], 'question_id': '2902'}, '1207': {'fact_surface': '[[bamboo]] is related to [[grass]]', 'answer': 'grass', 'question': 'What thing in this image is related to bamboo?', 'img_file': 'ILSVRC2012_test_00054446.JPEG', 'kb_source': 'conceptnet', 'fact': ['bamboo', 'related to', 'grass'], 'question_id': '2901'}, '1208': {'fact_surface': '[[motorcycle]] are so much lighter than [[car]]', 'answer': 'motorcycle', 'question': 'Which vehicle in this photo is lighter?', 'img_file': 'COCO_val2014_000000146701.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'light', 'car'], 'question_id': '708'}, '1209': {'fact_surface': '[[Chairs]] can be [[placed around a table]]', 'answer': 'chair', 'question': 'What are the blue things around the tables?', 'img_file': 'COCO_val2014_000000127050.jpg', 'kb_source': 'conceptnet', 'fact': ['chair', 'receives action', 'place around table'], 'question_id': '709'}, '1210': {'fact_surface': '[[a person]] wants to [[have money to buy chocolate]]', 'answer': 'person', 'question': 'What thing in this image desires to have money to buy chocolate?', 'img_file': 'COCO_val2014_000000136908.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'have money to buy chocolate'], 'question_id': '2905'}, '1211': {'fact_surface': 'You can use [[a saxophone]] to [[play jazz]]', 'answer': 'saxophone', 'question': 'Which thing is used to play jazz?', 'img_file': 'ILSVRC2012_test_00001600.JPEG', 'kb_source': 'conceptnet', 'fact': ['saxophone', 'used for', 'play jazz'], 'question_id': '705'}, '1212': {'fact_surface': 'You are likely to find [[a sink]] in [[a bathroom]]', 'answer': 'sink', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000104837.jpg', 'kb_source': 'conceptnet', 'fact': ['sink', 'at location', 'bathroom'], 'question_id': '2486'}, '1213': {'fact_surface': '[[Zebras]] have [[stripes]]', 'answer': 'stripe', 'question': 'What thing does the animal in this image have as a part?', 'img_file': 'COCO_val2014_000000010822.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'stripe'], 'question_id': '5318'}, '1214': {'fact_surface': '[[Zebras]] have [[stripes]]', 'answer': 'stripe', 'question': 'What thing does the animal in this image have as a part?', 'img_file': 'COCO_val2014_000000010822.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'stripe'], 'question_id': '5313'}, '1215': {'fact_surface': '[[Zebras]] have [[stripes]]', 'answer': 'zebra', 'question': 'What in this image has stripes?', 'img_file': 'COCO_val2014_000000010822.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'stripe'], 'question_id': '5312'}, '1216': {'fact_surface': '[[Zebras]] have [[stripes]]', 'answer': 'zebra', 'question': 'What in this image has stripes?', 'img_file': 'COCO_val2014_000000010822.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'stripe'], 'question_id': '5311'}, '1217': {'fact_surface': '[[zebras]] are [[black and white]].', 'answer': 'zebra', 'question': 'Which object in this image is black and white?', 'img_file': 'COCO_val2014_000000010822.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has property', 'black and white'], 'question_id': '5310'}, '1218': {'fact_surface': '[[Zebras]] have [[stripes]]', 'answer': 'stripe', 'question': 'What thing does the animal in this image have as a part?', 'img_file': 'COCO_val2014_000000010822.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'stripe'], 'question_id': '5317'}, '1219': {'fact_surface': '[[Zebras]] have [[stripes]]', 'answer': 'stripe', 'question': 'What thing does the animal in this image have as a part?', 'img_file': 'COCO_val2014_000000010822.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'stripe'], 'question_id': '5316'}, '1220': {'fact_surface': '[[Zebras]] have [[stripes]]', 'answer': 'stripe', 'question': 'What thing does the animal in this image have as a part?', 'img_file': 'COCO_val2014_000000010822.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'stripe'], 'question_id': '5315'}, '1221': {'fact_surface': '[[Zebras]] have [[stripes]]', 'answer': 'stripe', 'question': 'What thing does the animal in this image have as a part?', 'img_file': 'COCO_val2014_000000010822.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'stripe'], 'question_id': '5314'}, '1222': {'fact_surface': '[[bathroom]] has [[toilet]].', 'answer': 'toilet', 'question': 'What does this place contain?', 'img_file': 'COCO_val2014_000000104837.jpg', 'kb_source': 'conceptnet', 'fact': ['toilet', 'part of', 'bathroom'], 'question_id': '2487'}, '1223': {'fact_surface': '[[a tennis ball]] is [[a sphere]]', 'answer': 'tennis ball', 'question': 'Which object in this image is a sphere?', 'img_file': 'COCO_val2014_000000138180.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis ball', 'is a', 'sphere'], 'question_id': '3214'}, '1224': {'fact_surface': '[[hippopotamus]] belongs to the category of [[Megafauna]]', 'answer': 'hippopotamus', 'question': 'Which object in this image belongs to the category of Megafauna?', 'img_file': 'ILSVRC2012_test_00002904.JPEG', 'kb_source': 'dbpedia', 'fact': ['hippopotamus', 'belong to', 'megafauna'], 'question_id': '3153'}, '1225': {'fact_surface': '[[Motorcycles]] have [[2 wheels]]', 'answer': 'motorcycle', 'question': 'Which object in this image has two wheels?', 'img_file': 'COCO_val2014_000000101172.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'has a', '2 wheel'], 'question_id': '3157'}, '1226': {'fact_surface': '[[a helmet]] is used to [[protect your head]]', 'answer': 'helmet', 'question': 'Which object in this image is used to protect the head?', 'img_file': 'COCO_val2014_000000101172.jpg', 'kb_source': 'conceptnet', 'fact': ['helmet', 'used for', 'protect your head'], 'question_id': '3156'}, '1227': {'fact_surface': '[[iPod]] belongs to the category of [[ITunes]]', 'answer': 'ipod', 'question': 'What object is related to iTunes?', 'img_file': 'ILSVRC2012_test_00023514.JPEG', 'kb_source': 'dbpedia', 'fact': ['ipod', 'belong to', 'itunes'], 'question_id': '3155'}, '1228': {'fact_surface': '[[iPod]] belongs to the category of [[Digital audio players]]', 'answer': 'ipod', 'question': 'Which object in this image a digital audio player?', 'img_file': 'ILSVRC2012_test_00023514.JPEG', 'kb_source': 'dbpedia', 'fact': ['ipod', 'belong to', 'digital audio players'], 'question_id': '3154'}, '1229': {'fact_surface': '[[traffic light]] can [[stop cars]]', 'answer': 'traffic light', 'question': 'Which object in this image can stop cars?', 'img_file': 'COCO_val2014_000000100087.jpg', 'kb_source': 'conceptnet', 'fact': ['traffic light', 'capable of', 'stop car'], 'question_id': '1982'}, '1230': {'fact_surface': '[[motorcycle]] is used for [[riding]].', 'answer': 'motorcycle', 'question': 'Which object in this image is used for a ride?', 'img_file': 'COCO_val2014_000000101172.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'used for', 'ride'], 'question_id': '3158'}, '1231': {'fact_surface': '[[a sofa]] that [[turns into a bed]]', 'answer': 'sofa', 'question': 'Which object in this image is capable of change to bed?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'capable of', 'turn into bed'], 'question_id': '1260'}, '1232': {'fact_surface': '[[A cat]] wants to [[nap]]', 'answer': 'cat', 'question': 'Which object in this image wants to nap?', 'img_file': 'COCO_val2014_000000119233.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'desires', 'nap'], 'question_id': '2482'}, '1233': {'fact_surface': '[[The floor]] is part of [[a room]]', 'answer': 'room', 'question': 'Which thing does the place shown in this image have as a part?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['floor', 'part of', 'room'], 'question_id': '1266'}, '1234': {'fact_surface': '[[oranges]] are [[full of vitamin C]]', 'answer': 'vitamin c', 'question': 'What kind of vitamin does the fruit in the image contain?', 'img_file': 'ILSVRC2012_test_00022357.JPEG', 'kb_source': 'conceptnet', 'fact': ['orange', 'has property', 'vitamin c'], 'question_id': '568'}, '1235': {'fact_surface': '[[lipstick]] belongs to the category of [[Cosmetics]]', 'answer': 'lipstick', 'question': 'what object in this image is a cosmetic placed on the lips?', 'img_file': 'ILSVRC2012_test_00045533.JPEG', 'kb_source': 'dbpedia', 'fact': ['lipstick', 'belong to', 'cosmetics'], 'question_id': '569'}, '1236': {'fact_surface': '[[a computer]] is [[complicated]].', 'answer': 'computer', 'question': 'Which object in this image is the most complicated', 'img_file': 'COCO_val2014_000000137573.jpg', 'kb_source': 'conceptnet', 'fact': ['computer', 'has property', 'complicate'], 'question_id': '564'}, '1237': {'fact_surface': '*Something you find [[at a internet cafe]] is [[a computer]]', 'answer': 'computer', 'question': 'Which object in this image can be found at a internet cafe', 'img_file': 'COCO_val2014_000000137573.jpg', 'kb_source': 'conceptnet', 'fact': ['computer', 'at location', 'at internet cafe'], 'question_id': '565'}, '1238': {'fact_surface': '[[A fence]] is a type of [[barrier against people or animals]]', 'answer': 'fence', 'question': 'Which object in this image is a barrier against people and the elephant?', 'img_file': 'COCO_val2014_000000017282.jpg', 'kb_source': 'conceptnet', 'fact': ['fence', 'is a', 'barrier against person or animal'], 'question_id': '4714'}, '1239': {'fact_surface': '[[elephant]] are louder than [[horse]]', 'answer': 'horse', 'question': 'What thing is less loud than the object at the centre of this image?', 'img_file': 'COCO_val2014_000000017282.jpg', 'kb_source': 'webchild', 'fact': ['elephant', 'loud', 'horse'], 'question_id': '4715'}, '1240': {'fact_surface': 'You are likely to find [[a baseball]] in [[a baseball game]]', 'answer': 'baseball', 'question': 'What object is thrown at a baseball game?', 'img_file': 'COCO_val2014_000000004736.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'at location', 'baseball game'], 'question_id': '4717'}, '1241': {'fact_surface': '[[an orange]] is [[juicy]].', 'answer': 'orange', 'question': 'Which object in this image has the property of juicy?', 'img_file': 'COCO_val2014_000000118065.jpg', 'kb_source': 'conceptnet', 'fact': ['orange', 'has property', 'juicy'], 'question_id': '4711'}, '1242': {'fact_surface': 'You are likely to find [[a snake]] in [[the woods and jungles, as well as swamps]]', 'answer': 'snake', 'question': 'Which object in this image can usually be found in wood and jungle as well as swamp?', 'img_file': 'ILSVRC2012_test_00046810.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'at location', 'wood and jungle as well as swamp'], 'question_id': '4712'}, '1243': {'fact_surface': 'You are likely to find [[a kite]] in [[a windy sky]]', 'answer': 'kite', 'question': 'Which object in this image can be found in windy sky?', 'img_file': 'COCO_val2014_000000104841.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'at location', 'windy sky'], 'question_id': '2337'}, '1244': {'fact_surface': '[[glass]] belongs to the category of [[Serving and dining]]', 'answer': 'glass', 'question': \"which object in this image belongs to the category 'service and dining?\", 'img_file': 'COCO_val2014_000000016030.jpg', 'kb_source': 'dbpedia', 'fact': ['glass', 'belong to', 'serving and dining'], 'question_id': '2338'}, '1245': {'fact_surface': '[[wine glass]] belongs to the category of [[Liquid containers]]', 'answer': 'wine glass', 'question': 'Which type of liquid container is shown in this image ?', 'img_file': 'COCO_val2014_000000016030.jpg', 'kb_source': 'dbpedia', 'fact': ['wine glass', 'belong to', 'liquid containers'], 'question_id': '2339'}, '1246': {'fact_surface': '[[chairs]] is for [[sitting in]]', 'answer': 'chair', 'question': 'Which object in this image is used for sitting in?', 'img_file': 'COCO_val2014_000000106411.jpg', 'kb_source': 'conceptnet', 'fact': ['chair', 'used for', 'sit in'], 'question_id': '1995'}, '1247': {'fact_surface': '[[knife]] belongs to the category of [[Cutting]]', 'answer': 'knife', 'question': 'Which cuttlery in this image ist used for cutting?', 'img_file': 'COCO_val2014_000000153956.jpg', 'kb_source': 'dbpedia', 'fact': ['knife', 'belong to', 'cut'], 'question_id': '3717'}, '1248': {'fact_surface': '[[baseball glove]] belongs to the category of [[Gloves]]', 'answer': 'baseball glove', 'question': 'Which object in this image is a type of glove?', 'img_file': 'ILSVRC2012_test_00048343.JPEG', 'kb_source': 'dbpedia', 'fact': ['baseball glove', 'belong to', 'glove'], 'question_id': '3710'}, '1249': {'fact_surface': '[[antelope]] belongs to the category of [[Animal]]', 'answer': 'antelope', 'question': 'Which object in this image is an animal?', 'img_file': 'ILSVRC2012_test_00002108.JPEG', 'kb_source': 'dbpedia', 'fact': ['antelope', 'belong to', 'animal'], 'question_id': '4679'}, '1250': {'fact_surface': '[[springbok]] is related to [[antelope]]', 'answer': 'antelope', 'question': 'Which object in this image is related to a springbok?', 'img_file': 'ILSVRC2012_test_00002108.JPEG', 'kb_source': 'conceptnet', 'fact': ['springbok', 'related to', 'antelope'], 'question_id': '4678'}, '1251': {'fact_surface': '[[Computers]] have [[monitors]]', 'answer': 'monitor', 'question': 'Which object in this image is a part of computer?', 'img_file': 'ILSVRC2012_test_00002371.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'has a', 'monitor'], 'question_id': '4901'}, '1252': {'fact_surface': '[[laptop]] is better than [[desktop computer]]', 'answer': 'laptop', 'question': 'which object on the left is better than desktop computer?', 'img_file': 'COCO_val2014_000000014088.jpg', 'kb_source': 'webchild', 'fact': ['laptop', 'good', 'desktop computer'], 'question_id': '4676'}, '1253': {'fact_surface': '[[dog]] is related to [[four legs]]', 'answer': 'dog', 'question': 'What shown in this image has four legs?', 'img_file': 'ILSVRC2012_test_00048526.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'related to', 'four leg'], 'question_id': '4673'}, '1254': {'fact_surface': '[[carrot]] belongs to the category of [[Edible plants]]', 'answer': 'carrot', 'question': 'what object in this image is an edible plant', 'img_file': 'COCO_val2014_000000107108.jpg', 'kb_source': 'dbpedia', 'fact': ['carrot', 'belong to', 'edible plants'], 'question_id': '120'}, '1255': {'fact_surface': '[[carrot]] belongs to the category of [[Edible plants]]', 'answer': 'carrot', 'question': 'Which object in this image is edible plant', 'img_file': 'COCO_val2014_000000107108.jpg', 'kb_source': 'dbpedia', 'fact': ['carrot', 'belong to', 'edible plants'], 'question_id': '121'}, '1256': {'fact_surface': 'A [[hammer]] is a [[tool]]', 'answer': 'hammer', 'question': 'What tool the man is holding?', 'img_file': 'ILSVRC2012_test_00008415.JPEG', 'kb_source': 'conceptnet', 'fact': ['hammer', 'is a', 'tool'], 'question_id': '124'}, '1257': {'fact_surface': '[[axe]] is related to [[chopping]]', 'answer': 'axe', 'question': 'Which object in this image is related to chopping', 'img_file': 'ILSVRC2012_test_00008415.JPEG', 'kb_source': 'conceptnet', 'fact': ['axe', 'related to', 'chop'], 'question_id': '125'}, '1258': {'fact_surface': 'Something you might find [[in a zoo]] is [[an elephant]].', 'answer': 'elephant', 'question': 'which object in this image can be found in a zoo?', 'img_file': 'COCO_val2014_000000152785.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'at location', 'in zoo'], 'question_id': '3377'}, '1259': {'fact_surface': '[[a tree]] is part of [[a forrest]]', 'answer': 'tree', 'question': 'Which object in this image is a part of forrest?', 'img_file': 'COCO_val2014_000000105622.jpg', 'kb_source': 'conceptnet', 'fact': ['tree', 'part of', 'forrest'], 'question_id': '3375'}, '1260': {'fact_surface': '[[fruits]] belongs to the category of [[Foods]]', 'answer': 'fruit', 'question': 'Which object in this image belongs to the category Foods?', 'img_file': 'ILSVRC2012_test_00023648.JPEG', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'food'], 'question_id': '5421'}, '1261': {'fact_surface': '[[A computer]] has [[a keyboard]]', 'answer': 'computer', 'question': 'Which object in this image has a keyboard', 'img_file': 'COCO_val2014_000000013659.jpg', 'kb_source': 'conceptnet', 'fact': ['computer', 'has a', 'keyboard'], 'question_id': '3372'}, '1262': {'fact_surface': '[[teddy bear]] belongs to the category of [[Toy animals]]', 'answer': 'teddy bear', 'question': 'What toy animal is in the image?', 'img_file': 'COCO_val2014_000000134688.jpg', 'kb_source': 'dbpedia', 'fact': ['teddy bear', 'belong to', 'toy animals'], 'question_id': '3371'}, '1263': {'fact_surface': '[[a refrigerator]] is used for [[chilling food]]', 'answer': 'refrigerator', 'question': 'Which object in this image is used for chilling food?', 'img_file': 'ILSVRC2012_test_00054961.JPEG', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'used for', 'chill food'], 'question_id': '2306'}, '1264': {'fact_surface': 'You are likely to find [[people]] in [[room]].', 'answer': 'person', 'question': 'What is often found in this place?', 'img_file': 'ILSVRC2012_test_00020083.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'at location', 'room'], 'question_id': '1514'}, '1265': {'fact_surface': '[[A horse]] is [[a horse of course]]', 'answer': 'horse', 'question': 'Which object in this image is a horse of course?', 'img_file': 'COCO_val2014_000000104691.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'is a', 'horse of course'], 'question_id': '3395'}, '1266': {'fact_surface': '[[a helmet]] can [[protect a head from impact]]', 'answer': 'helmet', 'question': 'Which object in this image can protect a head from impact?', 'img_file': 'COCO_val2014_000000104691.jpg', 'kb_source': 'conceptnet', 'fact': ['helmet', 'capable of', 'protect head from impact'], 'question_id': '3394'}, '1267': {'fact_surface': '[[horses]] can [[carry people]]', 'answer': 'horse', 'question': 'What animal in this image is carrying person?', 'img_file': 'COCO_val2014_000000104691.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'capable of', 'carry person'], 'question_id': '3397'}, '1268': {'fact_surface': '[[horses]] are [[very trainable animals]]', 'answer': 'horse', 'question': '￼Which object in this image is a very trainable animal?', 'img_file': 'COCO_val2014_000000104691.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'is a', 'very trainable animal'], 'question_id': '3396'}, '1269': {'fact_surface': '[[A frisbee]] is [[a toy that you throw]]', 'answer': 'frisbee', 'question': 'what object in this image is a toy that you throw?', 'img_file': 'COCO_val2014_000000025057.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'is a', 'toy that you throw'], 'question_id': '982'}, '1270': {'fact_surface': '[[traffic lights]] are [[coloured red, amber and green]]', 'answer': 'traffic light', 'question': 'Which object is red, amber and green?', 'img_file': 'ILSVRC2012_test_00054474.JPEG', 'kb_source': 'conceptnet', 'fact': ['traffic light', 'has property', 'colour red amber and green'], 'question_id': '980'}, '1271': {'fact_surface': '[[a boat]] can be used for [[sailing]]', 'answer': 'boat', 'question': 'Which thing in this picture is used for sailing?', 'img_file': 'ILSVRC2012_test_00013199.JPEG', 'kb_source': 'conceptnet', 'fact': ['boat', 'used for', 'sail'], 'question_id': '984'}, '1272': {'fact_surface': '[[lorry]] is related to [[truck]]', 'answer': 'truck', 'question': 'Which part in this image is related to lorry?', 'img_file': 'ILSVRC2012_test_00053268.JPEG', 'kb_source': 'conceptnet', 'fact': ['lorry', 'related to', 'truck'], 'question_id': '5087'}, '1273': {'fact_surface': '[[truck]] belongs to the category of [[Industries]]', 'answer': 'truck', 'question': 'What in this image belongs to the category Industries?', 'img_file': 'ILSVRC2012_test_00053268.JPEG', 'kb_source': 'dbpedia', 'fact': ['truck', 'belong to', 'industry'], 'question_id': '5086'}, '1274': {'fact_surface': '[[a person]] can [[give money to charity]]', 'answer': 'person', 'question': 'which object in this image can give money to charity?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'give money to charity'], 'question_id': '2671'}, '1275': {'fact_surface': '[[A person]] can [[wash his hair]]', 'answer': 'person', 'question': 'which object in this image can wash their hair?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'wash his hair'], 'question_id': '2670'}, '1276': {'fact_surface': 'An [[person]] can [[eat meat]].', 'answer': 'person', 'question': 'which object in this image is capable of eating meat?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'eat meat'], 'question_id': '2673'}, '1277': {'fact_surface': 'A [[person]] can [[smell]].', 'answer': 'person', 'question': 'which object in this image has a sense of smell?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'smell'], 'question_id': '2672'}, '1278': {'fact_surface': '[[People]] often [[dine with other people]]', 'answer': 'person', 'question': 'what object in this image is capable of dineing with other people?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'dine with other person'], 'question_id': '2675'}, '1279': {'fact_surface': '[[People]] sometimes [[put flowers in their hair]]', 'answer': 'person', 'question': 'which object in this image is capable of putting flowers in their hair?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'put flower in their hair'], 'question_id': '2674'}, '1280': {'fact_surface': '[[a person]] can [[step over a sleeping cat]]', 'answer': 'person', 'question': 'which object in this image is capable of stepping over a sleeping cat?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'step over sleep cat'], 'question_id': '2677'}, '1281': {'fact_surface': '[[people]] can [[make tools]]', 'answer': 'person', 'question': 'what object in this image is capable of making tools?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'make tool'], 'question_id': '2676'}, '1282': {'fact_surface': '[[people]] can [[dance by themselves]]', 'answer': 'person', 'question': 'which object in this image can dance by themselves?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'dance by themselves'], 'question_id': '2679'}, '1283': {'fact_surface': '[[A person]] can [[throw a party]]', 'answer': 'person', 'question': 'what object in this image can throw a party?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'throw party'], 'question_id': '2678'}, '1284': {'fact_surface': 'A [[keyboard]] is a [[input device for a computer]]', 'answer': 'keyboard', 'question': 'Which object in this image is used as a input device for computer?', 'img_file': 'ILSVRC2012_test_00036774.JPEG', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'is a', 'input device for computer'], 'question_id': '2921'}, '1285': {'fact_surface': 'You are likely to find [[a printer]] in [[a home office]]', 'answer': 'printer', 'question': 'What can be found in this place?', 'img_file': 'ILSVRC2012_test_00036774.JPEG', 'kb_source': 'conceptnet', 'fact': ['printer', 'at location', 'home office'], 'question_id': '2920'}, '1286': {'fact_surface': 'A [[keyboard]] is a [[input device for a computer]]', 'answer': 'keyboard', 'question': 'Which object in this image is used as a input device for computer?', 'img_file': 'ILSVRC2012_test_00036774.JPEG', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'is a', 'input device for computer'], 'question_id': '2923'}, '1287': {'fact_surface': 'A [[keyboard]] is a [[input device for a computer]]', 'answer': 'keyboard', 'question': 'Which object in this image is used as a input device for computer?', 'img_file': 'ILSVRC2012_test_00036774.JPEG', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'is a', 'input device for computer'], 'question_id': '2922'}, '1288': {'fact_surface': 'A [[keyboard]] is a [[input device for a computer]]', 'answer': 'keyboard', 'question': 'Which object in this image is used as a input device for computer?', 'img_file': 'ILSVRC2012_test_00036774.JPEG', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'is a', 'input device for computer'], 'question_id': '2924'}, '1289': {'fact_surface': '[[People]] usually have [[five fingers on each hand]]', 'answer': 'person', 'question': 'which object in this image usually has five fingers on each hand?', 'img_file': 'ILSVRC2012_test_00031868.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'has a', 'five finger on each hand'], 'question_id': '5331'}, '1290': {'fact_surface': '[[People]] can [[experience pain]]', 'answer': 'person', 'question': 'which objects in this image can experience pain?', 'img_file': 'ILSVRC2012_test_00031868.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'experience pain'], 'question_id': '5330'}, '1291': {'fact_surface': '[[A person]] has [[four grandparents]]', 'answer': 'person', 'question': 'which object in this image has four grandparents?', 'img_file': 'ILSVRC2012_test_00031868.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'has a', 'four grandparent'], 'question_id': '5333'}, '1292': {'fact_surface': '[[a person]] can [[smell smells]]', 'answer': 'person', 'question': 'which object in this image is capable of smell?', 'img_file': 'ILSVRC2012_test_00031868.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'smell smell'], 'question_id': '5332'}, '1293': {'fact_surface': '[[horses]] can be used to [[ride on]]', 'answer': 'horse', 'question': 'Which animal in this image can be ride on?', 'img_file': 'COCO_val2014_000000018654.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'used for', 'ride on'], 'question_id': '5335'}, '1294': {'fact_surface': '[[An axe]] can [[hurt people]]', 'answer': 'axe', 'question': 'Which object in this image can be used for hurt person?', 'img_file': 'ILSVRC2012_test_00048011.JPEG', 'kb_source': 'conceptnet', 'fact': ['axe', 'capable of', 'hurt person'], 'question_id': '3179'}, '1295': {'fact_surface': '[[sunglasses]] belongs to the category of [[Eyewear]]', 'answer': 'sunglasses', 'question': 'Which object in this image belongs to the category Eyewear?', 'img_file': 'ILSVRC2012_test_00007894.JPEG', 'kb_source': 'dbpedia', 'fact': ['sunglasses', 'belong to', 'eyewear'], 'question_id': '3178'}, '1296': {'fact_surface': '[[frisbee]] belongs to the category of [[Sports]]', 'answer': 'frisbee', 'question': 'Which object in this image is related to the category Sports?', 'img_file': 'COCO_val2014_000000108130.jpg', 'kb_source': 'dbpedia', 'fact': ['frisbee', 'belong to', 'sport'], 'question_id': '2037'}, '1297': {'fact_surface': '[[lamp]] belongs to the category of [[Light sources]]', 'answer': 'lamp', 'question': 'What object in this image can be used as light source?', 'img_file': 'COCO_val2014_000000108853.jpg', 'kb_source': 'dbpedia', 'fact': ['light fixture', 'belong to', 'lamp'], 'question_id': '3177'}, '1298': {'fact_surface': '[[teddy bears]] are [[a popular toy]]', 'answer': 'teddy bear', 'question': 'What is the name of the popular toy shown in this image', 'img_file': 'COCO_val2014_000000100604.jpg', 'kb_source': 'conceptnet', 'fact': ['teddy bear', 'is a', 'popular toy'], 'question_id': '726'}, '1299': {'fact_surface': '[[Turtles]] can [[live to be 200 years old]]', 'answer': 'turtle', 'question': 'Which animal in this image can live to be 200 years old', 'img_file': 'ILSVRC2012_test_00034257.JPEG', 'kb_source': 'conceptnet', 'fact': ['turtle', 'capable of', 'live to be 200 year old'], 'question_id': '724'}, '1300': {'fact_surface': '[[Turtles]] have [[long lives]]', 'answer': 'turtle', 'question': 'Who has the longest lives in the image?', 'img_file': 'ILSVRC2012_test_00034257.JPEG', 'kb_source': 'conceptnet', 'fact': ['turtle', 'has a', 'long life'], 'question_id': '725'}, '1301': {'fact_surface': '[[turtle]] is related to [[slow mover]]', 'answer': 'turtle', 'question': \"Which animal in this image is called 'slow mover'\", 'img_file': 'ILSVRC2012_test_00034257.JPEG', 'kb_source': 'conceptnet', 'fact': ['turtle', 'related to', 'slow mover'], 'question_id': '722'}, '1302': {'fact_surface': '[[a turtle]] can [[hide in its shell]]', 'answer': 'turtle', 'question': 'Which species that can be found in this image can hide in its shell', 'img_file': 'ILSVRC2012_test_00034257.JPEG', 'kb_source': 'conceptnet', 'fact': ['turtle', 'capable of', 'hide in it shell'], 'question_id': '723'}, '1303': {'fact_surface': '[[A turtle]] has [[a hard shell]]', 'answer': 'turtle', 'question': 'What is the name of the animal that has a hard shell', 'img_file': 'ILSVRC2012_test_00034257.JPEG', 'kb_source': 'conceptnet', 'fact': ['turtle', 'has a', 'hard shell'], 'question_id': '721'}, '1304': {'fact_surface': '[[hot dogs]] are often [[refered to as mystery meat]]', 'answer': 'hot dog', 'question': \"Which food in this image is sometimes called 'mystery meat'?\", 'img_file': 'COCO_val2014_000000007961.jpg', 'kb_source': 'conceptnet', 'fact': ['hot dog', 'is a', 'refer to as mystery meat'], 'question_id': '728'}, '1305': {'fact_surface': '[[person]] wants [[professional satisfaction]]', 'answer': 'person', 'question': 'Which object in this image desires professional satisfaction?', 'img_file': 'COCO_val2014_000000126974.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'professional satisfaction'], 'question_id': '1160'}, '1306': {'fact_surface': '[[laptop]] belongs to the category of [[Personal computing]]', 'answer': 'laptop', 'question': 'Which object in this image is for Personal computing?', 'img_file': 'COCO_val2014_000000126974.jpg', 'kb_source': 'dbpedia', 'fact': ['laptop', 'belong to', 'personal computing'], 'question_id': '1161'}, '1307': {'fact_surface': '[[Mountains]] have [[snow all the year long]]', 'answer': 'mountain', 'question': 'Which object in this image have snow all the year long?', 'img_file': 'COCO_val2014_000000109889.jpg', 'kb_source': 'conceptnet', 'fact': ['mountain', 'has a', 'snow all year long'], 'question_id': '1169'}, '1308': {'fact_surface': '[[an elephant]] has [[a long nose called \"trunk\"]]', 'answer': 'elephant', 'question': 'Which object in this image has a long nose?', 'img_file': 'COCO_val2014_000000011340.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'has a', 'long nose call trunk'], 'question_id': '2035'}, '1309': {'fact_surface': '[[elephants]] are [[very big]]', 'answer': 'elephant', 'question': 'Which object in this image is very big?', 'img_file': 'COCO_val2014_000000011340.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'has property', 'very big'], 'question_id': '2034'}, '1310': {'fact_surface': '[[cat]] are less loyal than [[dog]]', 'answer': 'dog', 'question': 'which object in this image is more loyal than cat?', 'img_file': 'COCO_val2014_000000145815.jpg', 'kb_source': 'webchild', 'fact': ['cat', 'loyal', 'dog'], 'question_id': '1362'}, '1311': {'fact_surface': '[[car]] were faster than [[motorcycle]]', 'answer': 'motorcycle', 'question': 'which object in this image is slower than car?', 'img_file': 'COCO_val2014_000000104647.jpg', 'kb_source': 'webchild', 'fact': ['car', 'fast', 'motorcycle'], 'question_id': '2785'}, '1312': {'fact_surface': '[[vegetables]] belongs to the category of [[Foods]]', 'answer': 'vegetable', 'question': 'What type of food is that on the right side of the plate ?', 'img_file': 'COCO_val2014_000000136795.jpg', 'kb_source': 'dbpedia', 'fact': ['vegetable', 'belong to', 'food'], 'question_id': '1713'}, '1313': {'fact_surface': '[[Dogs]] like to [[catch things]]', 'answer': 'dog', 'question': 'Which animal in this image likes to catch things?', 'img_file': 'COCO_val2014_000000145815.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'desires', 'catch thing'], 'question_id': '1360'}, '1314': {'fact_surface': '[[bicycle]] has [[wheels]].', 'answer': 'bicycle', 'question': 'Which object in this image has two wheels?', 'img_file': 'COCO_val2014_000000011340.jpg', 'kb_source': 'conceptnet', 'fact': ['wheel', 'part of', 'bicycle'], 'question_id': '2033'}, '1315': {'fact_surface': '[[car]] are bigger than [[motorcycle]]', 'answer': 'motorcycle', 'question': 'which object in this image is smaller than car?', 'img_file': 'COCO_val2014_000000104647.jpg', 'kb_source': 'webchild', 'fact': ['car', 'big', 'motorcycle'], 'question_id': '2784'}, '1316': {'fact_surface': 'A [[airplane]] can [[go fast]].', 'answer': 'airplane', 'question': 'Which object in this image can go very fast?', 'img_file': 'COCO_val2014_000000145921.jpg', 'kb_source': 'conceptnet', 'fact': ['airplane', 'capable of', 'go fast'], 'question_id': '1716'}, '1317': {'fact_surface': '[[elephants]] are [[very big]]', 'answer': 'elephant', 'question': 'What is the big animal in the image?', 'img_file': 'COCO_val2014_000000011340.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'has property', 'very big'], 'question_id': '2032'}, '1318': {'fact_surface': 'An activity [[a cat]] can do is [[meow]]', 'answer': 'cat', 'question': \"which object in this image can 'meow'?\", 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'meow'], 'question_id': '5255'}, '1319': {'fact_surface': '[[zebras]] are [[black and white]].', 'answer': 'zebra', 'question': 'What shown here is black and white?', 'img_file': 'COCO_val2014_000000013948.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has property', 'black and white'], 'question_id': '1719'}, '1320': {'fact_surface': '[[airplane]] is an instance of [[transportation-topic]]', 'answer': 'airplane', 'question': 'Which transportation topic is shown in this image?', 'img_file': 'COCO_val2014_000000145921.jpg', 'kb_source': 'conceptnet', 'fact': ['airplane', 'is a', 'transportation topic'], 'question_id': '1718'}, '1321': {'fact_surface': '[[motorcycle]] are far more dangerous than [[car]]', 'answer': 'motorcycle', 'question': 'which object in this image is more dangerous than car?', 'img_file': 'COCO_val2014_000000104647.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'dangerous', 'car'], 'question_id': '2786'}, '1322': {'fact_surface': '[[a refrigerator]] is used for [[cooling drinks]]', 'answer': 'refrigerator', 'question': 'Which object in this image is capcable of cooling drinks?', 'img_file': 'COCO_val2014_000000121904.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'used for', 'cool drink'], 'question_id': '1868'}, '1323': {'fact_surface': '[[a banjo]] is for [[playing a song]]', 'answer': 'banjo', 'question': 'Which object in this image is used for playing songs?', 'img_file': 'ILSVRC2012_test_00029629.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'used for', 'play song'], 'question_id': '4931'}, '1324': {'fact_surface': 'A [[shelf]] is a [[flat place to store items]]', 'answer': 'shelf', 'question': 'Which object in this image is a flat place to store items?', 'img_file': 'ILSVRC2012_test_00027951.JPEG', 'kb_source': 'conceptnet', 'fact': ['shelf', 'is a', 'flat place to store item'], 'question_id': '4934'}, '1325': {'fact_surface': '[[Pizza]] is [[a favorite food of many]]', 'answer': 'pizza', 'question': 'Which object in this image is a favorite food of many?', 'img_file': 'COCO_val2014_000000018150.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'is a', 'favorite food of many'], 'question_id': '4732'}, '1326': {'fact_surface': '[[crust]] is related to [[pizza]]', 'answer': 'pizza', 'question': 'Which object in this image has a crust?', 'img_file': 'COCO_val2014_000000018150.jpg', 'kb_source': 'conceptnet', 'fact': ['crust', 'related to', 'pizza'], 'question_id': '4733'}, '1327': {'fact_surface': '[[Horses]] are sometimes [[used for travel]]', 'answer': 'horse', 'question': 'Which animal in this image is also used to travel?', 'img_file': 'COCO_val2014_000000102672.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'has property', 'use for travel'], 'question_id': '4730'}, '1328': {'fact_surface': '[[Cheese]] is part of [[a pizza]]', 'answer': 'pizza', 'question': 'What thing in this image might have cheese on it?', 'img_file': 'COCO_val2014_000000018150.jpg', 'kb_source': 'conceptnet', 'fact': ['cheese', 'part of', 'pizza'], 'question_id': '4731'}, '1329': {'fact_surface': '[[Pizza]] is [[baked in an oven]]', 'answer': 'pizza', 'question': 'Which object in this image was baked in an oven?', 'img_file': 'COCO_val2014_000000018150.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'has property', 'bake in oven'], 'question_id': '4736'}, '1330': {'fact_surface': '[[pizza]] is often [[ordered for delivery]]', 'answer': 'pizza', 'question': 'Which object in this image can you order for delivery?', 'img_file': 'COCO_val2014_000000018150.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'has property', 'order for delivery'], 'question_id': '4737'}, '1331': {'fact_surface': '[[slime]] is related to [[snail]]', 'answer': 'nail', 'question': 'What object in this image is slimy?', 'img_file': 'ILSVRC2012_test_00000138.JPEG', 'kb_source': 'conceptnet', 'fact': ['lime', 'related to', 'nail'], 'question_id': '2318'}, '1332': {'fact_surface': '[[slug]] is related to [[snail]]', 'answer': 'nail', 'question': 'What object in this image is like a slug?', 'img_file': 'ILSVRC2012_test_00000138.JPEG', 'kb_source': 'conceptnet', 'fact': ['gastropod', 'related to', 'nail'], 'question_id': '2319'}, '1333': {'fact_surface': '[[escargot]] is related to [[snail]]', 'answer': 'nail', 'question': 'Which object in this image is related to escargot?', 'img_file': 'ILSVRC2012_test_00000138.JPEG', 'kb_source': 'conceptnet', 'fact': ['escargot', 'related to', 'nail'], 'question_id': '2316'}, '1334': {'fact_surface': '[[snails]] have [[shells]]', 'answer': 'shell', 'question': 'What does the object in the right of this image have as a part?', 'img_file': 'ILSVRC2012_test_00000138.JPEG', 'kb_source': 'conceptnet', 'fact': ['nail', 'has a', 'shell'], 'question_id': '2317'}, '1335': {'fact_surface': '[[snail]] belongs to the category of [[Molluscs]]', 'answer': 'nail', 'question': 'What object in this image is a type of mollusc?', 'img_file': 'ILSVRC2012_test_00000138.JPEG', 'kb_source': 'dbpedia', 'fact': ['nail', 'belong to', 'molluscs'], 'question_id': '2314'}, '1336': {'fact_surface': '[[snails]] are [[hermaphrodites]]', 'answer': 'nail', 'question': 'Which object in this image is a hermaphrodite?', 'img_file': 'ILSVRC2012_test_00000138.JPEG', 'kb_source': 'conceptnet', 'fact': ['nail', 'is a', 'hermaphrodite'], 'question_id': '2315'}, '1337': {'fact_surface': '[[pizza]] is a kind of [[food]].', 'answer': 'pizza', 'question': 'Which object in this image is a food?', 'img_file': 'COCO_val2014_000000024144.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'is a', 'food'], 'question_id': '5854'}, '1338': {'fact_surface': '[[Pizza]] has [[cheese on it]]', 'answer': 'pizza', 'question': 'Which object in this image  has a cheese?', 'img_file': 'COCO_val2014_000000024144.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'has a', 'cheese on it'], 'question_id': '5855'}, '1339': {'fact_surface': '[[A bicycle]] is [[fun to ride]]', 'answer': 'bicycle', 'question': 'which object in this image can we ride for fun', 'img_file': 'ILSVRC2012_test_00022593.JPEG', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'has property', 'fun to ride'], 'question_id': '5856'}, '1340': {'fact_surface': '[[tomato paste]] is related to [[pizza]]', 'answer': 'pizza', 'question': 'Which object in this image is related to tomato paste?', 'img_file': 'COCO_val2014_000000114108.jpg', 'kb_source': 'conceptnet', 'fact': ['tomato paste', 'related to', 'pizza'], 'question_id': '5850'}, '1341': {'fact_surface': '[[crust]] is related to [[pizza]]', 'answer': 'pizza', 'question': 'Which object in this image is related to crust?', 'img_file': 'COCO_val2014_000000114108.jpg', 'kb_source': 'conceptnet', 'fact': ['crust', 'related to', 'pizza'], 'question_id': '5851'}, '1342': {'fact_surface': '[[Cheese]] is part of [[a pizza]]', 'answer': 'pizza', 'question': 'Which object in this image has cheese on it?', 'img_file': 'COCO_val2014_000000114108.jpg', 'kb_source': 'conceptnet', 'fact': ['cheese', 'part of', 'pizza'], 'question_id': '5852'}, '1343': {'fact_surface': '[[Cheese]] is made with [[milk]]', 'answer': 'cheese', 'question': 'What is made with mild in this image?', 'img_file': 'COCO_val2014_000000024144.jpg', 'kb_source': 'conceptnet', 'fact': ['cheese', 'created by', 'milk'], 'question_id': '5853'}, '1344': {'fact_surface': '[[pizza]] belongs to the category of [[Italian cuisine]]', 'answer': 'pizza', 'question': 'Which object in this image belongs to Italian cuisine?', 'img_file': 'COCO_val2014_000000144959.jpg', 'kb_source': 'dbpedia', 'fact': ['pizza', 'belong to', 'italian cuisine'], 'question_id': '3770'}, '1345': {'fact_surface': '[[a harbor]] has [[a variety of boats]]', 'answer': 'boat', 'question': 'What thing does the place shown in this image have as a part?', 'img_file': 'COCO_val2014_000000020395.jpg', 'kb_source': 'conceptnet', 'fact': ['harbor', 'has a', 'boat'], 'question_id': '3776'}, '1346': {'fact_surface': 'You are likely to find [[a kitchen]] in [[a restaurant]]', 'answer': 'restaurant', 'question': 'where can you find the the place shown in this image', 'img_file': 'COCO_val2014_000000124707.jpg', 'kb_source': 'conceptnet', 'fact': ['kitchen', 'at location', 'restaurant'], 'question_id': '3775'}, '1347': {'fact_surface': 'An activity [[people]] can do is [[love]].', 'answer': 'person', 'question': 'Which object in this image is capable of love?', 'img_file': 'ILSVRC2012_test_00001022.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'love'], 'question_id': '3778'}, '1348': {'fact_surface': '[[refrigerator]] is related to [[chill]]', 'answer': 'refrigerator', 'question': 'Which object in this image is used to chill?', 'img_file': 'COCO_val2014_000000104790.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'related to', 'chill'], 'question_id': '4654'}, '1349': {'fact_surface': '[[bird]] is related to [[flying]]', 'answer': 'bird', 'question': 'which object in this image can fly', 'img_file': 'ILSVRC2012_test_00049970.JPEG', 'kb_source': 'conceptnet', 'fact': ['bird', 'related to', 'fly'], 'question_id': '4657'}, '1350': {'fact_surface': '[[a stove]] can [[heat a pot]]', 'answer': 'stove', 'question': 'Which object in this image might be used to heat a pot?', 'img_file': 'COCO_val2014_000000104790.jpg', 'kb_source': 'conceptnet', 'fact': ['stove', 'capable of', 'heat pot'], 'question_id': '4656'}, '1351': {'fact_surface': '[[oven]] belongs to the category of [[Hazards]]', 'answer': 'oven', 'question': 'Which object in this image might be a hazard?', 'img_file': 'COCO_val2014_000000104790.jpg', 'kb_source': 'dbpedia', 'fact': ['oven', 'belong to', 'hazard'], 'question_id': '4651'}, '1352': {'fact_surface': 'You are likely to find [[a bus]] in [[the bus station]]', 'answer': 'bus', 'question': 'What are the objects found in bus station?', 'img_file': 'COCO_val2014_000000144251.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'at location', 'bus station'], 'question_id': '4650'}, '1353': {'fact_surface': 'You can use [[a stove]] to [[grill a steak]]', 'answer': 'stove', 'question': 'Which object in this image might be used to grill a steak?', 'img_file': 'COCO_val2014_000000104790.jpg', 'kb_source': 'conceptnet', 'fact': ['stove', 'used for', 'grill steak'], 'question_id': '4653'}, '1354': {'fact_surface': '[[cake]] is related to [[oven]]', 'answer': 'oven', 'question': 'Which object in this image might be used to make cake?', 'img_file': 'COCO_val2014_000000104790.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'related to', 'oven'], 'question_id': '4652'}, '1355': {'fact_surface': '[[alcohol]] is less dense than [[water]]', 'answer': 'water', 'question': 'which liquid in this image is denser than alcohol?', 'img_file': 'ILSVRC2012_test_00049970.JPEG', 'kb_source': 'webchild', 'fact': ['alcohol', 'dense', 'water'], 'question_id': '4658'}, '1356': {'fact_surface': '[[a refrigerator]] is used for [[chilling drinks]]', 'answer': 'refrigerator', 'question': 'Which will you select for chilling drinks', 'img_file': 'COCO_val2014_000000000802.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'used for', 'chill drink'], 'question_id': '108'}, '1357': {'fact_surface': '[[pineapple]] is related to [[peel]]', 'answer': 'peel', 'question': 'What is on the surface of the fruit in the image?', 'img_file': 'ILSVRC2012_test_00044733.JPEG', 'kb_source': 'conceptnet', 'fact': ['pineapple', 'related to', 'peel'], 'question_id': '109'}, '1358': {'fact_surface': '[[an oven]] can be used for [[cooking]]', 'answer': 'oven', 'question': 'Which object in this image is used for cooking', 'img_file': 'COCO_val2014_000000000802.jpg', 'kb_source': 'conceptnet', 'fact': ['oven', 'used for', 'cook'], 'question_id': '103'}, '1359': {'fact_surface': '[[refrigerator]] is for [[store food]].', 'answer': 'refrigerator', 'question': 'What thing in this image is used for storing food', 'img_file': 'COCO_val2014_000000000802.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'used for', 'store food'], 'question_id': '106'}, '1360': {'fact_surface': 'You can use [[refrigerator]] to [[keep food fresh]].', 'answer': 'refrigerator', 'question': 'Which appliance in this image will you use to keep food fresh', 'img_file': 'COCO_val2014_000000000802.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'used for', 'keep food fresh'], 'question_id': '107'}, '1361': {'fact_surface': '[[an oven]] can be used for [[cooking]]', 'answer': 'cooking', 'question': 'What is the left white object used for?', 'img_file': 'COCO_val2014_000000000802.jpg', 'kb_source': 'conceptnet', 'fact': ['oven', 'used for', 'cooking'], 'question_id': '104'}, '1362': {'fact_surface': '[[a refrigerator]] is used for [[chilling food]]', 'answer': 'refrigerator', 'question': 'Which object in this image is utilized to chill food', 'img_file': 'COCO_val2014_000000000802.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'used for', 'chill food'], 'question_id': '105'}, '1363': {'fact_surface': '[[People]] sometimes [[talk to plants]]', 'answer': 'person', 'question': 'Which object in this image is capable of talking to a plant?', 'img_file': 'ILSVRC2012_test_00021218.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'talk to plant'], 'question_id': '1759'}, '1364': {'fact_surface': '[[Cucumber]] is [[a cool, crisp vegetable]]', 'answer': 'cucumber', 'question': 'What cool, crisp vegetable can you see here?', 'img_file': 'ILSVRC2012_test_00021218.JPEG', 'kb_source': 'conceptnet', 'fact': ['cucumber', 'is a', 'cool crisp vegetable'], 'question_id': '1758'}, '1365': {'fact_surface': '[[a person]] wants to [[follow his heart]]', 'answer': 'person', 'question': 'which object in this image often want to do what they think', 'img_file': 'ILSVRC2012_test_00028994.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'follow his heart'], 'question_id': '1756'}, '1366': {'fact_surface': '*Something you find in [[the water]] is [[a whale]]', 'answer': 'whale', 'question': 'Which animal in this image can be found in water?', 'img_file': 'ILSVRC2012_test_00018705.JPEG', 'kb_source': 'conceptnet', 'fact': ['whale', 'at location', 'water'], 'question_id': '1751'}, '1367': {'fact_surface': '[[a whale]] is [[a mamal]]', 'answer': 'whale', 'question': 'Which object in this image is a mammal?', 'img_file': 'ILSVRC2012_test_00018705.JPEG', 'kb_source': 'conceptnet', 'fact': ['whale', 'is a', 'mamal'], 'question_id': '1750'}, '1368': {'fact_surface': '[[cat]] can be much more independent than [[dog]]', 'answer': 'dog', 'question': 'What thing is less independent than the object in the centre of this image?', 'img_file': 'COCO_val2014_000000000599.jpg', 'kb_source': 'webchild', 'fact': ['cat', 'independent', 'dog'], 'question_id': '1285'}, '1369': {'fact_surface': \"You are likely to find [[a cat]] in [[a catlover's home]]\", 'answer': 'cat', 'question': \"What are you likely to find in a catlover's home ?\", 'img_file': 'COCO_val2014_000000000599.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'at location', \"catlover's home\"], 'question_id': '1284'}, '1370': {'fact_surface': '[[remote]] belongs to the category of [[Television]]', 'answer': 'remote', 'question': 'What object is related to television?', 'img_file': 'COCO_val2014_000000000599.jpg', 'kb_source': 'dbpedia', 'fact': ['remote', 'belong to', 'television'], 'question_id': '1286'}, '1371': {'fact_surface': '[[Skateboards]] have [[ball bearings]]', 'answer': 'skateboard', 'question': 'Which object in this image has ball bearings?', 'img_file': 'COCO_val2014_000000012817.jpg', 'kb_source': 'conceptnet', 'fact': ['skateboard', 'has a', 'ball bear'], 'question_id': '1281'}, '1372': {'fact_surface': '[[police]] can [[tail a criminal]]', 'answer': 'police', 'question': 'What in this image is capable of tailing a criminal?', 'img_file': 'COCO_val2014_000000102461.jpg', 'kb_source': 'conceptnet', 'fact': ['police', 'capable of', 'tail criminal'], 'question_id': '1280'}, '1373': {'fact_surface': \"You are likely to find [[a cat]] in [[a catlover's home]]\", 'answer': 'cat', 'question': \"What are you likely to find in a catlover's home ?\", 'img_file': 'COCO_val2014_000000000599.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'at location', \"catlover's home\"], 'question_id': '1283'}, '1374': {'fact_surface': '[[plates]] belongs to the category of [[Kitchen]]', 'answer': 'plate', 'question': 'Which object in this image belongs to the category Kitchen?', 'img_file': 'COCO_val2014_000000103496.jpg', 'kb_source': 'dbpedia', 'fact': ['plate', 'belong to', 'kitchen'], 'question_id': '1289'}, '1375': {'fact_surface': '[[harp]] is related to [[musical instrument]]', 'answer': 'harp', 'question': 'Which object in this image is a kind of musical instrument?', 'img_file': 'ILSVRC2012_test_00050462.JPEG', 'kb_source': 'conceptnet', 'fact': ['harp', 'related to', 'musical instrument'], 'question_id': '1579'}, '1376': {'fact_surface': '[[harp]] belongs to the category of [[Composite chordophones]]', 'answer': 'harp', 'question': 'Which musical instrument in this image belongs to the category Composite chordophones?', 'img_file': 'ILSVRC2012_test_00050462.JPEG', 'kb_source': 'dbpedia', 'fact': ['harp', 'belong to', 'composite chordophones'], 'question_id': '1578'}, '1377': {'fact_surface': '[[banana]] is a subclass of [[edible fruit]]', 'answer': 'banana', 'question': 'Which edible fruit is seen here?', 'img_file': 'COCO_val2014_000000008844.jpg', 'kb_source': 'conceptnet', 'fact': ['banana', 'is a', 'edible fruit'], 'question_id': '688'}, '1378': {'fact_surface': '[[truck]] are higher than [[car]]', 'answer': 'truck', 'question': 'Tell me the vehicle in this image which is usually higher than car ', 'img_file': 'COCO_val2014_000000100539.jpg', 'kb_source': 'webchild', 'fact': ['truck', 'high', 'car'], 'question_id': '681'}, '1379': {'fact_surface': '[[A power drill]] can be used to [[drive screws]]', 'answer': 'drive screw', 'question': \"What is the object in the man's left hand used for\", 'img_file': 'ILSVRC2012_test_00037171.JPEG', 'kb_source': 'conceptnet', 'fact': ['power drill', 'used for', 'drive screw'], 'question_id': '680'}, '1380': {'fact_surface': '[[boats]] can [[travel over water]]', 'answer': 'boat', 'question': 'which object in this image can be used for travelling over water', 'img_file': 'COCO_val2014_000000129175.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'capable of', 'travel over water'], 'question_id': '683'}, '1381': {'fact_surface': '[[An axe]] is normally [[used for chopping wood]]', 'answer': 'axe', 'question': 'which object in this image can we use to chop wood', 'img_file': 'ILSVRC2012_test_00008415.JPEG', 'kb_source': 'conceptnet', 'fact': ['axe', 'has property', 'use for chop wood'], 'question_id': '1574'}, '1382': {'fact_surface': '[[blanket]] belongs to the category of [[Matter]]', 'answer': 'blanket', 'question': 'Which object in this image pertain to the category Matter?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'dbpedia', 'fact': ['blanket', 'belong to', 'matter'], 'question_id': '1240'}, '1383': {'fact_surface': '[[A turtle]] can [[be a pet]]', 'answer': 'turtle', 'question': 'What kind of pet is in this image?', 'img_file': 'ILSVRC2012_test_00002369.JPEG', 'kb_source': 'conceptnet', 'fact': ['turtle', 'capable of', 'be pet'], 'question_id': '5628'}, '1384': {'fact_surface': '[[pizza]] is [[a popular food]]', 'answer': 'pizza', 'question': 'Which popular food can you see in this image?', 'img_file': 'COCO_val2014_000000101919.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'is a', 'popular food'], 'question_id': '5627'}, '1385': {'fact_surface': '[[a cat]] can [[kill birds]]', 'answer': 'cat', 'question': 'what in this image is capable of kill bird?', 'img_file': 'COCO_val2014_000000101762.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'kill bird'], 'question_id': '5626'}, '1386': {'fact_surface': '[[cat]] are generally much more sensible than [[dog]]', 'answer': 'cat', 'question': 'what in this image is sensibler than dog?', 'img_file': 'COCO_val2014_000000101762.jpg', 'kb_source': 'webchild', 'fact': ['cat', 'sensible', 'dog'], 'question_id': '5625'}, '1387': {'fact_surface': 'You are likely to find [[a cat]] in [[place]].', 'answer': 'cat', 'question': 'Which animal in this image can be found in place?', 'img_file': 'COCO_val2014_000000101762.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'at location', 'place'], 'question_id': '5624'}, '1388': {'fact_surface': '[[snow]] is [[white and cold]]', 'answer': 'snow', 'question': 'what do the person stand on?', 'img_file': 'COCO_val2014_000000015559.jpg', 'kb_source': 'conceptnet', 'fact': ['snow', 'has property', 'white and cold'], 'question_id': '5623'}, '1389': {'fact_surface': 'You are likely to find [[snow]] in [[the street]].', 'answer': 'snow', 'question': 'Where does the place in this image can be found in?', 'img_file': 'COCO_val2014_000000015559.jpg', 'kb_source': 'conceptnet', 'fact': ['snow', 'at location', 'street'], 'question_id': '5622'}, '1390': {'fact_surface': 'You are likely to find [[snow]] in [[the street]].', 'answer': 'snow', 'question': 'Where does the place in this image can be found in?', 'img_file': 'COCO_val2014_000000015559.jpg', 'kb_source': 'conceptnet', 'fact': ['snow', 'at location', 'street'], 'question_id': '5621'}, '1391': {'fact_surface': '[[An elephant]] has [[four legs]]', 'answer': 'elephant', 'question': 'which object in this image has four legs?', 'img_file': 'COCO_val2014_000000103723.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'has a', 'four leg'], 'question_id': '5620'}, '1392': {'fact_surface': '[[sofa]] belongs to the category of [[Woodworking]]', 'answer': 'sofa', 'question': 'Which object in this image pertain to the category Woodworking?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'dbpedia', 'fact': ['sofa', 'belong to', 'woodworking'], 'question_id': '1242'}, '1393': {'fact_surface': '[[a sofa]] is a kind of [[a chair]].', 'answer': 'sofa', 'question': 'Which object in this image is similar with a chair?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'is a', 'chair'], 'question_id': '1245'}, '1394': {'fact_surface': '[[sofa]] belongs to the category of [[Human habitats]]', 'answer': 'sofa', 'question': 'Which object in this image pertain the category Human habitats?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'dbpedia', 'fact': ['sofa', 'belong to', 'human habitats'], 'question_id': '1247'}, '1395': {'fact_surface': 'You are likely to find [[mustard]] in [[a hot dog]]', 'answer': 'mustard', 'question': 'What condiment does the hot dog in the middle have on it?', 'img_file': 'ILSVRC2012_test_00015545.JPEG', 'kb_source': 'conceptnet', 'fact': ['mustard', 'at location', 'hot dog'], 'question_id': '245'}, '1396': {'fact_surface': '[[pretzels]] are [[salty, knotted snacks]]', 'answer': 'pretzel', 'question': 'What salty knotted snack can be seen here?', 'img_file': 'ILSVRC2012_test_00015545.JPEG', 'kb_source': 'conceptnet', 'fact': ['pretzel', 'is a', 'salty knot snack'], 'question_id': '244'}, '1397': {'fact_surface': '[[a helmet]] is used to [[protect your head]]', 'answer': 'helmet', 'question': 'Which object is used to protect your head in this image', 'img_file': 'ILSVRC2012_test_00005133.JPEG', 'kb_source': 'conceptnet', 'fact': ['helmet', 'used for', 'protect your head'], 'question_id': '249'}, '1398': {'fact_surface': '[[mature bull]] are normally darker than [[cow]]', 'answer': 'cow', 'question': 'Which thing shown in this image is generally less dark than a mature bull?', 'img_file': 'COCO_val2014_000000111367.jpg', 'kb_source': 'webchild', 'fact': ['mature bull', 'dark', 'cow'], 'question_id': '3695'}, '1399': {'fact_surface': '[[bus lane]] is related to [[bus]]', 'answer': 'bus', 'question': 'which object in this image can travel in a bus lane?', 'img_file': 'COCO_val2014_000000001584.jpg', 'kb_source': 'conceptnet', 'fact': ['bus lane', 'related to', 'bus'], 'question_id': '3526'}, '1400': {'fact_surface': '[[bus]] belongs to the category of [[Vehicle]]', 'answer': 'bus', 'question': 'which object in this image is a type of vehicle?', 'img_file': 'COCO_val2014_000000001584.jpg', 'kb_source': 'dbpedia', 'fact': ['bus', 'belong to', 'vehicle'], 'question_id': '3527'}, '1401': {'fact_surface': 'You can use [[a bus]] to [[travel between bus stops]]', 'answer': 'bus', 'question': 'which object in this image is used for travelling between bus stops?', 'img_file': 'COCO_val2014_000000001584.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'used for', 'travel between bus stop'], 'question_id': '3524'}, '1402': {'fact_surface': 'You can use [[a bus]] to [[commute to work]]', 'answer': 'bus', 'question': 'which object in this image could you use to commute to work?', 'img_file': 'COCO_val2014_000000001584.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'used for', 'commute to work'], 'question_id': '3525'}, '1403': {'fact_surface': '[[double-decker]] is related to [[bus]]', 'answer': 'bus', 'question': \"which object in this image could be descriped as a 'double-decker'?\", 'img_file': 'COCO_val2014_000000001584.jpg', 'kb_source': 'conceptnet', 'fact': ['double decker', 'related to', 'bus'], 'question_id': '3522'}, '1404': {'fact_surface': '[[bus]] is related to [[transport]]', 'answer': 'bus', 'question': 'which object in this image is a means of transportation?', 'img_file': 'COCO_val2014_000000001584.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'related to', 'transport'], 'question_id': '3523'}, '1405': {'fact_surface': '[[bus]] belongs to the category of [[Vehicles]]', 'answer': 'bus', 'question': 'which object in this image is a type vehicle?', 'img_file': 'COCO_val2014_000000001584.jpg', 'kb_source': 'dbpedia', 'fact': ['bus', 'belong to', 'vehicle'], 'question_id': '3520'}, '1406': {'fact_surface': '[[bus]] is related to [[travel]]', 'answer': 'bus', 'question': 'which object in this image can be used to travel?', 'img_file': 'COCO_val2014_000000001584.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'related to', 'travel'], 'question_id': '3521'}, '1407': {'fact_surface': '[[tree]] is related to [[wood]]', 'answer': 'tree', 'question': 'Which objects in this image are made of wood?', 'img_file': 'COCO_val2014_000000001840.jpg', 'kb_source': 'conceptnet', 'fact': ['tree', 'related to', 'wood'], 'question_id': '3528'}, '1408': {'fact_surface': 'You can use [[a bottle]] to [[hold a drink]]', 'answer': 'bottle', 'question': 'Which object in this image can hold drink?', 'img_file': 'ILSVRC2012_test_00018771.JPEG', 'kb_source': 'conceptnet', 'fact': ['bottle', 'used for', 'hold drink'], 'question_id': '3529'}, '1409': {'fact_surface': 'You can use [[a screwdriver]] to [[tighten a loose screw]]', 'answer': 'screwdriver', 'question': 'Which object in this image is used for tighten loose screw?', 'img_file': 'COCO_val2014_000000113126.jpg', 'kb_source': 'conceptnet', 'fact': ['screwdriver', 'used for', 'tighten loose screw'], 'question_id': '1364'}, '1410': {'fact_surface': '[[a person]] can [[complete a sentence]]', 'answer': 'person', 'question': 'which object in this image is capable of completing a senence?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'complete sentence'], 'question_id': '2699'}, '1411': {'fact_surface': '[[people]] can [[taste salt]]', 'answer': 'person', 'question': 'which object in this image can taste salt?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'taste salt'], 'question_id': '2698'}, '1412': {'fact_surface': '[[People]] have [[to eat to survive]]', 'answer': 'person', 'question': 'which object in this image must eat to survive?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'has a', 'eat to survive'], 'question_id': '2697'}, '1413': {'fact_surface': '[[A person]] has [[two ears]]', 'answer': 'person', 'question': 'which object in this image has two ears?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'has a', 'two ear'], 'question_id': '2696'}, '1414': {'fact_surface': '[[a person]] can [[decide on a place to live]]', 'answer': 'person', 'question': 'which object in this image is can decide on a place to live?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'decide on place to live'], 'question_id': '2695'}, '1415': {'fact_surface': '[[a person]] can [[clean a messy room]]', 'answer': 'person', 'question': 'which object in this image can clean a messy room?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'clean messy room'], 'question_id': '2694'}, '1416': {'fact_surface': '[[a person]] can [[eat shrimp for dinner]]', 'answer': 'person', 'question': 'which object in this image can eat shrimp for dinner?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'eat shrimp for dinner'], 'question_id': '2693'}, '1417': {'fact_surface': '[[people]] have [[social gatherings]]', 'answer': 'person', 'question': 'which object in this image is capable of having social gatherings?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'has a', 'social gather'], 'question_id': '2692'}, '1418': {'fact_surface': '[[people]] can [[read books for enjoyment]]', 'answer': 'person', 'question': 'which object in this image can read books for enjoyment?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'read book for enjoyment'], 'question_id': '2691'}, '1419': {'fact_surface': '[[people]] often [[drink coffee in the morning]]', 'answer': 'person', 'question': 'what object in this image is capable of drinking coffee in the morning?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'drink coffee in morning'], 'question_id': '2690'}, '1420': {'fact_surface': '[[Dogs]] usually [[play outside]]', 'answer': 'dog', 'question': 'Which object in this image is capable of play outside?', 'img_file': 'COCO_val2014_000000145815.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'capable of', 'play outside'], 'question_id': '1361'}, '1421': {'fact_surface': '[[A cat]] has [[hair]]', 'answer': 'cat', 'question': 'Which object in this image has hair?', 'img_file': 'COCO_val2014_000000139721.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'has a', 'hair'], 'question_id': '1142'}, '1422': {'fact_surface': '[[Cats]] can [[see well in the dark]]', 'answer': 'cat', 'question': 'Which object in this image is able to see well in dark?', 'img_file': 'COCO_val2014_000000139721.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'see well in dark'], 'question_id': '1143'}, '1423': {'fact_surface': '[[a frisbee]] is for [[having fun]]', 'answer': 'frisbee', 'question': 'Which object in this image is used for playing?', 'img_file': 'COCO_val2014_000000006954.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'used for', 'have fun'], 'question_id': '1140'}, '1424': {'fact_surface': '*Something you find in [[the ocean]] is [[large waves]]', 'answer': 'wave', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000115924.jpg', 'kb_source': 'conceptnet', 'fact': ['wave', 'at location', 'ocean'], 'question_id': '1141'}, '1425': {'fact_surface': 'People use [[computers]] to [[send email to friends]]', 'answer': 'computer', 'question': 'Which object in this image is used for send email to others?', 'img_file': 'COCO_val2014_000000006608.jpg', 'kb_source': 'conceptnet', 'fact': ['computer', 'used for', 'send email to friend'], 'question_id': '1146'}, '1426': {'fact_surface': '[[computers]] can [[speed up research]]', 'answer': 'computer', 'question': 'Which object in this image is capable of accelerating research?', 'img_file': 'COCO_val2014_000000006608.jpg', 'kb_source': 'conceptnet', 'fact': ['computer', 'capable of', 'speed up research'], 'question_id': '1147'}, '1427': {'fact_surface': '[[laptop]] belongs to the category of [[Computers]]', 'answer': 'laptop', 'question': 'Which device in this image belongs to the category computers?', 'img_file': 'COCO_val2014_000000006608.jpg', 'kb_source': 'dbpedia', 'fact': ['laptop', 'belong to', 'computer'], 'question_id': '1144'}, '1428': {'fact_surface': '[[Home office]] may [[mean an office in the home]]', 'answer': 'home office', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000006608.jpg', 'kb_source': 'conceptnet', 'fact': ['home office', 'capable of', 'mean office in home'], 'question_id': '1145'}, '1429': {'fact_surface': '[[desk]] belongs to the category of [[Furniture]]', 'answer': 'desk', 'question': 'Which object in this image belongs to the category furniture?', 'img_file': 'COCO_val2014_000000006608.jpg', 'kb_source': 'dbpedia', 'fact': ['desk', 'belong to', 'furniture'], 'question_id': '1148'}, '1430': {'fact_surface': 'You are likely to find [[a monitor]] in [[an office]].', 'answer': 'monitor', 'question': 'What can be found in this room?', 'img_file': 'COCO_val2014_000000006608.jpg', 'kb_source': 'conceptnet', 'fact': ['monitor', 'at location', 'office'], 'question_id': '1149'}, '1431': {'fact_surface': '[[dog]] were more loyal than [[cat]]', 'answer': 'dog', 'question': 'Which animal in the image are more loyal?', 'img_file': 'COCO_val2014_000000022892.jpg', 'kb_source': 'webchild', 'fact': ['dog', 'loyal', 'cat'], 'question_id': '766'}, '1432': {'fact_surface': '[[cat]] are said to be more independent than [[dog]]', 'answer': 'cat', 'question': 'Which animal in the image is more independent?', 'img_file': 'COCO_val2014_000000022892.jpg', 'kb_source': 'webchild', 'fact': ['cat', 'independent', 'dog'], 'question_id': '767'}, '1433': {'fact_surface': '[[snake pit]] is related to [[snake]]', 'answer': 'snake', 'question': 'What in this image is related to snake pit?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake pit', 'related to', 'snake'], 'question_id': '4282'}, '1434': {'fact_surface': 'You are likely to find [[a snake]] in [[Louisiana]]', 'answer': 'snake', 'question': 'Which animal in this image can be found in louisiana?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'at location', 'louisiana'], 'question_id': '4283'}, '1435': {'fact_surface': 'You are likely to find [[a snake]] in [[the brush]]', 'answer': 'snake', 'question': 'What in this image can be found in brush?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'at location', 'brush'], 'question_id': '4280'}, '1436': {'fact_surface': '[[snake]] is for [[Health]].', 'answer': 'snake', 'question': 'Which object in this image is used for health cares?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'used for', 'health'], 'question_id': '4281'}, '1437': {'fact_surface': '[[snake]] can [[hurt]].', 'answer': 'snake', 'question': 'Which object in this image is dangerous?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'capable of', 'hurt'], 'question_id': '4286'}, '1438': {'fact_surface': 'You are likely to find [[a snake]] in [[india]]', 'answer': 'snake', 'question': 'Which animal in this image can be found in india?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'at location', 'india'], 'question_id': '4287'}, '1439': {'fact_surface': '[[king cobra]] is related to [[snake]]', 'answer': 'snake', 'question': 'Which object in this image is  king cobra?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['king cobra', 'related to', 'snake'], 'question_id': '4284'}, '1440': {'fact_surface': 'You are likely to find [[a snake]] in [[box]].', 'answer': 'snake', 'question': 'Which object in this image can be found in an old box?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'at location', 'box'], 'question_id': '4285'}, '1441': {'fact_surface': 'You are likely to find [[snake]] in [[a kitchen]].', 'answer': 'snake', 'question': 'Which animal in this image can be found in kitchen?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'at location', 'kitchen'], 'question_id': '4288'}, '1442': {'fact_surface': 'You are likely to find [[a snake]] in [[Kansas]]', 'answer': 'snake', 'question': 'Which animal in this image can be found in kansa?', 'img_file': 'ILSVRC2012_test_00000165.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'at location', 'kansa'], 'question_id': '4289'}, '1443': {'fact_surface': '(football,/r/UsedFor,play)', 'answer': 'play', 'question': 'What is football used for', 'img_file': 'ILSVRC2012_test_00054461.JPEG', 'kb_source': 'conceptnet', 'fact': ['football', 'used for', 'play'], 'question_id': '384'}, '1444': {'fact_surface': '[[horses]] are used to [[carry goods]]', 'answer': 'horse', 'question': 'Which thin in the image can be used for carrying goods?', 'img_file': 'COCO_val2014_000000019032.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'used for', 'carry good'], 'question_id': '385'}, '1445': {'fact_surface': '[[Horses]] are [[domestic animals]]', 'answer': 'horse', 'question': 'Tell me the name of the domestic animal in this image', 'img_file': 'COCO_val2014_000000019032.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'is a', 'domestic animal'], 'question_id': '386'}, '1446': {'fact_surface': '[[horse]] belongs to the category of [[Animals]]', 'answer': 'animal', 'question': 'What category does a horse belongs to', 'img_file': 'COCO_val2014_000000019032.jpg', 'kb_source': 'dbpedia', 'fact': ['horse', 'belong to', 'animal'], 'question_id': '387'}, '1447': {'fact_surface': '[[cake]] is related to [[weddings]]', 'answer': 'wedding', 'question': 'What is this cake for?', 'img_file': 'COCO_val2014_000000123810.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'related to', 'wedding'], 'question_id': '388'}, '1448': {'fact_surface': '[[grind]] is related to [[skateboard]]', 'answer': 'skateboard', 'question': 'Which object in this image is related to grind?', 'img_file': 'COCO_val2014_000000113095.jpg', 'kb_source': 'conceptnet', 'fact': ['grind', 'related to', 'skateboard'], 'question_id': '4750'}, '1449': {'fact_surface': '[[pinstripe]] is related to [[suit]]', 'answer': 'suit', 'question': 'Which object in this image might also be of the type pinstripe?', 'img_file': 'COCO_val2014_000000001089.jpg', 'kb_source': 'conceptnet', 'fact': ['pinstripe', 'related to', 'suit'], 'question_id': '4751'}, '1450': {'fact_surface': '[[a clock]] can be used to [[tell the time]]', 'answer': 'clock', 'question': 'Which object in this image is used for telling the time?', 'img_file': 'COCO_val2014_000000008218.jpg', 'kb_source': 'conceptnet', 'fact': ['clock', 'used for', 'tell time'], 'question_id': '4752'}, '1451': {'fact_surface': '[[clocks]] can be used to [[indicate the passage of time]]', 'answer': 'clock', 'question': 'Which object in this image indicates the passage of time?', 'img_file': 'COCO_val2014_000000008218.jpg', 'kb_source': 'conceptnet', 'fact': ['clock', 'used for', 'indicate passage of time'], 'question_id': '4753'}, '1452': {'fact_surface': '[[clocks]] have [[pointers called hands]]', 'answer': 'clock', 'question': 'Which object in this image has pointers called hands?', 'img_file': 'COCO_val2014_000000008218.jpg', 'kb_source': 'conceptnet', 'fact': ['clock', 'has a', 'pointer call hand'], 'question_id': '4754'}, '1453': {'fact_surface': '[[hour hand]] is related to [[clock]]', 'answer': 'clock', 'question': 'Which object in this image is related to hour hand?', 'img_file': 'COCO_val2014_000000008218.jpg', 'kb_source': 'conceptnet', 'fact': ['hour hand', 'related to', 'clock'], 'question_id': '4755'}, '1454': {'fact_surface': '[[The dial]] is part of [[a clock]]', 'answer': 'clock', 'question': 'Which object in this image has a dial?', 'img_file': 'COCO_val2014_000000008218.jpg', 'kb_source': 'conceptnet', 'fact': ['dial', 'part of', 'clock'], 'question_id': '4756'}, '1455': {'fact_surface': '[[watch]] is related to [[clock]]', 'answer': 'clock', 'question': 'Which object in this image is related to watch?', 'img_file': 'COCO_val2014_000000008218.jpg', 'kb_source': 'conceptnet', 'fact': ['watch', 'related to', 'clock'], 'question_id': '4757'}, '1456': {'fact_surface': '[[Guitars]] are [[fun to learn to play]]', 'answer': 'guitar', 'question': 'which object in this image are fun to learn to play', 'img_file': 'ILSVRC2012_test_00051302.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'has property', 'fun to learn to play'], 'question_id': '5872'}, '1457': {'fact_surface': '[[dogs]] are [[great pets]]', 'answer': 'dog', 'question': 'Which object in this image is a great pet?', 'img_file': 'ILSVRC2012_test_00051302.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'is a', 'great pet'], 'question_id': '5870'}, '1458': {'fact_surface': 'A [[person]] can [[smell]].', 'answer': 'person', 'question': 'which object in this picture can smell', 'img_file': 'ILSVRC2012_test_00051302.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'smell'], 'question_id': '5871'}, '1459': {'fact_surface': '[[vegetables]] belongs to the category of [[Edible plants]]', 'answer': 'vegetable', 'question': 'Which object in this image belongs to the category Edible plants?', 'img_file': 'COCO_val2014_000000116182.jpg', 'kb_source': 'dbpedia', 'fact': ['vegetable', 'belong to', 'edible plants'], 'question_id': '5876'}, '1460': {'fact_surface': '[[carrots]] are [[orange]]', 'answer': 'carrot', 'question': 'Which object in this image is orange?', 'img_file': 'COCO_val2014_000000116182.jpg', 'kb_source': 'conceptnet', 'fact': ['carrot', 'has property', 'orange'], 'question_id': '5877'}, '1461': {'fact_surface': '[[an axe]] can be used to [[chop firewood]]', 'answer': 'axe', 'question': 'What tool can be used to chop firewood?', 'img_file': 'ILSVRC2012_test_00002767.JPEG', 'kb_source': 'conceptnet', 'fact': ['axe', 'used for', 'chop firewood'], 'question_id': '5874'}, '1462': {'fact_surface': 'A [[cat]] is a [[animal that hates water but likes fish]]', 'answer': 'cat', 'question': 'Which object in this image is a animal that hate water but like fish?', 'img_file': 'COCO_val2014_000000115070.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'is a', 'animal that hate water but like fish'], 'question_id': '5875'}, '1463': {'fact_surface': '[[helmet]] belongs to the category of [[Headgear]]', 'answer': 'helmet', 'question': 'Which object in this image belongs to the category Headgear?', 'img_file': 'ILSVRC2012_test_00003646.JPEG', 'kb_source': 'dbpedia', 'fact': ['helmet', 'belong to', 'headgear'], 'question_id': '1074'}, '1464': {'fact_surface': '[[ice]] is [[frozen liquid]]', 'answer': 'ice', 'question': ' Which object in this image constists out of frozen liquid?', 'img_file': 'ILSVRC2012_test_00003052.JPEG', 'kb_source': 'conceptnet', 'fact': ['ice', 'has property', 'freeze liquid'], 'question_id': '3758'}, '1465': {'fact_surface': '[[fruits]] belongs to the category of [[Agriculture]]', 'answer': 'fruit', 'question': 'what can we see from the image', 'img_file': 'ILSVRC2012_test_00022357.JPEG', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'agriculture'], 'question_id': '3754'}, '1466': {'fact_surface': '[[bar of chocolate]] is related to [[chocolate]]', 'answer': 'chocolate', 'question': 'Which object in this image is related to bar of chocolate?', 'img_file': 'ILSVRC2012_test_00003052.JPEG', 'kb_source': 'conceptnet', 'fact': ['bar of chocolate', 'related to', 'chocolate'], 'question_id': '3757'}, '1467': {'fact_surface': '[[Lipstick]] is for [[coloring the lips]]', 'answer': 'lipstick', 'question': 'Which item in this image is to color lips?', 'img_file': 'ILSVRC2012_test_00045533.JPEG', 'kb_source': 'conceptnet', 'fact': ['lipstick', 'used for', 'color lip'], 'question_id': '3756'}, '1468': {'fact_surface': '[[cell phone]] belongs to the category of [[Digital electronics]]', 'answer': 'cell phone', 'question': 'Which object in this image belongs to the category Digital device?', 'img_file': 'COCO_val2014_000000027517.jpg', 'kb_source': 'dbpedia', 'fact': ['cell phone', 'belong to', 'digital electronics'], 'question_id': '4633'}, '1469': {'fact_surface': 'An [[cell phone]] can [[ring]].', 'answer': 'cell phone', 'question': 'which object in this image can ring', 'img_file': 'COCO_val2014_000000013639.jpg', 'kb_source': 'conceptnet', 'fact': ['cell phone', 'capable of', 'ring'], 'question_id': '2196'}, '1470': {'fact_surface': 'The class of [[snail]] is [[Gastropoda]]', 'answer': 'gastropoda', 'question': 'What is the class of the animal in the middle of this image?', 'img_file': 'ILSVRC2012_test_00001734.JPEG', 'kb_source': 'dbpedia', 'fact': ['nail', 'animal class', 'gastropoda'], 'question_id': '1071'}, '1471': {'fact_surface': '[[volleyball]] is a subclass of [[ball]]', 'answer': 'volleyball', 'question': 'Which object in this image is a ball?', 'img_file': 'ILSVRC2012_test_00048128.JPEG', 'kb_source': 'conceptnet', 'fact': ['volleyball', 'is a', 'ball'], 'question_id': '4813'}, '1472': {'fact_surface': '[[a cello]] is for [[creating music]]', 'answer': 'cello', 'question': 'Which object in this image can be used for create music?', 'img_file': 'ILSVRC2012_test_00051257.JPEG', 'kb_source': 'conceptnet', 'fact': ['cello', 'used for', 'create music'], 'question_id': '4812'}, '1473': {'fact_surface': '[[a cello]] is used to [[make music]]', 'answer': 'cello', 'question': 'Which object in this image is used for making music?', 'img_file': 'ILSVRC2012_test_00051257.JPEG', 'kb_source': 'conceptnet', 'fact': ['cello', 'used for', 'make music'], 'question_id': '4811'}, '1474': {'fact_surface': 'You are likely to find [[a cello]] in [[a chamber quartet]]', 'answer': 'cello', 'question': 'Which object in this image can be found in a chamber quartet?', 'img_file': 'ILSVRC2012_test_00051257.JPEG', 'kb_source': 'conceptnet', 'fact': ['cello', 'at location', 'chamber quartet'], 'question_id': '4810'}, '1475': {'fact_surface': '[[turtles]] are [[very slow]]', 'answer': 'low', 'question': 'What is the animal famous for?', 'img_file': 'ILSVRC2012_test_00050750.JPEG', 'kb_source': 'conceptnet', 'fact': ['turtle', 'has property', 'low'], 'question_id': '168'}, '1476': {'fact_surface': '[[Giraffes]] are [[native to Africa]]', 'answer': 'giraffe', 'question': 'What object in this image is native to Africa?', 'img_file': 'COCO_val2014_000000108088.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'has property', 'native to africa'], 'question_id': '164'}, '1477': {'fact_surface': '[[dumbbell]] is related to [[weight training]]', 'answer': 'dumbbell', 'question': 'Which equipment in this image is related to weight training', 'img_file': 'ILSVRC2012_test_00009166.JPEG', 'kb_source': 'conceptnet', 'fact': ['dumbbell', 'related to', 'weight train'], 'question_id': '165'}, '1478': {'fact_surface': '[[motorcycle]] is used for [[travel]].', 'answer': 'motorcycle', 'question': 'What kind of machine the man choose to travel?', 'img_file': 'COCO_val2014_000000136833.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'used for', 'travel'], 'question_id': '161'}, '1479': {'fact_surface': '[[Monkeys]] are [[furry mammals with long, strong tails]]', 'answer': 'monkey', 'question': 'What object in this image is a furry mammal?', 'img_file': 'ILSVRC2012_test_00000622.JPEG', 'kb_source': 'conceptnet', 'fact': ['monkey', 'is a', 'furry mammal with long strong tail'], 'question_id': '163'}, '1480': {'fact_surface': '[[Grass]] can [[turn brown]]', 'answer': 'grass', 'question': \"What's one thing here that can turn brown?\", 'img_file': 'ILSVRC2012_test_00054434.JPEG', 'kb_source': 'conceptnet', 'fact': ['grass', 'capable of', 'turn brown'], 'question_id': '4815'}, '1481': {'fact_surface': '[[field]] is related to [[grass]]', 'answer': 'grass', 'question': 'Which object in this image could also form a field?', 'img_file': 'ILSVRC2012_test_00054434.JPEG', 'kb_source': 'conceptnet', 'fact': ['field', 'related to', 'grass'], 'question_id': '4814'}, '1482': {'fact_surface': '[[trumpet]] is related to [[elephant]]', 'answer': 'elephant', 'question': 'Which object in this image is related to trumpet?', 'img_file': 'ILSVRC2012_test_00037716.JPEG', 'kb_source': 'conceptnet', 'fact': ['trumpet', 'related to', 'elephant'], 'question_id': '2738'}, '1483': {'fact_surface': '[[trunk]] is related to [[elephant]]', 'answer': 'elephant', 'question': 'Which object in this image is related to trunk?', 'img_file': 'ILSVRC2012_test_00037716.JPEG', 'kb_source': 'conceptnet', 'fact': ['trunk', 'related to', 'elephant'], 'question_id': '2739'}, '1484': {'fact_surface': '[[Fire hydrants]] are [[important to fire fighters]]', 'answer': 'fire hydrant', 'question': 'Which object in this image is important to fire fighters?', 'img_file': 'COCO_val2014_000000125829.jpg', 'kb_source': 'conceptnet', 'fact': ['fire hydrant', 'has property', 'important to fire fighter'], 'question_id': '5558'}, '1485': {'fact_surface': '[[a boat]] is used for [[floating on the water]]', 'answer': 'boat', 'question': 'What object can float on the water?', 'img_file': 'COCO_val2014_000000120248.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'used for', 'float on water'], 'question_id': '3134'}, '1486': {'fact_surface': '(elephant,dbpedia/transnbhd,animals)', 'answer': 'animal', 'question': 'What does elephant belong to', 'img_file': 'COCO_val2014_000000118401.jpg', 'kb_source': 'dbpedia', 'fact': ['elephant', 'belong to', 'animal'], 'question_id': '808'}, '1487': {'fact_surface': '[[Cups]] can [[hold liquids]]', 'answer': 'cup', 'question': 'What the cylinder object is used for?', 'img_file': 'ILSVRC2012_test_00059159.JPEG', 'kb_source': 'conceptnet', 'fact': ['cup', 'capable of', 'hold liquid'], 'question_id': '803'}, '1488': {'fact_surface': '[[giraffe]] is [[long-necked]].', 'answer': 'giraffe', 'question': 'Which animal in this image is long-necked', 'img_file': 'COCO_val2014_000000118401.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'has property', 'long neck'], 'question_id': '807'}, '1489': {'fact_surface': '[[an elephant]] can [[weight 1000 kilos]]', 'answer': 'elephant', 'question': 'Which animal can weight 1000 kilos', 'img_file': 'COCO_val2014_000000118401.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'capable of', 'weight 1000 kilo'], 'question_id': '805'}, '1490': {'fact_surface': '[[An elephant]] can [[carry a trunk]]', 'answer': 'elephant', 'question': 'Which animal is able to carry a trunk', 'img_file': 'COCO_val2014_000000118401.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'capable of', 'carry trunk'], 'question_id': '804'}, '1491': {'fact_surface': 'You can use [[a banjo]] to [[perform music]]', 'answer': 'banjo', 'question': 'Which object in this image is used to perform music?', 'img_file': 'ILSVRC2012_test_00006983.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'used for', 'perform music'], 'question_id': '5274'}, '1492': {'fact_surface': '[[banjo]] belongs to the category of [[String instruments]]', 'answer': 'banjo', 'question': 'Which object in this image belongs to the category String instruments?', 'img_file': 'ILSVRC2012_test_00006983.JPEG', 'kb_source': 'dbpedia', 'fact': ['banjo', 'belong to', 'string instrument'], 'question_id': '5275'}, '1493': {'fact_surface': '[[banjo]] is related to [[pluck]]', 'answer': 'banjo', 'question': 'Which object in this image is related to pluck?', 'img_file': 'ILSVRC2012_test_00006983.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'related to', 'pluck'], 'question_id': '5276'}, '1494': {'fact_surface': '[[skis]] belongs to the category of [[Sports equipment]]', 'answer': 'ski', 'question': 'Which sports equipment can you see in this image?', 'img_file': 'COCO_val2014_000000000785.jpg', 'kb_source': 'dbpedia', 'fact': ['ski', 'belong to', 'sports equipment'], 'question_id': '1772'}, '1495': {'fact_surface': '[[a fence]] is a kind of [[barrier]]', 'answer': 'fence', 'question': 'Which object in this image is a barrier?', 'img_file': 'COCO_val2014_000000003109.jpg', 'kb_source': 'conceptnet', 'fact': ['fence', 'is a', 'barrier'], 'question_id': '1779'}, '1496': {'fact_surface': '[[knives]] are [[sharp and dangerous]]', 'answer': 'knife', 'question': 'Which kitchen tool in this image has the property of sharp and dangerous?', 'img_file': 'COCO_val2014_000000107831.jpg', 'kb_source': 'conceptnet', 'fact': ['knife', 'has property', 'sharp and dangerous'], 'question_id': '1778'}, '1497': {'fact_surface': '[[banjo]] has [[strings]]', 'answer': 'banjo', 'question': 'Which object in this image has strings?', 'img_file': 'ILSVRC2012_test_00021564.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'part of', 'string'], 'question_id': '3036'}, '1498': {'fact_surface': '[[a banjo]] can [[play bluegrass music]]', 'answer': 'banjo', 'question': 'Which object in this image can be used to play bluegrass music?', 'img_file': 'ILSVRC2012_test_00021564.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'capable of', 'play bluegrass music'], 'question_id': '3037'}, '1499': {'fact_surface': '[[tracks]] belongs to the category of [[Transport infrastructure]]', 'answer': 'track', 'question': 'What object in this image is part of transport infrastructure?', 'img_file': 'ILSVRC2012_test_00002425.JPEG', 'kb_source': 'dbpedia', 'fact': ['track', 'belong to', 'transport infrastructure'], 'question_id': '3030'}, '1500': {'fact_surface': '[[fast]] is related to [[train]]', 'answer': 'train', 'question': 'What kind of vehicle is very fast in this image.', 'img_file': 'COCO_val2014_000000103255.jpg', 'kb_source': 'conceptnet', 'fact': ['fast', 'related to', 'train'], 'question_id': '3032'}, '1501': {'fact_surface': 'A [[train]] is a [[form of transportation]]', 'answer': 'train', 'question': 'Which object in this image is a form of transportation?', 'img_file': 'COCO_val2014_000000103255.jpg', 'kb_source': 'conceptnet', 'fact': ['train', 'is a', 'form of transportation'], 'question_id': '3033'}, '1502': {'fact_surface': '[[oranges]] can be [[squeezed]]', 'answer': 'orange', 'question': 'Which food in this image can be squeezed', 'img_file': 'COCO_val2014_000000016161.jpg', 'kb_source': 'conceptnet', 'fact': ['orange', 'receives action', 'squeeze'], 'question_id': '229'}, '1503': {'fact_surface': '[[Frisbee]] is related to [[throw]]', 'answer': 'throw', 'question': 'What action do you need to play this game?', 'img_file': 'COCO_val2014_000000108130.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'related to', 'throw'], 'question_id': '228'}, '1504': {'fact_surface': 'You are likely to find [[elephants]] in [[zoos]]', 'answer': 'elephant', 'question': 'What are you likely to find in zoos?', 'img_file': 'COCO_val2014_000000011340.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'at location', 'zoo'], 'question_id': '227'}, '1505': {'fact_surface': 'You can use [[a French horn]] to [[play music]]', 'answer': 'french horn', 'question': 'Which object in this picture is used to play music?', 'img_file': 'ILSVRC2012_test_00008027.JPEG', 'kb_source': 'conceptnet', 'fact': ['french horn', 'used for', 'play music'], 'question_id': '223'}, '1506': {'fact_surface': '[[a tv]] is used for [[advertising]]', 'answer': 'tv', 'question': 'Which electronic device in the image can be used for advertising?', 'img_file': 'COCO_val2014_000000120747.jpg', 'kb_source': 'conceptnet', 'fact': ['tv', 'used for', 'advertise'], 'question_id': '222'}, '1507': {'fact_surface': '[[The zoo]] is in [[the city]]', 'answer': 'city', 'question': 'What is this place usually located?', 'img_file': 'COCO_val2014_000000022969.jpg', 'kb_source': 'conceptnet', 'fact': ['zoo', 'at location', 'city'], 'question_id': '2509'}, '1508': {'fact_surface': '[[keyboard]] belongs to the category of [[Computers]]', 'answer': 'keyboard', 'question': 'Which object in this image belongs to the category Computers?', 'img_file': 'ILSVRC2012_test_00024445.JPEG', 'kb_source': 'dbpedia', 'fact': ['keyboard', 'belong to', 'computer'], 'question_id': '2508'}, '1509': {'fact_surface': '[[dog]] is used for [[safty]]', 'answer': 'dog', 'question': 'Which object in this image can used for protecting people', 'img_file': 'COCO_val2014_000000016730.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'used for', 'safty'], 'question_id': '2507'}, '1510': {'fact_surface': '[[giraffe]] belongs to the category of [[Fauna of Africa]]', 'answer': 'giraffe', 'question': 'Which object in this image belongs to the category Fauna of Africa?', 'img_file': 'COCO_val2014_000000143129.jpg', 'kb_source': 'dbpedia', 'fact': ['giraffe', 'belong to', 'fauna of africa'], 'question_id': '5041'}, '1511': {'fact_surface': 'You are likely to find [[giraffes]] in [[the zoo]].', 'answer': 'giraffe', 'question': 'Which object in this image can be found in a zoo?', 'img_file': 'COCO_val2014_000000143129.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'at location', 'zoo'], 'question_id': '5040'}, '1512': {'fact_surface': 'Something you find [[in a living room]] is [[a sofa]].', 'answer': 'sofa', 'question': 'Which object in this image can be found in in living room?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'at location', 'in live room'], 'question_id': '1256'}, '1513': {'fact_surface': '[[sofas]] are [[comfortable]]', 'answer': 'sofa', 'question': 'Which object in this image has the property of comfortable to have a rest?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'has property', 'comfortable'], 'question_id': '1257'}, '1514': {'fact_surface': '[[a tv]] is for [[watching]]', 'answer': 'watch', 'question': 'What is a TV used for', 'img_file': 'ILSVRC2012_test_00027726.JPEG', 'kb_source': 'conceptnet', 'fact': ['tv', 'used for', 'watch'], 'question_id': '0'}, '1515': {'fact_surface': '[[A sofa]] is [[a piece of furniture]]', 'answer': 'sofa', 'question': 'Which object in this image  belongs to furniture?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'is a', 'piece of furniture'], 'question_id': '1255'}, '1516': {'fact_surface': '[[tidy]] is related to [[sofa]]', 'answer': 'sofa', 'question': 'What in this image is related to tidy?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['tidy', 'related to', 'sofa'], 'question_id': '1252'}, '1517': {'fact_surface': '[[sofa]] is a subclass of [[seat]]', 'answer': 'sofa', 'question': 'Which object in this image can seat a person?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'is a', 'seat'], 'question_id': '1250'}, '1518': {'fact_surface': '[[jumping]] is more strenuous than [[dressage]]', 'answer': 'dressage', 'question': 'Which action is less strenuous than the action shown in this image?', 'img_file': 'COCO_val2014_000000135361.jpg', 'kb_source': 'webchild', 'fact': ['jumping', 'strenuous', 'dressage'], 'question_id': '1523'}, '1519': {'fact_surface': 'You are likely to find [[a desk]] in [[the office]].', 'answer': 'desk', 'question': 'What is usually found in this place?', 'img_file': 'COCO_val2014_000000008721.jpg', 'kb_source': 'conceptnet', 'fact': ['desk', 'at location', 'office'], 'question_id': '3202'}, '1520': {'fact_surface': 'You are likely to find [[chair]] in [[room]].', 'answer': 'chair', 'question': 'What can be found in this place?', 'img_file': 'ILSVRC2012_test_00033253.JPEG', 'kb_source': 'conceptnet', 'fact': ['chair', 'at location', 'room'], 'question_id': '1128'}, '1521': {'fact_surface': 'You are likely to find [[chair]] in [[room]].', 'answer': 'chair', 'question': 'What can be found in this place?', 'img_file': 'ILSVRC2012_test_00033253.JPEG', 'kb_source': 'conceptnet', 'fact': ['chair', 'at location', 'room'], 'question_id': '1129'}, '1522': {'fact_surface': '[[flute]] is related to [[instrument]]', 'answer': 'flute', 'question': 'What object that is a type of instrument?', 'img_file': 'ILSVRC2012_test_00004426.JPEG', 'kb_source': 'conceptnet', 'fact': ['flute', 'related to', 'instrument'], 'question_id': '5189'}, '1523': {'fact_surface': '[[a person]] can [[reply to a letter]]', 'answer': 'person', 'question': 'What in this image could reply to a letter?', 'img_file': 'COCO_val2014_000000014549.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'reply to letter'], 'question_id': '1122'}, '1524': {'fact_surface': '[[violin]] is a kind of [[string instrument]]', 'answer': 'violin', 'question': 'Which object in this image is a stringed instrument?', 'img_file': 'ILSVRC2012_test_00040619.JPEG', 'kb_source': 'conceptnet', 'fact': ['violin', 'is a', 'string instrument'], 'question_id': '1124'}, '1525': {'fact_surface': '[[Wine]] can [[age in the bottle]]', 'answer': 'wine', 'question': 'Which object in this image is capable of age in bottle?', 'img_file': 'COCO_val2014_000000009007.jpg', 'kb_source': 'conceptnet', 'fact': ['wine', 'capable of', 'age in bottle'], 'question_id': '1125'}, '1526': {'fact_surface': '[[a cup]] is used for [[handling liquid]]', 'answer': 'cup', 'question': 'What object can hold liquid?', 'img_file': 'COCO_val2014_000000009007.jpg', 'kb_source': 'conceptnet', 'fact': ['cup', 'used for', 'handle liquid'], 'question_id': '1126'}, '1527': {'fact_surface': '[[shirt]] belongs to the category of [[Clothing]]', 'answer': 'shirt', 'question': 'What clothing is the man in the foreground wearing', 'img_file': 'COCO_val2014_000000009007.jpg', 'kb_source': 'dbpedia', 'fact': ['shirt', 'belong to', 'clothing'], 'question_id': '1127'}, '1528': {'fact_surface': '[[horses]] can [[live in the wild]]', 'answer': 'horse', 'question': 'Which object in this image is capable of live in wild?', 'img_file': 'COCO_val2014_000000019032.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'capable of', 'live in wild'], 'question_id': '2864'}, '1529': {'fact_surface': '[[horses]] are [[good leapers]]', 'answer': 'horse', 'question': 'Which object in this image is a good leaper?', 'img_file': 'COCO_val2014_000000019032.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'is a', 'good leaper'], 'question_id': '2865'}, '1530': {'fact_surface': '[[Trains]] are [[faster than cars]]', 'answer': 'train', 'question': 'which object in this image can run faster than cars', 'img_file': 'COCO_val2014_000000137727.jpg', 'kb_source': 'conceptnet', 'fact': ['train', 'is a', 'fast than car'], 'question_id': '4772'}, '1531': {'fact_surface': '[[train]] are cheaper than [[flight]]', 'answer': 'train', 'question': 'which object in this image is cheaper than plane?', 'img_file': 'COCO_val2014_000000137727.jpg', 'kb_source': 'webchild', 'fact': ['train', 'cheap', 'flight'], 'question_id': '4770'}, '1532': {'fact_surface': '[[train]] are much more efficient than [[bus]]', 'answer': 'train', 'question': 'which object in this image is more efficient than bus?', 'img_file': 'COCO_val2014_000000137727.jpg', 'kb_source': 'webchild', 'fact': ['train', 'efficient', 'bus'], 'question_id': '4771'}, '1533': {'fact_surface': '[[bus]] belongs to the category of [[Vehicles]]', 'answer': 'bus', 'question': 'What in this image is an instance of the category Vehicles?', 'img_file': 'COCO_val2014_000000138601.jpg', 'kb_source': 'dbpedia', 'fact': ['bus', 'belong to', 'vehicle'], 'question_id': '5818'}, '1534': {'fact_surface': '[[A bus]] is used to [[carry people]]', 'answer': 'bus', 'question': 'What object in this image is used to carry people?', 'img_file': 'COCO_val2014_000000138601.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'used for', 'carry person'], 'question_id': '5819'}, '1535': {'fact_surface': '[[desktop computer]] are faster than [[laptop]]', 'answer': 'laptop', 'question': 'which object in this image is less powerful than desktop computer?', 'img_file': 'COCO_val2014_000000146805.jpg', 'kb_source': 'webchild', 'fact': ['desktop computer', 'fast', 'laptop'], 'question_id': '5810'}, '1536': {'fact_surface': '[[keyboard]] belongs to the category of [[Computing input devices]]', 'answer': 'keyboard', 'question': 'Which object in this image belongs to the category computing input equipments?', 'img_file': 'COCO_val2014_000000146805.jpg', 'kb_source': 'dbpedia', 'fact': ['keyboard', 'belong to', 'computing input devices'], 'question_id': '5811'}, '1537': {'fact_surface': '[[monitor]] belongs to the category of [[Input/output]]', 'answer': 'monitor', 'question': 'Which object in this image belongs to the category computing output device?', 'img_file': 'COCO_val2014_000000146805.jpg', 'kb_source': 'dbpedia', 'fact': ['monitor', 'belong to', 'output'], 'question_id': '5812'}, '1538': {'fact_surface': '*Something you find [[in the office]] is [[a desk]]', 'answer': 'desk', 'question': 'Which furniture in this image can be found in in office?', 'img_file': 'COCO_val2014_000000146805.jpg', 'kb_source': 'conceptnet', 'fact': ['desk', 'at location', 'in office'], 'question_id': '5813'}, '1539': {'fact_surface': 'You can use [[a luggage]] to [[pack clothing]]', 'answer': 'luggage', 'question': 'Which object in this image is used to pack clothing?', 'img_file': 'COCO_val2014_000000101491.jpg', 'kb_source': 'conceptnet', 'fact': ['luggage', 'used for', 'pack clothe'], 'question_id': '5815'}, '1540': {'fact_surface': '[[a bus]] can [[carry passengers]]', 'answer': 'bus', 'question': 'Which object in this image is capable of carrying passengers?', 'img_file': 'COCO_val2014_000000138601.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'capable of', 'carry passenger'], 'question_id': '5816'}, '1541': {'fact_surface': 'A [[bus]] is a [[vehicle]]', 'answer': 'bus', 'question': 'Which object in this image is a vehicle?', 'img_file': 'COCO_val2014_000000138601.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'is a', 'vehicle'], 'question_id': '5817'}, '1542': {'fact_surface': '[[traffic lights]] are [[coloured red, amber and green]]', 'answer': 'traffic light', 'question': 'Which object in this image is coloured red, amber and green?', 'img_file': 'COCO_val2014_000000137156.jpg', 'kb_source': 'conceptnet', 'fact': ['traffic light', 'has property', 'colour red amber and green'], 'question_id': '4619'}, '1543': {'fact_surface': '[[green light]] is related to [[traffic light]]', 'answer': 'traffic light', 'question': 'Which object in this image is related to green light?', 'img_file': 'COCO_val2014_000000137156.jpg', 'kb_source': 'conceptnet', 'fact': ['green light', 'related to', 'traffic light'], 'question_id': '4618'}, '1544': {'fact_surface': '[[cat]] are far less social than [[dog]]', 'answer': 'cat', 'question': 'What object is less social than the object in the left of this image?', 'img_file': 'COCO_val2014_000000022892.jpg', 'kb_source': 'webchild', 'fact': ['cat', 'social', 'dog'], 'question_id': '4611'}, '1545': {'fact_surface': '[[cats]] are [[independent]]', 'answer': 'cat', 'question': 'What object in this image is independent?', 'img_file': 'COCO_val2014_000000022892.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'has property', 'independent'], 'question_id': '4610'}, '1546': {'fact_surface': '[[a dog]] can [[guide the blind]]', 'answer': 'dog', 'question': 'What object in this image might be able to guide a blind person?', 'img_file': 'COCO_val2014_000000022892.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'capable of', 'guide blind'], 'question_id': '4613'}, '1547': {'fact_surface': 'An activity [[a cat]] can do is [[scratch furniture]]', 'answer': 'cat', 'question': 'What object in this image scratches furniture?', 'img_file': 'COCO_val2014_000000022892.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'scratch furniture'], 'question_id': '4612'}, '1548': {'fact_surface': 'You can use [[a dog]] to [[guard a house]]', 'answer': 'dog', 'question': 'Which object in this image might be used to guard a house?', 'img_file': 'COCO_val2014_000000022892.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'used for', 'guard house'], 'question_id': '4615'}, '1549': {'fact_surface': '[[a dog]] is for [[providing friendship]]', 'answer': 'dog', 'question': 'What object in this image might be used for friendship?', 'img_file': 'COCO_val2014_000000022892.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'used for', 'provide friendship'], 'question_id': '4614'}, '1550': {'fact_surface': '[[horses]] can [[jump very high]]', 'answer': 'horse', 'question': 'Which animal in this image can jump very high?', 'img_file': 'ILSVRC2012_test_00013009.JPEG', 'kb_source': 'conceptnet', 'fact': ['horse', 'capable of', 'jump very high'], 'question_id': '4617'}, '1551': {'fact_surface': '[[horse]] is related to [[a pony]]', 'answer': 'horse', 'question': 'Which animal in this image is related to pony?', 'img_file': 'ILSVRC2012_test_00013009.JPEG', 'kb_source': 'conceptnet', 'fact': ['horse', 'related to', 'pony'], 'question_id': '4616'}, '1552': {'fact_surface': '[[motorcycle]] are less stable than [[car]]', 'answer': 'car', 'question': 'what thing is more stable than the vehicle shown in this image?', 'img_file': 'COCO_val2014_000000015596.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'stable', 'car'], 'question_id': '2705'}, '1553': {'fact_surface': '[[racing]] is more stressful than [[fun]]', 'answer': 'racing', 'question': 'which action in this image makes player feel more pressure than fun', 'img_file': 'COCO_val2014_000000015596.jpg', 'kb_source': 'webchild', 'fact': ['racing', 'stressful', 'fun'], 'question_id': '2704'}, '1554': {'fact_surface': '[[volleyball]] belongs to the category of [[Competitive games]]', 'answer': 'volleyball', 'question': 'What is the sport that belongs to competitive games?', 'img_file': 'ILSVRC2012_test_00045885.JPEG', 'kb_source': 'dbpedia', 'fact': ['volleyball', 'belong to', 'competitive games'], 'question_id': '2707'}, '1555': {'fact_surface': '[[a boat]] is for [[going down a river]]', 'answer': 'boat', 'question': 'Which object in this image is used for going down a river?', 'img_file': 'COCO_val2014_000000023489.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'used for', 'go down river'], 'question_id': '5458'}, '1556': {'fact_surface': '[[a person]] is generally [[lighter than an elephant]]', 'answer': 'elephant', 'question': 'What is the heaviest thing in this picture?', 'img_file': 'COCO_val2014_000000139555.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'has property', 'elephant'], 'question_id': '144'}, '1557': {'fact_surface': '[[Snakes]] have [[no feet]]', 'answer': 'snake', 'question': 'Which animal in this image has no feet', 'img_file': 'ILSVRC2012_test_00029408.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'has a', 'no foot'], 'question_id': '142'}, '1558': {'fact_surface': '[[an elephant]] has [[a long nose called \"trunk\"]]', 'answer': 'elephant', 'question': 'Who has a long nose in the image?', 'img_file': 'COCO_val2014_000000139555.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'has a', 'long nose call trunk'], 'question_id': '143'}, '1559': {'fact_surface': 'You are likely to find [[a snake]] in [[a hole in rocks]]', 'answer': 'snake', 'question': 'Which object in this image can be found in a hole in rocks', 'img_file': 'ILSVRC2012_test_00029408.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'at location', 'hole in rock'], 'question_id': '140'}, '1560': {'fact_surface': '[[snake]] is related to [[poison]]', 'answer': 'snake', 'question': 'Which animal in this image is related to poison', 'img_file': 'ILSVRC2012_test_00029408.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'related to', 'poison'], 'question_id': '141'}, '1561': {'fact_surface': '[[a person]] can [[see a painting]]', 'answer': 'person', 'question': 'which object in this image is capable of viewing a painting?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'see paint'], 'question_id': '2701'}, '1562': {'fact_surface': '[[a person]] can [[grow a plant]]', 'answer': 'person', 'question': 'which object in this image is capable of growing a plant?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'grow plant'], 'question_id': '2702'}, '1563': {'fact_surface': '[[an axe]] can [[chop wood]]', 'answer': 'axe', 'question': 'What object in this image can be used to chop wood?', 'img_file': 'ILSVRC2012_test_00014499.JPEG', 'kb_source': 'conceptnet', 'fact': ['axe', 'capable of', 'chop wood'], 'question_id': '2717'}, '1564': {'fact_surface': '[[an axe]] can [[chop wood]]', 'answer': 'axe', 'question': 'What object in this image can be used to chop wood?', 'img_file': 'ILSVRC2012_test_00014499.JPEG', 'kb_source': 'conceptnet', 'fact': ['axe', 'capable of', 'chop wood'], 'question_id': '2718'}, '1565': {'fact_surface': '[[an axe]] can [[chop wood]]', 'answer': 'axe', 'question': 'What object in this image can be used to chop wood?', 'img_file': 'ILSVRC2012_test_00014499.JPEG', 'kb_source': 'conceptnet', 'fact': ['axe', 'capable of', 'chop wood'], 'question_id': '2719'}, '1566': {'fact_surface': '(flower,/r/IsA,plant)', 'answer': 'plant', 'question': 'What kind of flower belongs to?', 'img_file': 'COCO_val2014_000000103358.jpg', 'kb_source': 'conceptnet', 'fact': ['flower', 'is a', 'plant'], 'question_id': '826'}, '1567': {'fact_surface': '[[a stove]] can [[heat a pot]]', 'answer': 'stove', 'question': 'What object in this image can heat a pot?', 'img_file': 'COCO_val2014_000000106392.jpg', 'kb_source': 'conceptnet', 'fact': ['stove', 'capable of', 'heat pot'], 'question_id': '823'}, '1568': {'fact_surface': '[[Cats]] can [[jump onto a table or chair]]', 'answer': 'cat', 'question': 'which object in this image is capable of jumping onto a table or chair?', 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'jump onto table or chair'], 'question_id': '5252'}, '1569': {'fact_surface': '[[Cats]] can [[drink water]]', 'answer': 'cat', 'question': 'which object in this image is capable of drinking water?', 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'drink water'], 'question_id': '5253'}, '1570': {'fact_surface': '[[cat]] has [[fur]]', 'answer': 'cat', 'question': 'which object in this image has fur?', 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'part of', 'fur'], 'question_id': '5250'}, '1571': {'fact_surface': '[[Cats]] can [[sense with their wiskers]]', 'answer': 'cat', 'question': 'which object in this image is capable of sensing things with their wiskers?', 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'sense with their wiskers'], 'question_id': '5251'}, '1572': {'fact_surface': '[[airplane]] is an instance of [[transportation-topic]]', 'answer': 'airplane', 'question': 'Which transportation topic is shown in this image?', 'img_file': 'COCO_val2014_000000145921.jpg', 'kb_source': 'conceptnet', 'fact': ['airplane', 'is a', 'transportation topic'], 'question_id': '1717'}, '1573': {'fact_surface': '[[cat]] belongs to the category of [[Mammal]]', 'answer': 'cat', 'question': 'which object in this image is a mammal?', 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'dbpedia', 'fact': ['cat', 'belong to', 'mammal'], 'question_id': '5254'}, '1574': {'fact_surface': 'You can use [[a bathtub]] to [[take a bath in]]', 'answer': 'bathtub', 'question': 'Which object in this image is used for take bath in?', 'img_file': 'COCO_val2014_000000107123.jpg', 'kb_source': 'conceptnet', 'fact': ['bathtub', 'used for', 'take bath in'], 'question_id': '5258'}, '1575': {'fact_surface': '[[a toilet]] can [[flush]].', 'answer': 'toilet', 'question': 'Which object in this image can flush?', 'img_file': 'COCO_val2014_000000107123.jpg', 'kb_source': 'conceptnet', 'fact': ['toilet', 'capable of', 'flush'], 'question_id': '5259'}, '1576': {'fact_surface': '[[A guitar]] is [[a stringed insturment]]', 'answer': 'guitar', 'question': 'Which musical instrument in this image belongs to the category String instrument?', 'img_file': 'ILSVRC2012_test_00048637.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'is a', 'string insturment'], 'question_id': '3018'}, '1577': {'fact_surface': '[[sheep]] is related to [[wool]]', 'answer': 'sheep', 'question': 'Which object in this image is related to wool?', 'img_file': 'COCO_val2014_000000109888.jpg', 'kb_source': 'conceptnet', 'fact': ['sheep', 'related to', 'wool'], 'question_id': '3019'}, '1578': {'fact_surface': '[[fruits]] belongs to the category of [[Edible plants]]', 'answer': 'fruit', 'question': 'Which object in this image belongs to the category Edible plants?', 'img_file': 'ILSVRC2012_test_00027435.JPEG', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'edible plants'], 'question_id': '3016'}, '1579': {'fact_surface': '[[orange]] is [[a secondary colour]]', 'answer': 'orange', 'question': 'What object in the image can be used as a secondary color?', 'img_file': 'ILSVRC2012_test_00027435.JPEG', 'kb_source': 'conceptnet', 'fact': ['orange', 'is a', 'secondary colour'], 'question_id': '3017'}, '1580': {'fact_surface': '[[lemon]] are a bit tougher than [[orange]]', 'answer': 'lemon', 'question': 'which fruit in this image is tougher than orange?', 'img_file': 'ILSVRC2012_test_00027435.JPEG', 'kb_source': 'webchild', 'fact': ['lemon', 'tough', 'orange'], 'question_id': '3014'}, '1581': {'fact_surface': '[[fruits]] belongs to the category of [[Agriculture]]', 'answer': 'fruit', 'question': 'What shown here is related to agriculture?', 'img_file': 'ILSVRC2012_test_00027435.JPEG', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'agriculture'], 'question_id': '3015'}, '1582': {'fact_surface': '[[Bottles]] often have [[lids or caps]]', 'answer': 'bottle', 'question': 'Which object in this image has a lid or cap?', 'img_file': 'COCO_val2014_000000025165.jpg', 'kb_source': 'conceptnet', 'fact': ['bottle', 'has a', 'lid or cap'], 'question_id': '5663'}, '1583': {'fact_surface': 'You are likely to find [[a computer]] in [[any school]]', 'answer': 'computer', 'question': 'Which object in this image can likely be found in any school?', 'img_file': 'ILSVRC2012_test_00018767.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'at location', 'any school'], 'question_id': '5662'}, '1584': {'fact_surface': '[[Keyboards]] have [[keys]]', 'answer': 'keyboard', 'question': 'Which object in this image has keys?', 'img_file': 'ILSVRC2012_test_00018767.JPEG', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'has a', 'key'], 'question_id': '5661'}, '1585': {'fact_surface': '[[cart]] belongs to the category of [[Road transport]]', 'answer': 'cart', 'question': 'What kind of Road transport is used in this image?', 'img_file': 'COCO_val2014_000000020779.jpg', 'kb_source': 'dbpedia', 'fact': ['cart', 'belong to', 'road transport'], 'question_id': '5660'}, '1586': {'fact_surface': 'You are likely to find [[dancers]] in [[a ballroom]].', 'answer': 'dancer', 'question': 'What kind people are you likely to find in a ballroom?', 'img_file': 'COCO_val2014_000000125983.jpg', 'kb_source': 'conceptnet', 'fact': ['dancer', 'at location', 'ballroom'], 'question_id': '5666'}, '1587': {'fact_surface': 'You can use [[a suitcase]] to [[carry your clothes]]', 'answer': 'suitcase', 'question': 'Which object in this image is used for carrying your clothes?', 'img_file': 'COCO_val2014_000000125983.jpg', 'kb_source': 'conceptnet', 'fact': ['suitcase', 'used for', 'carry your clothe'], 'question_id': '5665'}, '1588': {'fact_surface': '[[an airplane]] can [[land in the field]]', 'answer': 'airplane', 'question': 'Which object in this image is capable of land in a lane?', 'img_file': 'COCO_val2014_000000145383.jpg', 'kb_source': 'conceptnet', 'fact': ['airplane', 'capable of', 'land in field'], 'question_id': '5664'}, '1589': {'fact_surface': '[[Water]] can [[feel wet]]', 'answer': 'water', 'question': 'What shown here can feel wet?', 'img_file': 'COCO_val2014_000000018687.jpg', 'kb_source': 'conceptnet', 'fact': ['water', 'capable of', 'feel wet'], 'question_id': '5669'}, '1590': {'fact_surface': 'You can use [[a bridge]] to [[cross over a body of water]]', 'answer': 'bridge', 'question': 'What do we use to cross over the body of water?', 'img_file': 'COCO_val2014_000000001761.jpg', 'kb_source': 'conceptnet', 'fact': ['bridge', 'used for', 'cross over body of water'], 'question_id': '11'}, '1591': {'fact_surface': '[[snails]] have [[shells]]', 'answer': 'shell', 'question': 'What is special of the animal in the image?', 'img_file': 'ILSVRC2012_test_00001734.JPEG', 'kb_source': 'conceptnet', 'fact': ['nail', 'has a', 'shell'], 'question_id': '10'}, '1592': {'fact_surface': '[[A teddy bear]] is for [[cuddling]]', 'answer': 'teddy bear', 'question': 'What object in the image can be used for cuddling?', 'img_file': 'COCO_val2014_000000135975.jpg', 'kb_source': 'conceptnet', 'fact': ['teddy bear', 'used for', 'cuddle'], 'question_id': '19'}, '1593': {'fact_surface': '[[laptop]] are quite a bit more expensive than [[desktop]]', 'answer': 'laptop', 'question': 'which object in this image is more expensive than desktop?', 'img_file': 'ILSVRC2012_test_00022120.JPEG', 'kb_source': 'webchild', 'fact': ['laptop', 'expensive', 'desktop'], 'question_id': '3904'}, '1594': {'fact_surface': '[[stadium]] were much more important causes than [[steroid]]', 'answer': 'stadium', 'question': 'Which place is more important than the place shown in this image', 'img_file': 'COCO_val2014_000000101985.jpg', 'kb_source': 'webchild', 'fact': ['stadium', 'important', 'steroid'], 'question_id': '3906'}, '1595': {'fact_surface': '[[soccer ball]] belongs to the category of [[Balls]]', 'answer': 'soccer ball', 'question': 'What stuff belongs to balls?', 'img_file': 'COCO_val2014_000000101985.jpg', 'kb_source': 'dbpedia', 'fact': ['soccer ball', 'belong to', 'ball'], 'question_id': '3907'}, '1596': {'fact_surface': '[[pine]] is related to [[tree]]', 'answer': 'tree', 'question': 'Which object in this image is related to pine?', 'img_file': 'COCO_val2014_000000138040.jpg', 'kb_source': 'conceptnet', 'fact': ['pine', 'related to', 'tree'], 'question_id': '3900'}, '1597': {'fact_surface': '[[a car]] can be used for [[driving]].', 'answer': 'driving', 'question': 'What is the object in the left side of this image used for?', 'img_file': 'COCO_val2014_000000138040.jpg', 'kb_source': 'conceptnet', 'fact': ['car', 'used for', 'driving'], 'question_id': '3901'}, '1598': {'fact_surface': 'A [[bus]] is a [[mode of public transportation]]', 'answer': 'bus', 'question': 'Which object in this image is for public transportation?', 'img_file': 'COCO_val2014_000000138040.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'is a', 'mode of public transportation'], 'question_id': '3902'}, '1599': {'fact_surface': '[[laptop]] are sometimes more convenient than [[desktop computer]]', 'answer': 'laptop', 'question': 'What is the object in this image that is sometimes more convenient than a desktop computer?', 'img_file': 'ILSVRC2012_test_00022120.JPEG', 'kb_source': 'webchild', 'fact': ['laptop', 'convenient', 'desktop computer'], 'question_id': '3903'}, '1600': {'fact_surface': '[[camel]] are slower than [[horse]]', 'answer': 'low', 'question': 'Whether this animal runs slower or faster than horse?', 'img_file': 'ILSVRC2012_test_00000549.JPEG', 'kb_source': 'webchild', 'fact': ['camel', 'slow', 'low'], 'question_id': '206'}, '1601': {'fact_surface': '[[boat]] is related to [[water vehicle]]', 'answer': 'boat', 'question': 'what object in this image will you find on the water?', 'img_file': 'ILSVRC2012_test_00018834.JPEG', 'kb_source': 'conceptnet', 'fact': ['boat', 'related to', 'water vehicle'], 'question_id': '208'}, '1602': {'fact_surface': '[[piano]] has [[white and black keys]]', 'answer': 'piano', 'question': 'What thing in this image has white and black keys', 'img_file': 'ILSVRC2012_test_00030242.JPEG', 'kb_source': 'conceptnet', 'fact': ['piano', 'part of', 'white and black key'], 'question_id': '836'}, '1603': {'fact_surface': '[[a piano]] is [[a large musical instrument]]', 'answer': 'piano', 'question': 'Tell me the name of the large musical instrument', 'img_file': 'ILSVRC2012_test_00030242.JPEG', 'kb_source': 'conceptnet', 'fact': ['piano', 'is a', 'large musical instrument'], 'question_id': '837'}, '1604': {'fact_surface': '[[wine]] is [[an alcoholic drink]]', 'answer': 'wine', 'question': 'which object in this image is an alcoholic drink?', 'img_file': 'COCO_val2014_000000003595.jpg', 'kb_source': 'conceptnet', 'fact': ['wine', 'is a', 'alcoholic drink'], 'question_id': '3658'}, '1605': {'fact_surface': '[[wine glass]] is related to [[goblet]]', 'answer': 'wine glass', 'question': 'which object in this image is related to goblet?', 'img_file': 'COCO_val2014_000000003595.jpg', 'kb_source': 'conceptnet', 'fact': ['wine glass', 'related to', 'goblet'], 'question_id': '3659'}, '1606': {'fact_surface': '[[beer]] is cheaper than [[wine]]', 'answer': 'wine', 'question': 'What in this image is less cheap than beer?', 'img_file': 'COCO_val2014_000000003595.jpg', 'kb_source': 'webchild', 'fact': ['beer', 'cheap', 'wine'], 'question_id': '3654'}, '1607': {'fact_surface': '[[wood carving]] is related to [[wood]]', 'answer': 'wood', 'question': 'Which object in this image is related to wood carving?', 'img_file': 'COCO_val2014_000000003595.jpg', 'kb_source': 'conceptnet', 'fact': ['wood carve', 'related to', 'wood'], 'question_id': '3655'}, '1608': {'fact_surface': '[[wine glass]] belongs to the category of [[Drinkware]]', 'answer': 'wine glass', 'question': \"which object in this image belongs to the category 'drinkware'?\", 'img_file': 'COCO_val2014_000000003595.jpg', 'kb_source': 'dbpedia', 'fact': ['wine glass', 'belong to', 'drinkware'], 'question_id': '3656'}, '1609': {'fact_surface': '[[wine]] is related to [[alcohol]]', 'answer': 'wine', 'question': 'which object in this image is related to alcohol?', 'img_file': 'COCO_val2014_000000003595.jpg', 'kb_source': 'conceptnet', 'fact': ['wine', 'related to', 'alcohol'], 'question_id': '3657'}, '1610': {'fact_surface': 'You are likely to find [[a metronome]] in [[a music studio]]', 'answer': 'metronome', 'question': 'What can be likely found in a music studio?', 'img_file': 'ILSVRC2012_test_00031102.JPEG', 'kb_source': 'conceptnet', 'fact': ['metronome', 'at location', 'music studio'], 'question_id': '3652'}, '1611': {'fact_surface': 'You can use [[a violin]] to [[create music]]', 'answer': 'violin', 'question': 'Which object in this image is used for create music?', 'img_file': 'ILSVRC2012_test_00031102.JPEG', 'kb_source': 'conceptnet', 'fact': ['violin', 'used for', 'create music'], 'question_id': '3653'}, '1612': {'fact_surface': 'You are likely to find [[a piano]] in [[a living room]]', 'answer': 'piano', 'question': 'What instrument can be found in the living room?', 'img_file': 'ILSVRC2012_test_00000941.JPEG', 'kb_source': 'conceptnet', 'fact': ['piano', 'at location', 'live room'], 'question_id': '2525'}, '1613': {'fact_surface': 'You are likely to find [[a piano]] in [[a living room]]', 'answer': 'piano', 'question': 'What instrument can be found in the living room?', 'img_file': 'ILSVRC2012_test_00000941.JPEG', 'kb_source': 'conceptnet', 'fact': ['piano', 'at location', 'live room'], 'question_id': '2527'}, '1614': {'fact_surface': 'You are likely to find [[a piano]] in [[a living room]]', 'answer': 'piano', 'question': 'What instrument can be found in the living room?', 'img_file': 'ILSVRC2012_test_00000941.JPEG', 'kb_source': 'conceptnet', 'fact': ['piano', 'at location', 'live room'], 'question_id': '2526'}, '1615': {'fact_surface': '[[a sofa]] is a kind of [[a chair]].', 'answer': 'sofa', 'question': 'Which object in this image is a kind of chair?', 'img_file': 'ILSVRC2012_test_00011808.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'is a', 'chair'], 'question_id': '2520'}, '1616': {'fact_surface': '[[the sky]] is [[beautifully blue]]', 'answer': 'blue', 'question': 'How colour dominates this image?', 'img_file': 'COCO_val2014_000000147482.jpg', 'kb_source': 'conceptnet', 'fact': ['sky', 'has property', 'blue'], 'question_id': '2529'}, '1617': {'fact_surface': 'You are likely to find [[a kite]] in [[the air]]', 'answer': 'kite', 'question': 'Which kind of object can usually be found in the air?', 'img_file': 'COCO_val2014_000000147482.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'at location', 'air'], 'question_id': '2528'}, '1618': {'fact_surface': '[[clock]] belongs to the category of [[Mechanical engineering]]', 'answer': 'clock', 'question': 'Which object in this image belongs to the category Mechanical engineering?', 'img_file': 'COCO_val2014_000000137475.jpg', 'kb_source': 'dbpedia', 'fact': ['clock', 'belong to', 'mechanical engineering'], 'question_id': '5065'}, '1619': {'fact_surface': '[[axe]] belongs to the category of [[Forestry occupations]]', 'answer': 'axe', 'question': 'What is the tool in the image used in forestry occupations?', 'img_file': 'ILSVRC2012_test_00010774.JPEG', 'kb_source': 'dbpedia', 'fact': ['axe', 'belong to', 'forestry occupations'], 'question_id': '5064'}, '1620': {'fact_surface': '[[chair]] has [[a back you can lean against]]', 'answer': 'chair', 'question': 'Which object in this image has a back you can lean against?', 'img_file': 'COCO_val2014_000000137475.jpg', 'kb_source': 'conceptnet', 'fact': ['chair', 'part of', 'back you can lean against'], 'question_id': '5067'}, '1621': {'fact_surface': 'The class of [[snail]] is [[Gastropoda]]', 'answer': 'gastropoda', 'question': 'What is the class of the animal presented in this image?', 'img_file': 'ILSVRC2012_test_00017099.JPEG', 'kb_source': 'dbpedia', 'fact': ['nail', 'animal class', 'gastropoda'], 'question_id': '5061'}, '1622': {'fact_surface': '[[snails]] have [[shells]]', 'answer': 'nail', 'question': 'Which object in this image has a shell?', 'img_file': 'ILSVRC2012_test_00017099.JPEG', 'kb_source': 'conceptnet', 'fact': ['nail', 'has a', 'shell'], 'question_id': '5060'}, '1623': {'fact_surface': '[[fly]] is related to [[dragonfly]]', 'answer': 'dragonfly', 'question': 'Which object in this image is related to fly?', 'img_file': 'ILSVRC2012_test_00001551.JPEG', 'kb_source': 'conceptnet', 'fact': ['fly', 'related to', 'dragonfly'], 'question_id': '5069'}, '1624': {'fact_surface': '[[a kitchenette]] is for [[cooking]]', 'answer': 'cooking', 'question': 'What do you do in a kitchenette?', 'img_file': 'COCO_val2014_000000137475.jpg', 'kb_source': 'conceptnet', 'fact': ['kitchenette', 'used for', 'cooking'], 'question_id': '5068'}, '1625': {'fact_surface': '[[ape]] is related to [[monkey]]', 'answer': 'monkey', 'question': 'which object in this image is the similar animal to ape', 'img_file': 'ILSVRC2012_test_00000382.JPEG', 'kb_source': 'conceptnet', 'fact': ['ape', 'related to', 'monkey'], 'question_id': '4404'}, '1626': {'fact_surface': '[[motorcycle]] are smaller than [[automobile]]', 'answer': 'motorcycle', 'question': 'which object in this image is smaller than automobile?', 'img_file': 'COCO_val2014_000000146701.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'small', 'automobile'], 'question_id': '4400'}, '1627': {'fact_surface': '[[fruits]] belongs to the category of [[Food]]', 'answer': 'fruit', 'question': 'which object can be eaten?', 'img_file': 'ILSVRC2012_test_00040725.JPEG', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'food'], 'question_id': '4402'}, '1628': {'fact_surface': '[[Bananas]] are [[rich in potassium]]', 'answer': 'banana', 'question': 'Which object in this image is rich in potassium?', 'img_file': 'ILSVRC2012_test_00040725.JPEG', 'kb_source': 'conceptnet', 'fact': ['banana', 'has property', 'rich in potassium'], 'question_id': '4403'}, '1629': {'fact_surface': '[[hamburger]] is cheaper than [[steak price]]', 'answer': 'cheap', 'question': 'Whether this meal is normally cheaper or more expensive than steak?', 'img_file': 'ILSVRC2012_test_00040777.JPEG', 'kb_source': 'webchild', 'fact': ['hamburger', 'cheap', 'cheap'], 'question_id': '923'}, '1630': {'fact_surface': '*Something you find at [[the beach]] is [[waves]]', 'answer': 'wave', 'question': 'what object in this image can you find at a beach?', 'img_file': 'COCO_val2014_000000008981.jpg', 'kb_source': 'conceptnet', 'fact': ['wave', 'at location', 'beach'], 'question_id': '924'}, '1631': {'fact_surface': '[[zebra]] belongs to the category of [[Animal]]', 'answer': 'animal', 'question': 'What category does zebras belong to?', 'img_file': 'COCO_val2014_000000007566.jpg', 'kb_source': 'dbpedia', 'fact': ['zebra', 'belong to', 'animal'], 'question_id': '925'}, '1632': {'fact_surface': '[[candles]] belongs to the category of [[Light sources]]', 'answer': 'candles', 'question': 'What light sources are on the table?', 'img_file': 'COCO_val2014_000000104747.jpg', 'kb_source': 'dbpedia', 'fact': ['candles', 'belong to', 'light source'], 'question_id': '926'}, '1633': {'fact_surface': '[[donut]] belongs to the category of [[Snack food]]', 'answer': 'donut', 'question': 'What snack food is featured in this picture?', 'img_file': 'COCO_val2014_000000148957.jpg', 'kb_source': 'dbpedia', 'fact': ['donut', 'belong to', 'snack food'], 'question_id': '927'}, '1634': {'fact_surface': '[[iPod]] belongs to the category of [[MP3]]', 'answer': 'ipod', 'question': 'Which object in this image belongs to the category MP3?', 'img_file': 'ILSVRC2012_test_00049049.JPEG', 'kb_source': 'dbpedia', 'fact': ['ipod', 'belong to', 'mp3'], 'question_id': '5393'}, '1635': {'fact_surface': '[[computers]] are [[electronic devices]]', 'answer': 'computer', 'question': 'Which object in this image is an electronic device?', 'img_file': 'ILSVRC2012_test_00049049.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'is a', 'electronic device'], 'question_id': '5392'}, '1636': {'fact_surface': '[[desktop]] are more powerful than [[laptop]]', 'answer': 'laptop', 'question': 'which object in this image is usually less powerful than desktop?', 'img_file': 'ILSVRC2012_test_00049049.JPEG', 'kb_source': 'webchild', 'fact': ['desktop', 'powerful', 'laptop'], 'question_id': '5391'}, '1637': {'fact_surface': 'Something you might find [[at my desk]] is [[a laptop]].', 'answer': 'laptop', 'question': 'Which object in this image may be found at my desk?', 'img_file': 'ILSVRC2012_test_00049049.JPEG', 'kb_source': 'conceptnet', 'fact': ['laptop', 'at location', 'at my desk'], 'question_id': '5390'}, '1638': {'fact_surface': 'You are likely to find [[a desk]] in [[the office]].', 'answer': 'desk', 'question': 'Which object in this image can be found in the office?', 'img_file': 'ILSVRC2012_test_00049049.JPEG', 'kb_source': 'conceptnet', 'fact': ['desk', 'at location', 'office'], 'question_id': '5394'}, '1639': {'fact_surface': '*Something you find at [[a bar]] is [[drinks]]', 'answer': 'drink', 'question': 'What is usually found at this place?', 'img_file': 'COCO_val2014_000000100553.jpg', 'kb_source': 'conceptnet', 'fact': ['drink', 'at location', 'bar'], 'question_id': '5399'}, '1640': {'fact_surface': '[[hamburger]] belongs to the category of [[Sandwiches]]', 'answer': 'hamburger', 'question': 'Which object in this image belongs to the category Sandwiches?', 'img_file': 'ILSVRC2012_test_00040777.JPEG', 'kb_source': 'dbpedia', 'fact': ['hamburger', 'belong to', 'sandwich'], 'question_id': '5398'}, '1641': {'fact_surface': '[[elephant]] is related to [[four legs]]', 'answer': 'four', 'question': 'How many legs does the animal in the image have?', 'img_file': 'COCO_val2014_000000017282.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'related to', 'four'], 'question_id': '784'}, '1642': {'fact_surface': '[[a kite]] is for [[play games]]', 'answer': 'kite', 'question': 'What is the game are they playing?', 'img_file': 'COCO_val2014_000000007511.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'used for', 'play game'], 'question_id': '787'}, '1643': {'fact_surface': '(candle,/r/UsedFor,lighting)', 'answer': 'light', 'question': 'Why the candle is used hear?', 'img_file': 'ILSVRC2012_test_00025208.JPEG', 'kb_source': 'conceptnet', 'fact': ['candle', 'used for', 'light'], 'question_id': '781'}, '1644': {'fact_surface': '[[A kite]] can [[catch the wind]]', 'answer': 'kite', 'question': 'Which thing in the image can catch the wind?', 'img_file': 'COCO_val2014_000000114634.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'capable of', 'catch wind'], 'question_id': '783'}, '1645': {'fact_surface': '[[A bottle]] can [[hold water]]', 'answer': 'bottle', 'question': 'Which object in this image is capable of holding water', 'img_file': 'ILSVRC2012_test_00002967.JPEG', 'kb_source': 'conceptnet', 'fact': ['bottle', 'capable of', 'hold water'], 'question_id': '788'}, '1646': {'fact_surface': '[[An ipod]] is for [[listening to music]]', 'answer': 'ipod', 'question': 'Which object in this image is dedicated for listening to music', 'img_file': 'COCO_val2014_000000154202.jpg', 'kb_source': 'conceptnet', 'fact': ['ipod', 'used for', 'listen to music'], 'question_id': '789'}, '1647': {'fact_surface': '[[cow]] is related to [[meat]]', 'answer': 'cow', 'question': 'Which object in this image is the most related to meat', 'img_file': 'COCO_val2014_000000142722.jpg', 'kb_source': 'conceptnet', 'fact': ['cow', 'related to', 'meat'], 'question_id': '402'}, '1648': {'fact_surface': \"[[dogs]] are [[man's best friend]]\", 'answer': 'dog', 'question': \"Which animal in this image is man's best friend?\", 'img_file': 'COCO_val2014_000000142722.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'is a', \"man's best friend\"], 'question_id': '401'}, '1649': {'fact_surface': '[[Umbrellas]] can [[fold up]]', 'answer': 'umbrella', 'question': 'Which object in this image can fold up?', 'img_file': 'COCO_val2014_000000018666.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'capable of', 'fold up'], 'question_id': '1376'}, '1650': {'fact_surface': '[[motorcycle]] is generally [[a two wheeled vehicle]]', 'answer': 'motorcycle', 'question': 'Which object in this image is a two wheeled vehicle?', 'img_file': 'COCO_val2014_000000101933.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'has property', 'two wheel vehicle'], 'question_id': '1106'}, '1651': {'fact_surface': '[[motorcycle]] is [[a vehicle type]]', 'answer': 'motorcycle', 'question': 'Which object in this image is a vehicle type?', 'img_file': 'COCO_val2014_000000101933.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'is a', 'vehicle type'], 'question_id': '1107'}, '1652': {'fact_surface': '[[screw cap]] is related to [[bottle]]', 'answer': 'bottle', 'question': 'Which object in this image has a screw cap?', 'img_file': 'ILSVRC2012_test_00018273.JPEG', 'kb_source': 'conceptnet', 'fact': ['screw cap', 'related to', 'bottle'], 'question_id': '1102'}, '1653': {'fact_surface': '[[a bottle]] is for [[keeping liquid in]]', 'answer': 'bottle', 'question': 'Which object in this image is used to keep liquid in?', 'img_file': 'ILSVRC2012_test_00018273.JPEG', 'kb_source': 'conceptnet', 'fact': ['bottle', 'used for', 'keep liquid in'], 'question_id': '1103'}, '1654': {'fact_surface': '[[elephant]] is a kind of [[pack animal]]', 'answer': 'elephant', 'question': 'Which object in this image is a pack animal?', 'img_file': 'COCO_val2014_000000109819.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'is a', 'pack animal'], 'question_id': '1100'}, '1655': {'fact_surface': '[[hair gel]] is related to [[hair spray]]', 'answer': 'hair spray', 'question': 'Which object in this image is related to hair gel?', 'img_file': 'ILSVRC2012_test_00000208.JPEG', 'kb_source': 'conceptnet', 'fact': ['hair gel', 'related to', 'hair spray'], 'question_id': '1727'}, '1656': {'fact_surface': '[[a cat]] can [[wash itself]]', 'answer': 'cat', 'question': 'which object in this image is capable of washing itself?', 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'wash itself'], 'question_id': '5247'}, '1657': {'fact_surface': '[[a dishwasher]] can be used to [[clean eating implements]]', 'answer': 'dishwasher', 'question': 'Which object in this image is used to clean eating implements?', 'img_file': 'ILSVRC2012_test_00004708.JPEG', 'kb_source': 'conceptnet', 'fact': ['dishwasher', 'used for', 'clean eat implement'], 'question_id': '1108'}, '1658': {'fact_surface': 'A [[bread]] is a [[type of food]].', 'answer': 'bread', 'question': 'Which object in this image is a type of food?', 'img_file': 'COCO_val2014_000000131841.jpg', 'kb_source': 'conceptnet', 'fact': ['bread', 'is a', 'type of food'], 'question_id': '1109'}, '1659': {'fact_surface': '[[an umbrella]] can be used to [[protect someone from the rain]]', 'answer': 'umbrella', 'question': 'which object in this image can be used to protect someone from the rain?', 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'used for', 'protect someone from rain'], 'question_id': '5246'}, '1660': {'fact_surface': '[[Umbrellas]] can be [[open or closed]]', 'answer': 'umbrella', 'question': 'Which object in this image can be open or closed?', 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'has property', 'open or close'], 'question_id': '5241'}, '1661': {'fact_surface': '[[umbrella]] is a kind of [[rain protection]]', 'answer': 'umbrella', 'question': 'Which object in this image is a kind of rain protection?', 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'is a', 'rain protection'], 'question_id': '5240'}, '1662': {'fact_surface': '[[A baseball field]] is in [[the shape of a diamond]]', 'answer': 'baseball field', 'question': 'Where does the place in this image can be found in?', 'img_file': 'COCO_val2014_000000133042.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball field', 'at location', 'shape of diamond'], 'question_id': '1894'}, '1663': {'fact_surface': '[[cats]] can [[mind getting wet]]', 'answer': 'cat', 'question': \"Which object in this image doesn't like to get wet?\", 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'mind get wet'], 'question_id': '5243'}, '1664': {'fact_surface': '[[A baseball field]] is in [[the shape of a diamond]]', 'answer': 'baseball field', 'question': 'Where does the place in this image can be found in?', 'img_file': 'COCO_val2014_000000133042.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball field', 'at location', 'shape of diamond'], 'question_id': '1895'}, '1665': {'fact_surface': '[[An umbrella]] is used to [[protect people from sun and rain]]', 'answer': 'umbrella', 'question': 'Which object in this image is used to protect people from sun and rain?', 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'used for', 'protect person from sun and rain'], 'question_id': '5242'}, '1666': {'fact_surface': '[[baseball]] is [[very popular in some couries]]', 'answer': 'baseball', 'question': 'Which object in this image has the property of very popular in some countries?', 'img_file': 'COCO_val2014_000000133042.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'has property', 'very popular in some couries'], 'question_id': '1896'}, '1667': {'fact_surface': '[[baseball]] is [[very popular in some couries]]', 'answer': 'baseball', 'question': 'Which object in this image has the property of very popular in some countries?', 'img_file': 'COCO_val2014_000000133042.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'has property', 'very popular in some couries'], 'question_id': '1897'}, '1668': {'fact_surface': '[[laptop]] belongs to the category of [[Computer]]', 'answer': 'laptop', 'question': 'Which computer can you see in this image?', 'img_file': 'ILSVRC2012_test_00016048.JPEG', 'kb_source': 'dbpedia', 'fact': ['laptop', 'belong to', 'computer'], 'question_id': '1837'}, '1669': {'fact_surface': '[[Baseball]] is [[played outside]]', 'answer': 'baseball', 'question': 'Which object in this image should be played outside?', 'img_file': 'COCO_val2014_000000133042.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'has property', 'play outside'], 'question_id': '1892'}, '1670': {'fact_surface': '[[Baseball]] is [[played outside]]', 'answer': 'baseball', 'question': 'Which object in this image should be played outside?', 'img_file': 'COCO_val2014_000000133042.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'has property', 'play outside'], 'question_id': '1893'}, '1671': {'fact_surface': '[[cell phone]] belongs to the category of [[Portable electronics]]', 'answer': 'cell phone', 'question': 'What portable electronic devices can be found in this image? ', 'img_file': 'COCO_val2014_000000006771.jpg', 'kb_source': 'dbpedia', 'fact': ['cell phone', 'belong to', 'portable electronics'], 'question_id': '4923'}, '1672': {'fact_surface': '[[cell phone]] has [[buttons]].', 'answer': 'button', 'question': \"what does the object held in the woman's hand has as a part\", 'img_file': 'COCO_val2014_000000006771.jpg', 'kb_source': 'conceptnet', 'fact': ['button', 'part of', 'cell phone'], 'question_id': '4922'}, '1673': {'fact_surface': 'You are likely to find [[fork]] in [[a mall]].', 'answer': 'fork', 'question': 'what can be found in mall n this image', 'img_file': 'COCO_val2014_000000106392.jpg', 'kb_source': 'conceptnet', 'fact': ['fork', 'at location', 'mall'], 'question_id': '4920'}, '1674': {'fact_surface': 'You are likely to find [[pizza]] in [[a pizza store]].', 'answer': 'pizza', 'question': 'Which object in this image can be found in pizza store?', 'img_file': 'COCO_val2014_000000114586.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'at location', 'pizza store'], 'question_id': '2132'}, '1675': {'fact_surface': '[[pizza]] belongs to the category of [[Culture of Italy]]', 'answer': 'pizza', 'question': 'Which object in this image is related to the culture of Italy?', 'img_file': 'COCO_val2014_000000114586.jpg', 'kb_source': 'dbpedia', 'fact': ['pizza', 'belong to', 'culture of italy'], 'question_id': '2130'}, '1676': {'fact_surface': '[[people]] are [[alive]]', 'answer': 'person', 'question': 'which object in this image is alive?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'has property', 'alive'], 'question_id': '2668'}, '1677': {'fact_surface': '[[A person]] can [[be running a shop]]', 'answer': 'person', 'question': 'which object in this image can run a shop?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'be run shop'], 'question_id': '2669'}, '1678': {'fact_surface': '[[degauss]] is related to [[monitor]]', 'answer': 'monitor', 'question': 'Which object in this image can sometimes be degaussed?', 'img_file': 'COCO_val2014_000000148620.jpg', 'kb_source': 'conceptnet', 'fact': ['degauss', 'related to', 'monitor'], 'question_id': '2771'}, '1679': {'fact_surface': '[[An airplane]] is capable of [[flight]]', 'answer': 'airplane', 'question': 'Which object is capable of flight in this image?', 'img_file': 'COCO_val2014_000000100974.jpg', 'kb_source': 'conceptnet', 'fact': ['airplane', 'capable of', 'flight'], 'question_id': '2774'}, '1680': {'fact_surface': '[[airplanes]] can [[fly]].', 'answer': 'airplane', 'question': 'Which objects can fly in this image?', 'img_file': 'COCO_val2014_000000100974.jpg', 'kb_source': 'conceptnet', 'fact': ['airplane', 'capable of', 'fly'], 'question_id': '2775'}, '1681': {'fact_surface': '[[airplanes]] can [[carry people]].', 'answer': 'airplane', 'question': 'Which objects in this image are capable of carrying people?', 'img_file': 'COCO_val2014_000000100974.jpg', 'kb_source': 'conceptnet', 'fact': ['airplane', 'capable of', 'carry person'], 'question_id': '2776'}, '1682': {'fact_surface': '[[a bicycle]] is [[good exercise]]', 'answer': 'bicycle', 'question': 'Which object in this image is used for exercise?', 'img_file': 'COCO_val2014_000000108838.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'is a', 'good exercise'], 'question_id': '3286'}, '1683': {'fact_surface': '[[fire hydrants]] can be used to [[fight fires]]', 'answer': 'fight fire', 'question': 'Why there is a fire hydrant?', 'img_file': 'COCO_val2014_000000027658.jpg', 'kb_source': 'conceptnet', 'fact': ['fire hydrant', 'used for', 'fight fire'], 'question_id': '847'}, '1684': {'fact_surface': 'You are likely to find [[zebras]] in [[Africa]]', 'answer': 'africa', 'question': 'Where are these animals come from? ', 'img_file': 'COCO_val2014_000000132814.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'at location', 'africa'], 'question_id': '842'}, '1685': {'fact_surface': '[[dry]] are much more effective than [[water]]', 'answer': 'water', 'question': 'what in this image is less effective than dry?', 'img_file': 'ILSVRC2012_test_00002037.JPEG', 'kb_source': 'webchild', 'fact': ['dry', 'effective', 'water'], 'question_id': '3461'}, '1686': {'fact_surface': 'A [[saxophone]] is a [[wind instrument]]', 'answer': 'saxophone', 'question': 'What instrument in the image is a wind instrument?', 'img_file': 'ILSVRC2012_test_00059219.JPEG', 'kb_source': 'conceptnet', 'fact': ['saxophone', 'is a', 'wind instrument'], 'question_id': '849'}, '1687': {'fact_surface': '[[fire hydrant]] is related to [[firefighter]]', 'answer': 'fire hydrant', 'question': 'what object in this image is used to fight fires?', 'img_file': 'COCO_val2014_000000027658.jpg', 'kb_source': 'conceptnet', 'fact': ['fire hydrant', 'related to', 'firefighter'], 'question_id': '848'}, '1688': {'fact_surface': '[[a mouse wheel]] is part of [[a mouse]].', 'answer': 'mouse', 'question': 'Which object in this image has a mouse wheel?', 'img_file': 'ILSVRC2012_test_00002371.JPEG', 'kb_source': 'conceptnet', 'fact': ['mouse wheel', 'part of', 'mouse'], 'question_id': '4902'}, '1689': {'fact_surface': '[[bellhop]] is related to [[luggage]]', 'answer': 'luggage', 'question': 'Which object in this image could likely be moved by a bellhop?', 'img_file': 'ILSVRC2012_test_00010551.JPEG', 'kb_source': 'conceptnet', 'fact': ['bellhop', 'related to', 'luggage'], 'question_id': '1583'}, '1690': {'fact_surface': '[[camel]] is a kind of [[mammal]]', 'answer': 'camel', 'question': 'What mammal is in the image?', 'img_file': 'ILSVRC2012_test_00028360.JPEG', 'kb_source': 'conceptnet', 'fact': ['camel', 'is a', 'mammal'], 'question_id': '4905'}, '1691': {'fact_surface': '[[Grass]] has [[shallow roots]]', 'answer': 'grass', 'question': 'Which object in this image has shallow roots?', 'img_file': 'COCO_val2014_000000008498.jpg', 'kb_source': 'conceptnet', 'fact': ['grass', 'has a', 'shallow root'], 'question_id': '1738'}, '1692': {'fact_surface': '[[helmet]] belongs to the category of [[Safety]]', 'answer': 'helmet', 'question': 'Which object in this image is used for safety reasons?', 'img_file': 'ILSVRC2012_test_00026467.JPEG', 'kb_source': 'dbpedia', 'fact': ['helmet', 'belong to', 'safety'], 'question_id': '1730'}, '1693': {'fact_surface': '[[AstroTurf]] is related to [[grass]]', 'answer': 'grass', 'question': 'Which object in this image is related to astroturf?', 'img_file': 'COCO_val2014_000000008498.jpg', 'kb_source': 'conceptnet', 'fact': ['astroturf', 'related to', 'grass'], 'question_id': '1737'}, '1694': {'fact_surface': '[[Clocks]] usually have [[numbers on them]]', 'answer': 'clock', 'question': 'Which object in this image has numbers on it?', 'img_file': 'COCO_val2014_000000008498.jpg', 'kb_source': 'conceptnet', 'fact': ['clock', 'has a', 'number on them'], 'question_id': '1736'}, '1695': {'fact_surface': 'Somewhere [[a dog]] can be is [[the floor]].', 'answer': 'dog', 'question': 'Which object in this image can be found in floor?', 'img_file': 'ILSVRC2012_test_00055801.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'at location', 'floor'], 'question_id': '3070'}, '1696': {'fact_surface': 'Somewhere [[a dog]] can be is [[the floor]].', 'answer': 'dog', 'question': 'Which object in this image can be found in floor?', 'img_file': 'ILSVRC2012_test_00055801.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'at location', 'floor'], 'question_id': '3071'}, '1697': {'fact_surface': '[[Strawberries]] are [[small red fruits]]', 'answer': 'strawberry', 'question': 'What is the small red fruit in the image?', 'img_file': 'ILSVRC2012_test_00023364.JPEG', 'kb_source': 'conceptnet', 'fact': ['strawberry', 'is a', 'small red fruit'], 'question_id': '3074'}, '1698': {'fact_surface': '[[strawberry]] belongs to the category of [[Fragaria]]', 'answer': 'strawberry', 'question': 'Which object in this image belongs to the class fragaria?', 'img_file': 'ILSVRC2012_test_00023364.JPEG', 'kb_source': 'dbpedia', 'fact': ['strawberry', 'belong to', 'fragaria'], 'question_id': '3075'}, '1699': {'fact_surface': '[[strawberry]] belongs to the category of [[Fruit]]', 'answer': 'strawberry', 'question': 'Which object in this image belongs to the category Fruit?', 'img_file': 'ILSVRC2012_test_00023364.JPEG', 'kb_source': 'dbpedia', 'fact': ['strawberry', 'belong to', 'fruit'], 'question_id': '3076'}, '1700': {'fact_surface': '[[Bottles]] are often [[used to hold beverages]]', 'answer': 'bottle', 'question': 'Which object in this image is used to hold beverages?', 'img_file': 'ILSVRC2012_test_00022346.JPEG', 'kb_source': 'conceptnet', 'fact': ['bottle', 'has property', 'use to hold beverage'], 'question_id': '1592'}, '1701': {'fact_surface': '[[bromelein]] is related to [[pineapple]]', 'answer': 'pineapple', 'question': 'Which object in this image contains bromelain?', 'img_file': 'ILSVRC2012_test_00036186.JPEG', 'kb_source': 'conceptnet', 'fact': ['bromelein', 'related to', 'pineapple'], 'question_id': '3078'}, '1702': {'fact_surface': '[[plantain]] are also larger than [[banana]]', 'answer': 'banana', 'question': 'Which object in this image is like a small plantain?', 'img_file': 'ILSVRC2012_test_00036186.JPEG', 'kb_source': 'webchild', 'fact': ['plantain', 'large', 'banana'], 'question_id': '3079'}, '1703': {'fact_surface': '[[Elephants]] have [[leathery skin]]', 'answer': 'elephant', 'question': 'Which object in this image has leathery skin?', 'img_file': 'COCO_val2014_000000139555.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'has a', 'leathery skin'], 'question_id': '1599'}, '1704': {'fact_surface': '[[a person]] wants to [[go through life happy]]', 'answer': 'person', 'question': 'Which object in the image wants to go through life happy?', 'img_file': 'COCO_val2014_000000139555.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'go through life happy'], 'question_id': '1598'}, '1705': {'fact_surface': '[[People]] can [[draw with pencils]]', 'answer': 'person', 'question': 'which object in this image is able to use a pencil for drawing', 'img_file': 'ILSVRC2012_test_00052945.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'draw with pencil'], 'question_id': '5647'}, '1706': {'fact_surface': 'Kinds of [[alcohol]] : [[beer]]', 'answer': 'beer', 'question': 'What object in this image is alcoholic?', 'img_file': 'COCO_val2014_000000146489.jpg', 'kb_source': 'conceptnet', 'fact': ['beer', 'is a', 'alcohol'], 'question_id': '2400'}, '1707': {'fact_surface': '[[Frisbees]] are [[round]]', 'answer': 'frisbee', 'question': 'What is the round object in this image?', 'img_file': 'COCO_val2014_000000100238.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'has property', 'round'], 'question_id': '489'}, '1708': {'fact_surface': 'You are likely to find [[bread]] in [[a toaster]]', 'answer': 'bread', 'question': 'What might one find in this appliance?', 'img_file': 'ILSVRC2012_test_00002720.JPEG', 'kb_source': 'conceptnet', 'fact': ['bread', 'at location', 'toaster'], 'question_id': '488'}, '1709': {'fact_surface': '[[toaster]] is related to [[electric appliance]]', 'answer': 'toaster', 'question': 'What is the electronic appliance in this image', 'img_file': 'ILSVRC2012_test_00002720.JPEG', 'kb_source': 'conceptnet', 'fact': ['toaster', 'related to', 'electric appliance'], 'question_id': '486'}, '1710': {'fact_surface': '[[toaster]] is a subclass of [[kitchen tool]]', 'answer': 'toaster', 'question': 'What object in this image is a kitchen tool?', 'img_file': 'ILSVRC2012_test_00002720.JPEG', 'kb_source': 'conceptnet', 'fact': ['toaster', 'is a', 'kitchen tool'], 'question_id': '485'}, '1711': {'fact_surface': '[[Horses]] can [[jump higher than people]]', 'answer': 'horse', 'question': 'What thing in the image can jump higher than people?', 'img_file': 'COCO_val2014_000000102349.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'capable of', 'jump high than person'], 'question_id': '483'}, '1712': {'fact_surface': '[[harp]] is related to [[many strings]]', 'answer': 'harp', 'question': 'Which instrument has many strings?', 'img_file': 'ILSVRC2012_test_00010796.JPEG', 'kb_source': 'conceptnet', 'fact': ['harp', 'related to', 'many string'], 'question_id': '482'}, '1713': {'fact_surface': '[[guitars]] have [[5-7 strings]]', 'answer': 'guitar', 'question': 'Which musical instrument in this image has 5-7 strings?', 'img_file': 'ILSVRC2012_test_00010796.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'has a', '5 7 string'], 'question_id': '480'}, '1714': {'fact_surface': '[[buses]] are [[longer than cars]]', 'answer': 'bus', 'question': 'What object in this image is longer than a car?', 'img_file': 'COCO_val2014_000000017244.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'is a', 'long than car'], 'question_id': '3926'}, '1715': {'fact_surface': '[[a bus]] can [[carry passengers]]', 'answer': 'bus', 'question': 'What object in this image is capable of carrying passengers?', 'img_file': 'COCO_val2014_000000017244.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'capable of', 'carry passenger'], 'question_id': '3924'}, '1716': {'fact_surface': '[[bus]] is bigger than [[car]]', 'answer': 'bus', 'question': 'What object in this image is bigger than a car?', 'img_file': 'COCO_val2014_000000017244.jpg', 'kb_source': 'webchild', 'fact': ['bus', 'big', 'car'], 'question_id': '3925'}, '1717': {'fact_surface': '[[a bicycle]] has [[two peddles]]', 'answer': 'bicycle', 'question': 'Which object in this image has two peddles?', 'img_file': 'COCO_val2014_000000017244.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'has a', 'two peddle'], 'question_id': '3928'}, '1718': {'fact_surface': 'You can use [[a bicycle]] to [[travel short distances]]', 'answer': 'bicycle', 'question': 'Which object in this image is used to travel a short distance?', 'img_file': 'COCO_val2014_000000017244.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'used for', 'travel short distance'], 'question_id': '3929'}, '1719': {'fact_surface': '[[hot dog]] contain more fat than [[ham]]', 'answer': 'hot dog', 'question': 'what thing has less fat than the object in the middle of this image?', 'img_file': 'COCO_val2014_000000020465.jpg', 'kb_source': 'webchild', 'fact': ['hot dog', 'fat', 'ham'], 'question_id': '3672'}, '1720': {'fact_surface': '[[cheese]] is [[a dairy product]]', 'answer': 'cheese', 'question': 'Which object in this image is a dairy product?', 'img_file': 'COCO_val2014_000000020465.jpg', 'kb_source': 'conceptnet', 'fact': ['cheese', 'is a', 'dairy product'], 'question_id': '3673'}, '1721': {'fact_surface': '[[motorcycle]] is generally [[a two wheeled vehicle]]', 'answer': 'motorcycle', 'question': 'which object in this image has two wheel', 'img_file': 'COCO_val2014_000000102497.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'has property', 'two wheel vehicle'], 'question_id': '3670'}, '1722': {'fact_surface': '[[motorcycle]] are inherently less safe than [[car]]', 'answer': 'motorcycle', 'question': 'what thing is less safe than the object  in the middle in this image?', 'img_file': 'COCO_val2014_000000102497.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'safe', 'car'], 'question_id': '3671'}, '1723': {'fact_surface': '[[umbrella]] is related to [[rain]]', 'answer': 'umbrella', 'question': 'Which object in this image is related to rain ?', 'img_file': 'COCO_val2014_000000011181.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'related to', 'rain'], 'question_id': '3677'}, '1724': {'fact_surface': '[[hot dogs]] are [[a meet product]]', 'answer': 'hot dog', 'question': 'Which object in this image contains meat?', 'img_file': 'COCO_val2014_000000020465.jpg', 'kb_source': 'conceptnet', 'fact': ['hot dog', 'is a', 'meet product'], 'question_id': '3674'}, '1725': {'fact_surface': '[[people]] can [[speak languages]]', 'answer': 'person', 'question': 'Which object in this image is capable of speaking a language?', 'img_file': 'ILSVRC2012_test_00036135.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'speak language'], 'question_id': '2547'}, '1726': {'fact_surface': '[[lower jaw]] is related to [[mouth]]', 'answer': 'mouth', 'question': 'What thing shown is related to a lower jaw?', 'img_file': 'COCO_val2014_000000125291.jpg', 'kb_source': 'conceptnet', 'fact': ['low jaw', 'related to', 'mouth'], 'question_id': '2549'}, '1727': {'fact_surface': '[[a fork]] can be used to [[eat with]]', 'answer': 'fork', 'question': 'Which object in this image is used to eat with?', 'img_file': 'COCO_val2014_000000108303.jpg', 'kb_source': 'conceptnet', 'fact': ['fork', 'used for', 'eat with'], 'question_id': '1457'}, '1728': {'fact_surface': '*Something you find [[in the oven]] is [[cake]]', 'answer': 'cake', 'question': 'What object in this image can be found in an oven?', 'img_file': 'COCO_val2014_000000112437.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'at location', 'in oven'], 'question_id': '5003'}, '1729': {'fact_surface': '[[umbrellas]] can [[prtoect you from the sun]]', 'answer': 'umbrella', 'question': 'Which object in this image is capable of protecting you from the sun?', 'img_file': 'COCO_val2014_000000017272.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'capable of', 'prtoect you from sun'], 'question_id': '3586'}, '1730': {'fact_surface': '[[cake]] is related to [[flour]]', 'answer': 'flour', 'question': 'What is the cake in image made of?', 'img_file': 'COCO_val2014_000000112437.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'related to', 'flour'], 'question_id': '5004'}, '1731': {'fact_surface': '[[a monitor]] can [[display images]].', 'answer': 'monitor', 'question': 'Which object in this image is capable of displaying images?', 'img_file': 'COCO_val2014_000000122777.jpg', 'kb_source': 'conceptnet', 'fact': ['monitor', 'capable of', 'display image'], 'question_id': '3588'}, '1732': {'fact_surface': '[[rugby balls]] are [[oval shaped]].', 'answer': 'rugby ball', 'question': 'Which object in this image is oval shaped?', 'img_file': 'ILSVRC2012_test_00025041.JPEG', 'kb_source': 'conceptnet', 'fact': ['rugby ball', 'has property', 'oval shape'], 'question_id': '3589'}, '1733': {'fact_surface': '[[The saxophone]] is [[a very cool instrument]]', 'answer': 'saxophone', 'question': 'Which music instrument in this image makes it look cool?', 'img_file': 'ILSVRC2012_test_00000321.JPEG', 'kb_source': 'conceptnet', 'fact': ['saxophone', 'is a', 'very cool instrument'], 'question_id': '5009'}, '1734': {'fact_surface': '[[saxophones]] are usually [[used in jazz music]]', 'answer': 'saxophone', 'question': 'Which object in this image is used to play jazz music?', 'img_file': 'ILSVRC2012_test_00000321.JPEG', 'kb_source': 'conceptnet', 'fact': ['saxophone', 'has property', 'use in jazz music'], 'question_id': '5008'}, '1735': {'fact_surface': '[[carrot]] belongs to the category of [[List of root vegetables]]', 'answer': 'carrot', 'question': 'Which object in this image is a root vegetable?', 'img_file': 'ILSVRC2012_test_00009502.JPEG', 'kb_source': 'dbpedia', 'fact': ['carrot', 'belong to', 'list of root vegetables'], 'question_id': '4429'}, '1736': {'fact_surface': '[[chair]] is related to [[sit]]', 'answer': 'chair', 'question': 'Which object is related to sit', 'img_file': 'ILSVRC2012_test_00000499.JPEG', 'kb_source': 'conceptnet', 'fact': ['chair', 'related to', 'it'], 'question_id': '908'}, '1737': {'fact_surface': '[[trombone]] is related to [[music]]', 'answer': 'trombone', 'question': 'Which object in this image is closely related to music', 'img_file': 'ILSVRC2012_test_00000499.JPEG', 'kb_source': 'conceptnet', 'fact': ['trombone', 'related to', 'music'], 'question_id': '909'}, '1738': {'fact_surface': '[[vegetables]] belongs to the category of [[Food]]', 'answer': 'vegetable', 'question': 'Which objects in this image are considered as food?', 'img_file': 'ILSVRC2012_test_00009502.JPEG', 'kb_source': 'dbpedia', 'fact': ['vegetable', 'belong to', 'food'], 'question_id': '4427'}, '1739': {'fact_surface': '[[Glass]] is [[considered fragile]]', 'answer': 'glass', 'question': 'Which object in this image is considered fragile?', 'img_file': 'COCO_val2014_000000102517.jpg', 'kb_source': 'conceptnet', 'fact': ['glass', 'has property', 'consider fragile'], 'question_id': '2916'}, '1740': {'fact_surface': '[[a boat]] can be used for [[transportation at sea]]', 'answer': 'boat', 'question': 'what object in this image can be used for transportation at sea?', 'img_file': 'COCO_val2014_000000104629.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'used for', 'transportation at sea'], 'question_id': '1696'}, '1741': {'fact_surface': '[[a boat]] is used for [[floating and moving on the water]]', 'answer': 'boat', 'question': 'which object in this image can be used for floating and moving on water?', 'img_file': 'COCO_val2014_000000104629.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'used for', 'float and move on water'], 'question_id': '1697'}, '1742': {'fact_surface': '[[a boat]] is for [[crossing an ocean]]', 'answer': 'boat', 'question': 'what object in this image is used for crossing an ocean?', 'img_file': 'COCO_val2014_000000104629.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'used for', 'cross ocean'], 'question_id': '1695'}, '1743': {'fact_surface': '[[fig]] belongs to the category of [[Food]]', 'answer': 'fig', 'question': 'Which object in the centre of this image belongs to the category Food?', 'img_file': 'ILSVRC2012_test_00042247.JPEG', 'kb_source': 'dbpedia', 'fact': ['fig', 'belong to', 'food'], 'question_id': '1690'}, '1744': {'fact_surface': 'You can use [[a boat]] to [[travel across water]]', 'answer': 'boat', 'question': 'which object in this image can be used to travel across water?', 'img_file': 'COCO_val2014_000000104629.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'used for', 'travel across water'], 'question_id': '1698'}, '1745': {'fact_surface': '[[A boat]] is [[a mode of transportation]]', 'answer': 'boat', 'question': 'which object in this image is a mode of transportation?', 'img_file': 'COCO_val2014_000000104629.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'is a', 'mode of transportation'], 'question_id': '1699'}, '1746': {'fact_surface': '[[cell phone]] belongs to the category of [[Communication]]', 'answer': 'cell phone', 'question': 'Which object in this image belongs to the category Communication?', 'img_file': 'COCO_val2014_000000114453.jpg', 'kb_source': 'dbpedia', 'fact': ['cell phone', 'belong to', 'communication'], 'question_id': '1479'}, '1747': {'fact_surface': '[[Water]] can [[be liquid, ice, or steam]]', 'answer': 'water', 'question': 'what object in this image is capable of being in liquid, ice, or steam form?', 'img_file': 'COCO_val2014_000000129175.jpg', 'kb_source': 'conceptnet', 'fact': ['water', 'capable of', 'be liquid ice or steam'], 'question_id': '4228'}, '1748': {'fact_surface': '[[boats]] can be used for [[transport]]', 'answer': 'boat', 'question': 'Which object in this image is used for transport?', 'img_file': 'COCO_val2014_000000129175.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'used for', 'transport'], 'question_id': '4229'}, '1749': {'fact_surface': '[[horses]] are [[beasts of burden]]', 'answer': 'horse', 'question': 'Which object in this image is a beast of burden?', 'img_file': 'COCO_val2014_000000002302.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'is a', 'beast of burden'], 'question_id': '4225'}, '1750': {'fact_surface': '[[boats]] usually [[float on water]]', 'answer': 'boat', 'question': 'which object in this image can float on water?', 'img_file': 'COCO_val2014_000000129175.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'capable of', 'float on water'], 'question_id': '4227'}, '1751': {'fact_surface': '[[car]] may be faster than [[horse]]', 'answer': 'car', 'question': 'Which object in this image can have a higher speed than horse?', 'img_file': 'COCO_val2014_000000104176.jpg', 'kb_source': 'webchild', 'fact': ['car', 'fast', 'horse'], 'question_id': '4220'}, '1752': {'fact_surface': '[[All living humans]] have [[a head]]', 'answer': 'head', 'question': 'Which object in this image belongs to a human being?', 'img_file': 'COCO_val2014_000000104176.jpg', 'kb_source': 'conceptnet', 'fact': ['all live human', 'has a', 'head'], 'question_id': '4221'}, '1753': {'fact_surface': '[[hair]] is part of [[a head]].', 'answer': 'head', 'question': 'Which object of this image has hair', 'img_file': 'COCO_val2014_000000104176.jpg', 'kb_source': 'conceptnet', 'fact': ['hair', 'part of', 'head'], 'question_id': '4222'}, '1754': {'fact_surface': '[[head]] is related to [[brain]]', 'answer': 'head', 'question': 'Which object in this image contains brain?', 'img_file': 'COCO_val2014_000000104176.jpg', 'kb_source': 'conceptnet', 'fact': ['head', 'related to', 'brain'], 'question_id': '4223'}, '1755': {'fact_surface': '[[teddy bear]] belongs to the category of [[Toy]]', 'answer': 'teddy bear', 'question': 'What is the toy in the image?', 'img_file': 'COCO_val2014_000000135975.jpg', 'kb_source': 'dbpedia', 'fact': ['teddy bear', 'belong to', 'toy'], 'question_id': '20'}, '1756': {'fact_surface': '(elephant,/r/UsedFor,transport)', 'answer': 'transport', 'question': 'What is the elephant in the image used for?', 'img_file': 'COCO_val2014_000000109819.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'used for', 'transport'], 'question_id': '21'}, '1757': {'fact_surface': '[[Frisbees]] are [[flat discs]]', 'answer': 'frisbee', 'question': 'Which object in this image is a flat disc?', 'img_file': 'COCO_val2014_000000145734.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'is a', 'flat disc'], 'question_id': '5580'}, '1758': {'fact_surface': '[[A piano]] usually has [[white keys]]', 'answer': 'piano', 'question': 'Which object in this image usually has white keys?', 'img_file': 'ILSVRC2012_test_00058802.JPEG', 'kb_source': 'conceptnet', 'fact': ['piano', 'has a', 'white key'], 'question_id': '1069'}, '1759': {'fact_surface': '[[a piano]] is [[a large musical instrument]]', 'answer': 'piano', 'question': 'Which object in this image is a large musical instrument?', 'img_file': 'ILSVRC2012_test_00058802.JPEG', 'kb_source': 'conceptnet', 'fact': ['piano', 'is a', 'large musical instrument'], 'question_id': '1068'}, '1760': {'fact_surface': '[[tabbouleh]] is related to [[salad]]', 'answer': 'salad', 'question': 'What in this image is most closely related to tabbouleh?', 'img_file': 'ILSVRC2012_test_00003523.JPEG', 'kb_source': 'conceptnet', 'fact': ['tabbouleh', 'related to', 'salad'], 'question_id': '1061'}, '1761': {'fact_surface': '[[A vase]] is often [[used for holding flowers]]', 'answer': 'vase', 'question': 'Which object in this image could be used to hold flowers?', 'img_file': 'COCO_val2014_000000013632.jpg', 'kb_source': 'conceptnet', 'fact': ['vase', 'has property', 'use for hold flower'], 'question_id': '1060'}, '1762': {'fact_surface': '[[Dogs]] will [[eat almost anything]]', 'answer': 'dog', 'question': 'What shown here can eat almost anything?', 'img_file': 'ILSVRC2012_test_00000172.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'capable of', 'eat almost anything'], 'question_id': '1067'}, '1763': {'fact_surface': '[[hot dogs]] are [[a traditional American food]]', 'answer': 'hot dog', 'question': 'Which object described in this image is a kind of traditional american food?', 'img_file': 'COCO_val2014_000000118367.jpg', 'kb_source': 'conceptnet', 'fact': ['hot dog', 'is a', 'traditional american food'], 'question_id': '4921'}, '1764': {'fact_surface': '[[car]] is related to [[transportation]]', 'answer': 'car', 'question': 'Which object in this image is related to transportation?', 'img_file': 'ILSVRC2012_test_00000089.JPEG', 'kb_source': 'conceptnet', 'fact': ['car', 'related to', 'transportation'], 'question_id': '2280'}, '1765': {'fact_surface': '[[tv]] belongs to the category of [[Entertainment]]', 'answer': 'tv', 'question': 'Which object in this image is for Entertainment?', 'img_file': 'COCO_val2014_000000000139.jpg', 'kb_source': 'dbpedia', 'fact': ['tv', 'belong to', 'entertainment'], 'question_id': '4534'}, '1766': {'fact_surface': '[[goat]] are much more active than [[cow]]', 'answer': 'cow', 'question': 'which object in this image is less active than goat?', 'img_file': 'ILSVRC2012_test_00008031.JPEG', 'kb_source': 'webchild', 'fact': ['goat', 'active', 'cow'], 'question_id': '4823'}, '1767': {'fact_surface': '[[books]] contain [[text and pictures]]', 'answer': 'book', 'question': 'Which object in this image contains text and images?', 'img_file': 'COCO_val2014_000000026942.jpg', 'kb_source': 'conceptnet', 'fact': ['book', 'has a', 'text and picture'], 'question_id': '4820'}, '1768': {'fact_surface': '[[laptop]] run slower than [[desktop]]', 'answer': 'laptop', 'question': 'what object in this image runs slower than a desktop?', 'img_file': 'ILSVRC2012_test_00057293.JPEG', 'kb_source': 'webchild', 'fact': ['laptop', 'slow', 'desktop'], 'question_id': '186'}, '1769': {'fact_surface': '[[an accordion]] is like [[a hand-held piano]]', 'answer': 'accordion', 'question': 'Which object in this image is like a hand-held piano', 'img_file': 'ILSVRC2012_test_00040602.JPEG', 'kb_source': 'conceptnet', 'fact': ['accordion', 'is a', 'hand hold piano'], 'question_id': '188'}, '1770': {'fact_surface': '[[an accordion]] has [[a keyboard]]', 'answer': 'accordion', 'question': 'Which object in this image has a keyboard?', 'img_file': 'ILSVRC2012_test_00040602.JPEG', 'kb_source': 'conceptnet', 'fact': ['accordion', 'has a', 'keyboard'], 'question_id': '189'}, '1771': {'fact_surface': '[[a TV]] can [[display images]].', 'answer': 'tv', 'question': 'Which appliance in this image can be used to display images?', 'img_file': 'ILSVRC2012_test_00000595.JPEG', 'kb_source': 'conceptnet', 'fact': ['tv', 'capable of', 'display image'], 'question_id': '869'}, '1772': {'fact_surface': '[[a sofa]] is for [[sleeping]]', 'answer': 'sofa', 'question': 'What could you sleep on ?', 'img_file': 'COCO_val2014_000000142248.jpg', 'kb_source': 'conceptnet', 'fact': ['sofa', 'used for', 'sleep'], 'question_id': '3448'}, '1773': {'fact_surface': '[[donut]] belongs to the category of [[Food]]', 'answer': 'donut', 'question': 'Which object in this image is food?', 'img_file': 'COCO_val2014_000000003001.jpg', 'kb_source': 'dbpedia', 'fact': ['donut', 'belong to', 'food'], 'question_id': '3440'}, '1774': {'fact_surface': '[[cars]] have [[doors]]', 'answer': 'car', 'question': 'What thing in the image has doors?', 'img_file': 'ILSVRC2012_test_00053268.JPEG', 'kb_source': 'conceptnet', 'fact': ['car', 'has a', 'door'], 'question_id': '866'}, '1775': {'fact_surface': '[[The cat]] is capable of [[innocently knocking things off a table]]', 'answer': 'cat', 'question': 'Which object in this image is capable of innocently knock thing off table?', 'img_file': 'COCO_val2014_000000025138.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'innocently knock thing off table'], 'question_id': '2025'}, '1776': {'fact_surface': '[[balance beam]] is a subclass of [[gymnastics apparatus]]', 'answer': 'beam', 'question': 'Which object in this image is a gymnastics apparatus?', 'img_file': 'ILSVRC2012_test_00025390.JPEG', 'kb_source': 'conceptnet', 'fact': ['beam', 'is a', 'gymnastics apparatus'], 'question_id': '2022'}, '1777': {'fact_surface': '[[Orange]] is [[a colour of the rainbow]]', 'answer': 'orange', 'question': 'Which object in this image is also a colour of the rainbow?', 'img_file': 'ILSVRC2012_test_00007770.JPEG', 'kb_source': 'conceptnet', 'fact': ['orange', 'is a', 'colour of rainbow'], 'question_id': '2029'}, '1778': {'fact_surface': '[[A banjo]] is [[a musical instrument]]', 'answer': 'banjo', 'question': 'Which object in this image is a musical instrument?', 'img_file': 'ILSVRC2012_test_00001251.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'is a', 'musical instrument'], 'question_id': '2758'}, '1779': {'fact_surface': '[[a banjo]] is for [[strumming]]', 'answer': 'banjo', 'question': 'Which object in this image is used for strumming?', 'img_file': 'ILSVRC2012_test_00001251.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'used for', 'strum'], 'question_id': '2759'}, '1780': {'fact_surface': '[[a monitor]] can [[display images]].', 'answer': 'monitor', 'question': 'What device can display images?', 'img_file': 'ILSVRC2012_test_00060690.JPEG', 'kb_source': 'conceptnet', 'fact': ['monitor', 'capable of', 'display image'], 'question_id': '5216'}, '1781': {'fact_surface': '[[donut]] belongs to the category of [[Food]]', 'answer': 'donut', 'question': 'which thing has a small hole in the middle as a part?', 'img_file': 'COCO_val2014_000000111024.jpg', 'kb_source': 'dbpedia', 'fact': ['donut', 'belong to', 'food'], 'question_id': '5217'}, '1782': {'fact_surface': '[[donut]] belongs to the category of [[Food and drink in Canada]]', 'answer': 'donut', 'question': 'Which object can be classified into the category of Food and drink in Canada?', 'img_file': 'COCO_val2014_000000111024.jpg', 'kb_source': 'dbpedia', 'fact': ['donut', 'belong to', 'food and drink in canada'], 'question_id': '5218'}, '1783': {'fact_surface': '[[plates]] belongs to the category of [[Kitchenware]]', 'answer': 'plate', 'question': 'What do you call the Kitchenware on which the food is served? ', 'img_file': 'COCO_val2014_000000111024.jpg', 'kb_source': 'dbpedia', 'fact': ['plate', 'belong to', 'kitchenware'], 'question_id': '5219'}, '1784': {'fact_surface': '[[wool]] is related to [[sheep]]', 'answer': 'sheep', 'question': 'What woolly animal is seen here?', 'img_file': 'COCO_val2014_000000109888.jpg', 'kb_source': 'conceptnet', 'fact': ['wool', 'related to', 'sheep'], 'question_id': '418'}, '1785': {'fact_surface': '[[pizza]] is related to [[bread]]', 'answer': 'bread', 'question': 'What is base of this pizza?', 'img_file': 'COCO_val2014_000000027009.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'related to', 'bread'], 'question_id': '419'}, '1786': {'fact_surface': '[[a microwave]] is for [[cooking food fast]]', 'answer': 'microwave', 'question': 'Which object in this image is used for cooking food fast?', 'img_file': 'ILSVRC2012_test_00016160.JPEG', 'kb_source': 'conceptnet', 'fact': ['microwave', 'used for', 'cook food fast'], 'question_id': '3056'}, '1787': {'fact_surface': '[[a handbag]] is for [[carrying things]]', 'answer': 'handbag', 'question': 'Which object in this image can be used to carry things?', 'img_file': 'ILSVRC2012_test_00016160.JPEG', 'kb_source': 'conceptnet', 'fact': ['handbag', 'used for', 'carry thing'], 'question_id': '3054'}, '1788': {'fact_surface': '[[Chairs]] are for [[sitting]]', 'answer': 'chair', 'question': 'What object in this image is used for sitting on?', 'img_file': 'ILSVRC2012_test_00016160.JPEG', 'kb_source': 'conceptnet', 'fact': ['chair', 'is a', 'it'], 'question_id': '3055'}, '1789': {'fact_surface': '[[microwaves]] can [[heat food]]', 'answer': 'microwave', 'question': 'which object in this image can be used to heat food?', 'img_file': 'ILSVRC2012_test_00016160.JPEG', 'kb_source': 'conceptnet', 'fact': ['microwave', 'capable of', 'heat food'], 'question_id': '3053'}, '1790': {'fact_surface': '[[volleyball]] is a kind of [[ball sport]].', 'answer': 'volleyball', 'question': 'What ball sport is being played in this image?', 'img_file': 'ILSVRC2012_test_00008641.JPEG', 'kb_source': 'conceptnet', 'fact': ['volleyball', 'is a', 'ball sport'], 'question_id': '3050'}, '1791': {'fact_surface': '[[car]] are bigger than [[motorcycle]]', 'answer': 'car', 'question': 'What is the object used for transportation in this image is bigger than motorcycle?', 'img_file': 'COCO_val2014_000000102741.jpg', 'kb_source': 'webchild', 'fact': ['car', 'big', 'motorcycle'], 'question_id': '4597'}, '1792': {'fact_surface': '[[plectrum]] is related to [[guitar]]', 'answer': 'guitar', 'question': 'Which object in this image is related to plectrum?', 'img_file': 'ILSVRC2012_test_00001387.JPEG', 'kb_source': 'conceptnet', 'fact': ['plectrum', 'related to', 'guitar'], 'question_id': '1317'}, '1793': {'fact_surface': 'A [[mushroom]] is a [[fungus]]', 'answer': 'mushroom', 'question': 'which kind of fungus can we see in this image', 'img_file': 'ILSVRC2012_test_00009605.JPEG', 'kb_source': 'conceptnet', 'fact': ['mushroom', 'is a', 'fungus'], 'question_id': '1316'}, '1794': {'fact_surface': 'You are likely to find [[a bookshelf]] in [[a furniture store]]', 'answer': 'furniture store', 'question': 'Where does the object in the image can be found in?', 'img_file': 'ILSVRC2012_test_00002176.JPEG', 'kb_source': 'conceptnet', 'fact': ['bookshelf', 'at location', 'furniture store'], 'question_id': '1315'}, '1795': {'fact_surface': '[[a book]] is used for [[passing on what author knows]]', 'answer': 'book', 'question': 'Which object in this image is used to pass on what author knows?', 'img_file': 'ILSVRC2012_test_00002176.JPEG', 'kb_source': 'conceptnet', 'fact': ['book', 'used for', 'pass on what author know'], 'question_id': '1314'}, '1796': {'fact_surface': '[[a bookshelf]] can be used to [[hold books]]', 'answer': 'bookshelf', 'question': 'Which object in this image is used for holding book?', 'img_file': 'ILSVRC2012_test_00002176.JPEG', 'kb_source': 'conceptnet', 'fact': ['bookshelf', 'used for', 'hold book'], 'question_id': '1313'}, '1797': {'fact_surface': '[[grass]] is related to [[lawn]]', 'answer': 'grass', 'question': 'Which object in this image is related to lawn?', 'img_file': 'ILSVRC2012_test_00042528.JPEG', 'kb_source': 'conceptnet', 'fact': ['grass', 'related to', 'lawn'], 'question_id': '1310'}, '1798': {'fact_surface': 'You are likely to find [[a guitar]] in [[a rock band]]', 'answer': 'guitar', 'question': 'Which musical instrument in this image can be found in rock band?', 'img_file': 'ILSVRC2012_test_00001387.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'at location', 'rock band'], 'question_id': '1319'}, '1799': {'fact_surface': 'You can use [[a guitar]] to [[play a song]]', 'answer': 'guitar', 'question': 'Which object in this image is used for playing songs?', 'img_file': 'ILSVRC2012_test_00001387.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'used for', 'play song'], 'question_id': '1318'}, '1800': {'fact_surface': '[[a bus]] is for [[mass transportaion]]', 'answer': 'bus', 'question': 'Which object in the background is used for mass transportation?', 'img_file': 'COCO_val2014_000000120340.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'used for', 'mass transportaion'], 'question_id': '3948'}, '1801': {'fact_surface': 'An [[cell phone]] can [[vibrate]].', 'answer': 'cell phone', 'question': 'What can vibrate in this image?', 'img_file': 'COCO_val2014_000000112997.jpg', 'kb_source': 'conceptnet', 'fact': ['cell phone', 'capable of', 'vibrate'], 'question_id': '3944'}, '1802': {'fact_surface': 'An [[cell phone]] can [[ring]].', 'answer': 'cell phone', 'question': 'What can ring in this image?', 'img_file': 'COCO_val2014_000000112997.jpg', 'kb_source': 'conceptnet', 'fact': ['cell phone', 'capable of', 'ring'], 'question_id': '3945'}, '1803': {'fact_surface': '[[cell phone]] is related to [[call]]', 'answer': 'cell phone', 'question': 'Which object in this image is related to making a call?', 'img_file': 'COCO_val2014_000000112997.jpg', 'kb_source': 'conceptnet', 'fact': ['cell phone', 'related to', 'call'], 'question_id': '3946'}, '1804': {'fact_surface': '[[Bicycling]] is [[a good form of exercise]]', 'answer': 'bicycle', 'question': 'What sport is kind of good exercise?', 'img_file': 'COCO_val2014_000000120340.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'is a', 'good form of exercise'], 'question_id': '3947'}, '1805': {'fact_surface': '[[bears]] are [[dangerous animals]]', 'answer': 'bear', 'question': 'What can maul you to death?', 'img_file': 'COCO_val2014_000000008401.jpg', 'kb_source': 'conceptnet', 'fact': ['bear', 'is a', 'dangerous animal'], 'question_id': '4059'}, '1806': {'fact_surface': '[[motorcycle]] is used for [[riding]].', 'answer': 'motorcycle', 'question': 'Which object in this image is used for riding?', 'img_file': 'COCO_val2014_000000107990.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'used for', 'ride'], 'question_id': '3612'}, '1807': {'fact_surface': 'You are likely to find [[motorcycle]] in [[the street]].', 'answer': 'motorcycle', 'question': 'which object often parks on the street', 'img_file': 'COCO_val2014_000000107990.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'at location', 'street'], 'question_id': '3613'}, '1808': {'fact_surface': '[[tennis]] is related to [[racquet]]', 'answer': 'racquet', 'question': 'Which type of object in this image is also used for tennis?', 'img_file': 'ILSVRC2012_test_00048422.JPEG', 'kb_source': 'conceptnet', 'fact': ['tennis', 'related to', 'racquet'], 'question_id': '3614'}, '1809': {'fact_surface': '[[A person]] could [[die from an infection]]', 'answer': 'person', 'question': 'which object in this image can die from infection?', 'img_file': 'ILSVRC2012_test_00048422.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'die from infection'], 'question_id': '3615'}, '1810': {'fact_surface': '[[people]] can [[read letters]]', 'answer': 'person', 'question': 'which object in this image is capable of reading letters?', 'img_file': 'ILSVRC2012_test_00048422.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'read letter'], 'question_id': '3616'}, '1811': {'fact_surface': '[[people]] can [[drink coffee]]', 'answer': 'person', 'question': 'which object in this image can drink coffee?', 'img_file': 'ILSVRC2012_test_00048422.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'drink coffee'], 'question_id': '3617'}, '1812': {'fact_surface': '[[ping pong ball]] is related to [[table tennis]]', 'answer': 'ping pong ball', 'question': 'Which object in the image is related to ping pong ball?', 'img_file': 'ILSVRC2012_test_00048422.JPEG', 'kb_source': 'conceptnet', 'fact': ['ping pong ball', 'related to', 'table tennis'], 'question_id': '3618'}, '1813': {'fact_surface': '[[a refrigerator]] can [[store food for long times]]', 'answer': 'refrigerator', 'question': 'Which object in this image is capable of store food for long time?', 'img_file': 'COCO_val2014_000000126983.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'capable of', 'store food for long time'], 'question_id': '3619'}, '1814': {'fact_surface': '[[a train]] are used to [[go to a distant place]].', 'answer': 'train', 'question': 'Which object in this image could be used to go to distant places?', 'img_file': 'COCO_val2014_000000026226.jpg', 'kb_source': 'conceptnet', 'fact': ['train', 'used for', 'go to distant place'], 'question_id': '3842'}, '1815': {'fact_surface': 'You are likely to find [[a cello]] in [[a string quartet]]', 'answer': 'cello', 'question': 'Which object in this image might sometimes be found in a string quartet?', 'img_file': 'ILSVRC2012_test_00005137.JPEG', 'kb_source': 'conceptnet', 'fact': ['cello', 'at location', 'string quartet'], 'question_id': '2561'}, '1816': {'fact_surface': '[[A cello]] is like [[a big violin]]', 'answer': 'cello', 'question': 'Which object in this image is like a big violin?', 'img_file': 'ILSVRC2012_test_00005137.JPEG', 'kb_source': 'conceptnet', 'fact': ['cello', 'is a', 'big violin'], 'question_id': '2560'}, '1817': {'fact_surface': '*Something you find at [[the supermarket]] is [[people]]', 'answer': 'person', 'question': 'Which objects in this image might be found at a supermarket?', 'img_file': 'ILSVRC2012_test_00005137.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'at location', 'supermarket'], 'question_id': '2563'}, '1818': {'fact_surface': '[[People]] can [[sit around a table]]', 'answer': 'person', 'question': 'Which objects in this image are capable of sitting around a table?', 'img_file': 'ILSVRC2012_test_00005137.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'sit around table'], 'question_id': '2562'}, '1819': {'fact_surface': '[[Cheese]] is [[fermented milk]]', 'answer': 'cheese', 'question': 'Which object in this image is a type of fermented milk?', 'img_file': 'COCO_val2014_000000011042.jpg', 'kb_source': 'conceptnet', 'fact': ['cheese', 'is a', 'ferment milk'], 'question_id': '5029'}, '1820': {'fact_surface': '[[Pizza]] is often [[considered unhealthy]]', 'answer': 'pizza', 'question': 'Which object in this image is often considered unhealthy?', 'img_file': 'COCO_val2014_000000011042.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'has property', 'consider unhealthy'], 'question_id': '5028'}, '1821': {'fact_surface': '[[Normandy pippin]] is related to [[apple]]', 'answer': 'apple', 'question': 'Which object in the image is related to Normandy pippins?', 'img_file': 'COCO_val2014_000000007913.jpg', 'kb_source': 'conceptnet', 'fact': ['normandy pippin', 'related to', 'apple'], 'question_id': '5021'}, '1822': {'fact_surface': '[[zebras]] are [[black and white]].', 'answer': 'zebra', 'question': 'which object in this image is black and white?', 'img_file': 'COCO_val2014_000000132612.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has property', 'black and white'], 'question_id': '5020'}, '1823': {'fact_surface': '[[an apple]] is [[a piece of fruit]]', 'answer': 'apple', 'question': 'Which round object in this image is a piece of fruit?', 'img_file': 'COCO_val2014_000000007913.jpg', 'kb_source': 'conceptnet', 'fact': ['apple', 'is a', 'piece of fruit'], 'question_id': '5023'}, '1824': {'fact_surface': '[[fruits]] belongs to the category of [[Food]]', 'answer': 'fruit', 'question': 'Which object in this image is a kind of Food?', 'img_file': 'COCO_val2014_000000007913.jpg', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'food'], 'question_id': '5022'}, '1825': {'fact_surface': '[[apple]] is [[round]].', 'answer': 'apple', 'question': 'What round object is in this image?', 'img_file': 'COCO_val2014_000000007913.jpg', 'kb_source': 'conceptnet', 'fact': ['apple', 'has property', 'round'], 'question_id': '5025'}, '1826': {'fact_surface': '[[an apple]] is [[a piece of fruit]]', 'answer': 'apple', 'question': 'Which round object in this image is a piece of fruit?', 'img_file': 'COCO_val2014_000000007913.jpg', 'kb_source': 'conceptnet', 'fact': ['apple', 'is a', 'piece of fruit'], 'question_id': '5024'}, '1827': {'fact_surface': '[[apples]] are [[sweet and juicy]]', 'answer': 'apple', 'question': 'What is the sweet and juicy object in this image?', 'img_file': 'COCO_val2014_000000007913.jpg', 'kb_source': 'conceptnet', 'fact': ['apple', 'has property', 'sweet and juicy'], 'question_id': '5027'}, '1828': {'fact_surface': '*Something you find at [[a grocery store]] is [[apples]]', 'answer': 'apple', 'question': 'What object in this image is found in a grocery store?', 'img_file': 'COCO_val2014_000000007913.jpg', 'kb_source': 'conceptnet', 'fact': ['apple', 'at location', 'grocery store'], 'question_id': '5026'}, '1829': {'fact_surface': '[[laptop]] were usually weaker than [[desktop]]', 'answer': 'laptop', 'question': 'which object is weaker than desktop?', 'img_file': 'ILSVRC2012_test_00021967.JPEG', 'kb_source': 'webchild', 'fact': ['laptop', 'weak', 'desktop'], 'question_id': '4440'}, '1830': {'fact_surface': '[[cake]] is related to [[birthday]]', 'answer': 'cake', 'question': 'Which object in this image is used for birthday?', 'img_file': 'COCO_val2014_000000020641.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'related to', 'birthday'], 'question_id': '4446'}, '1831': {'fact_surface': 'You are likely to find [[a chair]] in [[kitchen]]', 'answer': 'chair', 'question': 'What can be found in the right top of this image around the table?', 'img_file': 'COCO_val2014_000000020641.jpg', 'kb_source': 'conceptnet', 'fact': ['chair', 'at location', 'kitchen'], 'question_id': '4447'}, '1832': {'fact_surface': '[[a cake]] is for [[a party]]', 'answer': 'cake', 'question': 'What object is used for party?', 'img_file': 'COCO_val2014_000000020641.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'used for', 'party'], 'question_id': '4448'}, '1833': {'fact_surface': 'You are likely to find [[a boy]] in [[a playground]]', 'answer': 'boy', 'question': 'What can be found in this playground?', 'img_file': 'COCO_val2014_000000105448.jpg', 'kb_source': 'conceptnet', 'fact': ['boy', 'at location', 'playground'], 'question_id': '4449'}, '1834': {'fact_surface': 'You can use [[a basketball]] to [[spin on a finger]]', 'answer': 'basketball', 'question': 'What can you use in the image to spin on your finger?', 'img_file': 'ILSVRC2012_test_00049700.JPEG', 'kb_source': 'conceptnet', 'fact': ['basketball', 'used for', 'spin on finger'], 'question_id': '961'}, '1835': {'fact_surface': '(scissors,/r/UsedFor,cutting)', 'answer': 'scissors', 'question': 'Which object in this image can be used for cutting', 'img_file': 'COCO_val2014_000000151790.jpg', 'kb_source': 'conceptnet', 'fact': ['scissors', 'used for', 'cut'], 'question_id': '968'}, '1836': {'fact_surface': '[[A rubber eraser]] can be used to [[erase pencil]]', 'answer': 'rubber eraser', 'question': 'Which object in this image can be used to erase pencil', 'img_file': 'COCO_val2014_000000151790.jpg', 'kb_source': 'conceptnet', 'fact': ['rubber eraser', 'used for', 'erase pencil'], 'question_id': '969'}, '1837': {'fact_surface': '[[sofa]] is a subclass of [[furniture that can support a person]]', 'answer': 'sofa', 'question': ' Which object in this image is a furniture that can load-bearing person?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'is a', 'furniture that can support person'], 'question_id': '1246'}, '1838': {'fact_surface': '[[a bow]] is used for [[archery]].', 'answer': 'bow', 'question': 'Which object in the image is related to archery?', 'img_file': 'ILSVRC2012_test_00024387.JPEG', 'kb_source': 'conceptnet', 'fact': ['bow', 'used for', 'archery'], 'question_id': '649'}, '1839': {'fact_surface': '[[cake]] is related to [[weddings]]', 'answer': 'cake', 'question': 'Which object in this image is related to wedding?', 'img_file': 'COCO_val2014_000000136270.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'related to', 'wedding'], 'question_id': '5199'}, '1840': {'fact_surface': '[[cake]] is related to [[birthday confection]]', 'answer': 'cake', 'question': 'Which object in this image is related to birthday party?', 'img_file': 'COCO_val2014_000000136270.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'related to', 'birthday confection'], 'question_id': '5198'}, '1841': {'fact_surface': 'You are likely to find [[a metronome]] in [[a music studio]]', 'answer': 'metronome', 'question': 'What musical instrument can be found in this place?', 'img_file': 'ILSVRC2012_test_00015696.JPEG', 'kb_source': 'conceptnet', 'fact': ['metronome', 'at location', 'music studio'], 'question_id': '3234'}, '1842': {'fact_surface': 'You are likely to find [[a metronome]] in [[a music studio]]', 'answer': 'metronome', 'question': 'What musical instrument can be found in this place?', 'img_file': 'ILSVRC2012_test_00015696.JPEG', 'kb_source': 'conceptnet', 'fact': ['metronome', 'at location', 'music studio'], 'question_id': '3235'}, '1843': {'fact_surface': '[[tennis racket]] belongs to the category of [[Game equipment]]', 'answer': 'tennis racket', 'question': 'What kind of Game equipment is used in this image?', 'img_file': 'COCO_val2014_000000133090.jpg', 'kb_source': 'dbpedia', 'fact': ['tennis racket', 'belong to', 'game equipment'], 'question_id': '5195'}, '1844': {'fact_surface': '[[tennis racket]] is related to [[string]]', 'answer': 'tennis racket', 'question': 'Which object in this image is strung?', 'img_file': 'COCO_val2014_000000133090.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis racket', 'related to', 'string'], 'question_id': '5194'}, '1845': {'fact_surface': '[[a cake]] is used for [[celebrating someones special event]]', 'answer': 'cake', 'question': \"Which object in this image is used for celebrate someone's birthday?\", 'img_file': 'COCO_val2014_000000136270.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'used for', 'celebrate someone special event'], 'question_id': '5197'}, '1846': {'fact_surface': '[[a banjo]] can be used for [[producing a musical sound]]', 'answer': 'banjo', 'question': 'Which object in this image can produce a musical sound?', 'img_file': 'ILSVRC2012_test_00028677.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'used for', 'produce musical sound'], 'question_id': '3239'}, '1847': {'fact_surface': 'Things that are often found together are [[computer]] and [[monitor]].', 'answer': 'monitor', 'question': 'What object in the image is related to computer?', 'img_file': 'ILSVRC2012_test_00046689.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'related to', 'monitor'], 'question_id': '1961'}, '1848': {'fact_surface': '[[Rain]] can [[cause floods]]', 'answer': 'rain', 'question': 'Which object in this image is capable of causing floods?', 'img_file': 'COCO_val2014_000000007394.jpg', 'kb_source': 'conceptnet', 'fact': ['rain', 'capable of', 'cause flood'], 'question_id': '1963'}, '1849': {'fact_surface': '[[pineapples]] are [[prickley]]', 'answer': 'pineapple', 'question': 'Which object in this image has a prickle?', 'img_file': 'ILSVRC2012_test_00047632.JPEG', 'kb_source': 'conceptnet', 'fact': ['pineapple', 'is a', 'prickley'], 'question_id': '1674'}, '1850': {'fact_surface': 'You are likely to find [[Pineapple]] in [[the supermarket]].', 'answer': 'pineapple', 'question': 'which object in this image can we always buy in the supermarket', 'img_file': 'ILSVRC2012_test_00047632.JPEG', 'kb_source': 'conceptnet', 'fact': ['pineapple', 'at location', 'supermarket'], 'question_id': '1675'}, '1851': {'fact_surface': '[[motorcycle]] are far more dangerous than [[car]]', 'answer': 'car', 'question': 'what vehicle is safer than the vehicle in the image?', 'img_file': 'COCO_val2014_000000136833.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'dangerous', 'car'], 'question_id': '1670'}, '1852': {'fact_surface': '[[motorcycle]] belongs to the category of [[Transport]]', 'answer': 'motorcycle', 'question': 'What are the people driving?', 'img_file': 'COCO_val2014_000000136833.jpg', 'kb_source': 'dbpedia', 'fact': ['motorcycle', 'belong to', 'transport'], 'question_id': '1671'}, '1853': {'fact_surface': '[[pineapples]] have [[yellow flesh]]', 'answer': 'pineapple', 'question': 'What thing shown here has yellow flesh?', 'img_file': 'ILSVRC2012_test_00047632.JPEG', 'kb_source': 'conceptnet', 'fact': ['pineapple', 'has a', 'yellow flesh'], 'question_id': '1672'}, '1854': {'fact_surface': '[[pineapple]] belongs to the category of [[Bromeliaceae cultivar]]', 'answer': 'pineapple', 'question': 'Which object in this image belongs to the class Bromeliaceae cultivar?', 'img_file': 'ILSVRC2012_test_00047632.JPEG', 'kb_source': 'dbpedia', 'fact': ['pineapple', 'belong to', 'bromeliaceae cultivar'], 'question_id': '1673'}, '1855': {'fact_surface': '[[broccoli]] is [[very nutritious]]', 'answer': 'broccoli', 'question': 'Which vegetable in this image is very nutritious?', 'img_file': 'COCO_val2014_000000010785.jpg', 'kb_source': 'conceptnet', 'fact': ['broccoli', 'has property', 'very nutritious'], 'question_id': '1410'}, '1856': {'fact_surface': '[[A dog]] has [[fur]]', 'answer': 'dog', 'question': 'What shown here has a fur?', 'img_file': 'ILSVRC2012_test_00016140.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'has a', 'fur'], 'question_id': '4208'}, '1857': {'fact_surface': '[[desktop computer]] are larger than [[laptop]]', 'answer': 'laptop', 'question': 'which electronic object in this image is smaller than a desktop computer?', 'img_file': 'COCO_val2014_000000022371.jpg', 'kb_source': 'webchild', 'fact': ['desktop computer', 'large', 'laptop'], 'question_id': '4203'}, '1858': {'fact_surface': '[[dogs]] are [[animals humans keep as pets]]', 'answer': 'dog', 'question': 'What object in this image can be kept as a pet?', 'img_file': 'ILSVRC2012_test_00016140.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'is a', 'animal human keep as pet'], 'question_id': '4207'}, '1859': {'fact_surface': '[[a bookshelf]] is [[a place to put books]]', 'answer': 'bookshelf', 'question': 'Which object in this image is a place to put books?', 'img_file': 'ILSVRC2012_test_00056342.JPEG', 'kb_source': 'conceptnet', 'fact': ['bookshelf', 'is a', 'place to put book'], 'question_id': '5568'}, '1860': {'fact_surface': '[[a bookshelf]] can be used to [[hold books]]', 'answer': 'bookshelf', 'question': 'Which object in this image is used to hold books?', 'img_file': 'ILSVRC2012_test_00056342.JPEG', 'kb_source': 'conceptnet', 'fact': ['bookshelf', 'used for', 'hold book'], 'question_id': '5569'}, '1861': {'fact_surface': '[[A bicycle]] is [[a vehicle with two wheels]]', 'answer': 'bicycle', 'question': 'Which object in this image is a vehicle with two wheels?', 'img_file': 'COCO_val2014_000000125829.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'is a', 'vehicle with two wheel'], 'question_id': '5564'}, '1862': {'fact_surface': '[[a bookshelf]] is for [[storing novels]]', 'answer': 'bookshelf', 'question': 'Which object in this image is used for storing novels?', 'img_file': 'ILSVRC2012_test_00056342.JPEG', 'kb_source': 'conceptnet', 'fact': ['bookshelf', 'used for', 'store novel'], 'question_id': '5565'}, '1863': {'fact_surface': '[[a bookshelf]] is used for [[book storage]]', 'answer': 'bookshelf', 'question': 'Which object in this image is used for book storage?', 'img_file': 'ILSVRC2012_test_00056342.JPEG', 'kb_source': 'conceptnet', 'fact': ['bookshelf', 'used for', 'book storage'], 'question_id': '5566'}, '1864': {'fact_surface': '[[a book]] is for [[reading for pleasure]]', 'answer': 'book', 'question': 'Which object in this image can be read for pleasure?', 'img_file': 'ILSVRC2012_test_00056342.JPEG', 'kb_source': 'conceptnet', 'fact': ['book', 'used for', 'read for pleasure'], 'question_id': '5567'}, '1865': {'fact_surface': '[[A bicycle]] has [[two wheels and pedals]]', 'answer': 'bicycle', 'question': 'Which object in this image has two wheels and pedals?', 'img_file': 'COCO_val2014_000000125829.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'has a', 'two wheel and pedal'], 'question_id': '5560'}, '1866': {'fact_surface': '[[A bicycle]] has [[two weheels]]', 'answer': 'bicycle', 'question': 'Which object in this image has two wheels?', 'img_file': 'COCO_val2014_000000125829.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'has a', 'two weheels'], 'question_id': '5561'}, '1867': {'fact_surface': '[[a bicycle]] is also [[known as a bike]]', 'answer': 'bicycle', 'question': 'Which object in this image is known as bike?', 'img_file': 'COCO_val2014_000000125829.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'has property', 'know as bike'], 'question_id': '5562'}, '1868': {'fact_surface': '[[a bicycle]] is [[a human powered form of transportation]]', 'answer': 'bicycle', 'question': 'Which object in this image is a human power form of transportation?', 'img_file': 'COCO_val2014_000000125829.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'is a', 'human power form of transportation'], 'question_id': '5563'}, '1869': {'fact_surface': '[[bow]] is related to [[shoot]]', 'answer': 'bow', 'question': 'Which object in this image is related to shooting?', 'img_file': 'ILSVRC2012_test_00034423.JPEG', 'kb_source': 'conceptnet', 'fact': ['bow', 'related to', 'shoot'], 'question_id': '308'}, '1870': {'fact_surface': '[[kite]] is related to [[string attached]]', 'answer': 'string attach', 'question': 'What the toy in the image is attached on?', 'img_file': 'COCO_val2014_000000104841.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'related to', 'string attach'], 'question_id': '303'}, '1871': {'fact_surface': '[[A power drill]] can be used to [[drive screws]]', 'answer': 'drive screw', 'question': 'What thing can the object in this image do?', 'img_file': 'ILSVRC2012_test_00002300.JPEG', 'kb_source': 'conceptnet', 'fact': ['power drill', 'used for', 'drive screw'], 'question_id': '305'}, '1872': {'fact_surface': '[[motorcycle]] are just cooler than [[car]]', 'answer': 'motorcycle', 'question': 'Which one is cooler? this one or the car', 'img_file': 'COCO_val2014_000000116712.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'cool', 'car'], 'question_id': '306'}, '1873': {'fact_surface': '[[bow]] is related to [[weapon]]', 'answer': 'bow', 'question': 'what is weapon in the image?', 'img_file': 'ILSVRC2012_test_00034423.JPEG', 'kb_source': 'conceptnet', 'fact': ['bow', 'related to', 'weapon'], 'question_id': '307'}, '1874': {'fact_surface': '[[a sofa]] is for [[resting upon]]', 'answer': 'sofa', 'question': 'Which object in this image is used for rest upon?', 'img_file': 'COCO_val2014_000000001436.jpg', 'kb_source': 'conceptnet', 'fact': ['sofa', 'used for', 'rest upon'], 'question_id': '4893'}, '1875': {'fact_surface': 'You can use [[an airplane]] to [[fly]]', 'answer': 'fly', 'question': 'What is the large object in the bottom of this image used for?', 'img_file': 'COCO_val2014_000000100974.jpg', 'kb_source': 'conceptnet', 'fact': ['airplane', 'used for', 'fly'], 'question_id': '2773'}, '1876': {'fact_surface': '[[motorcycle]] is used for [[driving]].', 'answer': 'motorcycle', 'question': 'Which vehicle in this image is used for driving?', 'img_file': 'ILSVRC2012_test_00045346.JPEG', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'used for', 'drive'], 'question_id': '3429'}, '1877': {'fact_surface': '[[motorcycle]] belongs to the category of [[Wheels]]', 'answer': 'motorcycle', 'question': 'Which object in this image has wheels?', 'img_file': 'ILSVRC2012_test_00045346.JPEG', 'kb_source': 'dbpedia', 'fact': ['motorcycle', 'belong to', 'wheel'], 'question_id': '3428'}, '1878': {'fact_surface': '[[a desk]] normally [[stands on the ground]]', 'answer': 'desk', 'question': 'Which object in the image is able to stand on the ground?', 'img_file': 'COCO_val2014_000000150320.jpg', 'kb_source': 'conceptnet', 'fact': ['desk', 'capable of', 'stand on grind'], 'question_id': '3422'}, '1879': {'fact_surface': '[[Computers]] are [[better than typewriters]]', 'answer': 'computer', 'question': 'Which object in the image is more useful than a typewriter?', 'img_file': 'COCO_val2014_000000150320.jpg', 'kb_source': 'conceptnet', 'fact': ['computer', 'has property', 'good than typewriter'], 'question_id': '3420'}, '1880': {'fact_surface': '[[motorcycle]] belongs to the category of [[Transport]]', 'answer': 'motorcycle', 'question': 'Which object in this image is used for transport?', 'img_file': 'ILSVRC2012_test_00045346.JPEG', 'kb_source': 'dbpedia', 'fact': ['motorcycle', 'belong to', 'transport'], 'question_id': '3427'}, '1881': {'fact_surface': '[[motorcycle]] are lighter than [[car]]', 'answer': 'motorcycle', 'question': 'Which object in this image is lighter than a car?', 'img_file': 'ILSVRC2012_test_00045346.JPEG', 'kb_source': 'webchild', 'fact': ['motorcycle', 'light', 'car'], 'question_id': '3426'}, '1882': {'fact_surface': '[[sunglasses]] belongs to the category of [[Eyewear]]', 'answer': 'sunglasses', 'question': 'What item of eyewear is in this image?', 'img_file': 'ILSVRC2012_test_00045346.JPEG', 'kb_source': 'dbpedia', 'fact': ['sunglasses', 'belong to', 'eyewear'], 'question_id': '3425'}, '1883': {'fact_surface': '[[people]] is related to [[humans]]', 'answer': 'person', 'question': 'Which object in this image is related to human?', 'img_file': 'ILSVRC2012_test_00045346.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'related to', 'human'], 'question_id': '3424'}, '1884': {'fact_surface': '[[helmet]] is a subclass of [[headgear]]', 'answer': 'helmet', 'question': 'Which object in this image is a type of headgear?', 'img_file': 'COCO_val2014_000000111244.jpg', 'kb_source': 'conceptnet', 'fact': ['helmet', 'is a', 'headgear'], 'question_id': '2007'}, '1885': {'fact_surface': '[[interrupt request]] is related to [[computer]]', 'answer': 'computer', 'question': 'Which object in this image can be related to interrupt requests?', 'img_file': 'ILSVRC2012_test_00008104.JPEG', 'kb_source': 'conceptnet', 'fact': ['interrupt request', 'related to', 'computer'], 'question_id': '4585'}, '1886': {'fact_surface': '[[computer]] is for [[enjoyment]].', 'answer': 'computer', 'question': 'What can you use to have fun ?', 'img_file': 'ILSVRC2012_test_00008104.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'used for', 'enjoyment'], 'question_id': '4586'}, '1887': {'fact_surface': '[[Bottle]] is [[an enclosed container for liquids]]', 'answer': 'bottle', 'question': 'Which object in this image is an enclosed container for liquids?', 'img_file': 'ILSVRC2012_test_00002544.JPEG', 'kb_source': 'conceptnet', 'fact': ['bottle', 'is a', 'enclose container for liquid'], 'question_id': '1906'}, '1888': {'fact_surface': '[[A dog]] has [[paws]]', 'answer': 'dog', 'question': 'Which object in this image has a paw', 'img_file': 'ILSVRC2012_test_00038016.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'has a', 'paw'], 'question_id': '1080'}, '1889': {'fact_surface': '[[a knife]] is used for [[slicing]]', 'answer': 'knife', 'question': 'Which object in this image is used for slicing?', 'img_file': 'ILSVRC2012_test_00002544.JPEG', 'kb_source': 'conceptnet', 'fact': ['knife', 'used for', 'slice'], 'question_id': '1904'}, '1890': {'fact_surface': '[[coffee]] belongs to the category of [[Caffeinated beverages]]', 'answer': 'coffee', 'question': 'Which object in this image is a caffeinated beverage?', 'img_file': 'COCO_val2014_000000145728.jpg', 'kb_source': 'dbpedia', 'fact': ['coffee', 'belong to', 'caffeinated beverages'], 'question_id': '1335'}, '1891': {'fact_surface': '[[lettuce]] belongs to the category of [[Leaf vegetable]]', 'answer': 'lettuce', 'question': 'Which object in this image is a leaf vegetable?', 'img_file': 'COCO_val2014_000000145728.jpg', 'kb_source': 'dbpedia', 'fact': ['lettuce', 'belong to', 'leaf vegetable'], 'question_id': '1334'}, '1892': {'fact_surface': '[[packed lunch]] is related to [[sandwich]]', 'answer': 'sandwich', 'question': 'Which object in this image is related to packed lunch?', 'img_file': 'COCO_val2014_000000145728.jpg', 'kb_source': 'conceptnet', 'fact': ['pack lunch', 'related to', 'sandwich'], 'question_id': '1337'}, '1893': {'fact_surface': '[[banana]] is a subclass of [[edible fruit]]', 'answer': 'banana', 'question': 'Which object in this image is an edible fruit?', 'img_file': 'COCO_val2014_000000145728.jpg', 'kb_source': 'conceptnet', 'fact': ['banana', 'is a', 'edible fruit'], 'question_id': '1336'}, '1894': {'fact_surface': '[[car]] is related to [[vehicle]]', 'answer': 'car', 'question': 'What kinds of vehicle is presented in this image?', 'img_file': 'ILSVRC2012_test_00053584.JPEG', 'kb_source': 'conceptnet', 'fact': ['car', 'related to', 'vehicle'], 'question_id': '447'}, '1895': {'fact_surface': '[[An ipod]] is for [[listening to music]]', 'answer': 'listen to music', 'question': 'These thing as sued for what?', 'img_file': 'ILSVRC2012_test_00023514.JPEG', 'kb_source': 'conceptnet', 'fact': ['ipod', 'used for', 'listen to music'], 'question_id': '446'}, '1896': {'fact_surface': '[[sea]] is related to [[holding fish]]', 'answer': 'sea', 'question': 'what object in this image sometimes has fish in it?', 'img_file': 'ILSVRC2012_test_00003117.JPEG', 'kb_source': 'conceptnet', 'fact': ['sea', 'related to', 'hold fish'], 'question_id': '39'}, '1897': {'fact_surface': '[[a bedroom]] may [[used for sleeping]]', 'answer': 'sleep', 'question': 'What the room in the image is used for?', 'img_file': 'COCO_val2014_000000029074.jpg', 'kb_source': 'conceptnet', 'fact': ['bedroom', 'capable of', 'sleep'], 'question_id': '32'}, '1898': {'fact_surface': '[[bench]] is related to [[sat on]]', 'answer': 'bench', 'question': 'what object in this image is usually sat on?', 'img_file': 'COCO_val2014_000000101913.jpg', 'kb_source': 'conceptnet', 'fact': ['bench', 'related to', 'sit on'], 'question_id': '37'}, '1899': {'fact_surface': 'You can use [[a kitchen]] to [[cook a meal]]', 'answer': 'kitchen', 'question': 'Where was this image taken ?', 'img_file': 'ILSVRC2012_test_00002544.JPEG', 'kb_source': 'conceptnet', 'fact': ['kitchen', 'used for', 'cook meal'], 'question_id': '1903'}, '1900': {'fact_surface': 'You can use [[a violin]] to [[mkae annoying noises]]', 'answer': 'violin', 'question': 'Which object in this image can be used to make annoying noises?', 'img_file': 'ILSVRC2012_test_00024564.JPEG', 'kb_source': 'conceptnet', 'fact': ['violin', 'used for', 'mkae annoy noise'], 'question_id': '1900'}, '1901': {'fact_surface': '[[birds]] can [[perch]].', 'answer': 'bird', 'question': 'Which object in this image can perch?', 'img_file': 'ILSVRC2012_test_00008669.JPEG', 'kb_source': 'conceptnet', 'fact': ['bird', 'capable of', 'perch'], 'question_id': '4078'}, '1902': {'fact_surface': '[[a bicycle]] has [[2 tires]]', 'answer': 'bicycle', 'question': 'Which object in this image has 2 tires?', 'img_file': 'COCO_val2014_000000144333.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'has a', '2 tire'], 'question_id': '4075'}, '1903': {'fact_surface': '[[bike]] is related to [[bicycle]]', 'answer': 'bicycle', 'question': \"which object in this image is related to 'bike'\", 'img_file': 'COCO_val2014_000000144333.jpg', 'kb_source': 'conceptnet', 'fact': ['bike', 'related to', 'bicycle'], 'question_id': '4074'}, '1904': {'fact_surface': '[[A bird]] can [[attempt to fly]]', 'answer': 'bird', 'question': 'What shown in this image can attempt to fly?', 'img_file': 'ILSVRC2012_test_00008669.JPEG', 'kb_source': 'conceptnet', 'fact': ['bird', 'capable of', 'attempt to fly'], 'question_id': '4077'}, '1905': {'fact_surface': '[[walking]] was better than [[driving]]', 'answer': 'driving', 'question': 'Which sport is better than the action shown in this image', 'img_file': 'ILSVRC2012_test_00002037.JPEG', 'kb_source': 'webchild', 'fact': ['walking', 'good', 'driving'], 'question_id': '3460'}, '1906': {'fact_surface': '[[a cell phone]] are [[dangerous]].', 'answer': 'cell phone', 'question': 'What object in this image makes the situation dangerous for the woman?', 'img_file': 'COCO_val2014_000000144333.jpg', 'kb_source': 'conceptnet', 'fact': ['cell phone', 'has property', 'dangerous'], 'question_id': '4071'}, '1907': {'fact_surface': 'You are likely to find [[bicycle]] in [[a street corner]].', 'answer': 'bicycle', 'question': 'What is the woman riding in the street corner?', 'img_file': 'COCO_val2014_000000144333.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'at location', 'street corner'], 'question_id': '4070'}, '1908': {'fact_surface': 'You can use [[a bicycle]] to [[go places]]', 'answer': 'bicycle', 'question': 'Which object in this image is used for go place?', 'img_file': 'COCO_val2014_000000144333.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'used for', 'go place'], 'question_id': '4073'}, '1909': {'fact_surface': '[[A bicycle]] has [[two wheels and pedals]]', 'answer': 'bicycle', 'question': 'Which object in this image has a two wheels and pedals?', 'img_file': 'COCO_val2014_000000144333.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'has a', 'two wheel and pedal'], 'question_id': '4072'}, '1910': {'fact_surface': 'A [[butterfly]] is a [[insect that has beautiful wings]]', 'answer': 'butterfly', 'question': 'What insect with beautiful wings is seen here?', 'img_file': 'ILSVRC2012_test_00008380.JPEG', 'kb_source': 'conceptnet', 'fact': ['butterfly', 'is a', 'insect that have beautiful wing'], 'question_id': '841'}, '1911': {'fact_surface': '[[A cat]] can [[look out a window]]', 'answer': 'cat', 'question': 'Which object in this image is capable of look out window?', 'img_file': 'COCO_val2014_000000015070.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'look out window'], 'question_id': '3962'}, '1912': {'fact_surface': '[[buses]] are [[a common type fo public transportation]]', 'answer': 'bus', 'question': 'Which object in this image belongs to a common type fo public transportation?', 'img_file': 'COCO_val2014_000000024195.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'is a', 'common type fo public transportation'], 'question_id': '3961'}, '1913': {'fact_surface': '[[bicycle]] is seven times higher than [[motorcycle]]', 'answer': 'motorcycle', 'question': 'which object in this image is less high than bicycle?', 'img_file': 'ILSVRC2012_test_00056482.JPEG', 'kb_source': 'webchild', 'fact': ['bicycle', 'high', 'motorcycle'], 'question_id': '3968'}, '1914': {'fact_surface': '[[airplane]] belongs to the category of [[Transport]]', 'answer': 'airplane', 'question': 'What object can be used for transport?', 'img_file': 'COCO_val2014_000000028157.jpg', 'kb_source': 'dbpedia', 'fact': ['airplane', 'belong to', 'transport'], 'question_id': '3638'}, '1915': {'fact_surface': '*Something you find on [[the beach]] is [[half-naked humans]]', 'answer': 'human', 'question': 'What can be found on the beach?', 'img_file': 'COCO_val2014_000000028157.jpg', 'kb_source': 'conceptnet', 'fact': ['human', 'at location', 'beach'], 'question_id': '3637'}, '1916': {'fact_surface': '[[sunglasses]] belongs to the category of [[Eye]]', 'answer': 'sunglasses', 'question': 'What object in this image is related to eyes?', 'img_file': 'ILSVRC2012_test_00030701.JPEG', 'kb_source': 'dbpedia', 'fact': ['sunglasses', 'belong to', 'eye'], 'question_id': '3634'}, '1917': {'fact_surface': 'A [[trombone]] is a [[musical insturment]]', 'answer': 'trombone', 'question': 'What is the musical instrument in this image?', 'img_file': 'ILSVRC2012_test_00030701.JPEG', 'kb_source': 'conceptnet', 'fact': ['trombone', 'is a', 'musical insturment'], 'question_id': '3632'}, '1918': {'fact_surface': '[[sunglasses]] belongs to the category of [[Headgear]]', 'answer': 'sunglasses', 'question': 'What object in this image is a type of headgear?', 'img_file': 'ILSVRC2012_test_00030701.JPEG', 'kb_source': 'dbpedia', 'fact': ['sunglasses', 'belong to', 'headgear'], 'question_id': '3633'}, '1919': {'fact_surface': '[[trombone]] is a kind of [[brass instrument]]', 'answer': 'trombone', 'question': 'What object in this image is a brass instrument?', 'img_file': 'ILSVRC2012_test_00030701.JPEG', 'kb_source': 'conceptnet', 'fact': ['trombone', 'is a', 'brass instrument'], 'question_id': '3630'}, '1920': {'fact_surface': '[[a trombone]] is for [[making music in a jazz band]]', 'answer': 'trombone', 'question': 'What object is used to make jazz music in this image?', 'img_file': 'ILSVRC2012_test_00030701.JPEG', 'kb_source': 'conceptnet', 'fact': ['trombone', 'used for', 'make music in jazz band'], 'question_id': '3631'}, '1921': {'fact_surface': '[[an axe]] can [[chop wood]]', 'answer': 'axe', 'question': 'Which object in this image is capable of chopping wood?', 'img_file': 'ILSVRC2012_test_00012233.JPEG', 'kb_source': 'conceptnet', 'fact': ['axe', 'capable of', 'chop wood'], 'question_id': '5450'}, '1922': {'fact_surface': '[[a pen]] is for [[writing a book]]', 'answer': 'pen', 'question': 'Which object in this image could be used to write book?', 'img_file': 'ILSVRC2012_test_00029179.JPEG', 'kb_source': 'conceptnet', 'fact': ['pen', 'used for', 'write book'], 'question_id': '4468'}, '1923': {'fact_surface': 'You can use [[a pen]] to [[sign a card]]', 'answer': 'pen', 'question': 'Which object in this image can be used to sign a card?', 'img_file': 'ILSVRC2012_test_00029179.JPEG', 'kb_source': 'conceptnet', 'fact': ['pen', 'used for', 'sign card'], 'question_id': '4469'}, '1924': {'fact_surface': '[[broccoli]] is [[a vegetable that people may cook]]', 'answer': 'broccoli', 'question': 'Which vegetable in this image is to cook?', 'img_file': 'COCO_val2014_000000013991.jpg', 'kb_source': 'conceptnet', 'fact': ['broccoli', 'is a', 'vegetable that person may cook'], 'question_id': '4466'}, '1925': {'fact_surface': '[[Pens]] is for [[writing]]', 'answer': 'pen', 'question': 'Which object in this image is used for writing?', 'img_file': 'ILSVRC2012_test_00029179.JPEG', 'kb_source': 'conceptnet', 'fact': ['pen', 'used for', 'write'], 'question_id': '4467'}, '1926': {'fact_surface': '[[motorcycle]] are smaller than [[car]]', 'answer': 'motorcycle', 'question': 'which object in this image is smaller than car?', 'img_file': 'COCO_val2014_000000140465.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'small', 'car'], 'question_id': '4464'}, '1927': {'fact_surface': '[[motorcycle]] are much less strict than [[automobile]]', 'answer': 'motorcycle', 'question': 'which object in this image is less stricter than automobile?', 'img_file': 'COCO_val2014_000000140465.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'strict', 'automobile'], 'question_id': '4465'}, '1928': {'fact_surface': 'You can use [[a bowl]] to [[hold mush]]', 'answer': 'bowl', 'question': 'Which object in this image can we use for holding the mush', 'img_file': 'COCO_val2014_000000021435.jpg', 'kb_source': 'conceptnet', 'fact': ['bowl', 'used for', 'hold mush'], 'question_id': '4462'}, '1929': {'fact_surface': '[[a couch]] can be used for [[sitting down]]', 'answer': 'couch', 'question': 'Which object in this image is used for sit down？', 'img_file': 'COCO_val2014_000000146963.jpg', 'kb_source': 'conceptnet', 'fact': ['couch', 'used for', 'sit down'], 'question_id': '4463'}, '1930': {'fact_surface': '[[a person]] wants to [[live in a loving enviroment]]', 'answer': 'person', 'question': 'Which object in this image desires live in a loving enviroment?', 'img_file': 'COCO_val2014_000000015303.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'live in love enviroment'], 'question_id': '4460'}, '1931': {'fact_surface': '[[The oceans]] are [[very deep]]', 'answer': 'ocean', 'question': 'What property does the place in this image have?', 'img_file': 'COCO_val2014_000000015303.jpg', 'kb_source': 'conceptnet', 'fact': ['ocean', 'has property', 'very deep'], 'question_id': '4461'}, '1932': {'fact_surface': '[[bicycle]] is related to [[exercise]]', 'answer': 'bicycle', 'question': 'Which object in the image is related to exercise?', 'img_file': 'COCO_val2014_000000125829.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'related to', 'exercise'], 'question_id': '948'}, '1933': {'fact_surface': '[[Giraffes]] are [[found in Africa]]', 'answer': 'africa', 'question': 'Where the animals in the image originally from? ', 'img_file': 'COCO_val2014_000000010211.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'receives action', 'africa'], 'question_id': '946'}, '1934': {'fact_surface': '[[tomatoes]] are [[green before they are red]]', 'answer': 'tomato', 'question': 'Which things in this picture are green before they are red?', 'img_file': 'COCO_val2014_000000105014.jpg', 'kb_source': 'conceptnet', 'fact': ['tomato', 'has property', 'green before they be red'], 'question_id': '944'}, '1935': {'fact_surface': '[[Toilet seats]] are often [[white]]', 'answer': 'white', 'question': 'What is the colour of the toilet seat?', 'img_file': 'COCO_val2014_000000005412.jpg', 'kb_source': 'conceptnet', 'fact': ['toilet seat', 'has property', 'white'], 'question_id': '943'}, '1936': {'fact_surface': '[[A chair]] has [[a back you can lean against]]', 'answer': 'chair', 'question': 'Which object in this image has a back you can lean against?', 'img_file': 'COCO_val2014_000000023731.jpg', 'kb_source': 'conceptnet', 'fact': ['chair', 'has a', 'back you can lean against'], 'question_id': '5185'}, '1937': {'fact_surface': '[[cow]] belongs to the category of [[Mammals with sequenced genomes]]', 'answer': 'cow', 'question': 'what is it  in this image belongs to the category Mammals with sequenced genomes?', 'img_file': 'COCO_val2014_000000149832.jpg', 'kb_source': 'dbpedia', 'fact': ['cow', 'belong to', 'mammals with sequenced genomes'], 'question_id': '1658'}, '1938': {'fact_surface': '[[cow]] belongs to the category of [[Mammals with sequenced genomes]]', 'answer': 'cow', 'question': 'what is it  in this image belongs to the category Mammals with sequenced genomes?', 'img_file': 'COCO_val2014_000000149832.jpg', 'kb_source': 'dbpedia', 'fact': ['cow', 'belong to', 'mammals with sequenced genomes'], 'question_id': '1659'}, '1939': {'fact_surface': 'The class of [[cow]] is [[Mammal]]', 'answer': 'mammal', 'question': 'What is the class of the animal in this image?', 'img_file': 'COCO_val2014_000000149832.jpg', 'kb_source': 'dbpedia', 'fact': ['cattle', 'animal class', 'mammal'], 'question_id': '1653'}, '1940': {'fact_surface': '[[playing]] was apparently more important than [[god fire alarm]]', 'answer': 'playing', 'question': 'Which action is less important than the action shown in this image', 'img_file': 'ILSVRC2012_test_00053722.JPEG', 'kb_source': 'webchild', 'fact': ['playing', 'important', 'god fire alarm'], 'question_id': '1650'}, '1941': {'fact_surface': '[[cow]] belongs to the category of [[Mammals with sequenced genomes]]', 'answer': 'cow', 'question': 'what is it  in this image belongs to the category Mammals with sequenced genomes?', 'img_file': 'COCO_val2014_000000149832.jpg', 'kb_source': 'dbpedia', 'fact': ['cow', 'belong to', 'mammals with sequenced genomes'], 'question_id': '1656'}, '1942': {'fact_surface': '[[cow]] belongs to the category of [[Mammals with sequenced genomes]]', 'answer': 'cow', 'question': 'what is it  in this image belongs to the category Mammals with sequenced genomes?', 'img_file': 'COCO_val2014_000000149832.jpg', 'kb_source': 'dbpedia', 'fact': ['cow', 'belong to', 'mammals with sequenced genomes'], 'question_id': '1657'}, '1943': {'fact_surface': 'The class of [[cow]] is [[Mammal]]', 'answer': 'mammal', 'question': 'What is the class of the animal in this image?', 'img_file': 'COCO_val2014_000000149832.jpg', 'kb_source': 'dbpedia', 'fact': ['cattle', 'animal class', 'mammal'], 'question_id': '1654'}, '1944': {'fact_surface': '[[tree]] is related to [[branches]]', 'answer': 'tree', 'question': 'Which object in this image has branches?', 'img_file': 'ILSVRC2012_test_00004200.JPEG', 'kb_source': 'conceptnet', 'fact': ['tree', 'related to', 'branch'], 'question_id': '1389'}, '1945': {'fact_surface': '[[clocks]] have [[pointers called hands]]', 'answer': 'clock', 'question': 'Which object in this image has pointers called hands?', 'img_file': 'COCO_val2014_000000008498.jpg', 'kb_source': 'conceptnet', 'fact': ['clock', 'has a', 'pointer call hand'], 'question_id': '1739'}, '1946': {'fact_surface': '[[helmets]] can [[prevent head injuries]]', 'answer': 'helmet', 'question': 'Which object in this image is capable of preventing head injury?', 'img_file': 'COCO_val2014_000000104691.jpg', 'kb_source': 'conceptnet', 'fact': ['helmet', 'capable of', 'prevent head injury'], 'question_id': '3393'}, '1947': {'fact_surface': \"You can use [[a spoon]] to [[eat soup']]\", 'answer': 'spoon', 'question': 'Which object in this image is used for eating soup?', 'img_file': 'COCO_val2014_000000002759.jpg', 'kb_source': 'conceptnet', 'fact': ['spoon', 'used for', 'eat soup'], 'question_id': '1435'}, '1948': {'fact_surface': '[[balance beam]] is a subclass of [[gymnastics apparatus]]', 'answer': 'balance beam', 'question': 'which object in this image can be used in gymnastics', 'img_file': 'ILSVRC2012_test_00021252.JPEG', 'kb_source': 'conceptnet', 'fact': ['balance beam', 'is a', 'gymnastics apparatus'], 'question_id': '5403'}, '1949': {'fact_surface': '[[balance beam]] belongs to the category of [[Gymnastics]]', 'answer': 'balance beam', 'question': 'Which object on the bottom of this image belongs to the category Gymnastics?', 'img_file': 'ILSVRC2012_test_00021252.JPEG', 'kb_source': 'dbpedia', 'fact': ['balance beam', 'belong to', 'gymnastics'], 'question_id': '5402'}, '1950': {'fact_surface': '[[lemon]] belongs to the category of [[Tropics]]', 'answer': 'lemon', 'question': 'What fruit in the image belongs to tropics?', 'img_file': 'COCO_val2014_000000100553.jpg', 'kb_source': 'dbpedia', 'fact': ['lemon', 'belong to', 'tropics'], 'question_id': '5401'}, '1951': {'fact_surface': '[[Lemons]] are [[yellow colored]]', 'answer': 'lemon', 'question': 'Which object in this image is yellow?', 'img_file': 'COCO_val2014_000000100553.jpg', 'kb_source': 'conceptnet', 'fact': ['lemon', 'has property', 'yellow color'], 'question_id': '5400'}, '1952': {'fact_surface': '[[rugby ball]] is used for [[playing rugby]].', 'answer': 'rugby ball', 'question': 'Which object in this image is used for playing rugby?', 'img_file': 'ILSVRC2012_test_00011383.JPEG', 'kb_source': 'conceptnet', 'fact': ['rugby ball', 'used for', 'play rugby'], 'question_id': '3399'}, '1953': {'fact_surface': '[[bladder]] is related to [[rugby ball]]', 'answer': 'rugby ball', 'question': 'Which object in this image has a bladder?', 'img_file': 'ILSVRC2012_test_00011383.JPEG', 'kb_source': 'conceptnet', 'fact': ['bladder', 'related to', 'rugby ball'], 'question_id': '3398'}, '1954': {'fact_surface': '[[botany]] is related to [[plant]]', 'answer': 'plant', 'question': 'What shown here is related to botany?', 'img_file': 'COCO_val2014_000000149371.jpg', 'kb_source': 'conceptnet', 'fact': ['botany', 'related to', 'plant'], 'question_id': '1439'}, '1955': {'fact_surface': '[[a person]] wants to [[experience the rich diversity of life]]', 'answer': 'person', 'question': 'Which object in this image desires experience rich diversity of life?', 'img_file': 'COCO_val2014_000000100896.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'experience rich diversity of life'], 'question_id': '4260'}, '1956': {'fact_surface': '[[motorcycle]] is used for [[riding]].', 'answer': 'motorcycle', 'question': 'Which object in this image is used for ride?', 'img_file': 'COCO_val2014_000000100896.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'used for', 'ride'], 'question_id': '4261'}, '1957': {'fact_surface': 'Somewhere [[sofas]] can be is [[livingroom]].', 'answer': 'sofa', 'question': 'Which object in this image can be found in livingroom?', 'img_file': 'COCO_val2014_000000115870.jpg', 'kb_source': 'conceptnet', 'fact': ['sofa', 'at location', 'livingroom'], 'question_id': '4268'}, '1958': {'fact_surface': '[[a sofa]] is for [[lying on it]]', 'answer': 'sofa', 'question': 'which object in this image can we lie on', 'img_file': 'COCO_val2014_000000115870.jpg', 'kb_source': 'conceptnet', 'fact': ['sofa', 'used for', 'lie on it'], 'question_id': '4269'}, '1959': {'fact_surface': '[[cake]] is related to [[birthday desert]]', 'answer': 'cake', 'question': 'Which object in this image is a birthday dessert?', 'img_file': 'COCO_val2014_000000102820.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'related to', 'birthday desert'], 'question_id': '3702'}, '1960': {'fact_surface': '[[A banana]] is [[good to eat]]', 'answer': 'banana', 'question': 'What is the name of the longest fruit in the image', 'img_file': 'COCO_val2014_000000000715.jpg', 'kb_source': 'conceptnet', 'fact': ['banana', 'has property', 'good to eat'], 'question_id': '5236'}, '1961': {'fact_surface': '[[Giraffes]] have [[long tongues]]', 'answer': 'giraffe', 'question': 'Which object in this image has a long tongue?', 'img_file': 'COCO_val2014_000000010211.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'has a', 'long tongue'], 'question_id': '5548'}, '1962': {'fact_surface': 'You are likely to find [[life]] in [[zoos]].', 'answer': 'zoo', 'question': 'where is this place?', 'img_file': 'COCO_val2014_000000010211.jpg', 'kb_source': 'conceptnet', 'fact': ['life', 'at location', 'zoo'], 'question_id': '5549'}, '1963': {'fact_surface': '[[giraffe]] is [[long-necked]].', 'answer': 'giraffe', 'question': 'Which object in this image has a long neck?', 'img_file': 'COCO_val2014_000000010211.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'has property', 'long neck'], 'question_id': '5543'}, '1964': {'fact_surface': '[[Giraffes]] are [[native to Africa]]', 'answer': 'giraffe', 'question': 'Which object in this image is native to africa?', 'img_file': 'COCO_val2014_000000010211.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'has property', 'native to africa'], 'question_id': '5546'}, '1965': {'fact_surface': '[[A Zebra]] is [[an African equine species]]', 'answer': 'zebra', 'question': 'Which object in this image is a member of an African equine species?', 'img_file': 'COCO_val2014_000000010211.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'is a', 'african equine specie'], 'question_id': '5547'}, '1966': {'fact_surface': '[[giraffe]] are taller than [[rhino]]', 'answer': 'giraffe', 'question': 'Which object in this image is taller than rhino?', 'img_file': 'COCO_val2014_000000010211.jpg', 'kb_source': 'webchild', 'fact': ['giraffe', 'tall', 'rhino'], 'question_id': '5544'}, '1967': {'fact_surface': '[[a giraffe]] has [[knubby things on its head]]', 'answer': 'giraffe', 'question': 'Which object in this image has knubby things on its head?', 'img_file': 'COCO_val2014_000000010211.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'has a', 'knubby thing on it head'], 'question_id': '5545'}, '1968': {'fact_surface': '[[a person]] can [[captain a team of people]]', 'answer': 'person', 'question': 'which object in this image can captain a team of people?', 'img_file': 'COCO_val2014_000000016590.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'captain team of person'], 'question_id': '5891'}, '1969': {'fact_surface': '[[People]] must [[breathe to survive]]', 'answer': 'person', 'question': 'which object in this image must breath to survive?', 'img_file': 'COCO_val2014_000000016590.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'breathe to survive'], 'question_id': '5892'}, '1970': {'fact_surface': '[[A person]] can [[rake leaves]].', 'answer': 'person', 'question': 'which object in this image is capable of raking leaves?', 'img_file': 'COCO_val2014_000000016590.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'rake leave'], 'question_id': '5893'}, '1971': {'fact_surface': '[[people]] are [[alive]]', 'answer': 'person', 'question': 'which object in this image is alive?', 'img_file': 'COCO_val2014_000000016590.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'has property', 'alive'], 'question_id': '5894'}, '1972': {'fact_surface': '[[Zebras]] have [[black and white stripes]]', 'answer': 'zebra', 'question': 'Which object in this image has a interleaved black and white stripe？', 'img_file': 'COCO_val2014_000000100661.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'black and white stripe'], 'question_id': '5897'}, '1973': {'fact_surface': '[[zebra]] are somewhat smaller than [[horse]]', 'answer': 'zebra', 'question': 'which object in this image is little smaller than horse?', 'img_file': 'COCO_val2014_000000100661.jpg', 'kb_source': 'webchild', 'fact': ['zebra', 'small', 'horse'], 'question_id': '5899'}, '1974': {'fact_surface': '[[ray]] belongs to the category of [[Fish by classification]]', 'answer': 'ray', 'question': 'Which object in this image is a fish?', 'img_file': 'ILSVRC2012_test_00000980.JPEG', 'kb_source': 'dbpedia', 'fact': ['ray', 'belong to', 'fish by classification'], 'question_id': '4669'}, '1975': {'fact_surface': '*Something you find in [[the corner]] is [[a lamp]]', 'answer': 'lamp', 'question': 'Which object in this image can be found in the corner?', 'img_file': 'COCO_val2014_000000106235.jpg', 'kb_source': 'conceptnet', 'fact': ['lamp', 'at location', 'corn'], 'question_id': '2127'}, '1976': {'fact_surface': '[[potted plant]] belongs to the category of [[Life]]', 'answer': 'potted plant', 'question': 'Which object in this image is alive?', 'img_file': 'COCO_val2014_000000106235.jpg', 'kb_source': 'dbpedia', 'fact': ['potted plant', 'belong to', 'life'], 'question_id': '2126'}, '1977': {'fact_surface': 'You are likely to find [[bottle]] on [[table]].', 'answer': 'bottle', 'question': 'Which object in this image can be found in table', 'img_file': 'COCO_val2014_000000106392.jpg', 'kb_source': 'conceptnet', 'fact': ['bottle', 'at location', 'table'], 'question_id': '4916'}, '1978': {'fact_surface': '[[A cup]] can be used to [[hold coffee]]', 'answer': 'cup', 'question': 'What in this image can be used for hold coffee?', 'img_file': 'COCO_val2014_000000106392.jpg', 'kb_source': 'conceptnet', 'fact': ['cup', 'used for', 'hold coffee'], 'question_id': '4917'}, '1979': {'fact_surface': '[[helmet]] is related to [[bike safety]]', 'answer': 'safety', 'question': 'Why are they wearing helmet?', 'img_file': 'COCO_val2014_000000108094.jpg', 'kb_source': 'conceptnet', 'fact': ['helmet', 'related to', 'safety'], 'question_id': '322'}, '1980': {'fact_surface': '[[jellyfish]] are [[not fish]]', 'answer': 'jellyfish', 'question': 'Whether the animal in the image is a fish?', 'img_file': 'ILSVRC2012_test_00003440.JPEG', 'kb_source': 'conceptnet', 'fact': ['jellyfish', 'is a', 'not fish'], 'question_id': '323'}, '1981': {'fact_surface': '[[grass]] is related to [[cow food]]', 'answer': 'grass', 'question': 'What cow food is seen here?', 'img_file': 'COCO_val2014_000000122203.jpg', 'kb_source': 'conceptnet', 'fact': ['grass', 'related to', 'cow food'], 'question_id': '321'}, '1982': {'fact_surface': '[[baseball glove]] is a subclass of [[protective garment]]', 'answer': 'baseball glove', 'question': 'What object in this image is protective equipment?', 'img_file': 'COCO_val2014_000000100909.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball glove', 'is a', 'protective garment'], 'question_id': '324'}, '1983': {'fact_surface': 'You can use [[a clock]] to [[see what time it is]]', 'answer': 'clock', 'question': 'what object in this image can be used to check the time?', 'img_file': 'ILSVRC2012_test_00008843.JPEG', 'kb_source': 'conceptnet', 'fact': ['clock', 'used for', 'see what time it be'], 'question_id': '325'}, '1984': {'fact_surface': '[[Pizza]] is usually [[cut into slices]]', 'answer': 'pizza', 'question': 'Which thing in this image would normally be cut into slices?', 'img_file': 'COCO_val2014_000000146489.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'has property', 'cut into slice'], 'question_id': '328'}, '1985': {'fact_surface': '[[Snakes]] have [[no feet]]', 'answer': 'snake', 'question': 'What living stuff in the image has no feet?', 'img_file': 'ILSVRC2012_test_00029408.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'has a', 'no foot'], 'question_id': '1591'}, '1986': {'fact_surface': '[[snake]] belongs to the category of [[Predators]]', 'answer': 'snake', 'question': 'Which object in this image belongs to the category of Predators?', 'img_file': 'ILSVRC2012_test_00029408.JPEG', 'kb_source': 'dbpedia', 'fact': ['snake', 'belong to', 'predators'], 'question_id': '1590'}, '1987': {'fact_surface': '[[cherry]] are typically a more intense red than [[strawberry]]', 'answer': 'strawberry', 'question': 'which object in this image is less intense red than cherry?', 'img_file': 'ILSVRC2012_test_00023364.JPEG', 'kb_source': 'webchild', 'fact': ['cherry', 'intense', 'strawberry'], 'question_id': '3077'}, '1988': {'fact_surface': '[[snow]] can be used for [[skiing on]]', 'answer': 'ski', 'question': 'What can you do in this place?', 'img_file': 'COCO_val2014_000000102329.jpg', 'kb_source': 'conceptnet', 'fact': ['snow', 'used for', 'ski'], 'question_id': '2248'}, '1989': {'fact_surface': '[[a tree]] is [[brown and green]].', 'answer': 'tree', 'question': 'Which objects in this image are brown and green?', 'img_file': 'COCO_val2014_000000102329.jpg', 'kb_source': 'conceptnet', 'fact': ['tree', 'has property', 'brown and green'], 'question_id': '2249'}, '1990': {'fact_surface': '[[A rabbit]] has [[long ears]]', 'answer': 'rabbit', 'question': 'Which object in this image has a long ear', 'img_file': 'ILSVRC2012_test_00002482.JPEG', 'kb_source': 'conceptnet', 'fact': ['rabbit', 'has a', 'long ear'], 'question_id': '2247'}, '1991': {'fact_surface': '[[soccer ball]] belongs to the category of [[Sports originating in England]]', 'answer': 'soccer ball', 'question': 'Which object in this image belongs to the category Sports originating in England?', 'img_file': 'ILSVRC2012_test_00011383.JPEG', 'kb_source': 'dbpedia', 'fact': ['soccer ball', 'belong to', 'sports originating in england'], 'question_id': '3401'}, '1992': {'fact_surface': '[[soccer ball]] belongs to the category of [[Sports originating in England]]', 'answer': 'soccer ball', 'question': 'Which object in this image belongs to the category Sports originating in England?', 'img_file': 'ILSVRC2012_test_00011383.JPEG', 'kb_source': 'dbpedia', 'fact': ['soccer ball', 'belong to', 'sports originating in england'], 'question_id': '3400'}, '1993': {'fact_surface': '[[a bathroom]] is for [[washing your hands]]', 'answer': 'wash your hand', 'question': 'What can you do in this place?', 'img_file': 'COCO_val2014_000000010643.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'used for', 'wash your hand'], 'question_id': '3403'}, '1994': {'fact_surface': '[[A stop sign]] is for [[controlling traffic]]', 'answer': 'stop sign', 'question': 'Which other object than the traffic light is used to control the traffic? ', 'img_file': 'COCO_val2014_000000006701.jpg', 'kb_source': 'conceptnet', 'fact': ['stop sign', 'used for', 'control traffic'], 'question_id': '3402'}, '1995': {'fact_surface': '[[banana]] belongs to the category of [[Fruit]]', 'answer': 'banana', 'question': 'What fruit can be seen in this image?', 'img_file': 'COCO_val2014_000000003817.jpg', 'kb_source': 'dbpedia', 'fact': ['banana', 'belong to', 'fruit'], 'question_id': '4875'}, '1996': {'fact_surface': '[[motorcycle]] are smaller than [[automobile]]', 'answer': 'motorcycle', 'question': 'Which vehicle in this image is smaller than automobile?', 'img_file': 'COCO_val2014_000000003817.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'small', 'automobile'], 'question_id': '4874'}, '1997': {'fact_surface': '[[tree]] is related to [[wood]]', 'answer': 'tree', 'question': 'Which object in this image is related to wood?', 'img_file': 'COCO_val2014_000000024931.jpg', 'kb_source': 'conceptnet', 'fact': ['tree', 'related to', 'wood'], 'question_id': '4877'}, '1998': {'fact_surface': '[[person]] is a subclass of [[genus Homo]]', 'answer': 'person', 'question': 'Which object in this image is a subclass of genus homo?', 'img_file': 'COCO_val2014_000000024931.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'is a', 'genus homo'], 'question_id': '4876'}, '1999': {'fact_surface': '[[kittens]] are [[soft and fuzzy]]', 'answer': 'kitten', 'question': 'Which object in this image is soft and fuzzy?', 'img_file': 'COCO_val2014_000000026768.jpg', 'kb_source': 'conceptnet', 'fact': ['kitten', 'has property', 'soft and fuzzy'], 'question_id': '4870'}, '2000': {'fact_surface': '[[a bathroom]] is for [[Cleaning your teeth in]]', 'answer': 'clean your tooth in', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000011727.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'used for', 'clean your tooth in'], 'question_id': '2798'}, '2001': {'fact_surface': '[[a bathroom]] is for [[Cleaning your teeth in]]', 'answer': 'clean your tooth in', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000011727.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'used for', 'clean your tooth in'], 'question_id': '2799'}, '2002': {'fact_surface': '[[a bathroom]] is for [[Cleaning your teeth in]]', 'answer': 'clean your tooth in', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000011727.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'used for', 'clean your tooth in'], 'question_id': '2792'}, '2003': {'fact_surface': 'You are likely to find [[a snake]] in [[a herpetarium]]', 'answer': 'snake', 'question': 'Which object in this image can be found in herpetarium?', 'img_file': 'ILSVRC2012_test_00000108.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'at location', 'herpetarium'], 'question_id': '2790'}, '2004': {'fact_surface': '[[soup]] is related to [[chicken]]', 'answer': 'chicken', 'question': 'Which little animal on the left of the image can be used to make soup?', 'img_file': 'COCO_val2014_000000146099.jpg', 'kb_source': 'conceptnet', 'fact': ['soup', 'related to', 'chicken'], 'question_id': '2791'}, '2005': {'fact_surface': '[[a bathroom]] is for [[Cleaning your teeth in]]', 'answer': 'clean your tooth in', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000011727.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'used for', 'clean your tooth in'], 'question_id': '2796'}, '2006': {'fact_surface': '[[a bathroom]] is for [[Cleaning your teeth in]]', 'answer': 'clean your tooth in', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000011727.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'used for', 'clean your tooth in'], 'question_id': '2797'}, '2007': {'fact_surface': '[[a bathroom]] is for [[Cleaning your teeth in]]', 'answer': 'clean your tooth in', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000011727.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'used for', 'clean your tooth in'], 'question_id': '2794'}, '2008': {'fact_surface': '[[a bathroom]] is for [[Cleaning your teeth in]]', 'answer': 'clean your tooth in', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000011727.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'used for', 'clean your tooth in'], 'question_id': '2795'}, '2009': {'fact_surface': '[[zebras]] are [[black and white]].', 'answer': 'zebra', 'question': 'Which objects in this image are black and white?', 'img_file': 'ILSVRC2012_test_00010048.JPEG', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has property', 'black and white'], 'question_id': '5690'}, '2010': {'fact_surface': 'You can use [[an oven]] to [[bake a cake]]', 'answer': 'oven', 'question': 'Which object in this image could be used for baking a cake?', 'img_file': 'ILSVRC2012_test_00020753.JPEG', 'kb_source': 'conceptnet', 'fact': ['oven', 'used for', 'bake cake'], 'question_id': '5696'}, '2011': {'fact_surface': '[[this dog]] has [[a frisbee]]', 'answer': 'frisbee', 'question': 'What does this dog have?', 'img_file': 'COCO_val2014_000000145815.jpg', 'kb_source': 'conceptnet', 'fact': ['this dog', 'has a', 'frisbee'], 'question_id': '1359'}, '2012': {'fact_surface': '*Something you find at [[beach]] is [[pretty girls]]', 'answer': 'pretty girl', 'question': 'What is usually found at this place?', 'img_file': 'ILSVRC2012_test_00001151.JPEG', 'kb_source': 'conceptnet', 'fact': ['pretty girl', 'at location', 'beach'], 'question_id': '1358'}, '2013': {'fact_surface': '[[a boat]] can [[sail through the sea]]', 'answer': 'boat', 'question': 'What thing in this photo is capable of sailing through the sea', 'img_file': 'COCO_val2014_000000112608.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'capable of', 'sail through sea'], 'question_id': '469'}, '2014': {'fact_surface': '[[A boat]] can [[swim on water]]', 'answer': 'boat', 'question': 'Which object in this image is able to swim on water', 'img_file': 'COCO_val2014_000000112608.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'capable of', 'swim on water'], 'question_id': '468'}, '2015': {'fact_surface': 'A [[bear]] is a [[big, furry mammal]]', 'answer': 'bear', 'question': 'Which object in this image is a big furry mammal?', 'img_file': 'COCO_val2014_000000127955.jpg', 'kb_source': 'conceptnet', 'fact': ['bear', 'is a', 'big furry mammal'], 'question_id': '1352'}, '2016': {'fact_surface': '[[sauce]] is related to [[tomato]]', 'answer': 'tomato', 'question': 'What object in this image can be used to make sauce?', 'img_file': 'ILSVRC2012_test_00048262.JPEG', 'kb_source': 'conceptnet', 'fact': ['sauce', 'related to', 'tomato'], 'question_id': '1351'}, '2017': {'fact_surface': '[[tie]] is related to [[neck wrap]]', 'answer': 'tie', 'question': 'What is the neck wrap on this man?', 'img_file': 'COCO_val2014_000000118124.jpg', 'kb_source': 'conceptnet', 'fact': ['tie', 'related to', 'neck wrap'], 'question_id': '466'}, '2018': {'fact_surface': '*Something you find at [[beach]] is [[pretty girls]]', 'answer': 'pretty girl', 'question': 'What is usually found at this place?', 'img_file': 'ILSVRC2012_test_00001151.JPEG', 'kb_source': 'conceptnet', 'fact': ['pretty girl', 'at location', 'beach'], 'question_id': '1357'}, '2019': {'fact_surface': 'A [[saxophone]] is a [[wind instrument]]', 'answer': 'saxophone', 'question': 'what object in this image is a wind instrument?', 'img_file': 'ILSVRC2012_test_00000761.JPEG', 'kb_source': 'conceptnet', 'fact': ['saxophone', 'is a', 'wind instrument'], 'question_id': '460'}, '2020': {'fact_surface': '[[strawberry]] is related to [[red]]', 'answer': 'strawberry', 'question': 'What this the red fruit in the image?', 'img_file': 'COCO_val2014_000000136772.jpg', 'kb_source': 'conceptnet', 'fact': ['strawberry', 'related to', 'red'], 'question_id': '462'}, '2021': {'fact_surface': '[[axes]] are [[dangerous]]', 'answer': 'axe', 'question': 'Which object in this image are dangerous?', 'img_file': 'ILSVRC2012_test_00048011.JPEG', 'kb_source': 'conceptnet', 'fact': ['axe', 'has property', 'dangerous'], 'question_id': '3184'}, '2022': {'fact_surface': '[[axes]] are [[dangerous]]', 'answer': 'axe', 'question': 'Which object in this image are dangerous?', 'img_file': 'ILSVRC2012_test_00048011.JPEG', 'kb_source': 'conceptnet', 'fact': ['axe', 'has property', 'dangerous'], 'question_id': '3185'}, '2023': {'fact_surface': '[[axes]] are [[dangerous]]', 'answer': 'axe', 'question': 'Which object in this image are dangerous?', 'img_file': 'ILSVRC2012_test_00048011.JPEG', 'kb_source': 'conceptnet', 'fact': ['axe', 'has property', 'dangerous'], 'question_id': '3186'}, '2024': {'fact_surface': '[[axes]] are [[dangerous]]', 'answer': 'axe', 'question': 'Which object in this image are dangerous?', 'img_file': 'ILSVRC2012_test_00048011.JPEG', 'kb_source': 'conceptnet', 'fact': ['axe', 'has property', 'dangerous'], 'question_id': '3187'}, '2025': {'fact_surface': '[[axe]] belongs to the category of [[Weapon]]', 'answer': 'axe', 'question': 'Which object in this image belongs to the category Weapon?', 'img_file': 'ILSVRC2012_test_00048011.JPEG', 'kb_source': 'dbpedia', 'fact': ['axe', 'belong to', 'weapon'], 'question_id': '3180'}, '2026': {'fact_surface': '[[A hammer]] can [[nail a board]]', 'answer': 'hammer', 'question': 'Which object in this image can be used to nail board?', 'img_file': 'ILSVRC2012_test_00048011.JPEG', 'kb_source': 'conceptnet', 'fact': ['hammer', 'capable of', 'nail board'], 'question_id': '3181'}, '2027': {'fact_surface': '[[hammer]] can [[strike nail]]', 'answer': 'hammer', 'question': 'Which object in this image can be used to strike nail?', 'img_file': 'ILSVRC2012_test_00048011.JPEG', 'kb_source': 'conceptnet', 'fact': ['hammer', 'capable of', 'strike nail'], 'question_id': '3182'}, '2028': {'fact_surface': '[[axes]] are [[dangerous]]', 'answer': 'axe', 'question': 'Which object in this image are dangerous?', 'img_file': 'ILSVRC2012_test_00048011.JPEG', 'kb_source': 'conceptnet', 'fact': ['axe', 'has property', 'dangerous'], 'question_id': '3183'}, '2029': {'fact_surface': '[[axes]] are [[dangerous]]', 'answer': 'axe', 'question': 'Which object in this image are dangerous?', 'img_file': 'ILSVRC2012_test_00048011.JPEG', 'kb_source': 'conceptnet', 'fact': ['axe', 'has property', 'dangerous'], 'question_id': '3188'}, '2030': {'fact_surface': '[[luggage]] is used to [[carry clothing on vacation]]', 'answer': 'luggage', 'question': 'Which object in this image is used for carrying clothes on vacation?', 'img_file': 'COCO_val2014_000000112022.jpg', 'kb_source': 'conceptnet', 'fact': ['luggage', 'used for', 'carry clothe on vacation'], 'question_id': '3189'}, '2031': {'fact_surface': '[[horse]] is related to [[zebra]]', 'answer': 'zebra', 'question': 'Which animal in this image is related to horse?', 'img_file': 'COCO_val2014_000000115182.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'related to', 'zebra'], 'question_id': '4011'}, '2032': {'fact_surface': 'You are likely to find [[zebras]] in [[Africa]]', 'answer': 'zebra', 'question': 'Which object in this image can be found in Africa?', 'img_file': 'COCO_val2014_000000115182.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'at location', 'africa'], 'question_id': '4010'}, '2033': {'fact_surface': '[[train]] is related to [[gun]]', 'answer': 'train', 'question': 'Which part in this image is related to gun?', 'img_file': 'COCO_val2014_000000129135.jpg', 'kb_source': 'conceptnet', 'fact': ['train', 'related to', 'gun'], 'question_id': '3989'}, '2034': {'fact_surface': '[[bench]] belongs to the category of [[Seats]]', 'answer': 'bench', 'question': 'Which object in this image belongs to the category Seats?', 'img_file': 'COCO_val2014_000000105303.jpg', 'kb_source': 'dbpedia', 'fact': ['bench', 'belong to', 'seat'], 'question_id': '3986'}, '2035': {'fact_surface': '[[lakes]] contain [[water]]', 'answer': 'lake', 'question': 'What thing has water in it in this image?', 'img_file': 'COCO_val2014_000000105303.jpg', 'kb_source': 'conceptnet', 'fact': ['lake', 'has a', 'water'], 'question_id': '3987'}, '2036': {'fact_surface': '[[An amusement park]] contains [[rides]]', 'answer': 'ride', 'question': 'What can you find in the place shown in this image', 'img_file': 'COCO_val2014_000000145020.jpg', 'kb_source': 'conceptnet', 'fact': ['amusement park', 'has a', 'ride'], 'question_id': '5796'}, '2037': {'fact_surface': '*Something you find at [[a hotel]] is [[a toilet]]', 'answer': 'toilet', 'question': 'Where is the place in hotel?', 'img_file': 'COCO_val2014_000000104015.jpg', 'kb_source': 'conceptnet', 'fact': ['toilet', 'at location', 'hotel'], 'question_id': '1445'}, '2038': {'fact_surface': '(traffic light,/r/UsedFor,controlling traffic)', 'answer': 'traffic light', 'question': 'What object in this image is used for controlling traffic?', 'img_file': 'COCO_val2014_000000135666.jpg', 'kb_source': 'conceptnet', 'fact': ['traffic light', 'used for', 'control traffic'], 'question_id': '289'}, '2039': {'fact_surface': '[[an elephant]] is [[big]].', 'answer': 'big', 'question': 'Which word is normaly used to describe the animal in the image?', 'img_file': 'COCO_val2014_000000108338.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'has property', 'big'], 'question_id': '287'}, '2040': {'fact_surface': '[[apple]] belongs to the category of [[Fruit]]', 'answer': 'apple', 'question': 'what kind can we see in this image', 'img_file': 'ILSVRC2012_test_00048805.JPEG', 'kb_source': 'dbpedia', 'fact': ['apple', 'belong to', 'fruit'], 'question_id': '1442'}, '2041': {'fact_surface': '[[Apples]] are [[sweet and mushy in pie]]', 'answer': 'apple', 'question': 'Which object in this image is sweet and mushy in pie?', 'img_file': 'ILSVRC2012_test_00048805.JPEG', 'kb_source': 'conceptnet', 'fact': ['apple', 'has property', 'sweet and mushy in pie'], 'question_id': '1441'}, '2042': {'fact_surface': '[[lemon]] is a kind of [[citrus fruit]].', 'answer': 'lemon', 'question': 'Which object in this image is a citrus fruit?', 'img_file': 'ILSVRC2012_test_00048805.JPEG', 'kb_source': 'conceptnet', 'fact': ['lemon', 'is a', 'citrus fruit'], 'question_id': '1440'}, '2043': {'fact_surface': '[[volleyball]] belongs to the category of [[Team sports]]', 'answer': 'volleyball', 'question': 'What team sport is this?', 'img_file': 'ILSVRC2012_test_00000462.JPEG', 'kb_source': 'dbpedia', 'fact': ['volleyball', 'belong to', 'team sports'], 'question_id': '2477'}, '2044': {'fact_surface': '[[Zebras]] have [[stripes]]', 'answer': 'zebra', 'question': 'Which object in this image has stripes?', 'img_file': 'ILSVRC2012_test_00041429.JPEG', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'stripe'], 'question_id': '2476'}, '2045': {'fact_surface': '[[a tail]] is part of [[a zebra]]', 'answer': 'zebra', 'question': 'Which object in this image has a tail?', 'img_file': 'ILSVRC2012_test_00041429.JPEG', 'kb_source': 'conceptnet', 'fact': ['tail', 'part of', 'zebra'], 'question_id': '2475'}, '2046': {'fact_surface': '[[a zebra]] has [[eyes]]', 'answer': 'zebra', 'question': 'Which object in this image has eyes?', 'img_file': 'ILSVRC2012_test_00041429.JPEG', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'eye'], 'question_id': '2474'}, '2047': {'fact_surface': '[[skateboard]] belongs to the category of [[Boardsports]]', 'answer': 'skateboard', 'question': 'what sports in the image is a boardsports', 'img_file': 'COCO_val2014_000000107360.jpg', 'kb_source': 'dbpedia', 'fact': ['skateboard', 'belong to', 'boardsports'], 'question_id': '2471'}, '2048': {'fact_surface': '[[a boat]] has [[sails]]', 'answer': 'boat', 'question': 'Which object in this image has a sail?', 'img_file': 'ILSVRC2012_test_00001035.JPEG', 'kb_source': 'conceptnet', 'fact': ['boat', 'has a', 'sail'], 'question_id': '2470'}, '2049': {'fact_surface': '[[volleyball]] is a kind of [[ball sport]].', 'answer': 'volleyball', 'question': 'Which thing in this image is a ball sport?', 'img_file': 'ILSVRC2012_test_00000462.JPEG', 'kb_source': 'conceptnet', 'fact': ['volleyball', 'is a', 'ball sport'], 'question_id': '2478'}, '2050': {'fact_surface': '[[zebras]] are [[black and white]].', 'answer': 'zebra', 'question': 'what is the black and white object in this image?', 'img_file': 'COCO_val2014_000000016716.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has property', 'black and white'], 'question_id': '1397'}, '2051': {'fact_surface': '[[a keyboard]] is used for [[coding]]', 'answer': 'keyboard', 'question': 'Which object in this image can be used for coding?', 'img_file': 'ILSVRC2012_test_00049561.JPEG', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'used for', 'code'], 'question_id': '1987'}, '2052': {'fact_surface': '[[chain saw]] are more efficient than [[crosscut saw]]', 'answer': 'chain saw', 'question': 'Which object in this image is more efficient than crosscut saw?', 'img_file': 'ILSVRC2012_test_00005620.JPEG', 'kb_source': 'webchild', 'fact': ['chain saw', 'efficient', 'crosscut saw'], 'question_id': '3217'}, '2053': {'fact_surface': '[[A tennis ball]] is [[round]]', 'answer': 'tennis ball', 'question': 'Which object in this image is round?', 'img_file': 'COCO_val2014_000000138180.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis ball', 'has property', 'round'], 'question_id': '3213'}, '2054': {'fact_surface': '[[A lemon]] is [[a sour, yellow fruit]]', 'answer': 'lemon', 'question': 'Which sour yellow fruit is shown in this image?', 'img_file': 'ILSVRC2012_test_00002559.JPEG', 'kb_source': 'conceptnet', 'fact': ['lemon', 'is a', 'sour yellow fruit'], 'question_id': '1639'}, '2055': {'fact_surface': '[[skateboard]] belongs to the category of [[Game equipment]]', 'answer': 'skateboard', 'question': 'Which object in this image is a game equipment?', 'img_file': 'COCO_val2014_000000136908.jpg', 'kb_source': 'dbpedia', 'fact': ['skateboard', 'belong to', 'game equipment'], 'question_id': '2904'}, '2056': {'fact_surface': '[[chain saw]] belongs to the category of [[Cutting tools]]', 'answer': 'chain saw', 'question': 'Which object in this image belongs to the category Cutting tools?', 'img_file': 'ILSVRC2012_test_00005620.JPEG', 'kb_source': 'dbpedia', 'fact': ['chain saw', 'belong to', 'cutting tools'], 'question_id': '3218'}, '2057': {'fact_surface': '[[tree]] has [[trunk]].', 'answer': 'tree', 'question': 'Which object in this image has a trunk?', 'img_file': 'ILSVRC2012_test_00005620.JPEG', 'kb_source': 'conceptnet', 'fact': ['trunk', 'part of', 'tree'], 'question_id': '3219'}, '2058': {'fact_surface': '[[Keyboards]] are used to [[being typed on]]', 'answer': 'keyboard', 'question': 'Which object in this image is used for typing?', 'img_file': 'ILSVRC2012_test_00049561.JPEG', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'used for', 'be type on'], 'question_id': '1988'}, '2059': {'fact_surface': '[[keyboard]] is used for [[typing letters onto the windows]]', 'answer': 'keyboard', 'question': 'Which object in this image is used for input letter onto window?', 'img_file': 'ILSVRC2012_test_00049561.JPEG', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'used for', 'type letter onto window'], 'question_id': '1989'}, '2060': {'fact_surface': '[[lamb]] is related to [[sheep]]', 'answer': 'sheep', 'question': 'Which object in this image is related to lamb?', 'img_file': 'COCO_val2014_000000024207.jpg', 'kb_source': 'conceptnet', 'fact': ['lamb', 'related to', 'sheep'], 'question_id': '2810'}, '2061': {'fact_surface': '[[cell phone]] belongs to the category of [[Electricity]]', 'answer': 'cell phone', 'question': 'Which object in this image belongs to the category Electricity?', 'img_file': 'COCO_val2014_000000119026.jpg', 'kb_source': 'dbpedia', 'fact': ['cell phone', 'belong to', 'electricity'], 'question_id': '2813'}, '2062': {'fact_surface': '[[cell phone]] belongs to the category of [[Technology by type]]', 'answer': 'cell phone', 'question': 'What is the technology stuff?', 'img_file': 'COCO_val2014_000000119026.jpg', 'kb_source': 'dbpedia', 'fact': ['cell phone', 'belong to', 'technology by type'], 'question_id': '2812'}, '2063': {'fact_surface': '[[A computer]] can have [[a virus]]', 'answer': 'computer', 'question': 'Which object in this image can have a virus', 'img_file': 'COCO_val2014_000000137573.jpg', 'kb_source': 'conceptnet', 'fact': ['computer', 'has a', 'virus'], 'question_id': '560'}, '2064': {'fact_surface': '[[A computer]] can [[save files on disk]]', 'answer': 'computer', 'question': 'Which object in this image can save files on disk', 'img_file': 'COCO_val2014_000000137573.jpg', 'kb_source': 'conceptnet', 'fact': ['computer', 'capable of', 'save file on disk'], 'question_id': '561'}, '2065': {'fact_surface': '[[A computer]] is used for [[Studying]].', 'answer': 'computer', 'question': 'Which object in this image is used for studying', 'img_file': 'COCO_val2014_000000137573.jpg', 'kb_source': 'conceptnet', 'fact': ['computer', 'used for', 'study'], 'question_id': '562'}, '2066': {'fact_surface': 'You can use [[a computer]] to [[send email]]', 'answer': 'computer', 'question': 'Which object in this image can be used to send email', 'img_file': 'COCO_val2014_000000137573.jpg', 'kb_source': 'conceptnet', 'fact': ['computer', 'used for', 'send email'], 'question_id': '563'}, '2067': {'fact_surface': '[[Roquefort]] is related to [[sheep]]', 'answer': 'sheep', 'question': 'What in this image reminds you of the Roquefort?', 'img_file': 'COCO_val2014_000000020608.jpg', 'kb_source': 'conceptnet', 'fact': ['roquefort', 'related to', 'sheep'], 'question_id': '2819'}, '2068': {'fact_surface': '[[fencing]] is for [[keeping animals on a property]]', 'answer': 'fence', 'question': 'Which object in this image is used for keeping animals on the property?', 'img_file': 'COCO_val2014_000000020608.jpg', 'kb_source': 'conceptnet', 'fact': ['fence', 'used for', 'keep animal on property'], 'question_id': '2818'}, '2069': {'fact_surface': 'A [[elephant]] is a [[big, gray animal with a trunk]]', 'answer': 'elephant', 'question': 'which object in this image is a big, grey, animal with a trunk?', 'img_file': 'COCO_val2014_000000152785.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'is a', 'big gray animal with trunk'], 'question_id': '3379'}, '2070': {'fact_surface': '[[elephant]] belongs to the category of [[Mammal]]', 'answer': 'elephant', 'question': \"which object in this image belongs to the category 'mammal'?\", 'img_file': 'COCO_val2014_000000152785.jpg', 'kb_source': 'dbpedia', 'fact': ['elephant', 'belong to', 'mammal'], 'question_id': '3378'}, '2071': {'fact_surface': '[[A dog]] can [[wear a collar]]', 'answer': 'dog', 'question': 'Which object in this image is capable of wearing a collar?', 'img_file': 'ILSVRC2012_test_00007574.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'capable of', 'wear collar'], 'question_id': '5425'}, '2072': {'fact_surface': '[[A Zebra]] is [[an African equine species]]', 'answer': 'zebra', 'question': 'Which object in this image is a african equine specie?', 'img_file': 'COCO_val2014_000000007566.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'is a', 'african equine specie'], 'question_id': '5424'}, '2073': {'fact_surface': '[[Dogs]] can [[dig holes in the yard]]', 'answer': 'dog', 'question': 'Which object in this image is capable of dig hole in yard?', 'img_file': 'ILSVRC2012_test_00007574.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'capable of', 'dig hole in yard'], 'question_id': '5426'}, '2074': {'fact_surface': 'You are likely to find [[a computer]] in [[the office]].', 'answer': 'computer', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000013659.jpg', 'kb_source': 'conceptnet', 'fact': ['computer', 'at location', 'office'], 'question_id': '3373'}, '2075': {'fact_surface': '[[apple]] is related to [[red fruit]]', 'answer': 'apple', 'question': 'Which fruit in this image is related to red fruit?', 'img_file': 'ILSVRC2012_test_00023648.JPEG', 'kb_source': 'conceptnet', 'fact': ['apple', 'related to', 'red fruit'], 'question_id': '5420'}, '2076': {'fact_surface': '[[antifluoridationist]] is related to [[water]]', 'answer': 'water', 'question': 'What substance in this image might an antifluoridationst be concerned with?', 'img_file': 'COCO_val2014_000000019608.jpg', 'kb_source': 'conceptnet', 'fact': ['antifluoridationist', 'related to', 'water'], 'question_id': '5423'}, '2077': {'fact_surface': '[[fruits]] belongs to the category of [[Foods]]', 'answer': 'fruit', 'question': \"what's shown in the image?\", 'img_file': 'ILSVRC2012_test_00023648.JPEG', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'food'], 'question_id': '5422'}, '2078': {'fact_surface': '[[shirt]] has [[sleeve]].', 'answer': 'shirt', 'question': 'Which object in this image has a sleeve?', 'img_file': 'ILSVRC2012_test_00005204.JPEG', 'kb_source': 'conceptnet', 'fact': ['sleeve', 'part of', 'shirt'], 'question_id': '4243'}, '2079': {'fact_surface': '[[Grass]] can [[continue to grow]]', 'answer': 'grass', 'question': 'What plant in this image can continue to grow?', 'img_file': 'COCO_val2014_000000027617.jpg', 'kb_source': 'conceptnet', 'fact': ['grass', 'capable of', 'continue to grow'], 'question_id': '5520'}, '2080': {'fact_surface': '[[a dog]] is [[very common pet]]', 'answer': 'dog', 'question': 'Which animal in this image is a common pet?', 'img_file': 'COCO_val2014_000000027617.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'has property', 'very common pet'], 'question_id': '5521'}, '2081': {'fact_surface': '[[a kitchen]] is used for [[cook food]]', 'answer': 'cook food', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000107516.jpg', 'kb_source': 'conceptnet', 'fact': ['kitchen', 'used for', 'cook food'], 'question_id': '5524'}, '2082': {'fact_surface': '[[fridge]] is related to [[refrigerator]]', 'answer': 'fridge', 'question': 'What is the another name of the electrical appliance on the left.', 'img_file': 'COCO_val2014_000000107516.jpg', 'kb_source': 'conceptnet', 'fact': ['fridge', 'related to', 'refrigerator'], 'question_id': '5525'}, '2083': {'fact_surface': '[[a refrigerator]] can [[stock food]]', 'answer': 'refrigerator', 'question': 'Which object in this image can be used to stock food?', 'img_file': 'COCO_val2014_000000107516.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'capable of', 'stock food'], 'question_id': '5526'}, '2084': {'fact_surface': 'You can use [[a stove]] to [[cook soup]]', 'answer': 'stove', 'question': 'What object in this image could be used to cook soup?', 'img_file': 'COCO_val2014_000000107516.jpg', 'kb_source': 'conceptnet', 'fact': ['stove', 'used for', 'cook soup'], 'question_id': '5528'}, '2085': {'fact_surface': '[[train station]] are less crowded than [[airport]]', 'answer': 'train station', 'question': 'Which place is more crowded than the place shown in this image', 'img_file': 'ILSVRC2012_test_00015539.JPEG', 'kb_source': 'webchild', 'fact': ['train station', 'crowded', 'airport'], 'question_id': '5529'}, '2086': {'fact_surface': '[[a hat]] is for [[protecting your head]]', 'answer': 'hat', 'question': 'what object in this image is used for protecting your head?', 'img_file': 'COCO_val2014_000000000974.jpg', 'kb_source': 'conceptnet', 'fact': ['hat', 'used for', 'protect your head'], 'question_id': '48'}, '2087': {'fact_surface': '[[suitcase]] is related to [[travel]]', 'answer': 'travel', 'question': 'Why people need these stuffs?', 'img_file': 'COCO_val2014_000000108408.jpg', 'kb_source': 'conceptnet', 'fact': ['suitcase', 'related to', 'travel'], 'question_id': '49'}, '2088': {'fact_surface': '[[cups]] are used to [[hold water]]', 'answer': 'cup', 'question': 'Which thing in the image can be used to hold water?', 'img_file': 'COCO_val2014_000000124601.jpg', 'kb_source': 'conceptnet', 'fact': ['cup', 'used for', 'hold water'], 'question_id': '44'}, '2089': {'fact_surface': 'You can use [[a microwave]] to [[make popcorn]]', 'answer': 'microwave', 'question': 'Which thing in this image you can used to make popcorn?', 'img_file': 'COCO_val2014_000000124601.jpg', 'kb_source': 'conceptnet', 'fact': ['microwave', 'used for', 'make popcorn'], 'question_id': '45'}, '2090': {'fact_surface': '(laptop,/r/UsedFor,play game)', 'answer': 'laptop', 'question': 'Which device in the image can be used for playing game?', 'img_file': 'COCO_val2014_000000124601.jpg', 'kb_source': 'conceptnet', 'fact': ['laptop', 'used for', 'play game'], 'question_id': '42'}, '2091': {'fact_surface': '[[a microwave]] can be used to [[heat food]]', 'answer': 'microwave', 'question': 'Which device in the image can be used for heating food?', 'img_file': 'COCO_val2014_000000124601.jpg', 'kb_source': 'conceptnet', 'fact': ['microwave', 'used for', 'heat food'], 'question_id': '43'}, '2092': {'fact_surface': '[[goldfish]] have [[short lifespans]]', 'answer': 'goldfish', 'question': 'what object in this image has a short lifespan?', 'img_file': 'ILSVRC2012_test_00042680.JPEG', 'kb_source': 'conceptnet', 'fact': ['goldfish', 'has a', 'short lifespan'], 'question_id': '41'}, '2093': {'fact_surface': '[[a handbag]] is used for [[storing things]]', 'answer': 'handbag', 'question': 'What object in this image is used for storing things?', 'img_file': 'COCO_val2014_000000000536.jpg', 'kb_source': 'conceptnet', 'fact': ['handbag', 'used for', 'store thing'], 'question_id': '347'}, '2094': {'fact_surface': '[[A sofa]] is [[a comfortable place to sit]]', 'answer': 'sofa', 'question': 'Where can I find a comfortable place to sit?', 'img_file': 'COCO_val2014_000000004125.jpg', 'kb_source': 'conceptnet', 'fact': ['sofa', 'is a', 'comfortable place to sit'], 'question_id': '341'}, '2095': {'fact_surface': 'You are likely to find [[remote control]] close to [[the tv]].', 'answer': 'close to tv', 'question': 'Where you can find the object shown in this image?', 'img_file': 'ILSVRC2012_test_00045390.JPEG', 'kb_source': 'conceptnet', 'fact': ['close to tv', 'at location', 'tv'], 'question_id': '349'}, '2096': {'fact_surface': '[[double bass]] is related to [[violin]]', 'answer': 'violin', 'question': 'Which object in this image is related to double bass?', 'img_file': 'ILSVRC2012_test_00015696.JPEG', 'kb_source': 'conceptnet', 'fact': ['double bass', 'related to', 'violin'], 'question_id': '3237'}, '2097': {'fact_surface': '[[teddy bear]] belongs to the category of [[Animals in art]]', 'answer': 'teddy bear', 'question': 'Which object in this image belongs to the category Animals in art?', 'img_file': 'COCO_val2014_000000009262.jpg', 'kb_source': 'dbpedia', 'fact': ['teddy bear', 'belong to', 'animals in art'], 'question_id': '4521'}, '2098': {'fact_surface': '[[monitors]] can [[show text]]', 'answer': 'monitor', 'question': 'Which object in this image is capable of showing text?', 'img_file': 'ILSVRC2012_test_00000705.JPEG', 'kb_source': 'conceptnet', 'fact': ['monitor', 'capable of', 'show text'], 'question_id': '4836'}, '2099': {'fact_surface': '[[lemon]] is [[citrus]]', 'answer': 'lemon', 'question': 'Which object in this image is a citrus?', 'img_file': 'ILSVRC2012_test_00038877.JPEG', 'kb_source': 'conceptnet', 'fact': ['lemon', 'has property', 'citrus'], 'question_id': '2268'}, '2100': {'fact_surface': '[[lemons]] are [[yellow]]', 'answer': 'lemon', 'question': 'What is the yellow object in this image?', 'img_file': 'ILSVRC2012_test_00038877.JPEG', 'kb_source': 'conceptnet', 'fact': ['lemon', 'has property', 'yellow'], 'question_id': '2269'}, '2101': {'fact_surface': '[[cucumbers]] are [[green]]', 'answer': 'cucumber', 'question': 'Which object in this image is green?', 'img_file': 'ILSVRC2012_test_00056044.JPEG', 'kb_source': 'conceptnet', 'fact': ['cucumber', 'has property', 'green'], 'question_id': '2262'}, '2102': {'fact_surface': '[[spaghetti sauce]] is related to [[tomato]]', 'answer': 'tomato', 'question': 'Which object in this image is used in spaghetti sauce?', 'img_file': 'ILSVRC2012_test_00056044.JPEG', 'kb_source': 'conceptnet', 'fact': ['spaghetti sauce', 'related to', 'tomato'], 'question_id': '2263'}, '2103': {'fact_surface': '[[a baseball]] is for [[pitching]]', 'answer': 'baseball', 'question': 'Which object in the image is required for pitching?', 'img_file': 'COCO_val2014_000000005388.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'used for', 'pitch'], 'question_id': '2260'}, '2104': {'fact_surface': '[[a lemon]] is [[sour]].', 'answer': 'lemon', 'question': 'Which object in this image is sour?', 'img_file': 'ILSVRC2012_test_00038877.JPEG', 'kb_source': 'conceptnet', 'fact': ['lemon', 'has property', 'sour'], 'question_id': '2266'}, '2105': {'fact_surface': '[[Artichokes]] are a kind of [[vegetables]]', 'answer': 'artichoke', 'question': 'Which object in this image is a vegetable?', 'img_file': 'ILSVRC2012_test_00038877.JPEG', 'kb_source': 'conceptnet', 'fact': ['artichoke', 'is a', 'vegetable'], 'question_id': '2267'}, '2106': {'fact_surface': '[[Roma]] is related to [[tomato]]', 'answer': 'tomato', 'question': 'Which object in this image is related to Roma?', 'img_file': 'ILSVRC2012_test_00056044.JPEG', 'kb_source': 'conceptnet', 'fact': ['rom', 'related to', 'tomato'], 'question_id': '2264'}, '2107': {'fact_surface': '[[cats]] have [[fur]]', 'answer': 'cat', 'question': 'Which object in this image has fur?', 'img_file': 'COCO_val2014_000000026942.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'has a', 'fur'], 'question_id': '4817'}, '2108': {'fact_surface': '[[cats]] are [[usually furry]]', 'answer': 'cat', 'question': 'Which object in this image is usually furry?', 'img_file': 'COCO_val2014_000000026942.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'has property', 'usually furry'], 'question_id': '4816'}, '2109': {'fact_surface': '[[books]] contain [[text and pictures]]', 'answer': 'book', 'question': 'Which object in this image contains text and images?', 'img_file': 'COCO_val2014_000000026942.jpg', 'kb_source': 'conceptnet', 'fact': ['book', 'has a', 'text and picture'], 'question_id': '4819'}, '2110': {'fact_surface': '[[Cats]] like to [[jump up on furniture and explore]]', 'answer': 'cat', 'question': 'Which object in this image likes to jump on furniture?', 'img_file': 'COCO_val2014_000000026942.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'desires', 'jump up on furniture and explore'], 'question_id': '4818'}, '2111': {'fact_surface': '[[a banjo]] is used for [[playing folk music]]', 'answer': 'banjo', 'question': 'Which object in this image can be used to play folk music?', 'img_file': 'ILSVRC2012_test_00028677.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'used for', 'play folk music'], 'question_id': '3238'}, '2112': {'fact_surface': '[[mouse]] belongs to the category of [[Computing]]', 'answer': 'mouse', 'question': 'Which object in this image belongs to a computer?', 'img_file': 'COCO_val2014_000000113126.jpg', 'kb_source': 'dbpedia', 'fact': ['mouse', 'belong to', 'computing'], 'question_id': '1365'}, '2113': {'fact_surface': '[[a person]] has [[one heart]]', 'answer': 'person', 'question': 'which object in this image has one heart?', 'img_file': 'ILSVRC2012_test_00044361.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'has a', 'one heart'], 'question_id': '4389'}, '2114': {'fact_surface': '[[A person]] can [[say \"I love you\"]]', 'answer': 'person', 'question': \"which object in this image can say 'I love you'?\", 'img_file': 'ILSVRC2012_test_00044361.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'say i love you'], 'question_id': '4388'}, '2115': {'fact_surface': '[[saxophone]] is used for [[music]].', 'answer': 'music', 'question': 'What is the object in the middle right of this image used for?', 'img_file': 'ILSVRC2012_test_00001600.JPEG', 'kb_source': 'conceptnet', 'fact': ['saxophone', 'used for', 'music'], 'question_id': '4382'}, '2116': {'fact_surface': '[[A person]] can [[iron pants]]', 'answer': 'person', 'question': 'which object in this image is capable of ironing pants?', 'img_file': 'ILSVRC2012_test_00044361.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'iron pant'], 'question_id': '4387'}, '2117': {'fact_surface': '[[people]] are [[paid their salary by companies]]', 'answer': 'person', 'question': 'which object in this image can be paid a salary by a company?', 'img_file': 'ILSVRC2012_test_00044361.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'is a', 'pay their salary by company'], 'question_id': '4386'}, '2118': {'fact_surface': '[[a banana]] is for [[eating]]', 'answer': 'banana', 'question': 'what object in this image is used for eating?', 'img_file': 'COCO_val2014_000000134460.jpg', 'kb_source': 'conceptnet', 'fact': ['banana', 'used for', 'eat'], 'question_id': '406'}, '2119': {'fact_surface': 'You can use [[a shirt]] to [[cover your chest]]', 'answer': 'shirt', 'question': 'Which object in this image can be used for covering your chest?', 'img_file': 'COCO_val2014_000000018666.jpg', 'kb_source': 'conceptnet', 'fact': ['shirt', 'used for', 'cover your chest'], 'question_id': '1377'}, '2120': {'fact_surface': 'A [[dog]] is a [[nice friend]]', 'answer': 'dog', 'question': 'Which animal is a nice friend', 'img_file': 'COCO_val2014_000000142722.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'is a', 'nice friend'], 'question_id': '400'}, '2121': {'fact_surface': '[[a luggage]] is used for [[carrying clothes on a trip]]', 'answer': 'luggage', 'question': 'Which object in this image is used for carrying clothes on trip?', 'img_file': 'COCO_val2014_000000004980.jpg', 'kb_source': 'conceptnet', 'fact': ['luggage', 'used for', 'carry clothe on trip'], 'question_id': '1379'}, '2122': {'fact_surface': 'You can use [[an umbrella]] to [[provide shelter]]', 'answer': 'umbrella', 'question': 'Which object in this image is used to provide shelter?', 'img_file': 'COCO_val2014_000000018666.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'used for', 'provide shelter'], 'question_id': '1378'}, '2123': {'fact_surface': '[[drum]] is related to [[sticks]]', 'answer': 'tick', 'question': 'What do you need to make the instrument in the image work?', 'img_file': 'ILSVRC2012_test_00022927.JPEG', 'kb_source': 'conceptnet', 'fact': ['drum', 'related to', 'tick'], 'question_id': '408'}, '2124': {'fact_surface': '[[The tail]] is part of [[a cat]]', 'answer': 'cat', 'question': 'Which object in this image has a tail as a part of the body?', 'img_file': 'ILSVRC2012_test_00018396.JPEG', 'kb_source': 'conceptnet', 'fact': ['tail', 'part of', 'cat'], 'question_id': '4033'}, '2125': {'fact_surface': '[[A cat]] can [[eat fish]]', 'answer': 'cat', 'question': 'Which object in this image likes eating fish?', 'img_file': 'ILSVRC2012_test_00018396.JPEG', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'eat fish'], 'question_id': '4032'}, '2126': {'fact_surface': '[[drum]] are easier than [[guitar]]', 'answer': 'drum', 'question': 'Which object is easier than guitar in this image?', 'img_file': 'ILSVRC2012_test_00027147.JPEG', 'kb_source': 'webchild', 'fact': ['drum', 'easy', 'guitar'], 'question_id': '4037'}, '2127': {'fact_surface': '[[a trumpet]] is for [[playing music]]', 'answer': 'trumpet', 'question': 'Which object in this image desires trick others?', 'img_file': 'ILSVRC2012_test_00027147.JPEG', 'kb_source': 'conceptnet', 'fact': ['trumpet', 'used for', 'play music'], 'question_id': '4036'}, '2128': {'fact_surface': 'You are likely to find [[a guitar]] in [[a band]]', 'answer': 'guitar', 'question': 'Which object in this image can be found in band?', 'img_file': 'ILSVRC2012_test_00031517.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'at location', 'band'], 'question_id': '4039'}, '2129': {'fact_surface': '[[A drum]] is used for [[making a rhythm]]', 'answer': 'drum', 'question': 'Which object in this image is used for making a rhythm?', 'img_file': 'ILSVRC2012_test_00027147.JPEG', 'kb_source': 'conceptnet', 'fact': ['drum', 'used for', 'make rhythm'], 'question_id': '4038'}, '2130': {'fact_surface': 'You can use [[a keyboard]] to [[press keys]]', 'answer': 'keyboard', 'question': 'Which object in this image is used for press key?', 'img_file': 'ILSVRC2012_test_00029694.JPEG', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'used for', 'press key'], 'question_id': '2455'}, '2131': {'fact_surface': 'You can use [[a keyboard]] to [[input data]]', 'answer': 'keyboard', 'question': 'Which object in this image is used for inputing?', 'img_file': 'ILSVRC2012_test_00029694.JPEG', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'used for', 'input data'], 'question_id': '2454'}, '2132': {'fact_surface': '[[Computers]] have [[revolutionized every part of life]]', 'answer': 'computer', 'question': 'Which object in this image has a significant impact to every part of life', 'img_file': 'ILSVRC2012_test_00029694.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'has a', 'revolutionize every part of life'], 'question_id': '2457'}, '2133': {'fact_surface': '[[keyboard]] belongs to the category of [[Computer peripherals]]', 'answer': 'keyboard', 'question': 'Which object in this image belongs to the category computer peripherals?', 'img_file': 'ILSVRC2012_test_00029694.JPEG', 'kb_source': 'dbpedia', 'fact': ['keyboard', 'belong to', 'computer peripherals'], 'question_id': '2456'}, '2134': {'fact_surface': '[[visual display unit]] is related to [[monitor]]', 'answer': 'monitor', 'question': 'Which object in this image is a visual display unit?', 'img_file': 'ILSVRC2012_test_00029694.JPEG', 'kb_source': 'conceptnet', 'fact': ['visual display unit', 'related to', 'monitor'], 'question_id': '2451'}, '2135': {'fact_surface': '[[machine language]] is related to [[computer]]', 'answer': 'computer', 'question': 'Which object in this image is related to machine language?', 'img_file': 'ILSVRC2012_test_00029694.JPEG', 'kb_source': 'conceptnet', 'fact': ['machine language', 'related to', 'computer'], 'question_id': '2453'}, '2136': {'fact_surface': '[[A computer]] can [[process information]]', 'answer': 'computer', 'question': 'Which object in this image is capable of process information?', 'img_file': 'ILSVRC2012_test_00029694.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'capable of', 'process information'], 'question_id': '2452'}, '2137': {'fact_surface': 'You can use [[a banjo]] to [[perform music]]', 'answer': 'banjo', 'question': 'Which object in this image can be used to perform music', 'img_file': 'ILSVRC2012_test_00000881.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'used for', 'perform music'], 'question_id': '656'}, '2138': {'fact_surface': '[[a banjo]] is used for [[playing folk music]]', 'answer': 'banjo', 'question': 'Which object in this image is used for playing folk music', 'img_file': 'ILSVRC2012_test_00000881.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'used for', 'play folk music'], 'question_id': '657'}, '2139': {'fact_surface': '[[A banjo]] is [[a stringed instrumetnt]]', 'answer': 'banjo', 'question': 'What is the name of the stringed instrument', 'img_file': 'ILSVRC2012_test_00000881.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'is a', 'string instrumetnt'], 'question_id': '654'}, '2140': {'fact_surface': '[[a banjo]] is used for [[music]]', 'answer': 'banjo', 'question': 'Which object in this image is used for music', 'img_file': 'ILSVRC2012_test_00000881.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'used for', 'music'], 'question_id': '655'}, '2141': {'fact_surface': '[[a bow]] can be used to [[play a violin]]', 'answer': 'violin', 'question': 'Which instrument in this image is played with a bow?', 'img_file': 'ILSVRC2012_test_00043712.JPEG', 'kb_source': 'conceptnet', 'fact': ['bow', 'used for', 'violin'], 'question_id': '650'}, '2142': {'fact_surface': '[[bear]] is related to [[furry]]', 'answer': 'bear', 'question': 'Which object in this image is furry?', 'img_file': 'COCO_val2014_000000020972.jpg', 'kb_source': 'conceptnet', 'fact': ['bear', 'related to', 'furry'], 'question_id': '3226'}, '2143': {'fact_surface': '[[headpiece]] is related to [[helmet]]', 'answer': 'helmet', 'question': 'Which object in this image is a type of headpiece?', 'img_file': 'COCO_val2014_000000116061.jpg', 'kb_source': 'conceptnet', 'fact': ['headpiece', 'related to', 'helmet'], 'question_id': '3230'}, '2144': {'fact_surface': '[[motorcycle]] is a type of [[motor vehicle]].', 'answer': 'motorcycle', 'question': 'what kind of motor vehicle can we observe in this iamge', 'img_file': 'COCO_val2014_000000116061.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'is a', 'motor vehicle'], 'question_id': '3231'}, '2145': {'fact_surface': '[[drum]] belongs to the category of [[Percussion instrument]]', 'answer': 'drum', 'question': 'Which object in this image belongs to the category Percussion instrument?', 'img_file': 'ILSVRC2012_test_00015696.JPEG', 'kb_source': 'dbpedia', 'fact': ['drum', 'belong to', 'percussion instrument'], 'question_id': '3236'}, '2146': {'fact_surface': '[[arctophile]] is related to [[teddy bear]]', 'answer': 'teddy bear', 'question': 'Which object in this image is collected by arctophiles?', 'img_file': 'COCO_val2014_000000119802.jpg', 'kb_source': 'conceptnet', 'fact': ['arctophile', 'related to', 'teddy bear'], 'question_id': '1618'}, '2147': {'fact_surface': 'You are likely to find [[a crossroads]] in [[the road]]', 'answer': 'road', 'question': 'where is this place?', 'img_file': 'COCO_val2014_000000119802.jpg', 'kb_source': 'conceptnet', 'fact': ['crossroad', 'at location', 'road'], 'question_id': '1619'}, '2148': {'fact_surface': 'You can use [[a baseball]] to [[hit a person]]', 'answer': 'baseball', 'question': 'What object can be used to hit person?', 'img_file': 'COCO_val2014_000000000357.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'used for', 'hit person'], 'question_id': '1616'}, '2149': {'fact_surface': '[[surfing]] is related to [[surfboard]]', 'answer': 'surfboard', 'question': 'Which object in this image is related to surfing?', 'img_file': 'COCO_val2014_000000026617.jpg', 'kb_source': 'conceptnet', 'fact': ['surf', 'related to', 'surfboard'], 'question_id': '1617'}, '2150': {'fact_surface': 'You can use [[an umbrella]] to [[keep yurself dry]]', 'answer': 'umbrella', 'question': 'Which object in this image is used for keeping yourself dry?', 'img_file': 'COCO_val2014_000000007394.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'used for', 'keep yurself dry'], 'question_id': '1966'}, '2151': {'fact_surface': 'You can use [[a baseball field]] to [[play a game of baseball]]', 'answer': 'play game of baseball', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000000357.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball field', 'used for', 'play game of baseball'], 'question_id': '1615'}, '2152': {'fact_surface': '[[bus]] are usually far slower than [[train]]', 'answer': 'bus', 'question': 'which object in this image is slower than train?', 'img_file': 'COCO_val2014_000000102056.jpg', 'kb_source': 'webchild', 'fact': ['bus', 'slow', 'train'], 'question_id': '1612'}, '2153': {'fact_surface': '[[bus]] are obviously much more flexible than [[train]]', 'answer': 'bus', 'question': 'which object in this image is more flexible than train?', 'img_file': 'COCO_val2014_000000102056.jpg', 'kb_source': 'webchild', 'fact': ['bus', 'flexible', 'train'], 'question_id': '1613'}, '2154': {'fact_surface': '[[a bus]] is for [[mass transportaion]]', 'answer': 'bus', 'question': 'Which object in this image is used for mass transportaion?', 'img_file': 'COCO_val2014_000000102056.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'used for', 'mass transportaion'], 'question_id': '1610'}, '2155': {'fact_surface': '[[bus]] is bigger than [[car]]', 'answer': 'bus', 'question': 'which object in this image is bigger than car?', 'img_file': 'COCO_val2014_000000102056.jpg', 'kb_source': 'webchild', 'fact': ['bus', 'big', 'car'], 'question_id': '1611'}, '2156': {'fact_surface': '[[weddings]] are [[romantic]]', 'answer': 'romantic', 'question': 'How is wedding feeling?', 'img_file': 'COCO_val2014_000000123810.jpg', 'kb_source': 'conceptnet', 'fact': ['wedding', 'has property', 'romantic'], 'question_id': '2873'}, '2157': {'fact_surface': '[[maraca]] is related to [[percussion]]', 'answer': 'maraca', 'question': 'What percussion instrument is in this image?', 'img_file': 'ILSVRC2012_test_00001366.JPEG', 'kb_source': 'conceptnet', 'fact': ['maraca', 'related to', 'percussion'], 'question_id': '2877'}, '2158': {'fact_surface': '[[hot dog]] belongs to the category of [[Street food]]', 'answer': 'hot dog', 'question': 'which kind of street food can we find in this image', 'img_file': 'COCO_val2014_000000108904.jpg', 'kb_source': 'dbpedia', 'fact': ['hot dog', 'belong to', 'street food'], 'question_id': '2876'}, '2159': {'fact_surface': '[[a baseball bat]] can be used to [[hit a baseball]]', 'answer': 'baseball bat', 'question': 'What is used to hit a baseball?', 'img_file': 'COCO_val2014_000000144252.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball bat', 'used for', 'hit baseball'], 'question_id': '2875'}, '2160': {'fact_surface': '[[weddings]] are [[happy for the bride and groom]]', 'answer': 'happy for bride and groom', 'question': 'What property does the action in this image have?', 'img_file': 'COCO_val2014_000000123810.jpg', 'kb_source': 'conceptnet', 'fact': ['wedding', 'has property', 'happy for bride and groom'], 'question_id': '2874'}, '2161': {'fact_surface': '[[a bottle]] is for [[holding juice]]', 'answer': 'bottle', 'question': 'Which object in this image might be used for holding juice?', 'img_file': 'COCO_val2014_000000135071.jpg', 'kb_source': 'conceptnet', 'fact': ['bottle', 'used for', 'hold juice'], 'question_id': '4986'}, '2162': {'fact_surface': '[[maraca]] is related to [[Latin American]]', 'answer': 'maraca', 'question': 'What object in this image is related to Latin America?', 'img_file': 'ILSVRC2012_test_00001366.JPEG', 'kb_source': 'conceptnet', 'fact': ['maraca', 'related to', 'latin american'], 'question_id': '2878'}, '2163': {'fact_surface': '[[Trees]] generally have [[green leaves]]', 'answer': 'tree', 'question': 'Which object in this image has a green leave?', 'img_file': 'COCO_val2014_000000017018.jpg', 'kb_source': 'conceptnet', 'fact': ['tree', 'has a', 'green leave'], 'question_id': '3353'}, '2164': {'fact_surface': '[[Trees]] can [[shade people from the sun]]', 'answer': 'tree', 'question': 'Which object in this image is capable of shading people from the sun?', 'img_file': 'COCO_val2014_000000017018.jpg', 'kb_source': 'conceptnet', 'fact': ['tree', 'capable of', 'shade person from sun'], 'question_id': '3352'}, '2165': {'fact_surface': '[[a drum]] is for [[banging]]', 'answer': 'drum', 'question': 'Which object in this image is used for banging?', 'img_file': 'ILSVRC2012_test_00032533.JPEG', 'kb_source': 'conceptnet', 'fact': ['drum', 'used for', 'bang'], 'question_id': '5443'}, '2166': {'fact_surface': '[[donut]] belongs to the category of [[Foods]]', 'answer': 'donut', 'question': 'What can I eat?', 'img_file': 'COCO_val2014_000000148957.jpg', 'kb_source': 'dbpedia', 'fact': ['donut', 'belong to', 'food'], 'question_id': '5442'}, '2167': {'fact_surface': '[[elephants]] are [[large mammals]]', 'answer': 'elephant', 'question': 'What is the large mammal shown in this image?', 'img_file': 'COCO_val2014_000000007108.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'is a', 'large mammal'], 'question_id': '5441'}, '2168': {'fact_surface': '[[An elephant]] has [[a nose]]', 'answer': 'elephant', 'question': 'Which object in this image has a nose?:', 'img_file': 'COCO_val2014_000000007108.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'has a', 'nose'], 'question_id': '5440'}, '2169': {'fact_surface': '[[horses]] are [[good aniamls to teach]]', 'answer': 'horse', 'question': 'Which animal in this image is good to teach?', 'img_file': 'COCO_val2014_000000139140.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'is a', 'good aniamls to teach'], 'question_id': '5446'}, '2170': {'fact_surface': '[[horses]] can [[be raced and ridden by humans]]', 'answer': 'horse', 'question': 'Which object in this image is capable of be race and ride by human?', 'img_file': 'COCO_val2014_000000139140.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'capable of', 'be race and ride by human'], 'question_id': '5445'}, '2171': {'fact_surface': '[[horses]] can [[run much faster than people]]', 'answer': 'horse', 'question': '￼Which object in this image is capable of running much faster than a person?', 'img_file': 'COCO_val2014_000000139140.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'capable of', 'run much fast than person'], 'question_id': '5444'}, '2172': {'fact_surface': '[[tomato sauce]] is related to [[tomato]]', 'answer': 'tomato', 'question': 'Which object in this image may be related to tomato sauce?', 'img_file': 'COCO_val2014_000000105014.jpg', 'kb_source': 'conceptnet', 'fact': ['tomato sauce', 'related to', 'tomato'], 'question_id': '5509'}, '2173': {'fact_surface': '[[monitor]] belongs to the category of [[Computing]]', 'answer': 'monitor', 'question': 'what can we find on the desk', 'img_file': 'ILSVRC2012_test_00041612.JPEG', 'kb_source': 'dbpedia', 'fact': ['monitor', 'belong to', 'computing'], 'question_id': '5500'}, '2174': {'fact_surface': 'You can use [[a keyboard]] to [[communicate with someone in a chatroom]]', 'answer': 'keyboard', 'question': 'Which object in this image could be used for communicating with someone in chatroom?', 'img_file': 'COCO_val2014_000000108026.jpg', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'used for', 'communicate with someone in chatroom'], 'question_id': '5501'}, '2175': {'fact_surface': '[[elephants]] are [[bigger than ants]]', 'answer': 'elephant', 'question': 'What object in this image is bigger than an ant?', 'img_file': 'COCO_val2014_000000101959.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'is a', 'big than ant'], 'question_id': '542'}, '2176': {'fact_surface': '[[motorcycle]] is used for [[travel]].', 'answer': 'motorcycle', 'question': 'What thing in the image is used for travel?', 'img_file': 'COCO_val2014_000000102497.jpg', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'used for', 'travel'], 'question_id': '543'}, '2177': {'fact_surface': '[[Violins]] can [[play beautiful music]]', 'answer': 'violin', 'question': 'Which object in this image is able to play beautiful music', 'img_file': 'ILSVRC2012_test_00031102.JPEG', 'kb_source': 'conceptnet', 'fact': ['violin', 'capable of', 'play beautiful music'], 'question_id': '540'}, '2178': {'fact_surface': 'You can use [[a bench]] to [[sit and rest]]', 'answer': 'bench', 'question': 'Where could one sit and rest in this image?', 'img_file': 'COCO_val2014_000000140908.jpg', 'kb_source': 'conceptnet', 'fact': ['bench', 'used for', 'sit and rest'], 'question_id': '545'}, '2179': {'fact_surface': '(surfboard,/r/UsedFor,surfing)', 'answer': 'surfboard', 'question': 'what object in this image is used for surfing', 'img_file': 'COCO_val2014_000000111644.jpg', 'kb_source': 'conceptnet', 'fact': ['surfboard', 'used for', 'surfing'], 'question_id': '548'}, '2180': {'fact_surface': '[[Cars]] can [[spend gas]]', 'answer': 'car', 'question': 'Which object in this image spends gas?', 'img_file': 'ILSVRC2012_test_00006342.JPEG', 'kb_source': 'conceptnet', 'fact': ['car', 'capable of', 'spend gas'], 'question_id': '5472'}, '2181': {'fact_surface': 'You are likely to find [[a banjo]] in [[the movie, Deliverance]]', 'answer': 'banjo', 'question': \"Which object in this image can be found in the movie 'Deliverance'?\", 'img_file': 'ILSVRC2012_test_00000658.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'at location', 'movie deliverance'], 'question_id': '5136'}, '2182': {'fact_surface': '[[whale]] are bigger than [[elephant]]', 'answer': 'whale', 'question': 'which object is bigger than an elephant', 'img_file': 'ILSVRC2012_test_00002435.JPEG', 'kb_source': 'webchild', 'fact': ['whale', 'big', 'elephant'], 'question_id': '3325'}, '2183': {'fact_surface': '[[a market]] is for [[buying and selling commodities futures]]', 'answer': 'buy and sell', 'question': 'What is the place in this image usually used for?', 'img_file': 'ILSVRC2012_test_00004006.JPEG', 'kb_source': 'conceptnet', 'fact': ['market', 'used for', 'buy and sell'], 'question_id': '3827'}, '2184': {'fact_surface': '[[drum]] is used for [[playing in an orchestra]].', 'answer': 'drum', 'question': 'What object in this image is used for play in orchestra?', 'img_file': 'ILSVRC2012_test_00004006.JPEG', 'kb_source': 'conceptnet', 'fact': ['drum', 'used for', 'play in orchestra'], 'question_id': '3826'}, '2185': {'fact_surface': '[[vegetables]] belongs to the category of [[Foods]]', 'answer': 'vegetable', 'question': 'Which object in this image belongs to the category Foods?', 'img_file': 'ILSVRC2012_test_00001705.JPEG', 'kb_source': 'dbpedia', 'fact': ['vegetable', 'belong to', 'food'], 'question_id': '3829'}, '2186': {'fact_surface': '[[silver]] is related to [[metal]]', 'answer': 'metal', 'question': 'Which substance in this image could also be related to silver?', 'img_file': 'ILSVRC2012_test_00000321.JPEG', 'kb_source': 'conceptnet', 'fact': ['silver', 'related to', 'metal'], 'question_id': '5007'}, '2187': {'fact_surface': '[[Computers]] can [[boot from a hard drive]]', 'answer': 'computer', 'question': 'Which object in this image is capable of boot from hard drive?', 'img_file': 'ILSVRC2012_test_00045649.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'capable of', 'boot from hard drive'], 'question_id': '5006'}, '2188': {'fact_surface': '[[Knives]] can [[cut food]]', 'answer': 'knife', 'question': 'Which object in this image is capable of cut food?', 'img_file': 'COCO_val2014_000000112437.jpg', 'kb_source': 'conceptnet', 'fact': ['knife', 'capable of', 'cut food'], 'question_id': '5005'}, '2189': {'fact_surface': '[[A computer]] is [[a high-speed electronic machine]]', 'answer': 'computer', 'question': 'Which object in this image is a high speed electronic machine?', 'img_file': 'COCO_val2014_000000122777.jpg', 'kb_source': 'conceptnet', 'fact': ['computer', 'is a', 'high speed electronic machine'], 'question_id': '3587'}, '2190': {'fact_surface': '[[Helmets]] are [[worn to protect the head]]', 'answer': 'helmet', 'question': \"What is protecting this person's head?\", 'img_file': 'ILSVRC2012_test_00019140.JPEG', 'kb_source': 'conceptnet', 'fact': ['helmet', 'receives action', 'wear to protect head'], 'question_id': '368'}, '2191': {'fact_surface': '[[an axe]] can be used for [[chopping wood]]', 'answer': 'axe', 'question': 'Which object in this image can be used for chopping wood?', 'img_file': 'ILSVRC2012_test_00014499.JPEG', 'kb_source': 'conceptnet', 'fact': ['axe', 'used for', 'chop wood'], 'question_id': '363'}, '2192': {'fact_surface': '[[A snake]] has [[no legs]]', 'answer': 'no leg', 'question': 'Whether the animal in the image has legs or not?', 'img_file': 'ILSVRC2012_test_00000037.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'has a', 'no leg'], 'question_id': '360'}, '2193': {'fact_surface': '[[a kite]] is used for [[flying and having fun]]', 'answer': 'kite', 'question': 'Which object in this image is used for flying and having fun?', 'img_file': 'COCO_val2014_000000005599.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'used for', 'fly and have fun'], 'question_id': '2204'}, '2194': {'fact_surface': '[[kite]] is related to [[lightweight]]', 'answer': 'kite', 'question': 'Which object in this image is related to lightweight?', 'img_file': 'COCO_val2014_000000005599.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'related to', 'lightweight'], 'question_id': '2205'}, '2195': {'fact_surface': '[[carrot cake]] is related to [[carrot]]', 'answer': 'carrot', 'question': 'Which object in this image is used in carrot cake?', 'img_file': 'ILSVRC2012_test_00009502.JPEG', 'kb_source': 'conceptnet', 'fact': ['carrot cake', 'related to', 'carrot'], 'question_id': '4428'}, '2196': {'fact_surface': 'You can use [[a keyboard]] to [[type a letter]]', 'answer': 'keyboard', 'question': 'Which object in this image is used for type letter?', 'img_file': 'ILSVRC2012_test_00000705.JPEG', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'used for', 'type letter'], 'question_id': '4839'}, '2197': {'fact_surface': '[[single-click]] is related to [[mouse]]', 'answer': 'mouse', 'question': 'Which object in this image is related to single click?', 'img_file': 'ILSVRC2012_test_00000705.JPEG', 'kb_source': 'conceptnet', 'fact': ['single click', 'related to', 'mouse'], 'question_id': '4838'}, '2198': {'fact_surface': '[[geek]] is related to [[computer]]', 'answer': 'computer', 'question': 'Which object in this image is favored by geeks?', 'img_file': 'COCO_val2014_000000124911.jpg', 'kb_source': 'conceptnet', 'fact': ['geek', 'related to', 'computer'], 'question_id': '4830'}, '2199': {'fact_surface': '[[a couch]] can be used for [[sitting]]', 'answer': 'couch', 'question': 'Which object in this image is used for sitting?', 'img_file': 'COCO_val2014_000000102904.jpg', 'kb_source': 'conceptnet', 'fact': ['couch', 'used for', 'it'], 'question_id': '4522'}, '2200': {'fact_surface': '[[computer]] are clearly much more complex than [[car]]', 'answer': 'computer', 'question': 'Which object in this image is clearly more complex than a car?', 'img_file': 'ILSVRC2012_test_00000705.JPEG', 'kb_source': 'webchild', 'fact': ['computer', 'complex', 'car'], 'question_id': '4837'}, '2201': {'fact_surface': '[[Broccoli]] is [[a green vegetable]]', 'answer': 'broccoli', 'question': 'Which object in this image is a green vegetable?', 'img_file': 'COCO_val2014_000000003501.jpg', 'kb_source': 'conceptnet', 'fact': ['broccoli', 'is a', 'green vegetable'], 'question_id': '4421'}, '2202': {'fact_surface': 'A [[person]] can [[play a game]].', 'answer': 'person', 'question': 'which object in this image can play a game?', 'img_file': 'COCO_val2014_000000014892.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'play game'], 'question_id': '5298'}, '2203': {'fact_surface': '[[People]] can [[move across the ground by running]]', 'answer': 'person', 'question': 'Which object in this image can run?', 'img_file': 'COCO_val2014_000000014892.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'move across grind by run'], 'question_id': '5299'}, '2204': {'fact_surface': '[[A person]] can [[open a letter]]', 'answer': 'person', 'question': 'which object in this image can open an letter?', 'img_file': 'COCO_val2014_000000014892.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'open letter'], 'question_id': '5296'}, '2205': {'fact_surface': '[[People]] can [[smell with their noses]]', 'answer': 'person', 'question': 'which object in this image can smell with their nose?', 'img_file': 'COCO_val2014_000000014892.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'smell with their nose'], 'question_id': '5297'}, '2206': {'fact_surface': '[[A person]] can [[taste an apple]]', 'answer': 'person', 'question': 'Which object in this image is capable of tasting an apple?', 'img_file': 'COCO_val2014_000000014892.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'taste apple'], 'question_id': '5294'}, '2207': {'fact_surface': '[[A person]] can [[open a jar]]', 'answer': 'person', 'question': 'which object in this image can open a jar?', 'img_file': 'COCO_val2014_000000014892.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'open jar'], 'question_id': '5295'}, '2208': {'fact_surface': '[[goldfish]] belongs to the category of [[Pet]]', 'answer': 'goldfish', 'question': 'What kind of pet is shown in this image?', 'img_file': 'ILSVRC2012_test_00019124.JPEG', 'kb_source': 'dbpedia', 'fact': ['goldfish', 'belong to', 'pet'], 'question_id': '5292'}, '2209': {'fact_surface': '[[a fish]] can only [[live under water]]', 'answer': 'fish', 'question': 'Which animal in this image lives under water?', 'img_file': 'ILSVRC2012_test_00019124.JPEG', 'kb_source': 'conceptnet', 'fact': ['fish', 'capable of', 'live under water'], 'question_id': '5293'}, '2210': {'fact_surface': '[[goldfish]] belongs to the category of [[Pet]]', 'answer': 'goldfish', 'question': 'What kind of pet is shown in this image?', 'img_file': 'ILSVRC2012_test_00019124.JPEG', 'kb_source': 'dbpedia', 'fact': ['goldfish', 'belong to', 'pet'], 'question_id': '5291'}, '2211': {'fact_surface': '[[A book]] is [[made of paper]]', 'answer': 'book', 'question': 'Which object shown in this photo is made of paper?', 'img_file': 'ILSVRC2012_test_00002176.JPEG', 'kb_source': 'conceptnet', 'fact': ['book', 'has property', 'make of paper'], 'question_id': '59'}, '2212': {'fact_surface': '[[Bell peppers]] are [[vegetables]]', 'answer': 'bell pepper', 'question': 'What is the vegetable in the image?', 'img_file': 'ILSVRC2012_test_00043794.JPEG', 'kb_source': 'conceptnet', 'fact': ['bell pepper', 'is a', 'vegetable'], 'question_id': '58'}, '2213': {'fact_surface': '[[engine]] is part of [[motorcycle]].', 'answer': 'motorcycle', 'question': 'Which object in this image has an engine?', 'img_file': 'COCO_val2014_000000025282.jpg', 'kb_source': 'conceptnet', 'fact': ['engine', 'part of', 'motorcycle'], 'question_id': '2990'}, '2214': {'fact_surface': '[[A sofa]] has [[legs]]', 'answer': 'sofa', 'question': 'Which piece of furniture in the image has legs?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'has a', 'leg'], 'question_id': '50'}, '2215': {'fact_surface': '[[a microwave]] is for [[cooking food fast]]', 'answer': 'microwave', 'question': 'Which appliance would you use to cook food quickly?', 'img_file': 'COCO_val2014_000000126744.jpg', 'kb_source': 'conceptnet', 'fact': ['microwave', 'used for', 'cook food fast'], 'question_id': '55'}, '2216': {'fact_surface': '[[stove]] is related to [[gas]]', 'answer': 'stove', 'question': 'Which one in the image is supplied by gas?', 'img_file': 'ILSVRC2012_test_00028847.JPEG', 'kb_source': 'conceptnet', 'fact': ['stove', 'related to', 'gas'], 'question_id': '57'}, '2217': {'fact_surface': '[[Power drills]] can [[cause injury when not used carefully]]', 'answer': 'power drill', 'question': 'Which object shown here can cause injury if not used carefully?', 'img_file': 'ILSVRC2012_test_00025032.JPEG', 'kb_source': 'conceptnet', 'fact': ['power drill', 'capable of', 'cause injury when not use carefully'], 'question_id': '56'}, '2218': {'fact_surface': '[[Strawberries]] are [[small red fruits]]', 'answer': 'strawberry', 'question': 'What is the small red fruit?', 'img_file': 'ILSVRC2012_test_00023364.JPEG', 'kb_source': 'conceptnet', 'fact': ['strawberry', 'is a', 'small red fruit'], 'question_id': '428'}, '2219': {'fact_surface': 'You are likely to find [[a jellyfish]] in [[the open ocean]]', 'answer': 'jellyfish', 'question': 'Which object in this image can be found in open ocean?', 'img_file': 'ILSVRC2012_test_00008683.JPEG', 'kb_source': 'conceptnet', 'fact': ['jellyfish', 'at location', 'open ocean'], 'question_id': '1399'}, '2220': {'fact_surface': '[[palm tree]] is related to [[tree]]', 'answer': 'palm tree', 'question': 'what object in this image is related to tree?', 'img_file': 'COCO_val2014_000000115571.jpg', 'kb_source': 'conceptnet', 'fact': ['palm tree', 'related to', 'tree'], 'question_id': '421'}, '2221': {'fact_surface': 'A [[banana]] is a [[yellow fruit]]', 'answer': 'banana', 'question': 'What is the yellow fruit on the top?', 'img_file': 'COCO_val2014_000000119061.jpg', 'kb_source': 'conceptnet', 'fact': ['banana', 'is a', 'yellow fruit'], 'question_id': '420'}, '2222': {'fact_surface': '[[Broccoli]] is [[green]]', 'answer': 'broccoli', 'question': 'What is the green vegetable shown in this image?', 'img_file': 'COCO_val2014_000000121016.jpg', 'kb_source': 'conceptnet', 'fact': ['broccoli', 'has property', 'green'], 'question_id': '1395'}, '2223': {'fact_surface': '[[broccoli]] belongs to the category of [[Brassica]]', 'answer': 'broccoli', 'question': 'Which object in this image belongs to the class of Brassica?', 'img_file': 'COCO_val2014_000000121016.jpg', 'kb_source': 'dbpedia', 'fact': ['broccoli', 'belong to', 'brassica'], 'question_id': '1394'}, '2224': {'fact_surface': '[[hotdog]] belongs to the category of [[Food and drink]]', 'answer': 'hotdog', 'question': 'Which object in this image belongs to the category Food and drink?', 'img_file': 'COCO_val2014_000000024567.jpg', 'kb_source': 'dbpedia', 'fact': ['hotdog', 'belong to', 'food and drink'], 'question_id': '1393'}, '2225': {'fact_surface': '[[squirrel]] is related to [[eat nuts]]', 'answer': 'squirrel', 'question': 'which object in this image like to eat nut', 'img_file': 'ILSVRC2012_test_00004200.JPEG', 'kb_source': 'conceptnet', 'fact': ['squirrel', 'related to', 'eat nut'], 'question_id': '1392'}, '2226': {'fact_surface': '[[strawberry]] is related to [[seeds outside]]', 'answer': 'seed', 'question': 'What is the stuff on the surface of the red fruit in the image?', 'img_file': 'ILSVRC2012_test_00023364.JPEG', 'kb_source': 'conceptnet', 'fact': ['strawberry', 'related to', 'seed'], 'question_id': '427'}, '2227': {'fact_surface': '[[Squirrels]] are [[animals]]', 'answer': 'squirrel', 'question': 'Which object in this image is an animal?', 'img_file': 'ILSVRC2012_test_00004200.JPEG', 'kb_source': 'conceptnet', 'fact': ['squirrel', 'is a', 'animal'], 'question_id': '1390'}, '2228': {'fact_surface': '[[skateboarding]] is related to [[skateboard]]', 'answer': 'skateboard', 'question': 'what is a skateboard used for?', 'img_file': 'COCO_val2014_000000008589.jpg', 'kb_source': 'conceptnet', 'fact': ['skateboard', 'related to', 'skateboard'], 'question_id': '3452'}, '2229': {'fact_surface': '[[Giraffes]] have [[extremely high blood pressure]]', 'answer': 'extremely high blood pressure', 'question': 'Whether the animal in the image has high or low blood pressure?', 'img_file': 'COCO_val2014_000000143129.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'has a', 'extremely high blood pressure'], 'question_id': '857'}, '2230': {'fact_surface': '[[trombone]] is related to [[long arm]]', 'answer': 'trombone', 'question': 'Which instrument in this image has a long arm?', 'img_file': 'ILSVRC2012_test_00059219.JPEG', 'kb_source': 'conceptnet', 'fact': ['trombone', 'related to', 'long arm'], 'question_id': '851'}, '2231': {'fact_surface': '[[trumpet]] is related to [[musician]]', 'answer': 'trumpet', 'question': 'Which object in this image is related to musician?', 'img_file': 'ILSVRC2012_test_00032903.JPEG', 'kb_source': 'conceptnet', 'fact': ['trumpet', 'related to', 'musician'], 'question_id': '2333'}, '2232': {'fact_surface': '[[memory chip]] is related to [[computer]]', 'answer': 'computer', 'question': 'Which object in this image has memory chips?', 'img_file': 'ILSVRC2012_test_00009465.JPEG', 'kb_source': 'conceptnet', 'fact': ['memory chip', 'related to', 'computer'], 'question_id': '2334'}, '2233': {'fact_surface': '[[screen capture]] is related to [[computer]]', 'answer': 'computer', 'question': 'Which object in this image could perform a screen capture?', 'img_file': 'ILSVRC2012_test_00009465.JPEG', 'kb_source': 'conceptnet', 'fact': ['screen capture', 'related to', 'computer'], 'question_id': '2335'}, '2234': {'fact_surface': 'You are likely to find [[a kite]] in [[a windy sky]]', 'answer': 'kite', 'question': 'Which object in this image can be found in windy sky?', 'img_file': 'COCO_val2014_000000104841.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'at location', 'windy sky'], 'question_id': '2336'}, '2235': {'fact_surface': 'You are likely to find [[elephants]] in [[zoos]]', 'answer': 'elephant', 'question': 'What can be found in this zoo?', 'img_file': 'COCO_val2014_000000017282.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'at location', 'zoo'], 'question_id': '4713'}, '2236': {'fact_surface': '[[Kites]] have [[been used in scientific research]]', 'answer': 'kite', 'question': 'Which object in this image has been used in scientific research ?', 'img_file': 'COCO_val2014_000000026670.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'has a', 'be use in scientific research'], 'question_id': '2439'}, '2237': {'fact_surface': '[[seal]] belongs to the category of [[Marine vertebrates]]', 'answer': 'seal', 'question': 'Which animal in this image belongs to the category Marine vertebrates?', 'img_file': 'ILSVRC2012_test_00018998.JPEG', 'kb_source': 'dbpedia', 'fact': ['pinniped', 'belong to', 'seal'], 'question_id': '2438'}, '2238': {'fact_surface': '[[otter]] are way more playful than [[sea lion]]', 'answer': 'otter', 'question': 'Which object is more playful? sea lion? or the animal in the image?', 'img_file': 'ILSVRC2012_test_00018998.JPEG', 'kb_source': 'webchild', 'fact': ['otter', 'playful', 'sea lion'], 'question_id': '2437'}, '2239': {'fact_surface': 'The class of [[otter]] is [[Mammal]]', 'answer': 'mammal', 'question': 'What is the class of the animal in this image?', 'img_file': 'ILSVRC2012_test_00018998.JPEG', 'kb_source': 'dbpedia', 'fact': ['otter', 'animal class', 'mammal'], 'question_id': '2436'}, '2240': {'fact_surface': '[[RAM]] is part of [[a computer]]', 'answer': 'computer', 'question': 'Which object in this image has RAM?', 'img_file': 'COCO_val2014_000000140860.jpg', 'kb_source': 'conceptnet', 'fact': ['ram', 'part of', 'computer'], 'question_id': '2435'}, '2241': {'fact_surface': '[[racquets]] is related to [[player]]', 'answer': 'racquet', 'question': 'What is the player holding?', 'img_file': 'ILSVRC2012_test_00029063.JPEG', 'kb_source': 'conceptnet', 'fact': ['racquet', 'related to', 'play'], 'question_id': '3782'}, '2242': {'fact_surface': '[[a trombone]] is used for [[playing music]]', 'answer': 'play music', 'question': 'What is the object on the right used for?', 'img_file': 'ILSVRC2012_test_00007896.JPEG', 'kb_source': 'conceptnet', 'fact': ['trombone', 'used for', 'play music'], 'question_id': '3781'}, '2243': {'fact_surface': 'You are likely to find [[a computer]] in [[the office]].', 'answer': 'computer', 'question': 'what can we find on the desk', 'img_file': 'ILSVRC2012_test_00057293.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'at location', 'office'], 'question_id': '1808'}, '2244': {'fact_surface': '[[mountains]] are [[high]]', 'answer': 'mountain', 'question': 'Which object in this image is high?', 'img_file': 'COCO_val2014_000000027658.jpg', 'kb_source': 'conceptnet', 'fact': ['mountain', 'has property', 'high'], 'question_id': '4996'}, '2245': {'fact_surface': '[[mitt]] is related to [[hand]]', 'answer': 'hand', 'question': 'Which object in this image is related to mitts?', 'img_file': 'ILSVRC2012_test_00059219.JPEG', 'kb_source': 'conceptnet', 'fact': ['mitt', 'related to', 'hand'], 'question_id': '4997'}, '2246': {'fact_surface': '[[fire hydrant]] belongs to the category of [[Firefighting]]', 'answer': 'fire hydrant', 'question': 'What object in this image is for firefighting?', 'img_file': 'COCO_val2014_000000027658.jpg', 'kb_source': 'dbpedia', 'fact': ['fire hydrant', 'belong to', 'firefighting'], 'question_id': '4994'}, '2247': {'fact_surface': '[[fire hydrants]] can be used to [[fight fires]]', 'answer': 'fight fire', 'question': 'What is the object in the left side of this image used for?', 'img_file': 'COCO_val2014_000000027658.jpg', 'kb_source': 'conceptnet', 'fact': ['fire hydrant', 'used for', 'fight fire'], 'question_id': '4995'}, '2248': {'fact_surface': '[[green]] is related to [[grass]]', 'answer': 'grass', 'question': 'Which object in this image is related to green?', 'img_file': 'COCO_val2014_000000027658.jpg', 'kb_source': 'conceptnet', 'fact': ['green', 'related to', 'grass'], 'question_id': '4992'}, '2249': {'fact_surface': '[[fire hydrant]] belongs to the category of [[Water supply]]', 'answer': 'fire hydrant', 'question': 'What object in this image is related to water supply?', 'img_file': 'COCO_val2014_000000027658.jpg', 'kb_source': 'dbpedia', 'fact': ['fire hydrant', 'belong to', 'water supply'], 'question_id': '4993'}, '2250': {'fact_surface': '[[snowboard]] is a subclass of [[sports equipment]]', 'answer': 'snowboard', 'question': 'Which object in this image is a winter sport equipment?', 'img_file': 'COCO_val2014_000000005032.jpg', 'kb_source': 'conceptnet', 'fact': ['snowboard', 'is a', 'sport equipment'], 'question_id': '4990'}, '2251': {'fact_surface': '[[skateboard]] belongs to the category of [[Skateboarding equipment]]', 'answer': 'skateboard', 'question': 'Which object in this image belongs to the category winter equipment?', 'img_file': 'COCO_val2014_000000005032.jpg', 'kb_source': 'dbpedia', 'fact': ['skateboard', 'belong to', 'skateboarding equipment'], 'question_id': '4991'}, '2252': {'fact_surface': '[[cell phone]] belongs to the category of [[Digital electronics]]', 'answer': 'cell phone', 'question': 'Which object in this image belongs to Digital electronics?', 'img_file': 'COCO_val2014_000000129706.jpg', 'kb_source': 'dbpedia', 'fact': ['cell phone', 'belong to', 'digital electronics'], 'question_id': '1942'}, '2253': {'fact_surface': '[[knot]] is related to [[tie]]', 'answer': 'tie', 'question': 'Which piece of clothes in this image has a knot?', 'img_file': 'COCO_val2014_000000129706.jpg', 'kb_source': 'conceptnet', 'fact': ['knot', 'related to', 'tie'], 'question_id': '1943'}, '2254': {'fact_surface': '[[person]] wants to [[feel joy]]', 'answer': 'person', 'question': 'Which object in this image desires feel joy?', 'img_file': 'COCO_val2014_000000104422.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'feel joy'], 'question_id': '3252'}, '2255': {'fact_surface': '[[carrots]] are [[long, thin, and orage]]', 'answer': 'carrot', 'question': 'Which object in this image is a long thin and orage?', 'img_file': 'ILSVRC2012_test_00056454.JPEG', 'kb_source': 'conceptnet', 'fact': ['carrot', 'is a', 'long thin and orage'], 'question_id': '1947'}, '2256': {'fact_surface': '[[cow]] belongs to the category of [[List of domesticated animals]]', 'answer': 'cow', 'question': 'What domesticated animal can be seen in this image?', 'img_file': 'COCO_val2014_000000019157.jpg', 'kb_source': 'dbpedia', 'fact': ['cow', 'belong to', 'list of domesticated animals'], 'question_id': '2859'}, '2257': {'fact_surface': '[[cattleman]] is related to [[cattle]]', 'answer': 'cattle', 'question': 'Which animal in this image is related to cattleman?', 'img_file': 'COCO_val2014_000000019157.jpg', 'kb_source': 'conceptnet', 'fact': ['cattleman', 'related to', 'cattle'], 'question_id': '2858'}, '2258': {'fact_surface': '[[Goldfish]] is an instance of [[living thing]]', 'answer': 'goldfish', 'question': 'which object in this image is alive', 'img_file': 'ILSVRC2012_test_00030000.JPEG', 'kb_source': 'conceptnet', 'fact': ['goldfish', 'is a', 'live thing'], 'question_id': '2851'}, '2259': {'fact_surface': 'You can use [[a bowl]] to [[eat cereal]]', 'answer': 'bowl', 'question': 'Which object in this image is used for eat cereal?', 'img_file': 'COCO_val2014_000000131725.jpg', 'kb_source': 'conceptnet', 'fact': ['bowl', 'used for', 'eat cereal'], 'question_id': '2850'}, '2260': {'fact_surface': '[[rugby balls]] are [[filled with pressurised air]].', 'answer': 'rugby ball', 'question': 'Which object in this image is filedl with pressurised air?', 'img_file': 'ILSVRC2012_test_00054461.JPEG', 'kb_source': 'conceptnet', 'fact': ['rugby ball', 'has property', 'fill with pressurise air'], 'question_id': '2857'}, '2261': {'fact_surface': 'Kinds of [[plant]] : [[grass]]', 'answer': 'grass', 'question': 'Which object in this image is a plant?', 'img_file': 'ILSVRC2012_test_00054461.JPEG', 'kb_source': 'conceptnet', 'fact': ['grass', 'is a', 'plant'], 'question_id': '2856'}, '2262': {'fact_surface': '[[A boat]] can be [[powered by an engine]]', 'answer': 'boat', 'question': 'Which object in this image can be powered by an engine?', 'img_file': 'COCO_val2014_000000023489.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'has property', 'power by engine'], 'question_id': '5461'}, '2263': {'fact_surface': '[[boats]] usually [[float on water]]', 'answer': 'boat', 'question': 'Which object in this image is capable of floating in water?', 'img_file': 'COCO_val2014_000000023489.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'capable of', 'float on water'], 'question_id': '5460'}, '2264': {'fact_surface': '[[boats]] usually [[float on water]]', 'answer': 'boat', 'question': 'Which object in this image is capable of floating in water?', 'img_file': 'COCO_val2014_000000023489.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'capable of', 'float on water'], 'question_id': '5463'}, '2265': {'fact_surface': '[[boat]] is related to [[transportation]]', 'answer': 'boat', 'question': 'which object in this image is a means of transportation?', 'img_file': 'COCO_val2014_000000023489.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'related to', 'transportation'], 'question_id': '5462'}, '2266': {'fact_surface': 'You can use [[a dog]] to [[guard a house]]', 'answer': 'dog', 'question': 'Which animal in the image can be used to guard animal?', 'img_file': 'ILSVRC2012_test_00055801.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'used for', 'guard house'], 'question_id': '425'}, '2267': {'fact_surface': '*Something you find [[at a street corner]] is [[a stop sign]]', 'answer': 'stop sign', 'question': 'What object in this image can be found at a street corner?', 'img_file': 'ILSVRC2012_test_00004200.JPEG', 'kb_source': 'conceptnet', 'fact': ['stop sign', 'at location', 'at street corner'], 'question_id': '1391'}, '2268': {'fact_surface': '[[A tree]] has [[roots]]', 'answer': 'tree', 'question': 'what object in this image has roots?', 'img_file': 'COCO_val2014_000000018888.jpg', 'kb_source': 'conceptnet', 'fact': ['tree', 'has a', 'root'], 'question_id': '526'}, '2269': {'fact_surface': '[[chair]] is related to [[wooden]]', 'answer': 'wooden', 'question': 'What is the material of the chair?', 'img_file': 'COCO_val2014_000000018888.jpg', 'kb_source': 'conceptnet', 'fact': ['chair', 'related to', 'wooden'], 'question_id': '527'}, '2270': {'fact_surface': '[[Carrots]] are [[only one kind of root vegetables]]', 'answer': 'carrot', 'question': 'Which food on the board are root vegetables?', 'img_file': 'COCO_val2014_000000116206.jpg', 'kb_source': 'conceptnet', 'fact': ['carrot', 'has property', 'only one kind of root vegetable'], 'question_id': '522'}, '2271': {'fact_surface': '[[refrigerators]] can [[cool milk]]', 'answer': 'refrigerator', 'question': 'Which device in the image can be used to cool milk?', 'img_file': 'COCO_val2014_000000103863.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'capable of', 'cool milk'], 'question_id': '528'}, '2272': {'fact_surface': 'You are likely to find [[mushrooms]] around [[old trees]]', 'answer': 'mushroom', 'question': 'Which vegetable in the image can be found around old trees?', 'img_file': 'COCO_val2014_000000016848.jpg', 'kb_source': 'conceptnet', 'fact': ['mushroom', 'at location', 'old tree'], 'question_id': '529'}, '2273': {'fact_surface': '[[a couch]] can be used for [[sitting down]]', 'answer': 'couch', 'question': 'Which object in this image is used for sitting down?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['couch', 'used for', 'sit down'], 'question_id': '1237'}, '2274': {'fact_surface': '[[A cart]] is [[a wheeled box]]', 'answer': 'cart', 'question': 'Which object in this image is a wheeled box?', 'img_file': 'ILSVRC2012_test_00008142.JPEG', 'kb_source': 'conceptnet', 'fact': ['cart', 'is a', 'wheel box'], 'question_id': '1231'}, '2275': {'fact_surface': '[[A cart]] is [[a vehicle]]', 'answer': 'cart', 'question': 'Which object in this image is a vehicle?', 'img_file': 'ILSVRC2012_test_00008142.JPEG', 'kb_source': 'conceptnet', 'fact': ['cart', 'is a', 'vehicle'], 'question_id': '1232'}, '2276': {'fact_surface': '[[a cart]] can [[transport things]]', 'answer': 'cart', 'question': 'Which object in this image can be used to transport things?', 'img_file': 'ILSVRC2012_test_00008142.JPEG', 'kb_source': 'conceptnet', 'fact': ['cart', 'capable of', 'transport thing'], 'question_id': '1233'}, '2277': {'fact_surface': '*Something you find in [[a house]] is [[a sofa]]', 'answer': 'sofa', 'question': \"what's shown in the image?\", 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'at location', 'house'], 'question_id': '1238'}, '2278': {'fact_surface': '[[living room]] can be warmer than [[bedroom]]', 'answer': 'living room', 'question': 'where is less warm than the place shown in this image', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'webchild', 'fact': ['living room', 'warm', 'bedroom'], 'question_id': '1239'}, '2279': {'fact_surface': '[[thunderstorm]] is related to [[rain]]', 'answer': 'rain', 'question': 'Which object in this image comes down in a thunderstorm?', 'img_file': 'COCO_val2014_000000007394.jpg', 'kb_source': 'conceptnet', 'fact': ['thunderstorm', 'related to', 'rain'], 'question_id': '1964'}, '2280': {'fact_surface': 'You are likely to find [[a mirror]] in [[the bathroom]]', 'answer': 'mirror', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000104837.jpg', 'kb_source': 'conceptnet', 'fact': ['mirror', 'at location', 'bathroom'], 'question_id': '2488'}, '2281': {'fact_surface': '[[a bathroom]] is for [[peeing]]', 'answer': 'pee', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000104837.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'used for', 'pee'], 'question_id': '2489'}, '2282': {'fact_surface': '[[laptop]] are more expensive than [[desktop]]', 'answer': 'laptop', 'question': 'which object in this image should be paid mcuh more than a desktop', 'img_file': 'COCO_val2014_000000014088.jpg', 'kb_source': 'webchild', 'fact': ['laptop', 'expensive', 'desktop'], 'question_id': '4677'}, '2283': {'fact_surface': 'You are likely to find [[a tv]] in [[a winery]].', 'answer': 'tv', 'question': 'Which object in this image can be found in winery?', 'img_file': 'ILSVRC2012_test_00002371.JPEG', 'kb_source': 'conceptnet', 'fact': ['tv', 'at location', 'winery'], 'question_id': '4900'}, '2284': {'fact_surface': '[[chair]] is related to [[a desk]]', 'answer': 'chair', 'question': 'Which thing in this image is related to desk?', 'img_file': 'COCO_val2014_000000014088.jpg', 'kb_source': 'conceptnet', 'fact': ['chair', 'related to', 'desk'], 'question_id': '4675'}, '2285': {'fact_surface': '[[train]] are typically faster than [[bus]]', 'answer': 'train', 'question': 'which object in this image is faster than car?', 'img_file': 'ILSVRC2012_test_00004714.JPEG', 'kb_source': 'webchild', 'fact': ['train', 'fast', 'bus'], 'question_id': '3805'}, '2286': {'fact_surface': '[[fast track]] is related to [[train]]', 'answer': 'train', 'question': 'Which object in this image is related to high-speed track?', 'img_file': 'ILSVRC2012_test_00004714.JPEG', 'kb_source': 'conceptnet', 'fact': ['fast track', 'related to', 'train'], 'question_id': '3804'}, '2287': {'fact_surface': '*Something you find at [[a train station]] is [[a railroad track]]', 'answer': 'train station', 'question': 'What place is shown in this image?', 'img_file': 'ILSVRC2012_test_00004714.JPEG', 'kb_source': 'conceptnet', 'fact': ['railroad track', 'at location', 'train station'], 'question_id': '3806'}, '2288': {'fact_surface': 'You are likely to find [[a cow]] in [[a pasture]]', 'answer': 'cow', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000115077.jpg', 'kb_source': 'conceptnet', 'fact': ['cow', 'at location', 'pasture'], 'question_id': '3801'}, '2289': {'fact_surface': '[[children]] belongs to the category of [[Kinship]]', 'answer': 'child', 'question': 'Which part in this image belongs to the category Kinship?', 'img_file': 'COCO_val2014_000000114183.jpg', 'kb_source': 'dbpedia', 'fact': ['child', 'belong to', 'kinship'], 'question_id': '3800'}, '2290': {'fact_surface': '[[station]] belongs to the category of [[Public transport]]', 'answer': 'station', 'question': 'Which object in this image belongs to the category public transportation system?', 'img_file': 'ILSVRC2012_test_00004714.JPEG', 'kb_source': 'dbpedia', 'fact': ['station', 'belong to', 'public transport'], 'question_id': '3803'}, '2291': {'fact_surface': '[[a train]] will [[leave the station]]', 'answer': 'train', 'question': 'Which object in this image is going to leave station?', 'img_file': 'ILSVRC2012_test_00004714.JPEG', 'kb_source': 'conceptnet', 'fact': ['train', 'capable of', 'leave station'], 'question_id': '3802'}, '2292': {'fact_surface': '[[A strawberry]] is [[rich in vitamin c]]', 'answer': 'strawberry', 'question': 'Which object in this image contains a lot of vitamin c?', 'img_file': 'ILSVRC2012_test_00014097.JPEG', 'kb_source': 'conceptnet', 'fact': ['strawberry', 'has property', 'rich in vitamin c'], 'question_id': '1967'}, '2293': {'fact_surface': 'The class of [[cow]] is [[Mammal]]', 'answer': 'mammal', 'question': 'What is the class of the animal in this image?', 'img_file': 'COCO_val2014_000000133061.jpg', 'kb_source': 'dbpedia', 'fact': ['cattle', 'animal class', 'mammal'], 'question_id': '4170'}, '2294': {'fact_surface': '[[monitor]] belongs to the category of [[Graphics hardware]]', 'answer': 'monitor', 'question': 'Which object in this image belongs to the category Graphics hardware?', 'img_file': 'ILSVRC2012_test_00050002.JPEG', 'kb_source': 'dbpedia', 'fact': ['monitor', 'belong to', 'graphics hardware'], 'question_id': '4178'}, '2295': {'fact_surface': '[[rain]] belongs to the category of [[Clouds, fog and precipitation]]', 'answer': 'rain', 'question': 'Which object in this image belongs to the category Clouds, fog and precipitation?', 'img_file': 'COCO_val2014_000000007394.jpg', 'kb_source': 'dbpedia', 'fact': ['rain', 'belong to', 'clouds, fog and precipitation'], 'question_id': '1962'}, '2296': {'fact_surface': '[[laptop]] are so much more compact than [[desktop]]', 'answer': 'laptop', 'question': 'Which object in this image is usually more compact than desktop?', 'img_file': 'COCO_val2014_000000111341.jpg', 'kb_source': 'webchild', 'fact': ['laptop', 'compact', 'desktop'], 'question_id': '2220'}, '2297': {'fact_surface': '[[mail]] is related to [[computer]]', 'answer': 'computer', 'question': 'Which object in this image is used to mail?', 'img_file': 'ILSVRC2012_test_00010098.JPEG', 'kb_source': 'conceptnet', 'fact': ['mail', 'related to', 'computer'], 'question_id': '4505'}, '2298': {'fact_surface': '[[a computer]] is for [[homework]]', 'answer': 'computer', 'question': 'Which object in this image is often  used for preparing a homework?', 'img_file': 'ILSVRC2012_test_00010098.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'used for', 'homework'], 'question_id': '4504'}, '2299': {'fact_surface': '[[a computer]] is [[rectangular]].', 'answer': 'computer', 'question': 'What in this image has the property of rectangular?', 'img_file': 'ILSVRC2012_test_00010098.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'has property', 'rectangular'], 'question_id': '4507'}, '2300': {'fact_surface': '[[A computer]] should [[be updated every few years]]', 'answer': 'computer', 'question': 'Which object in this image is capable of be replace every few year?', 'img_file': 'ILSVRC2012_test_00010098.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'capable of', 'be update every few year'], 'question_id': '4506'}, '2301': {'fact_surface': '[[elephant]] belongs to the category of [[Mammal]]', 'answer': 'elephant', 'question': 'Which object in this image belongs to the category mammal?', 'img_file': 'COCO_val2014_000000102996.jpg', 'kb_source': 'dbpedia', 'fact': ['elephant', 'belong to', 'mammal'], 'question_id': '4500'}, '2302': {'fact_surface': '[[a computer]] is for [[homework]]', 'answer': 'computer', 'question': 'Which object in this image is often  used for preparing a homework?', 'img_file': 'ILSVRC2012_test_00010098.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'used for', 'homework'], 'question_id': '4503'}, '2303': {'fact_surface': '[[minicomputer]] is related to [[computer]]', 'answer': 'computer', 'question': 'Which object in this image is similar to minicomputer?', 'img_file': 'ILSVRC2012_test_00010098.JPEG', 'kb_source': 'conceptnet', 'fact': ['minicomputer', 'related to', 'computer'], 'question_id': '4508'}, '2304': {'fact_surface': 'A [[giraffe]] is a [[animal]]', 'answer': 'giraffe', 'question': 'What is the animal in the image?', 'img_file': 'COCO_val2014_000000107481.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'is a', 'animal'], 'question_id': '1008'}, '2305': {'fact_surface': '[[Pizza]] is often [[considered unhealthy]]', 'answer': 'unhealthy', 'question': 'Whether this food is considered healthy or unhealthy?', 'img_file': 'COCO_val2014_000000024144.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'has property', 'unhealthy'], 'question_id': '1007'}, '2306': {'fact_surface': '[[Apples]] are [[not oranges, nor are they lemons]]', 'answer': 'apple', 'question': 'Which fruit here is neither orange nor lemon?', 'img_file': 'ILSVRC2012_test_00021198.JPEG', 'kb_source': 'conceptnet', 'fact': ['apple', 'is a', 'not orange nor be they lemon'], 'question_id': '1004'}, '2307': {'fact_surface': '[[squirrel]] is related to [[walnuts]]', 'answer': 'walnut', 'question': 'Which things in this picture would a squirrel be most interested in?', 'img_file': 'ILSVRC2012_test_00021198.JPEG', 'kb_source': 'conceptnet', 'fact': ['squirrel', 'related to', 'walnut'], 'question_id': '1003'}, '2308': {'fact_surface': '[[toilets]] sometimes [[get clogged]]', 'answer': 'toilet', 'question': 'What objects related to this image sometimes get clogged?', 'img_file': 'COCO_val2014_000000120157.jpg', 'kb_source': 'conceptnet', 'fact': ['toilet', 'capable of', 'get clog'], 'question_id': '4349'}, '2309': {'fact_surface': '[[flush]] is related to [[toilet]]', 'answer': 'toilet', 'question': 'Which object in this image can be used to flush?', 'img_file': 'COCO_val2014_000000120157.jpg', 'kb_source': 'conceptnet', 'fact': ['flush', 'related to', 'toilet'], 'question_id': '4348'}, '2310': {'fact_surface': '[[toilet]] belongs to the category of [[Plumbing]]', 'answer': 'toilet', 'question': 'Which object is related to plumbing in this image?', 'img_file': 'COCO_val2014_000000120157.jpg', 'kb_source': 'dbpedia', 'fact': ['toilet', 'belong to', 'plumb'], 'question_id': '4347'}, '2311': {'fact_surface': '[[many bathrooms]] have [[toilets]]', 'answer': 'toilet', 'question': 'What object in this image is in many bathrooms?', 'img_file': 'COCO_val2014_000000120157.jpg', 'kb_source': 'conceptnet', 'fact': ['many bathroom', 'has a', 'toilet'], 'question_id': '4346'}, '2312': {'fact_surface': '[[toilets]] are [[dirty]]', 'answer': 'toilet', 'question': 'Which object in this image is dirty?', 'img_file': 'COCO_val2014_000000120157.jpg', 'kb_source': 'conceptnet', 'fact': ['toilet', 'has property', 'dirty'], 'question_id': '4345'}, '2313': {'fact_surface': '[[Pizza]] is [[a disc-shaped food item]]', 'answer': 'pizza', 'question': 'which object in this image is a kind food in disc shape', 'img_file': 'COCO_val2014_000000113369.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'is a', 'disc shape food item'], 'question_id': '4343'}, '2314': {'fact_surface': '[[ice water]] is related to [[drinking]]', 'answer': 'drink', 'question': 'Which object in this image is related to ice water?', 'img_file': 'COCO_val2014_000000113369.jpg', 'kb_source': 'conceptnet', 'fact': ['ice water', 'related to', 'drink'], 'question_id': '4342'}, '2315': {'fact_surface': '[[screw]] have more surface area than [[nail]]', 'answer': 'nail', 'question': 'Which metal object in this image has less surface area than a screw?', 'img_file': 'ILSVRC2012_test_00008274.JPEG', 'kb_source': 'webchild', 'fact': ['screw', 'surface', 'nail'], 'question_id': '5719'}, '2316': {'fact_surface': '[[unicycle]] is a subclass of [[rideable transportation device]]', 'answer': 'unicycle', 'question': 'Which object in this image is a rideable transportation device?', 'img_file': 'ILSVRC2012_test_00045545.JPEG', 'kb_source': 'conceptnet', 'fact': ['unicycle', 'is a', 'rideable transportation device'], 'question_id': '5713'}, '2317': {'fact_surface': '[[a unicycle]] is [[a vehicle with just one wheel]]', 'answer': 'unicycle', 'question': 'Which object in this image is a vehicle with just one wheel?', 'img_file': 'ILSVRC2012_test_00045545.JPEG', 'kb_source': 'conceptnet', 'fact': ['unicycle', 'is a', 'vehicle with just one wheel'], 'question_id': '5712'}, '2318': {'fact_surface': '[[unicycle]] is related to [[acrobat]]', 'answer': 'unicycle', 'question': 'Which object in this image is related to acrobat?', 'img_file': 'ILSVRC2012_test_00045545.JPEG', 'kb_source': 'conceptnet', 'fact': ['unicycle', 'related to', 'acrobat'], 'question_id': '5711'}, '2319': {'fact_surface': '[[unicycle]] is a subclass of [[user-powered device]]', 'answer': 'unicycle', 'question': 'Which object in this image is a user powered device?', 'img_file': 'ILSVRC2012_test_00045545.JPEG', 'kb_source': 'conceptnet', 'fact': ['unicycle', 'is a', 'user power device'], 'question_id': '5710'}, '2320': {'fact_surface': 'Kinds of [[insects]] : [[ant]]', 'answer': 'ant', 'question': 'Which object in this image is a insect?', 'img_file': 'ILSVRC2012_test_00000196.JPEG', 'kb_source': 'conceptnet', 'fact': ['ant', 'is a', 'insect'], 'question_id': '3577'}, '2321': {'fact_surface': '[[the ocean]] is used for [[a place to swim]]', 'answer': 'swim', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000101280.jpg', 'kb_source': 'conceptnet', 'fact': ['ocean', 'used for', 'swim'], 'question_id': '3572'}, '2322': {'fact_surface': '[[people]] can [[dance for fun]]', 'answer': 'person', 'question': 'which object in this image can dance for enjoyment?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'dance for fun'], 'question_id': '2666'}, '2323': {'fact_surface': '[[People]] can [[forget things]]', 'answer': 'person', 'question': 'which object in this image can forget things?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'forget thing'], 'question_id': '2667'}, '2324': {'fact_surface': '[[People]] often [[eat food off a plate]]', 'answer': 'person', 'question': 'what object in this image eats food off a plate?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'eat food off plate'], 'question_id': '2664'}, '2325': {'fact_surface': '[[A person]] can [[blow that candle out]]', 'answer': 'person', 'question': 'which object in this image can blow out candles?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'blow that candle out'], 'question_id': '2665'}, '2326': {'fact_surface': '[[people]] can [[pout]].', 'answer': 'person', 'question': 'what object in this image can pout?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'pout'], 'question_id': '2662'}, '2327': {'fact_surface': '[[people]] can [[govern people]]', 'answer': 'person', 'question': 'what object in this image can govern other people?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'govern person'], 'question_id': '2663'}, '2328': {'fact_surface': 'You are likely to find [[a tennis ball]] in [[a tennis game]]', 'answer': 'tennis ball', 'question': 'which yellow object in this image can be found in a game of tennis?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis ball', 'at location', 'tennis game'], 'question_id': '2660'}, '2329': {'fact_surface': '[[a person]] can [[stand on one leg]]', 'answer': 'person', 'question': 'what object in this image can stand on one leg?', 'img_file': 'COCO_val2014_000000011567.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'stand on one leg'], 'question_id': '2661'}, '2330': {'fact_surface': '[[Forest roads]] are [[inspirational]]', 'answer': 'forest road', 'question': 'What objects in this image are inspirational', 'img_file': 'ILSVRC2012_test_00035105.JPEG', 'kb_source': 'conceptnet', 'fact': ['forest road', 'has property', 'inspirational'], 'question_id': '1829'}, '2331': {'fact_surface': '[[Forest roads]] are [[inspirational]]', 'answer': 'forest road', 'question': 'What objects in this image are inspirational', 'img_file': 'ILSVRC2012_test_00035105.JPEG', 'kb_source': 'conceptnet', 'fact': ['forest road', 'has property', 'inspirational'], 'question_id': '1828'}, '2332': {'fact_surface': '[[Forest roads]] are [[inspirational]]', 'answer': 'forest road', 'question': 'What objects in this image are inspirational', 'img_file': 'ILSVRC2012_test_00035105.JPEG', 'kb_source': 'conceptnet', 'fact': ['forest road', 'has property', 'inspirational'], 'question_id': '1825'}, '2333': {'fact_surface': '[[Forest roads]] are [[inspirational]]', 'answer': 'forest road', 'question': 'What objects in this image are inspirational', 'img_file': 'ILSVRC2012_test_00035105.JPEG', 'kb_source': 'conceptnet', 'fact': ['forest road', 'has property', 'inspirational'], 'question_id': '1824'}, '2334': {'fact_surface': '[[Forest roads]] are [[inspirational]]', 'answer': 'forest road', 'question': 'What objects in this image are inspirational', 'img_file': 'ILSVRC2012_test_00035105.JPEG', 'kb_source': 'conceptnet', 'fact': ['forest road', 'has property', 'inspirational'], 'question_id': '1827'}, '2335': {'fact_surface': '[[Forest roads]] are [[inspirational]]', 'answer': 'forest road', 'question': 'What objects in this image are inspirational', 'img_file': 'ILSVRC2012_test_00035105.JPEG', 'kb_source': 'conceptnet', 'fact': ['forest road', 'has property', 'inspirational'], 'question_id': '1826'}, '2336': {'fact_surface': '[[unicycle]] are much more maneuverable than [[bicycle]]', 'answer': 'unicycle', 'question': 'Which object in this image is more maneuverable than a bicycle?', 'img_file': 'ILSVRC2012_test_00035105.JPEG', 'kb_source': 'webchild', 'fact': ['unicycle', 'maneuverable', 'bicycle'], 'question_id': '1821'}, '2337': {'fact_surface': '[[A unicycle]] only has [[one wheel]]', 'answer': 'unicycle', 'question': 'Which object in this image has one wheel', 'img_file': 'ILSVRC2012_test_00035105.JPEG', 'kb_source': 'conceptnet', 'fact': ['unicycle', 'has a', 'one wheel'], 'question_id': '1820'}, '2338': {'fact_surface': '[[unicycle]] is a subclass of [[rideable transportation device]]', 'answer': 'unicycle', 'question': 'Which object in this image is a rideable transportation device?', 'img_file': 'ILSVRC2012_test_00035105.JPEG', 'kb_source': 'conceptnet', 'fact': ['unicycle', 'is a', 'rideable transportation device'], 'question_id': '1823'}, '2339': {'fact_surface': '[[unicycle]] is a subclass of [[wheeled vehicle]]', 'answer': 'unicycle', 'question': 'Which object in this image is a wheeled vehicle?', 'img_file': 'ILSVRC2012_test_00035105.JPEG', 'kb_source': 'conceptnet', 'fact': ['unicycle', 'is a', 'wheel vehicle'], 'question_id': '1822'}, '2340': {'fact_surface': '[[bottle]] is a subclass of [[fluid reservoir]]', 'answer': 'bottle', 'question': 'what thing in this image can be used for reserving liquid', 'img_file': 'ILSVRC2012_test_00020499.JPEG', 'kb_source': 'conceptnet', 'fact': ['bottle', 'is a', 'fluid reservoir'], 'question_id': '2413'}, '2341': {'fact_surface': '[[a luggage]] is used for [[storing clothes for a trip]]', 'answer': 'luggage', 'question': 'which object in this image is used to store clothes on a trip?', 'img_file': 'COCO_val2014_000000115245.jpg', 'kb_source': 'conceptnet', 'fact': ['luggage', 'used for', 'store clothe for trip'], 'question_id': '4978'}, '2342': {'fact_surface': '[[Zebras]] have [[black and white stripes]]', 'answer': 'zebra', 'question': 'Which object in this image has a black and white stripe', 'img_file': 'COCO_val2014_000000132814.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'black and white stripe'], 'question_id': '4979'}, '2343': {'fact_surface': '[[baggage]] is related to [[luggage]]', 'answer': 'luggage', 'question': 'which object in this image is related to baggage?', 'img_file': 'COCO_val2014_000000115245.jpg', 'kb_source': 'conceptnet', 'fact': ['baggage', 'related to', 'luggage'], 'question_id': '4974'}, '2344': {'fact_surface': 'A [[horse]] is a [[large animal]]', 'answer': 'horse', 'question': 'What large animal can be seen here?', 'img_file': 'COCO_val2014_000000136285.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'is a', 'large animal'], 'question_id': '2418'}, '2345': {'fact_surface': '[[carry-on]] is related to [[luggage]]', 'answer': 'luggage', 'question': 'which object in this image is related to carry-on?', 'img_file': 'COCO_val2014_000000115245.jpg', 'kb_source': 'conceptnet', 'fact': ['carry on', 'related to', 'luggage'], 'question_id': '4976'}, '2346': {'fact_surface': 'You are likely to find [[a luggage]] in [[an airport]]', 'answer': 'luggage', 'question': 'which object in this image can be found in an airport?', 'img_file': 'COCO_val2014_000000115245.jpg', 'kb_source': 'conceptnet', 'fact': ['luggage', 'at location', 'airport'], 'question_id': '4977'}, '2347': {'fact_surface': '[[carry-on]] is related to [[luggage]]', 'answer': 'luggage', 'question': 'Which object in this image is related to carry-on?', 'img_file': 'COCO_val2014_000000115245.jpg', 'kb_source': 'conceptnet', 'fact': ['carry on', 'related to', 'luggage'], 'question_id': '4971'}, '2348': {'fact_surface': '[[a luggage]] is for [[packing]]', 'answer': 'luggage', 'question': 'Which object in this image is used for packing?', 'img_file': 'COCO_val2014_000000115245.jpg', 'kb_source': 'conceptnet', 'fact': ['luggage', 'used for', 'pack'], 'question_id': '4972'}, '2349': {'fact_surface': '[[luggage cart]] is related to [[luggage]]', 'answer': 'luggage', 'question': 'which object in this image is relate to luggage cart?', 'img_file': 'COCO_val2014_000000115245.jpg', 'kb_source': 'conceptnet', 'fact': ['luggage cart', 'related to', 'luggage'], 'question_id': '4973'}, '2350': {'fact_surface': '[[Books]] have [[spines]]', 'answer': 'book', 'question': 'Which object in this image has a spine?', 'img_file': 'COCO_val2014_000000008708.jpg', 'kb_source': 'conceptnet', 'fact': ['book', 'has a', 'pine'], 'question_id': '1920'}, '2351': {'fact_surface': '[[tennis racket]] is related to [[strike]]', 'answer': 'tennis racket', 'question': 'What in this image may be used to strike something?', 'img_file': 'COCO_val2014_000000007304.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis racket', 'related to', 'strike'], 'question_id': '1929'}, '2352': {'fact_surface': '[[saxophone]] is used for [[creating music]].', 'answer': 'saxophone', 'question': 'Which object in this image is used for creating music?', 'img_file': 'ILSVRC2012_test_00000761.JPEG', 'kb_source': 'conceptnet', 'fact': ['saxophone', 'used for', 'create music'], 'question_id': '3279'}, '2353': {'fact_surface': 'Kinds of [[fruit]] : [[pineapple]]', 'answer': 'pineapple', 'question': 'Which object in this image is a fruit?', 'img_file': 'ILSVRC2012_test_00013335.JPEG', 'kb_source': 'conceptnet', 'fact': ['pineapple', 'is a', 'fruit'], 'question_id': '3319'}, '2354': {'fact_surface': '[[Broccoli]] is [[a green vegetable]]', 'answer': 'broccoli', 'question': 'which object in this image is a green vegetable?', 'img_file': 'ILSVRC2012_test_00000783.JPEG', 'kb_source': 'conceptnet', 'fact': ['broccoli', 'is a', 'green vegetable'], 'question_id': '3318'}, '2355': {'fact_surface': '[[a saxophone]] is for [[blowing]]', 'answer': 'saxophone', 'question': 'What instrument in the image is used for blow?', 'img_file': 'ILSVRC2012_test_00007902.JPEG', 'kb_source': 'conceptnet', 'fact': ['saxophone', 'used for', 'blow'], 'question_id': '5488'}, '2356': {'fact_surface': '*Something you find at [[the corner of two streets]] is [[a traffic light]]', 'answer': 'traffic light', 'question': 'Which object in this image can be found at the corner of two streets?', 'img_file': 'COCO_val2014_000000128939.jpg', 'kb_source': 'conceptnet', 'fact': ['traffic light', 'at location', 'corner of two street'], 'question_id': '5486'}, '2357': {'fact_surface': '[[a car]] is for [[travelling around]]', 'answer': 'car', 'question': 'which object in this image is used for travel?', 'img_file': 'COCO_val2014_000000128939.jpg', 'kb_source': 'conceptnet', 'fact': ['car', 'used for', 'travel around'], 'question_id': '5485'}, '2358': {'fact_surface': '[[a car]] is for [[travelling around]]', 'answer': 'car', 'question': 'which object in this image is used for travel?', 'img_file': 'COCO_val2014_000000128939.jpg', 'kb_source': 'conceptnet', 'fact': ['car', 'used for', 'travel around'], 'question_id': '5484'}, '2359': {'fact_surface': '[[a car]] is for [[travelling around]]', 'answer': 'car', 'question': 'which object in this image is used for travel?', 'img_file': 'COCO_val2014_000000128939.jpg', 'kb_source': 'conceptnet', 'fact': ['car', 'used for', 'travel around'], 'question_id': '5483'}, '2360': {'fact_surface': '[[Frisbee]] is related to [[throw]]', 'answer': 'frisbee', 'question': 'Which object in this image can be thrown?', 'img_file': 'COCO_val2014_000000145734.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'related to', 'throw'], 'question_id': '5581'}, '2361': {'fact_surface': '[[a book]] is used for [[passing on what author knows]]', 'answer': 'book', 'question': 'What thing in this image can be used for passing on what author knows', 'img_file': 'ILSVRC2012_test_00002176.JPEG', 'kb_source': 'conceptnet', 'fact': ['book', 'used for', 'pass on what author know'], 'question_id': '60'}, '2362': {'fact_surface': '[[bicycles]] are [[human powered transports]]', 'answer': 'bicycle', 'question': 'What human powered transportation device is seen in this image?', 'img_file': 'COCO_val2014_000000120745.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'is a', 'human power transport'], 'question_id': '62'}, '2363': {'fact_surface': '[[A bottle]] can [[hold water]]', 'answer': 'water', 'question': 'What is in the bottle?', 'img_file': 'ILSVRC2012_test_00001387.JPEG', 'kb_source': 'conceptnet', 'fact': ['bottle', 'capable of', 'water'], 'question_id': '63'}, '2364': {'fact_surface': '[[maraca]] belongs to the category of [[Percussion instruments by tradition]]', 'answer': 'maraca', 'question': 'What percussion instrument is seen here?', 'img_file': 'ILSVRC2012_test_00003337.JPEG', 'kb_source': 'dbpedia', 'fact': ['maraca', 'belong to', 'percussion instruments by tradition'], 'question_id': '64'}, '2365': {'fact_surface': '[[tomatoes]] are [[green before they are red]]', 'answer': 'tomato', 'question': 'Which object in this image is green before they are red', 'img_file': 'ILSVRC2012_test_00048262.JPEG', 'kb_source': 'conceptnet', 'fact': ['tomato', 'has property', 'green before they be red'], 'question_id': '69'}, '2366': {'fact_surface': '[[A stop sign]] is usually [[a red octogon]]', 'answer': 'octogon', 'question': 'What is the shape of the sign?', 'img_file': 'COCO_val2014_000000110369.jpg', 'kb_source': 'conceptnet', 'fact': ['stop sign', 'is a', 'octogon'], 'question_id': '508'}, '2367': {'fact_surface': '[[A stop sign]] is for [[controlling traffic]]', 'answer': 'stop sign', 'question': 'Which object in this image is used to control traffic', 'img_file': 'COCO_val2014_000000110369.jpg', 'kb_source': 'conceptnet', 'fact': ['stop sign', 'used for', 'control traffic'], 'question_id': '509'}, '2368': {'fact_surface': '*Something you find at [[sea]] is [[large ships]]', 'answer': 'large ship', 'question': 'What can you find at sea', 'img_file': 'COCO_val2014_000000001682.jpg', 'kb_source': 'conceptnet', 'fact': ['large ship', 'at location', 'sea'], 'question_id': '506'}, '2369': {'fact_surface': '[[a boat]] is used for [[floating on the water]]', 'answer': 'boat', 'question': 'What is floating on the water?', 'img_file': 'COCO_val2014_000000001682.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'used for', 'float on water'], 'question_id': '505'}, '2370': {'fact_surface': '[[a sofa]] is for [[lying on it]]', 'answer': 'sofa', 'question': 'Which thing in the image can I lying on it?', 'img_file': 'COCO_val2014_000000142248.jpg', 'kb_source': 'conceptnet', 'fact': ['sofa', 'used for', 'lie on it'], 'question_id': '503'}, '2371': {'fact_surface': '[[lamp]] is related to [[heat]]', 'answer': 'lamp', 'question': 'Which thing in the image can produce heat?', 'img_file': 'COCO_val2014_000000122954.jpg', 'kb_source': 'conceptnet', 'fact': ['lamp', 'related to', 'heat'], 'question_id': '500'}, '2372': {'fact_surface': '[[a squirrel]] wants [[nuts]]', 'answer': 'squirrel', 'question': 'Which animal in this image like nuts', 'img_file': 'COCO_val2014_000000015070.jpg', 'kb_source': 'conceptnet', 'fact': ['squirrel', 'desires', 'nut'], 'question_id': '632'}, '2373': {'fact_surface': 'You are likely to find [[squirrel]] in [[the jungle]].', 'answer': 'squirrel', 'question': 'Which animal in this image can be found in jungle', 'img_file': 'COCO_val2014_000000015070.jpg', 'kb_source': 'conceptnet', 'fact': ['squirrel', 'at location', 'jungle'], 'question_id': '634'}, '2374': {'fact_surface': '[[elephants]] are [[bigger than ants]]', 'answer': 'elephant', 'question': 'Which animal in this image is a big than ant?', 'img_file': 'COCO_val2014_000000000974.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'is a', 'big than ant'], 'question_id': '1217'}, '2375': {'fact_surface': '[[a motorcycle]] has [[two wheels]]', 'answer': 'motorcycle', 'question': 'Which vehicle in this photo has two wheels?', 'img_file': 'ILSVRC2012_test_00056482.JPEG', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'has a', 'two wheel'], 'question_id': '636'}, '2376': {'fact_surface': '[[A car]] has [[four tyres]]', 'answer': 'car', 'question': 'Which vehicle in this image has four tyres', 'img_file': 'ILSVRC2012_test_00056482.JPEG', 'kb_source': 'conceptnet', 'fact': ['car', 'has a', 'four tyre'], 'question_id': '637'}, '2377': {'fact_surface': '[[Cars]] have [[two headlights]]', 'answer': 'car', 'question': 'Which vehicle in this image has two headlights', 'img_file': 'ILSVRC2012_test_00056482.JPEG', 'kb_source': 'conceptnet', 'fact': ['car', 'has a', 'two headlight'], 'question_id': '638'}, '2378': {'fact_surface': 'A [[kite]] is a [[toy]]', 'answer': 'kite', 'question': 'What toy can be found in the image?', 'img_file': 'COCO_val2014_000000118432.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'is a', 'toy'], 'question_id': '1219'}, '2379': {'fact_surface': '[[harmonica]] is a subclass of [[multi-reed woodwind instrument]]', 'answer': 'harmonica', 'question': 'Which object in this image is a multi reed woodwind instrument?', 'img_file': 'ILSVRC2012_test_00053752.JPEG', 'kb_source': 'conceptnet', 'fact': ['harmonica', 'is a', 'multi reed woodwind instrument'], 'question_id': '3869'}, '2380': {'fact_surface': '[[vegetables]] belongs to the category of [[Food]]', 'answer': 'vegetable', 'question': 'Which object in this image belongs to the category Food?', 'img_file': 'COCO_val2014_000000140664.jpg', 'kb_source': 'dbpedia', 'fact': ['vegetable', 'belong to', 'food'], 'question_id': '3863'}, '2381': {'fact_surface': '[[A tie]] is [[neckwear]]', 'answer': 'tie', 'question': 'Which object in this image is neckwear?', 'img_file': 'COCO_val2014_000000100428.jpg', 'kb_source': 'conceptnet', 'fact': ['tie', 'is a', 'neckwear'], 'question_id': '3867'}, '2382': {'fact_surface': '[[tuck in]] is related to [[shirt]]', 'answer': 'shirt', 'question': 'Which object in this image can be tucked in?', 'img_file': 'COCO_val2014_000000100428.jpg', 'kb_source': 'conceptnet', 'fact': ['tuck in', 'related to', 'shirt'], 'question_id': '3866'}, '2383': {'fact_surface': '[[bicycles]] have [[two pedals]]', 'answer': 'bicycle', 'question': 'Which object in this image has two pedals?', 'img_file': 'COCO_val2014_000000140197.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'has a', 'two pedal'], 'question_id': '3865'}, '2384': {'fact_surface': '[[a bicycle]] can [[travel on a road]]', 'answer': 'bicycle', 'question': 'Which object in this image is capable of travelling on the road?', 'img_file': 'COCO_val2014_000000140197.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'capable of', 'travel on road'], 'question_id': '3864'}, '2385': {'fact_surface': '[[a tennis ball]] is for [[hitting with a racket]]', 'answer': 'tennis ball', 'question': 'What object in this image is hit with a racket?', 'img_file': 'COCO_val2014_000000000962.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis ball', 'used for', 'hit with racket'], 'question_id': '4152'}, '2386': {'fact_surface': '[[A tennis ball]] is [[round]]', 'answer': 'tennis ball', 'question': 'What is the round object in this image?', 'img_file': 'COCO_val2014_000000000962.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis ball', 'has property', 'round'], 'question_id': '4153'}, '2387': {'fact_surface': '[[a tennis racket]] can be used to [[play tennis]].', 'answer': 'play tennis', 'question': 'What is the large object in the right of this image used for?', 'img_file': 'COCO_val2014_000000000962.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis racket', 'used for', 'play tennis'], 'question_id': '4150'}, '2388': {'fact_surface': '[[A tennis ball]] is often [[yellow]]', 'answer': 'tennis ball', 'question': 'What is the yellow object in this image?', 'img_file': 'COCO_val2014_000000000962.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis ball', 'has property', 'yellow'], 'question_id': '4151'}, '2389': {'fact_surface': '[[tennis racket]] is related to [[string]]', 'answer': 'tennis racket', 'question': 'What object in this image has strings?', 'img_file': 'COCO_val2014_000000000962.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis racket', 'related to', 'string'], 'question_id': '4154'}, '2390': {'fact_surface': '[[tennis racket]] is related to [[frame]]', 'answer': 'tennis racket', 'question': 'What object in this image has a frame?', 'img_file': 'COCO_val2014_000000000962.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis racket', 'related to', 'frame'], 'question_id': '4155'}, '2391': {'fact_surface': '[[A couch]] can comfortably [[seat more than one person]]', 'answer': 'couch', 'question': 'Which furniture in this image is capable of seat more than one person?', 'img_file': 'COCO_val2014_000000003145.jpg', 'kb_source': 'conceptnet', 'fact': ['couch', 'capable of', 'seat more than one person'], 'question_id': '4159'}, '2392': {'fact_surface': '[[boat]] belongs to the category of [[Ship transport]]', 'answer': 'boat', 'question': \"Which object in this image belong to the category 'water transport'?\", 'img_file': 'COCO_val2014_000000023489.jpg', 'kb_source': 'dbpedia', 'fact': ['boat', 'belong to', 'ship transport'], 'question_id': '5459'}, '2393': {'fact_surface': '*Something you find [[at a zoo]] is [[a zebra]]', 'answer': 'zebra', 'question': 'Which object in this image can be found in a zoo?', 'img_file': 'COCO_val2014_000000100661.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'at location', 'at zoo'], 'question_id': '5902'}, '2394': {'fact_surface': '[[A Zebra]] is [[an African equine species]]', 'answer': 'zebra', 'question': 'Which object in this image is an African equine specie?', 'img_file': 'COCO_val2014_000000100661.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'is a', 'african equine specie'], 'question_id': '5903'}, '2395': {'fact_surface': '[[grass]] belongs to the category of [[Plant taxonomy]]', 'answer': 'grass', 'question': 'Which object in this image belongs to the class Plant taxonomy?', 'img_file': 'COCO_val2014_000000100661.jpg', 'kb_source': 'dbpedia', 'fact': ['grass', 'belong to', 'plant taxonomy'], 'question_id': '5900'}, '2396': {'fact_surface': '[[zebra]] is a subclass of [[herd animal]]', 'answer': 'zebra', 'question': 'Which object in this image is a herd animal?', 'img_file': 'COCO_val2014_000000100661.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'is a', 'herd animal'], 'question_id': '5901'}, '2397': {'fact_surface': '[[motorcycle]] are far more dangerous than [[car]]', 'answer': 'car', 'question': 'What thing is less dangerous than the object in the foreground of this image?', 'img_file': 'COCO_val2014_000000131597.jpg', 'kb_source': 'webchild', 'fact': ['motorcycle', 'dangerous', 'car'], 'question_id': '5907'}, '2398': {'fact_surface': '[[Zebras]] have [[stripes]]', 'answer': 'zebra', 'question': 'Which object in this image has stripes?', 'img_file': 'COCO_val2014_000000100661.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'stripe'], 'question_id': '5904'}, '2399': {'fact_surface': '[[A zebra]] has [[a nose]]', 'answer': 'zebra', 'question': 'Which object in this image has a nose?', 'img_file': 'COCO_val2014_000000100661.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'nose'], 'question_id': '5905'}, '2400': {'fact_surface': '[[water]] is [[cool]]', 'answer': 'water', 'question': 'Which object in this image is likely to be most cool?', 'img_file': 'COCO_val2014_000000019447.jpg', 'kb_source': 'conceptnet', 'fact': ['water', 'has property', 'cool'], 'question_id': '5908'}, '2401': {'fact_surface': '[[Giraffes]] have [[long tongues]]', 'answer': 'giraffe', 'question': 'What in this image has a long tongue?', 'img_file': 'COCO_val2014_000000019447.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'has a', 'long tongue'], 'question_id': '5909'}, '2402': {'fact_surface': '[[a dog]] is [[a a mammal]]', 'answer': 'dog', 'question': 'What thing in the image is a mammal?', 'img_file': 'COCO_val2014_000000022599.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'is a', 'mammal'], 'question_id': '3481'}, '2403': {'fact_surface': '[[an oven]] is used for [[preparing food]]', 'answer': 'oven', 'question': 'Which object in this image is used for preparing food?', 'img_file': 'COCO_val2014_000000148588.jpg', 'kb_source': 'conceptnet', 'fact': ['oven', 'used for', 'prepare food'], 'question_id': '3483'}, '2404': {'fact_surface': '[[Dogs]] like to [[run a lot]]', 'answer': 'dog', 'question': 'Which object in this image likes to run a lot?', 'img_file': 'COCO_val2014_000000022599.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'desires', 'run lot'], 'question_id': '3482'}, '2405': {'fact_surface': '[[A pizza]] contains [[mostly dough, cheese, and tomato]]', 'answer': 'pizza', 'question': 'Which object in this image has is mostly dough, cheese and tomato?', 'img_file': 'COCO_val2014_000000148588.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'has a', 'mostly dough cheese and tomato'], 'question_id': '3484'}, '2406': {'fact_surface': '[[a bus]] is for [[mass transportaion]]', 'answer': 'bus', 'question': 'Which kind of mass transportaion is used in this image?', 'img_file': 'COCO_val2014_000000107247.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'used for', 'mass transportaion'], 'question_id': '4563'}, '2407': {'fact_surface': 'A [[bus]] is a [[vehicle]]', 'answer': 'bus', 'question': 'Which object in this image is a vehicle?', 'img_file': 'COCO_val2014_000000107247.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'is a', 'vehicle'], 'question_id': '4562'}, '2408': {'fact_surface': '[[burrito]] belongs to the category of [[Culture of Mexico]]', 'answer': 'burrito', 'question': 'Which food in this image is Mexican?', 'img_file': 'ILSVRC2012_test_00044153.JPEG', 'kb_source': 'dbpedia', 'fact': ['burrito', 'belong to', 'culture of mexico'], 'question_id': '4565'}, '2409': {'fact_surface': '[[person]] wants [[clear vision]]', 'answer': 'person', 'question': 'Which object in this image desires clear vision?', 'img_file': 'ILSVRC2012_test_00014182.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'clear vision'], 'question_id': '4564'}, '2410': {'fact_surface': '[[Basketball]] is an instance of [[sport]]', 'answer': 'basketball', 'question': 'Which object in this image is a sport?', 'img_file': 'ILSVRC2012_test_00016243.JPEG', 'kb_source': 'conceptnet', 'fact': ['basketball', 'is a', 'sport'], 'question_id': '2604'}, '2411': {'fact_surface': '[[a zebra]] has [[eyes]]', 'answer': 'zebra', 'question': 'Which object in this image has a eye', 'img_file': 'COCO_val2014_000000027377.jpg', 'kb_source': 'conceptnet', 'fact': ['zebra', 'has a', 'eye'], 'question_id': '2606'}, '2412': {'fact_surface': '[[computer]] belongs to the category of [[Equipment]]', 'answer': 'computer', 'question': 'Which object in this image belongs to the category Equipment?', 'img_file': 'ILSVRC2012_test_00033675.JPEG', 'kb_source': 'dbpedia', 'fact': ['computer', 'belong to', 'equipment'], 'question_id': '2607'}, '2413': {'fact_surface': '[[cats]] can [[eat meat]]', 'answer': 'cat', 'question': 'Which object in this image is capable of eat meat?', 'img_file': 'COCO_val2014_000000104625.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'eat meat'], 'question_id': '2601'}, '2414': {'fact_surface': '[[A tv]] is used to [[display a transmitted image]]', 'answer': 'tv', 'question': 'Which object in this image is used to display a transmitted image?', 'img_file': 'COCO_val2014_000000104625.jpg', 'kb_source': 'conceptnet', 'fact': ['tv', 'used for', 'display transmit image'], 'question_id': '2602'}, '2415': {'fact_surface': '[[A cat]] will [[shed its hair]]', 'answer': 'cat', 'question': 'Which object in this image is capable of shedding its hair?', 'img_file': 'COCO_val2014_000000104625.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'capable of', 'shed it hair'], 'question_id': '2603'}, '2416': {'fact_surface': '[[laptop]] are now more popular than [[desktop]]', 'answer': 'laptop', 'question': 'which object in this image is more popular than desktop?', 'img_file': 'ILSVRC2012_test_00033675.JPEG', 'kb_source': 'webchild', 'fact': ['laptop', 'popular', 'desktop'], 'question_id': '2608'}, '2417': {'fact_surface': '[[printers]] are for [[printing things]].', 'answer': 'printer', 'question': 'Which object in this image is used for printing thing?', 'img_file': 'ILSVRC2012_test_00002776.JPEG', 'kb_source': 'conceptnet', 'fact': ['printer', 'used for', 'print thing'], 'question_id': '5453'}, '2418': {'fact_surface': 'A [[printer]] can [[print pictures]].', 'answer': 'printer', 'question': 'Which object in this image is capable of printing picture?', 'img_file': 'ILSVRC2012_test_00002776.JPEG', 'kb_source': 'conceptnet', 'fact': ['printer', 'capable of', 'print picture'], 'question_id': '5454'}, '2419': {'fact_surface': '[[Hippopotamus]] is an instance of [[mammal]]', 'answer': 'hippopotamus', 'question': 'Which mammal is present in this picture?', 'img_file': 'ILSVRC2012_test_00000775.JPEG', 'kb_source': 'conceptnet', 'fact': ['hippopotamus', 'is a', 'mammal'], 'question_id': '753'}, '2420': {'fact_surface': '[[trombone]] is related to [[sliding]]', 'answer': 'trombone', 'question': 'Which object in this image is related to slide?', 'img_file': 'ILSVRC2012_test_00007896.JPEG', 'kb_source': 'conceptnet', 'fact': ['trombone', 'related to', 'slide'], 'question_id': '3780'}, '2421': {'fact_surface': '[[people]] can [[jump]]', 'answer': 'person', 'question': 'Which objects in this image can jump?', 'img_file': 'COCO_val2014_000000023489.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'jump'], 'question_id': '5455'}, '2422': {'fact_surface': '[[a baseball field]] is [[green]]', 'answer': 'baseball field', 'question': 'What property does the place in this image have?', 'img_file': 'COCO_val2014_000000106331.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball field', 'has property', 'green'], 'question_id': '2950'}, '2423': {'fact_surface': '[[papers]] belongs to the category of [[Stationery]]', 'answer': 'paper', 'question': 'What is an item of stationary visible in this image?', 'img_file': 'ILSVRC2012_test_00002875.JPEG', 'kb_source': 'dbpedia', 'fact': ['paper', 'belong to', 'stationery'], 'question_id': '2952'}, '2424': {'fact_surface': '[[laptop]] belongs to the category of [[Personal computing]]', 'answer': 'laptop', 'question': 'hich object in this image is considered to belong to the cateogry Personal computing?', 'img_file': 'ILSVRC2012_test_00002875.JPEG', 'kb_source': 'dbpedia', 'fact': ['laptop', 'belong to', 'personal computing'], 'question_id': '2953'}, '2425': {'fact_surface': '[[zebra]] are a bit smaller than [[normal horse]]', 'answer': 'small', 'question': 'Are the animals in the image smaller or bigger than normal horse?', 'img_file': 'COCO_val2014_000000100661.jpg', 'kb_source': 'webchild', 'fact': ['zebra', 'small', 'small'], 'question_id': '1024'}, '2426': {'fact_surface': '[[trombone]] is a kind of [[brass instrument]]', 'answer': 'trombone', 'question': 'Which object in this image is a brass instrument?', 'img_file': 'ILSVRC2012_test_00000499.JPEG', 'kb_source': 'conceptnet', 'fact': ['trombone', 'is a', 'brass instrument'], 'question_id': '5347'}, '2427': {'fact_surface': '[[elephant]] is bigger than [[horse]]', 'answer': 'elephant', 'question': 'which animal in this image is bigger than horse?', 'img_file': 'COCO_val2014_000000121123.jpg', 'kb_source': 'webchild', 'fact': ['elephant', 'big', 'horse'], 'question_id': '1801'}, '2428': {'fact_surface': '[[slide]] is related to [[trombone]]', 'answer': 'trombone', 'question': 'Which object in this image has a slide?', 'img_file': 'ILSVRC2012_test_00000499.JPEG', 'kb_source': 'conceptnet', 'fact': ['slide', 'related to', 'trombone'], 'question_id': '5342'}, '2429': {'fact_surface': '[[Elephants]] are sometimes [[driven by people]]', 'answer': 'elephant', 'question': 'Which object in this image is sometimes driven by a person?', 'img_file': 'COCO_val2014_000000121123.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'has property', 'drive by person'], 'question_id': '1800'}, '2430': {'fact_surface': 'You are likely to find [[cushions]] in [[the room]].', 'answer': 'room', 'question': 'What can be found in this place?', 'img_file': 'ILSVRC2012_test_00027726.JPEG', 'kb_source': 'conceptnet', 'fact': ['cushion', 'at location', 'room'], 'question_id': '1029'}, '2431': {'fact_surface': '[[a key]] is part of [[a keyboard]]', 'answer': 'keyboard', 'question': 'which object can we find keys in', 'img_file': 'ILSVRC2012_test_00031261.JPEG', 'kb_source': 'conceptnet', 'fact': ['key', 'part of', 'keyboard'], 'question_id': '5349'}, '2432': {'fact_surface': '[[Rivers]] contain [[water]]', 'answer': 'river', 'question': 'What thing in this image contains water?', 'img_file': 'COCO_val2014_000000023489.jpg', 'kb_source': 'conceptnet', 'fact': ['river', 'has a', 'water'], 'question_id': '5456'}, '2433': {'fact_surface': '[[an orange]] is [[both a fruit and a colour]]', 'answer': 'orange', 'question': 'Which object in this image is both a fruit and a colour?', 'img_file': 'COCO_val2014_000000138115.jpg', 'kb_source': 'conceptnet', 'fact': ['orange', 'is a', 'both fruit and colour'], 'question_id': '4368'}, '2434': {'fact_surface': '[[boating]] is related to [[on water]]', 'answer': 'boat', 'question': 'What activity can be done on water in this image?', 'img_file': 'COCO_val2014_000000023489.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'related to', 'on water'], 'question_id': '5457'}, '2435': {'fact_surface': '[[Water]] can [[dribble]]', 'answer': 'water', 'question': 'Which object in this image is capable of dribble?', 'img_file': 'COCO_val2014_000000107548.jpg', 'kb_source': 'conceptnet', 'fact': ['water', 'capable of', 'dribble'], 'question_id': '3108'}, '2436': {'fact_surface': '[[boating]] is related to [[sailing]]', 'answer': 'boat', 'question': 'Which object in this image is related to sail?', 'img_file': 'COCO_val2014_000000107548.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'related to', 'sail'], 'question_id': '3109'}, '2437': {'fact_surface': '[[Soccer balls]] are [[round]].', 'answer': 'soccer ball', 'question': 'Which object in the image is round', 'img_file': 'ILSVRC2012_test_00001157.JPEG', 'kb_source': 'conceptnet', 'fact': ['soccer ball', 'has property', 'round'], 'question_id': '3104'}, '2438': {'fact_surface': '[[lakes]] contain [[water]]', 'answer': 'water', 'question': 'What thing does the place shown in this image have as a part?', 'img_file': 'COCO_val2014_000000107548.jpg', 'kb_source': 'conceptnet', 'fact': ['lake', 'has a', 'water'], 'question_id': '3107'}, '2439': {'fact_surface': '[[lower jaw]] is related to [[mouth]]', 'answer': 'mouth', 'question': 'Which object in this image is part of a lower jaw?', 'img_file': 'ILSVRC2012_test_00008234.JPEG', 'kb_source': 'conceptnet', 'fact': ['low jaw', 'related to', 'mouth'], 'question_id': '3100'}, '2440': {'fact_surface': '[[braid]] is related to [[hair]]', 'answer': 'hair', 'question': 'Which object in this image is related to braid?', 'img_file': 'ILSVRC2012_test_00008234.JPEG', 'kb_source': 'conceptnet', 'fact': ['braid', 'related to', 'hair'], 'question_id': '3101'}, '2441': {'fact_surface': '[[a person]] can [[learn to swim]].', 'answer': 'person', 'question': 'which object in this image can learn to swim?', 'img_file': 'ILSVRC2012_test_00008234.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'learn to swim'], 'question_id': '3102'}, '2442': {'fact_surface': '[[Soccer balls]] are [[round]].', 'answer': 'soccer ball', 'question': 'Which object in the image is round', 'img_file': 'ILSVRC2012_test_00001157.JPEG', 'kb_source': 'conceptnet', 'fact': ['soccer ball', 'has property', 'round'], 'question_id': '3103'}, '2443': {'fact_surface': 'You can use [[an airplane]] to [[fly]]', 'answer': 'airplane', 'question': 'Which object in this image is used for flying?', 'img_file': 'COCO_val2014_000000153038.jpg', 'kb_source': 'conceptnet', 'fact': ['airplane', 'used for', 'fly'], 'question_id': '4093'}, '2444': {'fact_surface': '[[snowboarding]] is a subclass of [[outdoor activity]]', 'answer': 'snowboard', 'question': 'What kind of outdoor activity is shown in this image?', 'img_file': 'COCO_val2014_000000104091.jpg', 'kb_source': 'conceptnet', 'fact': ['snowboard', 'is a', 'outdoor activity'], 'question_id': '4092'}, '2445': {'fact_surface': '[[snails]] have [[shells]]', 'answer': 'nail', 'question': 'Which animal in this image has a shell?', 'img_file': 'ILSVRC2012_test_00003143.JPEG', 'kb_source': 'conceptnet', 'fact': ['nail', 'has a', 'shell'], 'question_id': '4091'}, '2446': {'fact_surface': '[[worm]] is related to [[snail]]', 'answer': 'nail', 'question': 'What is the object like worm in this image?', 'img_file': 'ILSVRC2012_test_00003143.JPEG', 'kb_source': 'conceptnet', 'fact': ['worm', 'related to', 'nail'], 'question_id': '4090'}, '2447': {'fact_surface': 'A [[elephant]] is a [[big, gray animal with a trunk]]', 'answer': 'elephant', 'question': 'Which object in this image is a big gray animal with trunk?', 'img_file': 'COCO_val2014_000000015599.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'is a', 'big gray animal with trunk'], 'question_id': '4099'}, '2448': {'fact_surface': '[[trunk]] is related to [[elephant]]', 'answer': 'elephant', 'question': 'Which object in this image has a trunk?', 'img_file': 'COCO_val2014_000000015599.jpg', 'kb_source': 'conceptnet', 'fact': ['trunk', 'related to', 'elephant'], 'question_id': '4098'}, '2449': {'fact_surface': 'You are likely to find [[a lizard]] in [[a terrarium]]', 'answer': 'lizard', 'question': 'Which object in this image can be found in a terrarium?', 'img_file': 'ILSVRC2012_test_00030135.JPEG', 'kb_source': 'conceptnet', 'fact': ['lizard', 'at location', 'terrarium'], 'question_id': '5734'}, '2450': {'fact_surface': '[[basketball]] is [[a fast moving sport]]', 'answer': 'basketball', 'question': 'What is the fast moving sport in the image?', 'img_file': 'ILSVRC2012_test_00018760.JPEG', 'kb_source': 'conceptnet', 'fact': ['basketball', 'is a', 'fast move sport'], 'question_id': '5737'}, '2451': {'fact_surface': '[[Lizards]] are [[small animals]]', 'answer': 'lizard', 'question': 'What small animal is in this image?', 'img_file': 'ILSVRC2012_test_00030135.JPEG', 'kb_source': 'conceptnet', 'fact': ['lizard', 'is a', 'small animal'], 'question_id': '5736'}, '2452': {'fact_surface': '[[a car]] can [[carry few persons]]', 'answer': 'car', 'question': 'Which object in this image can carry few people?', 'img_file': 'COCO_val2014_000000006789.jpg', 'kb_source': 'conceptnet', 'fact': ['car', 'capable of', 'carry few person'], 'question_id': '5731'}, '2453': {'fact_surface': '[[Cars]] can [[travel on a county highway]]', 'answer': 'car', 'question': 'Which objects in this image can travel on a highway?', 'img_file': 'COCO_val2014_000000006789.jpg', 'kb_source': 'conceptnet', 'fact': ['car', 'capable of', 'travel on county highway'], 'question_id': '5730'}, '2454': {'fact_surface': 'You are likely to find [[a lizard]] in [[sunny spots]]', 'answer': 'lizard', 'question': 'Which object in this image can be found in sunny spots?', 'img_file': 'ILSVRC2012_test_00030135.JPEG', 'kb_source': 'conceptnet', 'fact': ['lizard', 'at location', 'sunny spot'], 'question_id': '5733'}, '2455': {'fact_surface': '[[a train]] can [[arrive at a station]]', 'answer': 'train', 'question': 'Which object in this image might arrive at a station?', 'img_file': 'COCO_val2014_000000006789.jpg', 'kb_source': 'conceptnet', 'fact': ['train', 'capable of', 'arrive at station'], 'question_id': '5732'}, '2456': {'fact_surface': '[[a microwave]] can be used to [[heat food]]', 'answer': 'microwave', 'question': 'Which object in this image is used for heating food?', 'img_file': 'ILSVRC2012_test_00001244.JPEG', 'kb_source': 'conceptnet', 'fact': ['microwave', 'used for', 'heat food'], 'question_id': '5739'}, '2457': {'fact_surface': '[[chicken]] are smaller than [[cow]]', 'answer': 'cow', 'question': 'Which object in this image is bigger than chicken', 'img_file': 'COCO_val2014_000000122203.jpg', 'kb_source': 'webchild', 'fact': ['chicken', 'small', 'cow'], 'question_id': '2387'}, '2458': {'fact_surface': '[[people]] like to [[go on vacations in beautiful places]]', 'answer': 'person', 'question': 'Which thing in this image likes to go on vacations in beautiful places?', 'img_file': 'COCO_val2014_000000021551.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'go on vacation in beautiful place'], 'question_id': '2389'}, '2459': {'fact_surface': '[[a jacket]] has [[a zipper]]', 'answer': 'jacket', 'question': 'What in this image likely has a zipper?', 'img_file': 'COCO_val2014_000000021551.jpg', 'kb_source': 'conceptnet', 'fact': ['jacket', 'has a', 'zipper'], 'question_id': '2388'}, '2460': {'fact_surface': 'You are likely to find [[a trumpet]] in [[a music store]]', 'answer': 'trumpet', 'question': 'Which object in this image can be bought from a music store?', 'img_file': 'ILSVRC2012_test_00037498.JPEG', 'kb_source': 'conceptnet', 'fact': ['trumpet', 'at location', 'music store'], 'question_id': '1849'}, '2461': {'fact_surface': '[[sheep]] are [[farm animals that are raised for wool and meat]]', 'answer': 'sheep', 'question': 'Which object in this image is a farm animal that is raised for wool and meat?', 'img_file': 'COCO_val2014_000000139512.jpg', 'kb_source': 'conceptnet', 'fact': ['sheep', 'is a', 'farm animal that be raise for wool and meat'], 'question_id': '1842'}, '2462': {'fact_surface': '[[A computer]] is part of [[a network]]', 'answer': 'computer', 'question': 'Which object in this image is a part of network?', 'img_file': 'ILSVRC2012_test_00019338.JPEG', 'kb_source': 'conceptnet', 'fact': ['computer', 'part of', 'network'], 'question_id': '1846'}, '2463': {'fact_surface': '[[monitor]] is used to [[show information]].', 'answer': 'monitor', 'question': 'Which object in this image is used to show information?', 'img_file': 'ILSVRC2012_test_00019338.JPEG', 'kb_source': 'conceptnet', 'fact': ['monitor', 'used for', 'show information'], 'question_id': '1845'}, '2464': {'fact_surface': '[[A guitar]] is [[one kind of stringed instrument]]', 'answer': 'guitar', 'question': 'Which object in this image is a kind of stringed instrument?', 'img_file': 'ILSVRC2012_test_00010154.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'has property', 'one kind of string instrument'], 'question_id': '4958'}, '2465': {'fact_surface': '[[guitars]] have [[5 strings]]', 'answer': 'guitar', 'question': 'Which thing in this image has 5 string?', 'img_file': 'ILSVRC2012_test_00010154.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'has a', '5 string'], 'question_id': '4952'}, '2466': {'fact_surface': '[[a tuning peg]] is part of [[a guitar]].', 'answer': 'guitar', 'question': 'Which object in this image has a tuning peg?', 'img_file': 'ILSVRC2012_test_00010154.JPEG', 'kb_source': 'conceptnet', 'fact': ['tune peg', 'part of', 'guitar'], 'question_id': '4953'}, '2467': {'fact_surface': '[[guitars]] are usually [[made from wood]]', 'answer': 'wood', 'question': 'What is the musical instrument in the image made from?', 'img_file': 'ILSVRC2012_test_00010154.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'has property', 'wood'], 'question_id': '4951'}, '2468': {'fact_surface': 'You can use [[a guitar]] to [[play a song]]', 'answer': 'guitar', 'question': 'Which object in this image is used for playing songs?', 'img_file': 'ILSVRC2012_test_00010154.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'used for', 'play song'], 'question_id': '4956'}, '2469': {'fact_surface': '[[a fret]] is part of [[a guitar]].', 'answer': 'guitar', 'question': 'Which object in this image has frets?', 'img_file': 'ILSVRC2012_test_00010154.JPEG', 'kb_source': 'conceptnet', 'fact': ['fret', 'part of', 'guitar'], 'question_id': '4957'}, '2470': {'fact_surface': '[[A guitar]] is [[a very common musical instrument]]', 'answer': 'guitar', 'question': 'Which object in this image is a very common musical instrument?', 'img_file': 'ILSVRC2012_test_00010154.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'is a', 'very common musical instrument'], 'question_id': '4954'}, '2471': {'fact_surface': '[[sofa]] is a subclass of [[seat]]', 'answer': 'sofa', 'question': 'Which object in this image is a seat?', 'img_file': 'COCO_val2014_000000106235.jpg', 'kb_source': 'conceptnet', 'fact': ['sofa', 'is a', 'seat'], 'question_id': '2129'}, '2472': {'fact_surface': '[[bears]] can [[kill humans]].', 'answer': 'bear', 'question': 'which object in this image is dangerous for human', 'img_file': 'COCO_val2014_000000006437.jpg', 'kb_source': 'conceptnet', 'fact': ['bear', 'capable of', 'kill human'], 'question_id': '5139'}, '2473': {'fact_surface': 'You are likely to find [[a banjo]] in [[a band]]', 'answer': 'banjo', 'question': 'Which object in this image might be found in a band?', 'img_file': 'ILSVRC2012_test_00000658.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'at location', 'band'], 'question_id': '5138'}, '2474': {'fact_surface': '[[a banjo]] is used for [[music]]', 'answer': 'banjo', 'question': 'Which object in this image is used for music?', 'img_file': 'ILSVRC2012_test_00000658.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'used for', 'music'], 'question_id': '5137'}, '2475': {'fact_surface': '[[a bottle]] is for [[pouring liquid from]]', 'answer': 'bottle', 'question': 'Which object in this image is used to pour liquid from?', 'img_file': 'ILSVRC2012_test_00002544.JPEG', 'kb_source': 'conceptnet', 'fact': ['bottle', 'used for', 'pour liquid from'], 'question_id': '1907'}, '2476': {'fact_surface': '[[A banjo]] is [[a stringed instrumetnt]]', 'answer': 'banjo', 'question': 'Which object in this image is a stringed instrument?', 'img_file': 'ILSVRC2012_test_00000658.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'is a', 'string instrumetnt'], 'question_id': '5135'}, '2477': {'fact_surface': '[[a guitar]] has [[6 strings]]', 'answer': 'string', 'question': \"what does the object held in the man's hand has\", 'img_file': 'ILSVRC2012_test_00024564.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'has a', 'string'], 'question_id': '1902'}, '2478': {'fact_surface': '[[lamps]] can be used to [[generate light]]', 'answer': 'lamp', 'question': 'Which object in this image is used for generating light?', 'img_file': 'COCO_val2014_000000106235.jpg', 'kb_source': 'conceptnet', 'fact': ['lamp', 'used for', 'generate light'], 'question_id': '2128'}, '2479': {'fact_surface': '[[police]] belongs to the category of [[Law enforcement]]', 'answer': 'police', 'question': 'What in this image belongs to the category Law enforcement?', 'img_file': 'COCO_val2014_000000102461.jpg', 'kb_source': 'dbpedia', 'fact': ['police', 'belong to', 'law enforcement'], 'question_id': '1279'}, '2480': {'fact_surface': '[[Bicycles]] are [[built for one person]]', 'answer': 'bicycle', 'question': 'Which vehicle in this image is built for one person', 'img_file': 'COCO_val2014_000000017244.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'receives action', 'build for one person'], 'question_id': '619'}, '2481': {'fact_surface': '[[an umbrella]] can be used to [[shield yourself from rain if you must be outside]]', 'answer': 'umbrella', 'question': 'What object can shield yourself from rain?', 'img_file': 'COCO_val2014_000000025668.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'used for', 'shield yourself from rain if you must be outside'], 'question_id': '1271'}, '2482': {'fact_surface': '[[something]] can be at [[the ski resort]]', 'answer': 'ski', 'question': 'What is this place used for?', 'img_file': 'COCO_val2014_000000021613.jpg', 'kb_source': 'conceptnet', 'fact': ['something', 'at location', 'ski'], 'question_id': '1272'}, '2483': {'fact_surface': '[[Soccer fields]] have [[grass]]', 'answer': 'grass', 'question': 'What kind of field do you need to play this game?', 'img_file': 'COCO_val2014_000000101985.jpg', 'kb_source': 'conceptnet', 'fact': ['soccer field', 'has a', 'grass'], 'question_id': '616'}, '2484': {'fact_surface': '[[monitor]] belongs to the category of [[Digital electronics]]', 'answer': 'monitor', 'question': 'Which object in this image belongs to the category Digital electronics?', 'img_file': 'COCO_val2014_000000131131.jpg', 'kb_source': 'dbpedia', 'fact': ['monitor', 'belong to', 'digital electronics'], 'question_id': '3332'}, '2485': {'fact_surface': '[[sunglasses]] belongs to the category of [[Fashion]]', 'answer': 'sunglasses', 'question': 'Which object in this image belongs to the category Fashion?', 'img_file': 'COCO_val2014_000000110392.jpg', 'kb_source': 'dbpedia', 'fact': ['sunglasses', 'belong to', 'fashion'], 'question_id': '1496'}, '2486': {'fact_surface': 'You are likely to find [[a cat]] in [[many peoples homes]]', 'answer': 'cat', 'question': 'which object in this image is regarded as a pet in most family ?', 'img_file': 'COCO_val2014_000000131131.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'at location', 'many people home'], 'question_id': '3334'}, '2487': {'fact_surface': 'A [[violin]] is a [[instrument]]', 'answer': 'violin', 'question': 'Which object in this image is an instrument?', 'img_file': 'ILSVRC2012_test_00019880.JPEG', 'kb_source': 'conceptnet', 'fact': ['violin', 'is a', 'instrument'], 'question_id': '3338'}, '2488': {'fact_surface': '[[Giraffes]] have [[long tongues]]', 'answer': 'giraffe', 'question': 'Which object in this image has a long tongue?', 'img_file': 'COCO_val2014_000000143129.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'has a', 'long tongue'], 'question_id': '5038'}, '2489': {'fact_surface': '[[giraffe]] is [[long-necked]].', 'answer': 'giraffe', 'question': 'Which object in this image has a long neck?', 'img_file': 'COCO_val2014_000000143129.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'has property', 'long neck'], 'question_id': '5039'}, '2490': {'fact_surface': 'A [[suitcase]] is a [[container]]', 'answer': 'suitcase', 'question': 'What kind of container is shown in this image ?', 'img_file': 'COCO_val2014_000000130419.jpg', 'kb_source': 'conceptnet', 'fact': ['suitcase', 'is a', 'container'], 'question_id': '4138'}, '2491': {'fact_surface': '[[living room]] is related to [[house]]', 'answer': 'house', 'question': 'which object in this image often has a living room', 'img_file': 'COCO_val2014_000000130419.jpg', 'kb_source': 'conceptnet', 'fact': ['live room', 'related to', 'house'], 'question_id': '4139'}, '2492': {'fact_surface': '[[hot dog]] belongs to the category of [[North American cuisine]]', 'answer': 'hot dog', 'question': 'Which object in this image belongs to the category North American cuisine?', 'img_file': 'ILSVRC2012_test_00018817.JPEG', 'kb_source': 'dbpedia', 'fact': ['hot dog', 'belong to', 'north american cuisine'], 'question_id': '4130'}, '2493': {'fact_surface': '[[A hot dog]] is really [[delicious]]', 'answer': 'hot dog', 'question': 'Which object in this image is delicious?', 'img_file': 'ILSVRC2012_test_00018817.JPEG', 'kb_source': 'conceptnet', 'fact': ['hot dog', 'has property', 'delicious'], 'question_id': '4131'}, '2494': {'fact_surface': '[[Hot dogs]] are [[a popular food with kids]]', 'answer': 'hot dog', 'question': 'Which object in this image is a popular food with kid?', 'img_file': 'ILSVRC2012_test_00018817.JPEG', 'kb_source': 'conceptnet', 'fact': ['hot dog', 'is a', 'popular food with kid'], 'question_id': '4132'}, '2495': {'fact_surface': '[[hot dog]] is for [[eating]]', 'answer': 'hot dog', 'question': 'Which object in this image is used for eating?', 'img_file': 'ILSVRC2012_test_00018817.JPEG', 'kb_source': 'conceptnet', 'fact': ['hot dog', 'used for', 'eat'], 'question_id': '4133'}, '2496': {'fact_surface': '[[hot dog]] belongs to the category of [[Fast food]]', 'answer': 'hot dog', 'question': 'Which object in this image belongs to the category of fast food?', 'img_file': 'ILSVRC2012_test_00018817.JPEG', 'kb_source': 'dbpedia', 'fact': ['hot dog', 'belong to', 'fast food'], 'question_id': '4134'}, '2497': {'fact_surface': 'You can use [[a luggage]] to [[pack clothing]]', 'answer': 'luggage', 'question': 'Which object in this image is used for packing clothes?', 'img_file': 'COCO_val2014_000000130419.jpg', 'kb_source': 'conceptnet', 'fact': ['luggage', 'used for', 'pack clothe'], 'question_id': '4137'}, '2498': {'fact_surface': '[[train station]] is related to [[trains]]', 'answer': 'train', 'question': 'Train station is related to which object in this image?', 'img_file': 'COCO_val2014_000000026226.jpg', 'kb_source': 'conceptnet', 'fact': ['train station', 'related to', 'train'], 'question_id': '3843'}, '2499': {'fact_surface': '[[train]] are a lot slower than [[plane]]', 'answer': 'train', 'question': 'What transportation in the image is slower than plane?', 'img_file': 'COCO_val2014_000000026226.jpg', 'kb_source': 'webchild', 'fact': ['train', 'slow', 'plane'], 'question_id': '3845'}, '2500': {'fact_surface': '[[a refrigerator]] is for [[freezing food]]', 'answer': 'refrigerator', 'question': 'Which object in this image is used for freezing food?', 'img_file': 'ILSVRC2012_test_00020753.JPEG', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'used for', 'freeze food'], 'question_id': '5697'}, '2501': {'fact_surface': '*Something you find at [[the corner of two streets]] is [[a traffic light]]', 'answer': 'traffic light', 'question': 'Which traffic signal can be found in the corner of two streets?', 'img_file': 'ILSVRC2012_test_00007890.JPEG', 'kb_source': 'conceptnet', 'fact': ['traffic light', 'at location', 'corner of two street'], 'question_id': '3847'}, '2502': {'fact_surface': '[[traffic light]] is related to [[intersection]]', 'answer': 'traffic light', 'question': 'Which object in this image is related to intersection?', 'img_file': 'ILSVRC2012_test_00007890.JPEG', 'kb_source': 'conceptnet', 'fact': ['traffic light', 'related to', 'intersection'], 'question_id': '3846'}, '2503': {'fact_surface': 'A [[refrigerator]] is a [[machine that keeps food cold]]', 'answer': 'refrigerator', 'question': 'Which object in this image is a machine that keeps food cold?', 'img_file': 'ILSVRC2012_test_00020753.JPEG', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'is a', 'machine that keep food cold'], 'question_id': '5698'}, '2504': {'fact_surface': '[[wood]] usually has [[a grain]]', 'answer': 'wood', 'question': 'What material in this image has a grain?', 'img_file': 'ILSVRC2012_test_00020753.JPEG', 'kb_source': 'conceptnet', 'fact': ['wood', 'has a', 'grain'], 'question_id': '5699'}, '2505': {'fact_surface': 'You can use [[a baseball field]] to [[play]]', 'answer': 'baseball field', 'question': 'what place is this shown in this picture', 'img_file': 'ILSVRC2012_test_00003646.JPEG', 'kb_source': 'conceptnet', 'fact': ['baseball field', 'used for', 'play'], 'question_id': '1077'}, '2506': {'fact_surface': '[[cello]] is related to [[violin]]', 'answer': 'violin', 'question': 'Which object in this image is related to cello?', 'img_file': 'ILSVRC2012_test_00053657.JPEG', 'kb_source': 'conceptnet', 'fact': ['cello', 'related to', 'violin'], 'question_id': '4541'}, '2507': {'fact_surface': '[[fig]] belongs to the category of [[Fruit]]', 'answer': 'fig', 'question': 'Which food can you see in this image?', 'img_file': 'ILSVRC2012_test_00036755.JPEG', 'kb_source': 'dbpedia', 'fact': ['common fig', 'belong to', 'fig'], 'question_id': '4542'}, '2508': {'fact_surface': '[[a car]] is [[faster than a bicycle]]', 'answer': 'car', 'question': 'Which vehicle is faster than a bucycle', 'img_file': 'ILSVRC2012_test_00004254.JPEG', 'kb_source': 'conceptnet', 'fact': ['car', 'is a', 'fast than bicycle'], 'question_id': '4547'}, '2509': {'fact_surface': '[[engine]] is related to [[car]]', 'answer': 'car', 'question': 'Which object in this image has an engine?', 'img_file': 'ILSVRC2012_test_00004254.JPEG', 'kb_source': 'conceptnet', 'fact': ['engine', 'related to', 'car'], 'question_id': '4546'}, '2510': {'fact_surface': '[[snails]] are [[slow]]', 'answer': 'nail', 'question': 'Which animal in this image is slow?', 'img_file': 'ILSVRC2012_test_00001734.JPEG', 'kb_source': 'conceptnet', 'fact': ['nail', 'has property', 'low'], 'question_id': '1073'}, '2511': {'fact_surface': '[[Pizza]] is [[baked in an oven]]', 'answer': 'pizza', 'question': 'Which object in this image is baked in oven?', 'img_file': 'COCO_val2014_000000113720.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'has property', 'bake in oven'], 'question_id': '2594'}, '2512': {'fact_surface': '[[pizza]] is made with [[dough, tomato sauce and mozzarella cheese]]', 'answer': 'pizza', 'question': 'Which object in this image is made with dough, tomato sauce and mozzarella cheese?', 'img_file': 'COCO_val2014_000000113720.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'created by', 'dough tomato sauce and mozzarella cheese'], 'question_id': '2595'}, '2513': {'fact_surface': '[[trumpet]] belongs to the category of [[Jazz]]', 'answer': 'trumpet', 'question': 'Which object in the image is often associated with Jazz music?', 'img_file': 'ILSVRC2012_test_00004214.JPEG', 'kb_source': 'dbpedia', 'fact': ['trumpet', 'belong to', 'jazz'], 'question_id': '2596'}, '2514': {'fact_surface': 'Kinds of [[wind instrument]] : [[trumpet]]', 'answer': 'trumpet', 'question': 'Which object in the image is a type of of wind instrument?', 'img_file': 'ILSVRC2012_test_00004214.JPEG', 'kb_source': 'conceptnet', 'fact': ['trumpet', 'is a', 'wind instrument'], 'question_id': '2597'}, '2515': {'fact_surface': '[[People]] can [[join organizations]]', 'answer': 'person', 'question': 'What object in this image can joing organizations?', 'img_file': 'ILSVRC2012_test_00005014.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'join organization'], 'question_id': '2590'}, '2516': {'fact_surface': '[[A person]] can [[eat a banana]]', 'answer': 'person', 'question': 'What object in this image can eat a banana?', 'img_file': 'ILSVRC2012_test_00005014.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'eat banana'], 'question_id': '2591'}, '2517': {'fact_surface': '[[A person]] is [[an individual, unlike any other]]', 'answer': 'person', 'question': 'Which object in this image is a individual unlike any other?', 'img_file': 'COCO_val2014_000000000536.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'is a', 'individual unlike any other'], 'question_id': '2592'}, '2518': {'fact_surface': '[[A person]] is [[an individual, unlike any other]]', 'answer': 'person', 'question': 'Which object in this image is a individual unlike any other?', 'img_file': 'COCO_val2014_000000000536.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'is a', 'individual unlike any other'], 'question_id': '2593'}, '2519': {'fact_surface': '[[A frisbee]] can [[fly]].', 'answer': 'frisbee', 'question': 'Which object in this image is capable of flying?', 'img_file': 'COCO_val2014_000000002753.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'capable of', 'fly'], 'question_id': '2598'}, '2520': {'fact_surface': '[[keyboard]] is related to [[piano]]', 'answer': 'piano', 'question': 'Which object in this image is related to keyboard?', 'img_file': 'ILSVRC2012_test_00058802.JPEG', 'kb_source': 'conceptnet', 'fact': ['keyboard', 'related to', 'piano'], 'question_id': '1070'}, '2521': {'fact_surface': '[[memory chip]] is related to [[computer]]', 'answer': 'computer', 'question': 'Which object in this image is related to memory chips?', 'img_file': 'ILSVRC2012_test_00056291.JPEG', 'kb_source': 'conceptnet', 'fact': ['memory chip', 'related to', 'computer'], 'question_id': '2623'}, '2522': {'fact_surface': '[[gangplank]] is related to [[ship]]', 'answer': 'ship', 'question': 'Which object in this image might have a gangplank?', 'img_file': 'ILSVRC2012_test_00000149.JPEG', 'kb_source': 'conceptnet', 'fact': ['gangplank', 'related to', 'ship'], 'question_id': '2626'}, '2523': {'fact_surface': '[[gunport]] is related to [[ship]]', 'answer': 'ship', 'question': 'Which object in this image has gunports?', 'img_file': 'ILSVRC2012_test_00000149.JPEG', 'kb_source': 'conceptnet', 'fact': ['gunport', 'related to', 'ship'], 'question_id': '2627'}, '2524': {'fact_surface': '[[Water]] can [[act as a reflector]]', 'answer': 'water', 'question': 'Which thing in this image can act as a reflector?', 'img_file': 'ILSVRC2012_test_00000149.JPEG', 'kb_source': 'conceptnet', 'fact': ['water', 'capable of', 'act as reflector'], 'question_id': '2625'}, '2525': {'fact_surface': '[[ships]] can be used to [[travel across water]]', 'answer': 'ship', 'question': 'Which object in this image is used for travelling across water?', 'img_file': 'ILSVRC2012_test_00000149.JPEG', 'kb_source': 'conceptnet', 'fact': ['ship', 'used for', 'travel across water'], 'question_id': '2628'}, '2526': {'fact_surface': '[[A lemon]] is [[a sour, yellow fruit]]', 'answer': 'lemon', 'question': 'Which object in this image is a sour yellow fruit?', 'img_file': 'ILSVRC2012_test_00049151.JPEG', 'kb_source': 'conceptnet', 'fact': ['lemon', 'is a', 'sour yellow fruit'], 'question_id': '2629'}, '2527': {'fact_surface': '[[bus]] is slower than [[car]]', 'answer': 'low', 'question': 'Whether this thing is faster or slower than a car?', 'img_file': 'COCO_val2014_000000144251.jpg', 'kb_source': 'webchild', 'fact': ['bus', 'slow', 'low'], 'question_id': '775'}, '2528': {'fact_surface': '[[a refrigerator]] can [[stock food]]', 'answer': 'refrigerator', 'question': 'Which stuff in the image is used for stock food?', 'img_file': 'COCO_val2014_000000104790.jpg', 'kb_source': 'conceptnet', 'fact': ['refrigerator', 'capable of', 'stock food'], 'question_id': '776'}, '2529': {'fact_surface': '[[surfboard]] is a subclass of [[sports equipment]]', 'answer': 'surfboard', 'question': 'What kind of sports equipment is presented in the image?', 'img_file': 'COCO_val2014_000000124620.jpg', 'kb_source': 'conceptnet', 'fact': ['surfboard', 'is a', 'sport equipment'], 'question_id': '770'}, '2530': {'fact_surface': '[[dishwasher]] can be more efficient than [[hand wash]]', 'answer': 'dishwasher', 'question': \"Which device in the image can free people's hand?\", 'img_file': 'COCO_val2014_000000009236.jpg', 'kb_source': 'webchild', 'fact': ['dishwasher', 'efficient', 'hand wash'], 'question_id': '779'}, '2531': {'fact_surface': '[[wood]] can be [[burned in a fireplace]]', 'answer': 'wood', 'question': 'What is burning in the fireplace?', 'img_file': 'COCO_val2014_000000014088.jpg', 'kb_source': 'conceptnet', 'fact': ['wood', 'receives action', 'burn in fireplace'], 'question_id': '778'}, '2532': {'fact_surface': '[[frisbee]] belongs to the category of [[Entertainment]]', 'answer': 'frisbee', 'question': 'What is the entertainment in the image?', 'img_file': 'COCO_val2014_000000145815.jpg', 'kb_source': 'dbpedia', 'fact': ['frisbee', 'belong to', 'entertainment'], 'question_id': '77'}, '2533': {'fact_surface': '[[bear]] is related to [[eat fish]]', 'answer': 'fish', 'question': 'What kind of seafood does the animal in the image likes to eat?', 'img_file': 'COCO_val2014_000000127955.jpg', 'kb_source': 'conceptnet', 'fact': ['bear', 'related to', 'fish'], 'question_id': '73'}, '2534': {'fact_surface': '[[bear]] run much faster than [[human]]', 'answer': 'bear', 'question': 'Who run faster? human or the animal in the image?', 'img_file': 'COCO_val2014_000000127955.jpg', 'kb_source': 'webchild', 'fact': ['bear', 'fast', 'human'], 'question_id': '72'}, '2535': {'fact_surface': '[[cucumber]] is related to [[pickle]]', 'answer': 'cucumber', 'question': 'Which object in this image is the most related to pickle', 'img_file': 'ILSVRC2012_test_00048262.JPEG', 'kb_source': 'conceptnet', 'fact': ['cucumber', 'related to', 'pickle'], 'question_id': '71'}, '2536': {'fact_surface': '[[cucumber]] is related to [[green long]]', 'answer': 'cucumber', 'question': 'Which object in this image is related to green long', 'img_file': 'ILSVRC2012_test_00048262.JPEG', 'kb_source': 'conceptnet', 'fact': ['cucumber', 'related to', 'green long'], 'question_id': '70'}, '2537': {'fact_surface': '[[vegetables]] belongs to the category of [[Vegetarian cuisine]]', 'answer': 'vegetarian', 'question': 'What kind of dish is this ?', 'img_file': 'COCO_val2014_000000104612.jpg', 'kb_source': 'dbpedia', 'fact': ['vegetable', 'belong to', 'vegetarian'], 'question_id': '2970'}, '2538': {'fact_surface': '[[broccoli]] belongs to the category of [[Garden plants]]', 'answer': 'broccoli', 'question': 'Which object in this image belongs to Garden plants?', 'img_file': 'COCO_val2014_000000104612.jpg', 'kb_source': 'dbpedia', 'fact': ['broccoli', 'belong to', 'garden plants'], 'question_id': '2971'}, '2539': {'fact_surface': '(scissors,/r/UsedFor,cutting)', 'answer': 'scissors', 'question': 'Which object in this image is used for cutting ', 'img_file': 'COCO_val2014_000000113126.jpg', 'kb_source': 'conceptnet', 'fact': ['scissors', 'used for', 'cut'], 'question_id': '79'}, '2540': {'fact_surface': '[[Bedrooms]] usually have [[beds]]', 'answer': 'bed', 'question': 'What does this place have?', 'img_file': 'COCO_val2014_000000134112.jpg', 'kb_source': 'conceptnet', 'fact': ['bedroom', 'has a', 'bed'], 'question_id': '5363'}, '2541': {'fact_surface': '[[sheep]] is related to [[woolly animals]]', 'answer': 'sheep', 'question': \"which object in this image is related to 'woolly animal'?\", 'img_file': 'COCO_val2014_000000027438.jpg', 'kb_source': 'conceptnet', 'fact': ['sheep', 'related to', 'woolly animal'], 'question_id': '1047'}, '2542': {'fact_surface': '[[baa]] is related to [[sheep]]', 'answer': 'sheep', 'question': \"which object in this image is related to 'baa'?\", 'img_file': 'COCO_val2014_000000027438.jpg', 'kb_source': 'conceptnet', 'fact': ['baa', 'related to', 'sheep'], 'question_id': '1046'}, '2543': {'fact_surface': '[[sheep]] is related to [[wool]]', 'answer': 'sheep', 'question': \"which object in this image is related to 'wool'?\", 'img_file': 'COCO_val2014_000000027438.jpg', 'kb_source': 'conceptnet', 'fact': ['sheep', 'related to', 'wool'], 'question_id': '1045'}, '2544': {'fact_surface': '[[sheep]] are [[farm animals]]', 'answer': 'sheep', 'question': 'which object in this image is a farm animal?', 'img_file': 'COCO_val2014_000000027438.jpg', 'kb_source': 'conceptnet', 'fact': ['sheep', 'is a', 'farm animal'], 'question_id': '1049'}, '2545': {'fact_surface': '[[sheep]] is related to [[mammal]]', 'answer': 'sheep', 'question': \"which object in this image is related to 'mammal'?\", 'img_file': 'COCO_val2014_000000027438.jpg', 'kb_source': 'conceptnet', 'fact': ['sheep', 'related to', 'mammal'], 'question_id': '1048'}, '2546': {'fact_surface': '[[skis]] belongs to the category of [[Sports equipment]]', 'answer': 'ski', 'question': 'What object in this image is a type of sports equipment?', 'img_file': 'COCO_val2014_000000129982.jpg', 'kb_source': 'dbpedia', 'fact': ['ski', 'belong to', 'sports equipment'], 'question_id': '4303'}, '2547': {'fact_surface': 'You are likely to find [[a basketball]] in [[store]]', 'answer': 'basketball', 'question': 'Which object in this image can be found in store?', 'img_file': 'ILSVRC2012_test_00005398.JPEG', 'kb_source': 'conceptnet', 'fact': ['basketball', 'at location', 'store'], 'question_id': '4307'}, '2548': {'fact_surface': '[[Basketball]] is [[a team game]]', 'answer': 'basketball', 'question': 'What kind of team game does this image describe?', 'img_file': 'ILSVRC2012_test_00005398.JPEG', 'kb_source': 'conceptnet', 'fact': ['basketball', 'is a', 'team game'], 'question_id': '4306'}, '2549': {'fact_surface': '[[skis]] belongs to the category of [[Racing]]', 'answer': 'ski', 'question': 'What objects in this image are used for racing?', 'img_file': 'COCO_val2014_000000129982.jpg', 'kb_source': 'dbpedia', 'fact': ['ski', 'belong to', 'racing'], 'question_id': '4305'}, '2550': {'fact_surface': 'Somewhere [[skiiers]] can be is on [[a ski slope]]', 'answer': 'skiiers', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000129982.jpg', 'kb_source': 'conceptnet', 'fact': ['skiiers', 'at location', 'ski slope'], 'question_id': '4304'}, '2551': {'fact_surface': 'You are likely to find [[a basketball]] in [[store]]', 'answer': 'basketball', 'question': 'Which object in this image can be found in store?', 'img_file': 'ILSVRC2012_test_00005398.JPEG', 'kb_source': 'conceptnet', 'fact': ['basketball', 'at location', 'store'], 'question_id': '4308'}, '2552': {'fact_surface': '[[raster graphics]] is related to [[monitor]]', 'answer': 'monitor', 'question': 'Which object in this image is related to raster graphics?', 'img_file': 'ILSVRC2012_test_00055834.JPEG', 'kb_source': 'conceptnet', 'fact': ['raster graphic', 'related to', 'monitor'], 'question_id': '3128'}, '2553': {'fact_surface': '[[boats]] usually [[float on water]]', 'answer': 'boat', 'question': 'which object in this image can float on water?', 'img_file': 'COCO_val2014_000000120248.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'capable of', 'float on water'], 'question_id': '3129'}, '2554': {'fact_surface': '[[A jacket]] is for [[keeping warm]]', 'answer': 'jacket', 'question': 'Which object keeps this person warm?', 'img_file': 'COCO_val2014_000000105053.jpg', 'kb_source': 'conceptnet', 'fact': ['jacket', 'used for', 'keep warm'], 'question_id': '3122'}, '2555': {'fact_surface': '[[finger]] is part of [[hand]].', 'answer': 'hand', 'question': 'Which objects in this image have fingers?', 'img_file': 'COCO_val2014_000000153563.jpg', 'kb_source': 'conceptnet', 'fact': ['finger', 'part of', 'hand'], 'question_id': '3120'}, '2556': {'fact_surface': '[[sand]] is [[very small rocks]]', 'answer': 'sand', 'question': 'What in this image consists of very small rocks?', 'img_file': 'COCO_val2014_000000105264.jpg', 'kb_source': 'conceptnet', 'fact': ['sand', 'is a', 'very small rock'], 'question_id': '3121'}, '2557': {'fact_surface': '[[A toddler]] can [[eat a banana]]', 'answer': 'toddler', 'question': 'What thing which you see here may be capable of eating a banana?', 'img_file': 'COCO_val2014_000000018928.jpg', 'kb_source': 'conceptnet', 'fact': ['toddler', 'capable of', 'eat banana'], 'question_id': '3126'}, '2558': {'fact_surface': '[[fish]] is related to [[water animals]]', 'answer': 'fish', 'question': 'What kind of water animal is in the image?', 'img_file': 'ILSVRC2012_test_00052304.JPEG', 'kb_source': 'conceptnet', 'fact': ['fish', 'related to', 'water animal'], 'question_id': '3127'}, '2559': {'fact_surface': '[[children]] belongs to the category of [[Youth]]', 'answer': 'child', 'question': 'What in this image is a youth?', 'img_file': 'COCO_val2014_000000018928.jpg', 'kb_source': 'dbpedia', 'fact': ['child', 'belong to', 'youth'], 'question_id': '3125'}, '2560': {'fact_surface': '[[Strawberries]] are [[small red fruits]]', 'answer': 'strawberry', 'question': 'Which object in this image is a small red fruit?', 'img_file': 'ILSVRC2012_test_00057307.JPEG', 'kb_source': 'conceptnet', 'fact': ['strawberry', 'is a', 'small red fruit'], 'question_id': '5753'}, '2561': {'fact_surface': '[[fire hydrant]] belongs to the category of [[Firefighting equipment]]', 'answer': 'fire hydrant', 'question': 'Which object in this image belongs to the category Firefighting equipment?', 'img_file': 'COCO_val2014_000000148392.jpg', 'kb_source': 'dbpedia', 'fact': ['fire hydrant', 'belong to', 'firefighting equipment'], 'question_id': '5752'}, '2562': {'fact_surface': '[[fire hydrant]] is related to [[fire engine]]', 'answer': 'fire hydrant', 'question': 'Which object in this image is related to fire engine?', 'img_file': 'COCO_val2014_000000148392.jpg', 'kb_source': 'conceptnet', 'fact': ['fire hydrant', 'related to', 'fire engine'], 'question_id': '5751'}, '2563': {'fact_surface': '[[fire hydrants]] can be used to [[fight fires]]', 'answer': 'fire hydrant', 'question': 'Which object in this image is used for fighting fires?', 'img_file': 'COCO_val2014_000000148392.jpg', 'kb_source': 'conceptnet', 'fact': ['fire hydrant', 'used for', 'fight fire'], 'question_id': '5750'}, '2564': {'fact_surface': '[[a bowl]] is used for [[cereal]]', 'answer': 'bowl', 'question': 'What in this image could be used for holding cereal?', 'img_file': 'ILSVRC2012_test_00027426.JPEG', 'kb_source': 'conceptnet', 'fact': ['bowl', 'used for', 'cereal'], 'question_id': '5757'}, '2565': {'fact_surface': 'A [[cup]] can [[hold coffee]].', 'answer': 'cup', 'question': 'Which object in this image is capable of holding coffee?', 'img_file': 'COCO_val2014_000000151790.jpg', 'kb_source': 'conceptnet', 'fact': ['cup', 'capable of', 'hold coffee'], 'question_id': '5754'}, '2566': {'fact_surface': '[[bowl]] is a subclass of [[non-powered device]]', 'answer': 'bowl', 'question': 'which object in this image can be used without power', 'img_file': 'ILSVRC2012_test_00027426.JPEG', 'kb_source': 'conceptnet', 'fact': ['bowl', 'is a', 'non power device'], 'question_id': '5759'}, '2567': {'fact_surface': 'You can use [[a bowl]] to [[hold blueberries]]', 'answer': 'bowl', 'question': 'Which object in this image can be use to hold blueberry?', 'img_file': 'ILSVRC2012_test_00027426.JPEG', 'kb_source': 'conceptnet', 'fact': ['bowl', 'used for', 'hold blueberry'], 'question_id': '5758'}, '2568': {'fact_surface': '[[follicle]] is related to [[hair]]', 'answer': 'hair', 'question': 'What thing shown in this image has follicles?', 'img_file': 'COCO_val2014_000000022892.jpg', 'kb_source': 'conceptnet', 'fact': ['follicle', 'related to', 'hair'], 'question_id': '4609'}, '2569': {'fact_surface': '[[snail]] are [[slower than turtles]]', 'answer': 'low', 'question': 'Whether the animal in the image is slower or faster than turtles?', 'img_file': 'ILSVRC2012_test_00017099.JPEG', 'kb_source': 'conceptnet', 'fact': ['nail', 'is a', 'low'], 'question_id': '862'}, '2570': {'fact_surface': '[[Cake]] is [[a sweet dessert]]', 'answer': 'cake', 'question': 'Which food in this image is a sweet dessert?', 'img_file': 'COCO_val2014_000000003001.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'is a', 'sweet dessert'], 'question_id': '3441'}, '2571': {'fact_surface': '[[Kittens]] are [[soft and furry]]', 'answer': 'kitten', 'question': 'Which object in this image is soft and furry?', 'img_file': 'COCO_val2014_000000025138.jpg', 'kb_source': 'conceptnet', 'fact': ['kitten', 'has property', 'soft and furry'], 'question_id': '2024'}, '2572': {'fact_surface': '[[a baseball field]] is [[green]]', 'answer': 'green', 'question': 'What is color of this place?', 'img_file': 'COCO_val2014_000000111874.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball field', 'has property', 'green'], 'question_id': '2323'}, '2573': {'fact_surface': '[[Baseballs]] can [[travel very fast]]', 'answer': 'baseball', 'question': 'Which object in this image is travelling very fast?', 'img_file': 'COCO_val2014_000000111874.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'capable of', 'travel very fast'], 'question_id': '2322'}, '2574': {'fact_surface': 'A [[kitten]] is a [[infant cat]]', 'answer': 'kitten', 'question': 'Which object in this image is an infant cat?', 'img_file': 'COCO_val2014_000000025138.jpg', 'kb_source': 'conceptnet', 'fact': ['kitten', 'is a', 'infant cat'], 'question_id': '2023'}, '2575': {'fact_surface': '[[A kite]] can [[catch the wind]]', 'answer': 'kite', 'question': 'Which object in this image is catching wind?', 'img_file': 'COCO_val2014_000000153865.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'capable of', 'catch wind'], 'question_id': '4604'}, '2576': {'fact_surface': '[[A baseball]] is [[round]]', 'answer': 'baseball', 'question': 'Which object in this image has the property of round?', 'img_file': 'COCO_val2014_000000111874.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'has property', 'round'], 'question_id': '2321'}, '2577': {'fact_surface': '[[snail]] belongs to the category of [[Meat]]', 'answer': 'nail', 'question': 'Which object in this image has meat?', 'img_file': 'ILSVRC2012_test_00000138.JPEG', 'kb_source': 'dbpedia', 'fact': ['nail', 'belong to', 'meat'], 'question_id': '2320'}, '2578': {'fact_surface': 'You can use [[a baseball field]] to [[play]]', 'answer': 'play', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000111874.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball field', 'used for', 'play'], 'question_id': '2324'}, '2579': {'fact_surface': '[[bus]] are generally cheaper than [[taxi]]', 'answer': 'taxi', 'question': 'what kind of transportation is cheeper than the object in the middle of this image', 'img_file': 'COCO_val2014_000000102056.jpg', 'kb_source': 'webchild', 'fact': ['bus', 'cheap', 'taxi'], 'question_id': '1614'}, '2580': {'fact_surface': '[[people]] can [[farm carrots]]', 'answer': 'person', 'question': 'Which object in this image is capable of farming carrots?', 'img_file': 'COCO_val2014_000000016382.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'farm carrot'], 'question_id': '4801'}, '2581': {'fact_surface': '[[party]] is related to [[cake]]', 'answer': 'cake', 'question': 'Which object in this image is related to party?', 'img_file': 'COCO_val2014_000000136270.jpg', 'kb_source': 'conceptnet', 'fact': ['party', 'related to', 'cake'], 'question_id': '5196'}, '2582': {'fact_surface': '[[A tree]] is part of [[an orchard]]', 'answer': 'tree', 'question': 'Which object in this image could sometimes form part of an orchard?', 'img_file': 'COCO_val2014_000000115765.jpg', 'kb_source': 'conceptnet', 'fact': ['tree', 'part of', 'orchard'], 'question_id': '2369'}, '2583': {'fact_surface': '[[trees]] have [[leaves on their branches]]', 'answer': 'tree', 'question': 'Which object in this image has leaves on its branches?', 'img_file': 'COCO_val2014_000000115765.jpg', 'kb_source': 'conceptnet', 'fact': ['tree', 'has a', 'leave on their branch'], 'question_id': '2368'}, '2584': {'fact_surface': '[[A bookshelf]] contains [[books]]', 'answer': 'bookshelf', 'question': 'Which object in this image contains books?', 'img_file': 'ILSVRC2012_test_00032881.JPEG', 'kb_source': 'conceptnet', 'fact': ['bookshelf', 'has a', 'book'], 'question_id': '2367'}, '2585': {'fact_surface': 'You can use [[a tv]] to [[watch movies]]', 'answer': 'tv', 'question': 'Which object in this image can be used for watching movies?', 'img_file': 'ILSVRC2012_test_00032881.JPEG', 'kb_source': 'conceptnet', 'fact': ['tv', 'used for', 'watch movie'], 'question_id': '2366'}, '2586': {'fact_surface': 'A [[guitar]] is a [[instrument]].', 'answer': 'guitar', 'question': 'Which object in this image is an instrument?', 'img_file': 'ILSVRC2012_test_00032881.JPEG', 'kb_source': 'conceptnet', 'fact': ['guitar', 'is a', 'instrument'], 'question_id': '2365'}, '2587': {'fact_surface': '[[hair]] is part of [[a head]].', 'answer': 'head', 'question': 'What body part in this image has hair?', 'img_file': 'ILSVRC2012_test_00000957.JPEG', 'kb_source': 'conceptnet', 'fact': ['hair', 'part of', 'head'], 'question_id': '2362'}, '2588': {'fact_surface': '[[bird]] is related to [[feather]]', 'answer': 'bird', 'question': 'Which object in this image has feathers?', 'img_file': 'ILSVRC2012_test_00001506.JPEG', 'kb_source': 'conceptnet', 'fact': ['bird', 'related to', 'feather'], 'question_id': '2360'}, '2589': {'fact_surface': '[[wheel]] is part of [[a skateboard]]', 'answer': 'skateboard', 'question': 'Which sport object in this image has wheels?', 'img_file': 'COCO_val2014_000000137622.jpg', 'kb_source': 'conceptnet', 'fact': ['wheel', 'part of', 'skateboard'], 'question_id': '5191'}, '2590': {'fact_surface': '[[people]] can [[order food]]', 'answer': 'person', 'question': 'which object in this image can order food', 'img_file': 'ILSVRC2012_test_00036594.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'order food'], 'question_id': '1861'}, '2591': {'fact_surface': '[[A frisbee]] is used for [[recreation]].', 'answer': 'frisbee', 'question': 'What object in the image can be used for recreation?', 'img_file': 'COCO_val2014_000000103227.jpg', 'kb_source': 'conceptnet', 'fact': ['frisbee', 'used for', 'recreation'], 'question_id': '1860'}, '2592': {'fact_surface': '[[antelope]] belongs to the category of [[Animal]]', 'answer': 'antelope', 'question': 'Which object in this image is an animal?', 'img_file': 'ILSVRC2012_test_00002108.JPEG', 'kb_source': 'dbpedia', 'fact': ['antelope', 'belong to', 'animal'], 'question_id': '4680'}, '2593': {'fact_surface': '[[antelope]] have [[four legs]]', 'answer': 'antelope', 'question': 'What is the four legged object in this image?', 'img_file': 'ILSVRC2012_test_00002108.JPEG', 'kb_source': 'conceptnet', 'fact': ['antelope', 'has a', 'four leg'], 'question_id': '4681'}, '2594': {'fact_surface': '[[flowers]] belongs to the category of [[Plant]]', 'answer': 'flowers', 'question': 'What kind of plant is in the image?', 'img_file': 'COCO_val2014_000000103358.jpg', 'kb_source': 'dbpedia', 'fact': ['flowers', 'belong to', 'plant'], 'question_id': '4938'}, '2595': {'fact_surface': '[[giraffes]] have [[long necks]]', 'answer': 'giraffe', 'question': 'Which object in this image has longer neck?', 'img_file': 'COCO_val2014_000000004286.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'has a', 'long neck'], 'question_id': '4688'}, '2596': {'fact_surface': 'You are likely to find [[a door]] as [[a part of a wall]]', 'answer': 'door', 'question': 'Which object in this image can be found as a part of the wall?', 'img_file': 'COCO_val2014_000000009236.jpg', 'kb_source': 'conceptnet', 'fact': ['door', 'at location', 'part of wall'], 'question_id': '4689'}, '2597': {'fact_surface': '[[cake]] is related to [[bake good]]', 'answer': 'cake', 'question': 'Which food is related to bake good?', 'img_file': 'COCO_val2014_000000009270.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'related to', 'bake good'], 'question_id': '2100'}, '2598': {'fact_surface': '[[a baseball bat]] is [[a long round tapered object]]', 'answer': 'baseball bat', 'question': 'Which object in this image is a long round tapered object?', 'img_file': 'COCO_val2014_000000104185.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball bat', 'is a', 'long round taper object'], 'question_id': '2107'}, '2599': {'fact_surface': '[[a bicycle]] has [[2 tires]]', 'answer': 'bicycle', 'question': 'What object has two tires?', 'img_file': 'ILSVRC2012_test_00000023.JPEG', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'has a', '2 tire'], 'question_id': '5115'}, '2600': {'fact_surface': '[[a road]] can be used for [[traveling]]', 'answer': 'road', 'question': 'What in the image facilitates traveling?', 'img_file': 'ILSVRC2012_test_00000023.JPEG', 'kb_source': 'conceptnet', 'fact': ['road', 'used for', 'travel'], 'question_id': '5114'}, '2601': {'fact_surface': '[[bicycle]] is related to [[pedal]]', 'answer': 'bicycle', 'question': 'Which object in this image is related to pedal?', 'img_file': 'ILSVRC2012_test_00000023.JPEG', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'related to', 'pedal'], 'question_id': '5111'}, '2602': {'fact_surface': '[[bicycles]] are [[powered by humans]]', 'answer': 'bicycle', 'question': 'Which object in this image is powered by humans?', 'img_file': 'ILSVRC2012_test_00000023.JPEG', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'has property', 'power by human'], 'question_id': '5110'}, '2603': {'fact_surface': '[[shorts]] belongs to the category of [[Fashion]]', 'answer': 'short', 'question': 'Which object in the image is associated with Fashion?', 'img_file': 'ILSVRC2012_test_00000023.JPEG', 'kb_source': 'dbpedia', 'fact': ['short', 'belong to', 'fashion'], 'question_id': '5113'}, '2604': {'fact_surface': '[[a bicycle]] is [[a human powered form of transportation]]', 'answer': 'bicycle', 'question': 'Which object in this image is a human powered form of transportation?', 'img_file': 'ILSVRC2012_test_00000023.JPEG', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'is a', 'human power form of transportation'], 'question_id': '5112'}, '2605': {'fact_surface': '[[weddings]] are [[fun]]', 'answer': 'fun', 'question': 'what do you feel with the action in this image', 'img_file': 'ILSVRC2012_test_00019930.JPEG', 'kb_source': 'conceptnet', 'fact': ['wedding', 'has property', 'fun'], 'question_id': '5119'}, '2606': {'fact_surface': 'You are likely to find [[dancers]] in [[a ballroom]].', 'answer': 'dancer', 'question': 'What can be found in this place?', 'img_file': 'ILSVRC2012_test_00019930.JPEG', 'kb_source': 'conceptnet', 'fact': ['dancer', 'at location', 'ballroom'], 'question_id': '5118'}, '2607': {'fact_surface': '[[A cat]] has [[four legs]]', 'answer': 'cat', 'question': 'which object in this image has four legs?', 'img_file': 'COCO_val2014_000000127781.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'has a', 'four leg'], 'question_id': '5256'}, '2608': {'fact_surface': '[[A tie]] is [[neckwear]]', 'answer': 'tie', 'question': 'Which object in this image is an item of neckwear?', 'img_file': 'COCO_val2014_000000115579.jpg', 'kb_source': 'conceptnet', 'fact': ['tie', 'is a', 'neckwear'], 'question_id': '5192'}, '2609': {'fact_surface': '[[knife]] is used for [[ cut something]].', 'answer': 'knife', 'question': 'Which object in this image can be used to cut something', 'img_file': 'COCO_val2014_000000136270.jpg', 'kb_source': 'conceptnet', 'fact': ['knife', 'used for', 'cut something'], 'question_id': '890'}, '2610': {'fact_surface': '[[a knife]] can [[cut an apple]]', 'answer': 'knife', 'question': 'Which object can cut an apple', 'img_file': 'COCO_val2014_000000136270.jpg', 'kb_source': 'conceptnet', 'fact': ['knife', 'capable of', 'cut apple'], 'question_id': '891'}, '2611': {'fact_surface': 'When you want to [[cut]], you will use [[knife]].', 'answer': 'knife', 'question': 'Which object will you use, when you want to cut?', 'img_file': 'COCO_val2014_000000136270.jpg', 'kb_source': 'conceptnet', 'fact': ['knife', 'used for', 'cut'], 'question_id': '892'}, '2612': {'fact_surface': '[[a fork]] is used for [[piercing food]]', 'answer': 'fork', 'question': 'what object in this image is used for piercing food?', 'img_file': 'COCO_val2014_000000111024.jpg', 'kb_source': 'conceptnet', 'fact': ['fork', 'used for', 'pierce food'], 'question_id': '894'}, '2613': {'fact_surface': '[[doughnut]] is related to [[fried bread]]', 'answer': 'fry bread', 'question': 'Where the food in the image is fried or not?', 'img_file': 'COCO_val2014_000000111024.jpg', 'kb_source': 'conceptnet', 'fact': ['doughnut', 'related to', 'fry bread'], 'question_id': '895'}, '2614': {'fact_surface': '[[a bathtub]] is used for [[cleaning the body]]', 'answer': 'bathtub', 'question': 'Which one in the image can be used for cleaning the body?', 'img_file': 'COCO_val2014_000000107123.jpg', 'kb_source': 'conceptnet', 'fact': ['bathtub', 'used for', 'clean body'], 'question_id': '898'}, '2615': {'fact_surface': '[[Coffee]] contains [[caffeine]]', 'answer': 'coffee', 'question': 'Which liquid in the mug on the bottom of the image contains caffeine', 'img_file': 'COCO_val2014_000000024112.jpg', 'kb_source': 'conceptnet', 'fact': ['coffee', 'has a', 'caffeine'], 'question_id': '1789'}, '2616': {'fact_surface': '[[chair]] is related to [[four legs]]', 'answer': 'chair', 'question': 'What object in this image has four legs?', 'img_file': 'COCO_val2014_000000003109.jpg', 'kb_source': 'conceptnet', 'fact': ['chair', 'related to', 'four leg'], 'question_id': '1780'}, '2617': {'fact_surface': '[[umbrella]] is a subclass of [[shelter-providing artifact]]', 'answer': 'umbrella', 'question': 'Which object in this image provides shelter?', 'img_file': 'COCO_val2014_000000003109.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'is a', 'shelter provide artifact'], 'question_id': '1781'}, '2618': {'fact_surface': '[[fencing]] is for [[privacy]]', 'answer': 'fence', 'question': 'Which object in this image is used for privacy?', 'img_file': 'COCO_val2014_000000003109.jpg', 'kb_source': 'conceptnet', 'fact': ['fence', 'used for', 'privacy'], 'question_id': '1782'}, '2619': {'fact_surface': '[[starfish]] have [[no brain]]', 'answer': 'no brain', 'question': 'Whether the animal in the image has brain or not?', 'img_file': 'ILSVRC2012_test_00002915.JPEG', 'kb_source': 'conceptnet', 'fact': ['starfish', 'has a', 'no brain'], 'question_id': '678'}, '2620': {'fact_surface': '*Something you find [[on the beach]] is [[a starfish]]', 'answer': 'beach', 'question': 'Where you can usually find the sea life in this image', 'img_file': 'ILSVRC2012_test_00002915.JPEG', 'kb_source': 'conceptnet', 'fact': ['starfish', 'at location', 'beach'], 'question_id': '677'}, '2621': {'fact_surface': '[[a couch]] is for [[sitting on]]', 'answer': 'couch', 'question': 'Which thing is for sitting on?', 'img_file': 'COCO_val2014_000000138070.jpg', 'kb_source': 'conceptnet', 'fact': ['couch', 'used for', 'sit on'], 'question_id': '672'}, '2622': {'fact_surface': '[[bottle]] is related to [[drink]]', 'answer': 'bottle', 'question': 'Where can you find something to drink in the image?', 'img_file': 'COCO_val2014_000000135748.jpg', 'kb_source': 'conceptnet', 'fact': ['bottle', 'related to', 'drink'], 'question_id': '673'}, '2623': {'fact_surface': '*Something you find [[at a bus depot]] is [[a bus]]', 'answer': 'bus', 'question': 'What in this image can be found in at bus depot?', 'img_file': 'COCO_val2014_000000144251.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'at location', 'at bus depot'], 'question_id': '4649'}, '2624': {'fact_surface': '[[a bathroom]] is for [[using the toilet]]', 'answer': 'use toilet', 'question': 'What can you do in this place?', 'img_file': 'COCO_val2014_000000104837.jpg', 'kb_source': 'conceptnet', 'fact': ['bathroom', 'used for', 'use toilet'], 'question_id': '2491'}, '2625': {'fact_surface': '[[horizontal bar]] belongs to the category of [[Gymnastics]]', 'answer': 'horizontal bar', 'question': 'Which object in this image is used for Gymnastics?', 'img_file': 'ILSVRC2012_test_00030469.JPEG', 'kb_source': 'dbpedia', 'fact': ['horizontal bar', 'belong to', 'gymnastics'], 'question_id': '2492'}, '2626': {'fact_surface': '[[an umbrella]] is used to [[shield a person from rain]]', 'answer': 'umbrella', 'question': 'Which object in this image is used for shielding a person from rain?', 'img_file': 'COCO_val2014_000000007394.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'used for', 'shield person from rain'], 'question_id': '1965'}, '2627': {'fact_surface': '[[A car]] can [[head north]]', 'answer': 'car', 'question': 'Which object in this image is capable of head north?', 'img_file': 'COCO_val2014_000000009769.jpg', 'kb_source': 'conceptnet', 'fact': ['car', 'capable of', 'head north'], 'question_id': '2494'}, '2628': {'fact_surface': '[[a tennis ball]] is for [[sports]]', 'answer': 'tennis ball', 'question': 'which object in this image is used by the woman for sport', 'img_file': 'COCO_val2014_000000135361.jpg', 'kb_source': 'conceptnet', 'fact': ['tennis ball', 'used for', 'sport'], 'question_id': '1524'}, '2629': {'fact_surface': '[[a sofa]] is for [[watching tv]]', 'answer': 'sofa', 'question': 'Which object in this image is used for play?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'used for', 'watch tv'], 'question_id': '1254'}, '2630': {'fact_surface': '[[Pizza]] is [[a disc-shaped food item]]', 'answer': 'pizza', 'question': 'What is the disc-shaped food item in this image?', 'img_file': 'COCO_val2014_000000014353.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'is a', 'disc shape food item'], 'question_id': '1527'}, '2631': {'fact_surface': '[[Sofas]] are [[larger than chairs]]', 'answer': 'sofa', 'question': 'Which object in this image is a soft than chair?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'is a', 'large than chair'], 'question_id': '1253'}, '2632': {'fact_surface': '[[a sofa]] is for [[sleeping upon]]', 'answer': 'sofa', 'question': 'Which object in this image is used for rest?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'used for', 'sleep upon'], 'question_id': '1251'}, '2633': {'fact_surface': '[[An oven]] is [[an appliance]]', 'answer': 'oven', 'question': 'What appliance is in this image?', 'img_file': 'COCO_val2014_000000014353.jpg', 'kb_source': 'conceptnet', 'fact': ['oven', 'is a', 'appliance'], 'question_id': '1528'}, '2634': {'fact_surface': '[[pizza parlor]] is related to [[pizza]]', 'answer': 'pizza', 'question': 'Which object in this image can sometimes be found in a pizza parlour?', 'img_file': 'COCO_val2014_000000014353.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza parlor', 'related to', 'pizza'], 'question_id': '1529'}, '2635': {'fact_surface': '[[sofa]] belongs to the category of [[Personal life]]', 'answer': 'sofa', 'question': 'Which object in this image pertains to the category Personal life?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'dbpedia', 'fact': ['couch', 'belong to', 'sofa'], 'question_id': '1258'}, '2636': {'fact_surface': '[[a sofa]] is used for [[relaxing]]', 'answer': 'sofa', 'question': 'Which object in this image can you relax on it?', 'img_file': 'ILSVRC2012_test_00002135.JPEG', 'kb_source': 'conceptnet', 'fact': ['sofa', 'used for', 'relax'], 'question_id': '1259'}, '2637': {'fact_surface': '[[Baseball]] is [[a popular sport in South Korea]]', 'answer': 'baseball', 'question': 'Which sport depicted in this image is a popular sport in South Korea?', 'img_file': 'COCO_val2014_000000154139.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'is a', 'popular sport in south korea'], 'question_id': '4116'}, '2638': {'fact_surface': '[[Baseball]] is [[a popular sport in America]]', 'answer': 'baseball', 'question': 'what sports described in the image is popular in America', 'img_file': 'COCO_val2014_000000154139.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball', 'is a', 'popular sport in america'], 'question_id': '4114'}, '2639': {'fact_surface': 'You can use [[a baseball field]] to [[play baseball on it]]', 'answer': 'play baseball on it', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000154139.jpg', 'kb_source': 'conceptnet', 'fact': ['baseball field', 'used for', 'play baseball on it'], 'question_id': '4115'}, '2640': {'fact_surface': 'You are likely to find [[a jellyfish]] in [[underwater]]', 'answer': 'jellyfish', 'question': 'Which object in this image can be found in underwater?', 'img_file': 'ILSVRC2012_test_00022747.JPEG', 'kb_source': 'conceptnet', 'fact': ['jellyfish', 'at location', 'underwater'], 'question_id': '4113'}, '2641': {'fact_surface': '[[double-click]] is related to [[mouse]]', 'answer': 'mouse', 'question': 'What thing is related to double click?', 'img_file': 'COCO_val2014_000000116252.jpg', 'kb_source': 'conceptnet', 'fact': ['double click', 'related to', 'mouse'], 'question_id': '4118'}, '2642': {'fact_surface': '[[computer]] belongs to the category of [[Media technology]]', 'answer': 'computer', 'question': 'Which object in this image belongs to the category information technology?', 'img_file': 'COCO_val2014_000000116252.jpg', 'kb_source': 'dbpedia', 'fact': ['computer', 'belong to', 'media technology'], 'question_id': '4119'}, '2643': {'fact_surface': '[[waffle iron]] is related to [[hinged]]', 'answer': 'waffle iron', 'question': 'Which object in this image is hinged?', 'img_file': 'ILSVRC2012_test_00059360.JPEG', 'kb_source': 'conceptnet', 'fact': ['waffle iron', 'related to', 'hinge'], 'question_id': '2641'}, '2644': {'fact_surface': '[[a cake]] can [[dry out]]', 'answer': 'cake', 'question': 'What object in this image can dry out?', 'img_file': 'COCO_val2014_000000022474.jpg', 'kb_source': 'conceptnet', 'fact': ['cake', 'capable of', 'dry out'], 'question_id': '2644'}, '2645': {'fact_surface': 'An [[snake]] can [[be dangerous]].', 'answer': 'snake', 'question': 'What is the dangerous animal in the image?', 'img_file': 'ILSVRC2012_test_00000037.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'capable of', 'be dangerous'], 'question_id': '2645'}, '2646': {'fact_surface': 'You are likely to find [[a ball]] in [[a playground]]', 'answer': 'ball', 'question': 'what is subject in this playground?', 'img_file': 'COCO_val2014_000000025358.jpg', 'kb_source': 'conceptnet', 'fact': ['ball', 'at location', 'playground'], 'question_id': '3557'}, '2647': {'fact_surface': 'Kinds of [[music instrument]] : [[drum]]', 'answer': 'drum', 'question': 'What musical instrument is the shiny metallic object at the bottom of the image.', 'img_file': 'ILSVRC2012_test_00015015.JPEG', 'kb_source': 'conceptnet', 'fact': ['drum', 'is a', 'music instrument'], 'question_id': '3556'}, '2648': {'fact_surface': '[[a soccer ball]] is used for [[soccer]].', 'answer': 'soccer ball', 'question': 'What object is used for soccer?', 'img_file': 'COCO_val2014_000000025358.jpg', 'kb_source': 'conceptnet', 'fact': ['soccer ball', 'used for', 'soccer'], 'question_id': '3559'}, '2649': {'fact_surface': 'You are likely to find [[a child]] at [[the playground]].', 'answer': 'child', 'question': 'Which kind of creature can be found in this place?', 'img_file': 'COCO_val2014_000000025358.jpg', 'kb_source': 'conceptnet', 'fact': ['child', 'at location', 'playground'], 'question_id': '3558'}, '2650': {'fact_surface': '[[Bedrooms]] usually have [[beds]]', 'answer': 'bed', 'question': 'What thing does the place shown in this image have as a part?', 'img_file': 'COCO_val2014_000000145651.jpg', 'kb_source': 'conceptnet', 'fact': ['bedroom', 'has a', 'bed'], 'question_id': '2913'}, '2651': {'fact_surface': '[[a bicycle]] is used for [[personal transport]]', 'answer': 'bicycle', 'question': 'Which objects shown here are used for personal transport?', 'img_file': 'COCO_val2014_000000129100.jpg', 'kb_source': 'conceptnet', 'fact': ['bicycle', 'used for', 'personal transport'], 'question_id': '719'}, '2652': {'fact_surface': 'You are likely to find [[an office]] in [[a tall building]]', 'answer': 'tall build', 'question': 'Where does the place in this image can be found in?', 'img_file': 'COCO_val2014_000000152492.jpg', 'kb_source': 'conceptnet', 'fact': ['office', 'at location', 'tall build'], 'question_id': '2917'}, '2653': {'fact_surface': '[[keyboard]] belongs to the category of [[Input/output]]', 'answer': 'keyboard', 'question': 'Which object in this image belongs to the category of Input/output devices?', 'img_file': 'ILSVRC2012_test_00036774.JPEG', 'kb_source': 'dbpedia', 'fact': ['keyboard', 'belong to', 'output'], 'question_id': '2919'}, '2654': {'fact_surface': '(rice,/r/IsA,food)', 'answer': 'food', 'question': 'What do rice belong to', 'img_file': 'COCO_val2014_000000003501.jpg', 'kb_source': 'conceptnet', 'fact': ['rice', 'is a', 'food'], 'question_id': '713'}, '2655': {'fact_surface': '[[broccoli]] belongs to the category of [[Cultivars]]', 'answer': 'broccoli', 'question': 'Which thing in this picture is a cultivar?', 'img_file': 'COCO_val2014_000000003501.jpg', 'kb_source': 'dbpedia', 'fact': ['broccoli', 'belong to', 'cultivars'], 'question_id': '712'}, '2656': {'fact_surface': '[[train]] are typically faster than [[bus]]', 'answer': 'bus', 'question': 'which object in this image often moves slower than train', 'img_file': 'COCO_val2014_000000110330.jpg', 'kb_source': 'webchild', 'fact': ['train', 'fast', 'bus'], 'question_id': '5308'}, '2657': {'fact_surface': '[[drum]] is related to [[cylindrical]]', 'answer': 'drum', 'question': 'What is the cylindrical object shown in this image ?', 'img_file': 'ILSVRC2012_test_00019516.JPEG', 'kb_source': 'conceptnet', 'fact': ['drum', 'related to', 'cylindrical'], 'question_id': '5309'}, '2658': {'fact_surface': '[[A person]] can [[view a picture]]', 'answer': 'person', 'question': 'which object in this image can view a picture?', 'img_file': 'COCO_val2014_000000014892.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'view picture'], 'question_id': '5300'}, '2659': {'fact_surface': '[[people]] sometimes [[live on an island]]', 'answer': 'person', 'question': 'which object in this image is capable of living on an island?', 'img_file': 'COCO_val2014_000000014892.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'live on island'], 'question_id': '5301'}, '2660': {'fact_surface': '[[wood]] is related to [[tree]]', 'answer': 'tree', 'question': 'Which object in this image made of wood?', 'img_file': 'COCO_val2014_000000110330.jpg', 'kb_source': 'conceptnet', 'fact': ['wood', 'related to', 'tree'], 'question_id': '5304'}, '2661': {'fact_surface': '[[A person]] can [[be planting plants in their yard]]', 'answer': 'person', 'question': 'Which object in this image is capable of planting plants in their yard?', 'img_file': 'COCO_val2014_000000110330.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'capable of', 'be plant plant in their yard'], 'question_id': '5305'}, '2662': {'fact_surface': 'A [[bus]] is a [[vehicle]]', 'answer': 'bus', 'question': 'Which object in this image is a vehicle?', 'img_file': 'COCO_val2014_000000110330.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'is a', 'vehicle'], 'question_id': '5306'}, '2663': {'fact_surface': '[[bus]] is related to [[travel]]', 'answer': 'bus', 'question': 'What are the people travelling with in this image?', 'img_file': 'COCO_val2014_000000110330.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'related to', 'travel'], 'question_id': '5307'}, '2664': {'fact_surface': '[[a cat]] is used for [[a pet]]', 'answer': 'cat', 'question': 'Which object in this image is a pet for people?', 'img_file': 'COCO_val2014_000000127477.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'used for', 'pet'], 'question_id': '4320'}, '2665': {'fact_surface': '[[Wood]] is [[a common builing material]]', 'answer': 'wood', 'question': 'What shown here is a common builing material?', 'img_file': 'COCO_val2014_000000140122.jpg', 'kb_source': 'conceptnet', 'fact': ['wood', 'is a', 'common builing material'], 'question_id': '4325'}, '2666': {'fact_surface': '[[monitor]] belongs to the category of [[Computers]]', 'answer': 'monitor', 'question': 'Which object in the top right is part of computers?', 'img_file': 'COCO_val2014_000000140122.jpg', 'kb_source': 'dbpedia', 'fact': ['monitor', 'belong to', 'computer'], 'question_id': '4327'}, '2667': {'fact_surface': '[[a key]] is part of [[a keyboard]]', 'answer': 'keyboard', 'question': 'Which object in this image contains a key', 'img_file': 'COCO_val2014_000000140122.jpg', 'kb_source': 'conceptnet', 'fact': ['key', 'part of', 'keyboard'], 'question_id': '4326'}, '2668': {'fact_surface': '[[teddy bear]] is a subclass of [[stuffed animal]]', 'answer': 'teddy bear', 'question': 'Which object in this image is a stuffed animal?', 'img_file': 'COCO_val2014_000000100343.jpg', 'kb_source': 'conceptnet', 'fact': ['teddy bear', 'is a', 'stuff animal'], 'question_id': '3140'}, '2669': {'fact_surface': '[[toys]] belongs to the category of [[Play]]', 'answer': 'toy', 'question': 'Which object in the image might be used for play?', 'img_file': 'COCO_val2014_000000100343.jpg', 'kb_source': 'dbpedia', 'fact': ['toy', 'belong to', 'play'], 'question_id': '3141'}, '2670': {'fact_surface': '[[teddy bear]] belongs to the category of [[Stuffed toys]]', 'answer': 'teddy bear', 'question': 'Which object in this image belongs to the category Stuffed toys?', 'img_file': 'COCO_val2014_000000100343.jpg', 'kb_source': 'dbpedia', 'fact': ['teddy bear', 'belong to', 'stuffed toys'], 'question_id': '3142'}, '2671': {'fact_surface': '[[banana]] belongs to the category of [[Food]]', 'answer': 'banana', 'question': 'Which object in this image is a kind of Food?', 'img_file': 'COCO_val2014_000000100343.jpg', 'kb_source': 'dbpedia', 'fact': ['banana', 'belong to', 'food'], 'question_id': '3143'}, '2672': {'fact_surface': '[[toys]] belongs to the category of [[Childhood]]', 'answer': 'toy', 'question': 'Which object in this image is more often seen in childhood?', 'img_file': 'COCO_val2014_000000100343.jpg', 'kb_source': 'dbpedia', 'fact': ['toy', 'belong to', 'childhood'], 'question_id': '3144'}, '2673': {'fact_surface': '[[toys]] belongs to the category of [[Play]]', 'answer': 'toy', 'question': 'Which object in the image can you play with?', 'img_file': 'COCO_val2014_000000100343.jpg', 'kb_source': 'dbpedia', 'fact': ['toy', 'belong to', 'play'], 'question_id': '3145'}, '2674': {'fact_surface': '[[A lizard]] can [[sun to warm up]]', 'answer': 'lizard', 'question': 'Which animal in this image is capable of sun to warm up?', 'img_file': 'ILSVRC2012_test_00000767.JPEG', 'kb_source': 'conceptnet', 'fact': ['lizard', 'capable of', 'sun to warm up'], 'question_id': '5779'}, '2675': {'fact_surface': 'You are likely to find [[a lizard]] in [[rocks]]', 'answer': 'lizard', 'question': 'Which animal in this image can be found in rock?', 'img_file': 'ILSVRC2012_test_00000767.JPEG', 'kb_source': 'conceptnet', 'fact': ['lizard', 'at location', 'rock'], 'question_id': '5778'}, '2676': {'fact_surface': '[[An airplane]] has [[wheels]]', 'answer': 'airplane', 'question': 'Which object in this image has a wheel？', 'img_file': 'COCO_val2014_000000109231.jpg', 'kb_source': 'conceptnet', 'fact': ['airplane', 'has a', 'wheel'], 'question_id': '1631'}, '2677': {'fact_surface': '[[lizards]] are [[cold blooded animals]]', 'answer': 'lizard', 'question': 'Which animal in this image is a cold blood animal?', 'img_file': 'ILSVRC2012_test_00000767.JPEG', 'kb_source': 'conceptnet', 'fact': ['lizard', 'is a', 'cold blood animal'], 'question_id': '5777'}, '2678': {'fact_surface': '[[banana skin]] is related to [[banana]]', 'answer': 'banana', 'question': 'What in this image has a banana skin', 'img_file': 'COCO_val2014_000000003093.jpg', 'kb_source': 'conceptnet', 'fact': ['banana skin', 'related to', 'banana'], 'question_id': '5776'}, '2679': {'fact_surface': '[[An airplane]] is [[flying]]', 'answer': 'airplane', 'question': 'Which object in the middle can fly?', 'img_file': 'COCO_val2014_000000109231.jpg', 'kb_source': 'conceptnet', 'fact': ['airplane', 'has property', 'fly'], 'question_id': '1632'}, '2680': {'fact_surface': '[[motorcycle]] is generally [[a two wheeled vehicle]]', 'answer': 'motorcycle', 'question': '￼Which object in this image is a two wheeled vehicle?', 'img_file': 'ILSVRC2012_test_00056482.JPEG', 'kb_source': 'conceptnet', 'fact': ['motorcycle', 'has property', 'two wheel vehicle'], 'question_id': '3967'}, '2681': {'fact_surface': 'You are likely to find [[sand]] in [[the ocean]]', 'answer': 'ocean', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000106624.jpg', 'kb_source': 'conceptnet', 'fact': ['sand', 'at location', 'ocean'], 'question_id': '1634'}, '2682': {'fact_surface': 'You are likely to find [[sand]] in [[the ocean]]', 'answer': 'ocean', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000106624.jpg', 'kb_source': 'conceptnet', 'fact': ['sand', 'at location', 'ocean'], 'question_id': '1635'}, '2683': {'fact_surface': '[[book]] belongs to the category of [[Printing]]', 'answer': 'book', 'question': 'Which object in this image belongs to the category Printing?', 'img_file': 'ILSVRC2012_test_00015342.JPEG', 'kb_source': 'dbpedia', 'fact': ['book', 'belong to', 'print'], 'question_id': '3502'}, '2684': {'fact_surface': '[[a banana]] is for [[eating]]', 'answer': 'banana', 'question': 'Which object in this image is used for eat?', 'img_file': 'COCO_val2014_000000142108.jpg', 'kb_source': 'conceptnet', 'fact': ['banana', 'used for', 'eat'], 'question_id': '2345'}, '2685': {'fact_surface': '[[a person]] wants to [[trick others]]', 'answer': 'person', 'question': 'Which object in this image desires trick others?', 'img_file': 'COCO_val2014_000000142108.jpg', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'trick others'], 'question_id': '2344'}, '2686': {'fact_surface': '[[A cup]] can contain [[a drink]]', 'answer': 'cup', 'question': 'Which object in this image has a drink', 'img_file': 'COCO_val2014_000000016030.jpg', 'kb_source': 'conceptnet', 'fact': ['cup', 'has a', 'drink'], 'question_id': '2340'}, '2687': {'fact_surface': '[[laptop]] are smaller than [[desktop computer]]', 'answer': 'laptop', 'question': 'What is object smaller than desktop computer?', 'img_file': 'COCO_val2014_000000001503.jpg', 'kb_source': 'webchild', 'fact': ['laptop', 'small', 'desktop computer'], 'question_id': '3708'}, '2688': {'fact_surface': '[[a kite]] is used for [[flying and having fun]]', 'answer': 'kite', 'question': 'Which object in this image is used for fly and have fun?', 'img_file': 'COCO_val2014_000000026534.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'used for', 'fly and have fun'], 'question_id': '3709'}, '2689': {'fact_surface': '[[Cats]] have [[two eyes]]', 'answer': 'cat', 'question': 'Which animal in this image has two eyes?', 'img_file': 'COCO_val2014_000000121112.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'has a', 'two eye'], 'question_id': '3700'}, '2690': {'fact_surface': '[[children]] belongs to the category of [[Society]]', 'answer': 'child', 'question': 'Which object in this image is part of Society?', 'img_file': 'COCO_val2014_000000102820.jpg', 'kb_source': 'dbpedia', 'fact': ['child', 'belong to', 'society'], 'question_id': '3701'}, '2691': {'fact_surface': '[[a tv]] is for [[getting information]]', 'answer': 'tv', 'question': 'Which object in this image is for get information?', 'img_file': 'ILSVRC2012_test_00001045.JPEG', 'kb_source': 'conceptnet', 'fact': ['tv', 'used for', 'get information'], 'question_id': '3706'}, '2692': {'fact_surface': '[[news]] is related to [[tv]]', 'answer': 'tv', 'question': 'What object can report news?', 'img_file': 'ILSVRC2012_test_00001045.JPEG', 'kb_source': 'conceptnet', 'fact': ['new', 'related to', 'tv'], 'question_id': '3707'}, '2693': {'fact_surface': '[[a tv]] is used for [[advertising]]', 'answer': 'tv', 'question': 'Which object in this image is used for advertising?', 'img_file': 'ILSVRC2012_test_00001045.JPEG', 'kb_source': 'conceptnet', 'fact': ['tv', 'used for', 'advertise'], 'question_id': '3705'}, '2694': {'fact_surface': 'A [[train]] is a [[longh vehicle composed of many cars linked together]]', 'answer': 'train', 'question': 'Which object in this image is a long vehicle composed of many cars linked together?', 'img_file': 'COCO_val2014_000000116957.jpg', 'kb_source': 'conceptnet', 'fact': ['train', 'is a', 'longh vehicle compose of many car link together'], 'question_id': '2121'}, '2695': {'fact_surface': '[[fleece]] is related to [[sheep]]', 'answer': 'sheep', 'question': 'Which object in this image has fleece?', 'img_file': 'COCO_val2014_000000003932.jpg', 'kb_source': 'conceptnet', 'fact': ['fleece', 'related to', 'sheep'], 'question_id': '2120'}, '2696': {'fact_surface': '[[a sofa]] is [[usually to sit or lie on]]', 'answer': 'sofa', 'question': 'Which object in this image is a usually to sit or lie on?', 'img_file': 'COCO_val2014_000000106235.jpg', 'kb_source': 'conceptnet', 'fact': ['sofa', 'is a', 'usually to sit or lie on'], 'question_id': '2125'}, '2697': {'fact_surface': '[[cup]] is related to [[wine]]', 'answer': 'cup', 'question': 'what is it  in this image is related to wine?', 'img_file': 'COCO_val2014_000000106392.jpg', 'kb_source': 'conceptnet', 'fact': ['cup', 'related to', 'wine'], 'question_id': '4918'}, '2698': {'fact_surface': '[[box]] are much lighter than [[bottle]]', 'answer': 'box', 'question': 'which one in this image is less light than box?', 'img_file': 'COCO_val2014_000000106392.jpg', 'kb_source': 'webchild', 'fact': ['box', 'light', 'bottle'], 'question_id': '4919'}, '2699': {'fact_surface': 'You are likely to find [[a microwave]] at [[a kitchen]].', 'answer': 'microwave', 'question': 'What is likely to be found in this place?', 'img_file': 'COCO_val2014_000000106392.jpg', 'kb_source': 'conceptnet', 'fact': ['microwave', 'at location', 'kitchen'], 'question_id': '4914'}, '2700': {'fact_surface': 'You are likely to find [[a washing machine]] in [[a laundromat]].', 'answer': 'wash machine', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000106392.jpg', 'kb_source': 'conceptnet', 'fact': ['wash machine', 'at location', 'laundromat'], 'question_id': '4915'}, '2701': {'fact_surface': 'You can use [[an apple]] to [[enjoy the fruit]]', 'answer': 'apple', 'question': 'Which object in this image can you eat to enjoy fruit?', 'img_file': 'COCO_val2014_000000136271.jpg', 'kb_source': 'conceptnet', 'fact': ['apple', 'used for', 'enjoy fruit'], 'question_id': '5173'}, '2702': {'fact_surface': '[[snowmobile]] belongs to the category of [[Off-road vehicle]]', 'answer': 'snowmobile', 'question': 'Which object in this image belongs to the category Off-road vehicle?', 'img_file': 'ILSVRC2012_test_00026134.JPEG', 'kb_source': 'dbpedia', 'fact': ['snowmobile', 'belong to', 'off road vehicle'], 'question_id': '5171'}, '2703': {'fact_surface': '[[snocross]] is related to [[snowmobile]]', 'answer': 'snowmobile', 'question': 'Which object in this image might be used in snocross?', 'img_file': 'ILSVRC2012_test_00026134.JPEG', 'kb_source': 'conceptnet', 'fact': ['snocross', 'related to', 'snowmobile'], 'question_id': '5170'}, '2704': {'fact_surface': '[[bread]] is related to [[bake]]', 'answer': 'bread', 'question': 'Which food in this image is baked?', 'img_file': 'COCO_val2014_000000022690.jpg', 'kb_source': 'conceptnet', 'fact': ['bread', 'related to', 'bake'], 'question_id': '5177'}, '2705': {'fact_surface': '[[Bread]] is part of [[a sandwich]]', 'answer': 'bread', 'question': 'What shown in this image is a part of a sandwich?', 'img_file': 'COCO_val2014_000000022690.jpg', 'kb_source': 'conceptnet', 'fact': ['bread', 'part of', 'sandwich'], 'question_id': '5175'}, '2706': {'fact_surface': '[[A snake]] wants [[live mice]]', 'answer': 'snake', 'question': 'Which animal in this image like live mice', 'img_file': 'ILSVRC2012_test_00029408.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'desires', 'live mouse'], 'question_id': '133'}, '2707': {'fact_surface': 'You are likely to find [[a snake]] in [[a hole]]', 'answer': 'snake', 'question': 'What thing in this image is likely to be found in a hole', 'img_file': 'ILSVRC2012_test_00029408.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'at location', 'hole'], 'question_id': '132'}, '2708': {'fact_surface': '[[An umbrella]] is used to [[protect people from sun and rain]]', 'answer': 'protect person from sun and rain', 'question': 'What is the object the girl holding used to?', 'img_file': 'COCO_val2014_000000007088.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'used for', 'protect person from sun and rain'], 'question_id': '130'}, '2709': {'fact_surface': '[[A snake]] has [[no legs]]', 'answer': 'snake', 'question': 'Which animal in this image has no leg', 'img_file': 'ILSVRC2012_test_00029408.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'has a', 'no leg'], 'question_id': '137'}, '2710': {'fact_surface': '[[A snake]] wants [[live mice]]', 'answer': 'snake', 'question': 'Tell me the name of the limbless creature?', 'img_file': 'ILSVRC2012_test_00029408.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'desires', 'live mouse'], 'question_id': '136'}, '2711': {'fact_surface': '[[A snake]] wants [[live mice]]', 'answer': 'snake', 'question': 'What thing in this image like live mice', 'img_file': 'ILSVRC2012_test_00029408.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'desires', 'live mouse'], 'question_id': '135'}, '2712': {'fact_surface': '[[snake]] is for [[living in]].', 'answer': 'snake', 'question': 'Which object has fangs in its mouth', 'img_file': 'ILSVRC2012_test_00029408.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'used for', 'live in'], 'question_id': '134'}, '2713': {'fact_surface': '[[snake]] is related to [[long]]', 'answer': 'snake', 'question': 'Which object in this image is the most related to long', 'img_file': 'ILSVRC2012_test_00029408.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'related to', 'long'], 'question_id': '139'}, '2714': {'fact_surface': '[[snake]] is related to [[long reptile]]', 'answer': 'snake', 'question': 'Which object in this image is the most related to long reptile', 'img_file': 'ILSVRC2012_test_00029408.JPEG', 'kb_source': 'conceptnet', 'fact': ['snake', 'related to', 'long reptile'], 'question_id': '138'}, '2715': {'fact_surface': 'Kinds of [[musical instrument]] : [[drum]]', 'answer': 'drum', 'question': 'Tell me the name of the musical instrument in this image?', 'img_file': 'ILSVRC2012_test_00022927.JPEG', 'kb_source': 'conceptnet', 'fact': ['drum', 'is a', 'musical instrument'], 'question_id': '410'}, '2716': {'fact_surface': 'You are likely to find [[a cat]] in [[any place where people live]]', 'answer': 'any place where person live', 'question': 'Where does the animal in the middle of the image can be found in?', 'img_file': 'COCO_val2014_000000119581.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'at location', 'any place where person live'], 'question_id': '5339'}, '2717': {'fact_surface': '[[coffee]] is related to [[morning drink]]', 'answer': 'coffee', 'question': 'What is the morning drink?', 'img_file': 'ILSVRC2012_test_00012831.JPEG', 'kb_source': 'conceptnet', 'fact': ['coffee', 'related to', 'morning drink'], 'question_id': '88'}, '2718': {'fact_surface': '[[Some flowers]] are [[yellow]]', 'answer': 'flowers', 'question': 'what object in this image is yellow?', 'img_file': 'ILSVRC2012_test_00001769.JPEG', 'kb_source': 'conceptnet', 'fact': ['flowers', 'has property', 'yellow'], 'question_id': '80'}, '2719': {'fact_surface': 'You are likely to find [[a jellyfish]] in [[the sea]]', 'answer': 'sea', 'question': 'Whether this animal lives in the sea or on land?', 'img_file': 'ILSVRC2012_test_00008683.JPEG', 'kb_source': 'conceptnet', 'fact': ['jellyfish', 'at location', 'sea'], 'question_id': '81'}, '2720': {'fact_surface': '[[bear]] is related to [[large claws]]', 'answer': 'large claw', 'question': 'Why these animal can hurt people?', 'img_file': 'COCO_val2014_000000016776.jpg', 'kb_source': 'conceptnet', 'fact': ['bear', 'related to', 'large claw'], 'question_id': '86'}, '2721': {'fact_surface': '[[video card]] is related to [[monitor]]', 'answer': 'monitor', 'question': 'Which object in this image has a video card?', 'img_file': 'ILSVRC2012_test_00020897.JPEG', 'kb_source': 'conceptnet', 'fact': ['video card', 'related to', 'monitor'], 'question_id': '1503'}, '2722': {'fact_surface': '[[a kitchen]] is for [[Cooking in]]', 'answer': 'kitchen', 'question': 'what kind of scene is shown in the image?', 'img_file': 'COCO_val2014_000000000802.jpg', 'kb_source': 'conceptnet', 'fact': ['kitchen', 'used for', 'cook in'], 'question_id': '1506'}, '2723': {'fact_surface': '[[a kitchenette]] is for [[preparing food]]', 'answer': 'prepare food', 'question': 'What is the place in this image used for?', 'img_file': 'COCO_val2014_000000000802.jpg', 'kb_source': 'conceptnet', 'fact': ['kitchenette', 'used for', 'prepare food'], 'question_id': '1504'}, '2724': {'fact_surface': 'You can use [[a kitchenette]] to [[serve breakfast]]', 'answer': 'breakfast', 'question': 'What can be served here?', 'img_file': 'COCO_val2014_000000000802.jpg', 'kb_source': 'conceptnet', 'fact': ['kitchenette', 'used for', 'breakfast'], 'question_id': '1505'}, '2725': {'fact_surface': '[[fruits]] belongs to the category of [[Developmental biology]]', 'answer': 'fruit', 'question': 'What in this image belongs to the category Developmental biology?', 'img_file': 'ILSVRC2012_test_00036186.JPEG', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'developmental biology'], 'question_id': '3085'}, '2726': {'fact_surface': '[[fruits]] belongs to the category of [[Pollination]]', 'answer': 'fruit', 'question': 'What object in this image belongs to the category Pollination?', 'img_file': 'ILSVRC2012_test_00036186.JPEG', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'pollination'], 'question_id': '3084'}, '2727': {'fact_surface': '[[fruits]] belongs to the category of [[Plant sexuality]]', 'answer': 'fruit', 'question': 'What in this image belongs to the category Plant sexuality?', 'img_file': 'ILSVRC2012_test_00036186.JPEG', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'plant sexuality'], 'question_id': '3087'}, '2728': {'fact_surface': '[[fruits]] belongs to the category of [[Environmental design]]', 'answer': 'fruit', 'question': 'What in this image belongs to the category Environmental design?', 'img_file': 'ILSVRC2012_test_00036186.JPEG', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'environmental design'], 'question_id': '3086'}, '2729': {'fact_surface': '[[fruits]] belongs to the category of [[Human sexuality]]', 'answer': 'fruit', 'question': 'what in this image belongs to the category Human sexuality?', 'img_file': 'ILSVRC2012_test_00036186.JPEG', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'human sexuality'], 'question_id': '3081'}, '2730': {'fact_surface': '[[fruits]] belongs to the category of [[Human sexuality]]', 'answer': 'fruit', 'question': 'What in this image belongs to the category Human sexuality?', 'img_file': 'ILSVRC2012_test_00036186.JPEG', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'human sexuality'], 'question_id': '3080'}, '2731': {'fact_surface': '[[fruits]] belongs to the category of [[Landscape]]', 'answer': 'fruit', 'question': 'What object in this image belongs to the category Landscape?', 'img_file': 'ILSVRC2012_test_00036186.JPEG', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'landscape'], 'question_id': '3083'}, '2732': {'fact_surface': '[[fruits]] belongs to the category of [[Outdoor recreation]]', 'answer': 'fruit', 'question': 'What in this image belongs to the category Outdoor recreation?', 'img_file': 'ILSVRC2012_test_00036186.JPEG', 'kb_source': 'dbpedia', 'fact': ['fruit', 'belong to', 'outdoor recreation'], 'question_id': '3082'}, '2733': {'fact_surface': '[[a wall]] is [[a vertical plane]]', 'answer': 'wall', 'question': 'What thing in this image is a vertical plane?', 'img_file': 'COCO_val2014_000000013300.jpg', 'kb_source': 'conceptnet', 'fact': ['wall', 'is a', 'vertical plane'], 'question_id': '3881'}, '2734': {'fact_surface': '[[vitamin E]] is related to [[plant]]', 'answer': 'plant', 'question': 'Which object in this image is related to vitamin e?', 'img_file': 'COCO_val2014_000000013300.jpg', 'kb_source': 'conceptnet', 'fact': ['vitamin e', 'related to', 'plant'], 'question_id': '3880'}, '2735': {'fact_surface': '[[potted plant]] belongs to the category of [[Environmental design]]', 'answer': 'potted plant', 'question': 'Which object in this image relates to Environmental design?', 'img_file': 'COCO_val2014_000000013300.jpg', 'kb_source': 'dbpedia', 'fact': ['potted plant', 'belong to', 'environmental design'], 'question_id': '3882'}, '2736': {'fact_surface': '[[orange]] is a kind of [[food]].', 'answer': 'orange', 'question': 'What food is in this image?', 'img_file': 'ILSVRC2012_test_00028372.JPEG', 'kb_source': 'conceptnet', 'fact': ['orange', 'is a', 'food'], 'question_id': '2484'}, '2737': {'fact_surface': '[[dining table]] belongs to the category of [[Furniture]]', 'answer': 'dining table', 'question': 'Which object in this image belongs to the category Furniture?', 'img_file': 'COCO_val2014_000000103496.jpg', 'kb_source': 'dbpedia', 'fact': ['dining table', 'belong to', 'furniture'], 'question_id': '1291'}, '2738': {'fact_surface': '[[person]] wants [[inner peace, health and happyness]]', 'answer': 'person', 'question': 'What thing shown here desires inner peace, health, and happiness?', 'img_file': 'ILSVRC2012_test_00025032.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'inner peace health and happyness'], 'question_id': '1296'}, '2739': {'fact_surface': '[[A bus]] is used to [[carry people]]', 'answer': 'bus', 'question': 'Which object in this image is capcable of carrying person?', 'img_file': 'COCO_val2014_000000024195.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'used for', 'carry person'], 'question_id': '3960'}, '2740': {'fact_surface': '[[A power drill]] is a type of [[tool]]', 'answer': 'power drill', 'question': 'Which object in this image is a tool?', 'img_file': 'ILSVRC2012_test_00025032.JPEG', 'kb_source': 'conceptnet', 'fact': ['power drill', 'is a', 'tool'], 'question_id': '1297'}, '2741': {'fact_surface': '[[wine]] belongs to the category of [[Food]]', 'answer': 'wine', 'question': 'Which object in this image belongs to the alcoholic drink?', 'img_file': 'COCO_val2014_000000111032.jpg', 'kb_source': 'dbpedia', 'fact': ['wine', 'belong to', 'food'], 'question_id': '3579'}, '2742': {'fact_surface': '[[ants]] are [[a pest]]', 'answer': 'ant', 'question': 'Which object in this image is a pest?', 'img_file': 'ILSVRC2012_test_00000196.JPEG', 'kb_source': 'conceptnet', 'fact': ['ant', 'is a', 'pet'], 'question_id': '3578'}, '2743': {'fact_surface': '[[bus]] is [[a form of public transportation]]', 'answer': 'bus', 'question': 'Which object in this image is a form of public transportation', 'img_file': 'COCO_val2014_000000109939.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'is a', 'form of public transportation'], 'question_id': '727'}, '2744': {'fact_surface': '[[The bridge]] can [[cross the river]]', 'answer': 'cross river', 'question': 'What is the place in this image capable of?', 'img_file': 'COCO_val2014_000000001268.jpg', 'kb_source': 'conceptnet', 'fact': ['bridge', 'capable of', 'cross river'], 'question_id': '5094'}, '2745': {'fact_surface': 'You are likely to find [[a printer]] in [[a home office]]', 'answer': 'printer', 'question': 'Which electronic device can be found in this place?', 'img_file': 'ILSVRC2012_test_00024563.JPEG', 'kb_source': 'conceptnet', 'fact': ['printer', 'at location', 'home office'], 'question_id': '5095'}, '2746': {'fact_surface': '[[horse]] is related to [[farm animal]]', 'answer': 'horse', 'question': 'Which animal in this image is related to farm animal?', 'img_file': 'COCO_val2014_000000110482.jpg', 'kb_source': 'conceptnet', 'fact': ['horse', 'related to', 'farm animal'], 'question_id': '5097'}, '2747': {'fact_surface': '[[vegetable soup]] is related to [[carrot]]', 'answer': 'carrot', 'question': 'which object in this image may be used in making the  vegetable soup', 'img_file': 'COCO_val2014_000000026611.jpg', 'kb_source': 'conceptnet', 'fact': ['vegetable soup', 'related to', 'carrot'], 'question_id': '4496'}, '2748': {'fact_surface': '[[carrot]] is a subclass of [[root]]', 'answer': 'carrot', 'question': 'Which object in this image is a root?', 'img_file': 'COCO_val2014_000000026611.jpg', 'kb_source': 'conceptnet', 'fact': ['carrot', 'is a', 'root'], 'question_id': '4495'}, '2749': {'fact_surface': '[[salad]] belongs to the category of [[Cold cut]]', 'answer': 'salad', 'question': 'What is the cold cut food in the image?', 'img_file': 'ILSVRC2012_test_00048410.JPEG', 'kb_source': 'dbpedia', 'fact': ['salad', 'belong to', 'cold cut'], 'question_id': '4494'}, '2750': {'fact_surface': '[[umbrellas]] can be used to [[keep people dry when it rains]]', 'answer': 'umbrella', 'question': 'Which object in this image is used to keep people dry when it rains?', 'img_file': 'COCO_val2014_000000020774.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'used for', 'keep person dry when it rain'], 'question_id': '4493'}, '2751': {'fact_surface': '[[An umbrella]] can [[shield one from rain or sun]]', 'answer': 'umbrella', 'question': 'Which object in this image can shield one from the rain or sun?', 'img_file': 'COCO_val2014_000000020774.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'capable of', 'shield one from rain or sun'], 'question_id': '4492'}, '2752': {'fact_surface': '[[rain]] can [[wet clothes]]', 'answer': 'rain', 'question': 'What will make the clothe wet in this image?', 'img_file': 'COCO_val2014_000000020774.jpg', 'kb_source': 'conceptnet', 'fact': ['rain', 'capable of', 'wet clothe'], 'question_id': '4491'}, '2753': {'fact_surface': '[[An umbrella]] is used to [[protect people from sun and rain]]', 'answer': 'umbrella', 'question': 'In the image, what is used for protecting person from sun and rain?', 'img_file': 'COCO_val2014_000000020774.jpg', 'kb_source': 'conceptnet', 'fact': ['umbrella', 'used for', 'protect person from sun and rain'], 'question_id': '4490'}, '2754': {'fact_surface': '[[elephant]] are bigger than [[mouse]]', 'answer': 'elephant', 'question': 'which object in this image is bigger than mouse?', 'img_file': 'COCO_val2014_000000102996.jpg', 'kb_source': 'webchild', 'fact': ['elephant', 'big', 'mouse'], 'question_id': '4499'}, '2755': {'fact_surface': 'A [[elephant]] is a [[big, gray animal with a trunk]]', 'answer': 'elephant', 'question': 'Which object in this image is a big gray animal with trunk?', 'img_file': 'COCO_val2014_000000102996.jpg', 'kb_source': 'conceptnet', 'fact': ['elephant', 'is a', 'big gray animal with trunk'], 'question_id': '4498'}, '2756': {'fact_surface': '[[pretzels]] are [[salty, knotted snacks]]', 'answer': 'pretzel', 'question': 'Which object in this image is a salty knotted snack?', 'img_file': 'ILSVRC2012_test_00031868.JPEG', 'kb_source': 'conceptnet', 'fact': ['pretzel', 'is a', 'salty knot snack'], 'question_id': '5326'}, '2757': {'fact_surface': '[[a person]] wants [[identity]]', 'answer': 'person', 'question': 'Which object in this image desires an identity?', 'img_file': 'ILSVRC2012_test_00031868.JPEG', 'kb_source': 'conceptnet', 'fact': ['person', 'desires', 'identity'], 'question_id': '5327'}, '2758': {'fact_surface': '[[pretzel]] belongs to the category of [[Food]]', 'answer': 'pretzel', 'question': 'which object in this image is a type of food?', 'img_file': 'ILSVRC2012_test_00031868.JPEG', 'kb_source': 'dbpedia', 'fact': ['pretzel', 'belong to', 'food'], 'question_id': '5328'}, '2759': {'fact_surface': '[[pretzel]] belongs to the category of [[Food and drink]]', 'answer': 'pretzel', 'question': 'which object in this image is a type of food or drink?', 'img_file': 'ILSVRC2012_test_00031868.JPEG', 'kb_source': 'dbpedia', 'fact': ['pretzel', 'belong to', 'food and drink'], 'question_id': '5329'}, '2760': {'fact_surface': '[[bike]] are slower than [[car]]', 'answer': 'car', 'question': 'which object in this image is faster than bike?', 'img_file': 'ILSVRC2012_test_00001769.JPEG', 'kb_source': 'webchild', 'fact': ['bike', 'slow', 'car'], 'question_id': '1396'}, '2761': {'fact_surface': '*Something you find in [[the closet]] is [[cup]]', 'answer': 'cup', 'question': 'Which object in this image can be found in closet?', 'img_file': 'COCO_val2014_000000105177.jpg', 'kb_source': 'conceptnet', 'fact': ['cup', 'at location', 'closet'], 'question_id': '1743'}, '2762': {'fact_surface': '[[cats]] are [[alive]]', 'answer': 'cat', 'question': 'Which thing in this image is alive?', 'img_file': 'COCO_val2014_000000009170.jpg', 'kb_source': 'conceptnet', 'fact': ['cat', 'has property', 'alive'], 'question_id': '3797'}, '2763': {'fact_surface': '[[traffic light]] can [[stop cars]]', 'answer': 'traffic light', 'question': 'Which object in this image can stop cars?', 'img_file': 'ILSVRC2012_test_00054478.JPEG', 'kb_source': 'conceptnet', 'fact': ['traffic light', 'capable of', 'stop car'], 'question_id': '1839'}, '2764': {'fact_surface': '[[Dogs]] like to [[interract with people]]', 'answer': 'dog', 'question': 'What in this image desires to interact with people?', 'img_file': 'ILSVRC2012_test_00053584.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'desires', 'interract with person'], 'question_id': '3164'}, '2765': {'fact_surface': '[[dogs]] are [[animals humans keep as pets]]', 'answer': 'dog', 'question': 'Which object in this image is a animal human keep as pet?', 'img_file': 'ILSVRC2012_test_00053584.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'is a', 'animal human keep as pet'], 'question_id': '3165'}, '2766': {'fact_surface': '[[snow]] is [[cold]]', 'answer': 'cold', 'question': 'How would you describe the place in this image?', 'img_file': 'COCO_val2014_000000016931.jpg', 'kb_source': 'conceptnet', 'fact': ['snow', 'has property', 'cold'], 'question_id': '4981'}, '2767': {'fact_surface': '[[Giraffes]] have [[bones in their necks]]', 'answer': 'giraffe', 'question': 'Which animal in this image has bones in their long neck?', 'img_file': 'COCO_val2014_000000132814.jpg', 'kb_source': 'conceptnet', 'fact': ['giraffe', 'has a', 'bone in their neck'], 'question_id': '4980'}, '2768': {'fact_surface': '[[Snow]] has [[a white colour]]', 'answer': 'white', 'question': 'What colour is the stuff covering the car?', 'img_file': 'COCO_val2014_000000016931.jpg', 'kb_source': 'conceptnet', 'fact': ['snow', 'has a', 'white'], 'question_id': '4983'}, '2769': {'fact_surface': '[[carrot]] is a subclass of [[root]]', 'answer': 'root', 'question': 'Which part of the food can be eaten?', 'img_file': 'COCO_val2014_000000026611.jpg', 'kb_source': 'conceptnet', 'fact': ['carrot', 'is a', 'root'], 'question_id': '733'}, '2770': {'fact_surface': '[[Dogs]] can be [[trained to catch]]', 'answer': 'dog', 'question': 'Which animal in the image can be trained to catch?', 'img_file': 'COCO_val2014_000000138204.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'receives action', 'train to catch'], 'question_id': '735'}, '2771': {'fact_surface': '[[lamp]] is related to [[bright]]', 'answer': 'lamp', 'question': 'what object in this image produces light?', 'img_file': 'ILSVRC2012_test_00010098.JPEG', 'kb_source': 'conceptnet', 'fact': ['lamp', 'related to', 'bright'], 'question_id': '734'}, '2772': {'fact_surface': '[[teddy bear]] is a subclass of [[stuffed animal]]', 'answer': 'teddy bear', 'question': 'what object in this image is a stuffed animal?', 'img_file': 'COCO_val2014_000000009262.jpg', 'kb_source': 'conceptnet', 'fact': ['teddy bear', 'is a', 'stuff animal'], 'question_id': '737'}, '2773': {'fact_surface': '[[a tv]] can be used for [[entertainment]]', 'answer': 'tv', 'question': 'What thing in the image can be used for entertainment?', 'img_file': 'COCO_val2014_000000000139.jpg', 'kb_source': 'conceptnet', 'fact': ['tv', 'used for', 'entertainment'], 'question_id': '739'}, '2774': {'fact_surface': '[[vegetables]] belongs to the category of [[Plants]]', 'answer': 'vegetable', 'question': 'What category of plants is shown in this image?', 'img_file': 'COCO_val2014_000000007991.jpg', 'kb_source': 'dbpedia', 'fact': ['vegetable', 'belong to', 'plant'], 'question_id': '2151'}, '2775': {'fact_surface': '[[Carrots]] are [[only one kind of root vegetables]]', 'answer': 'carrot', 'question': 'Which object in this image is a kind of root vegetable?', 'img_file': 'ILSVRC2012_test_00003419.JPEG', 'kb_source': 'conceptnet', 'fact': ['carrot', 'has property', 'only one kind of root vegetable'], 'question_id': '2152'}, '2776': {'fact_surface': '[[a cup]] can [[store liquid]]', 'answer': 'cup', 'question': 'What is used to store liquid?', 'img_file': 'COCO_val2014_000000146489.jpg', 'kb_source': 'conceptnet', 'fact': ['cup', 'capable of', 'store liquid'], 'question_id': '2401'}, '2777': {'fact_surface': '[[snowmobile]] belongs to the category of [[Automotive technologies]]', 'answer': 'snowmobile', 'question': 'Which object in this image is a kind of Automotive technologies?', 'img_file': 'ILSVRC2012_test_00004836.JPEG', 'kb_source': 'dbpedia', 'fact': ['snowmobile', 'belong to', 'automotive technologies'], 'question_id': '2008'}, '2778': {'fact_surface': 'You are likely to find [[a kite]] in [[the sky]]', 'answer': 'kite', 'question': 'Which object in this image can be found in the sky?', 'img_file': 'COCO_val2014_000000114634.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'at location', 'sky'], 'question_id': '4707'}, '2779': {'fact_surface': '[[kite]] is related to [[soar]]', 'answer': 'kite', 'question': 'Which object in this image can soar?', 'img_file': 'COCO_val2014_000000114634.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'related to', 'oar'], 'question_id': '4706'}, '2780': {'fact_surface': '[[An apple]] is [[a healthy treat]]', 'answer': 'apple', 'question': 'Which object in this image is a healthy treat?', 'img_file': 'COCO_val2014_000000102641.jpg', 'kb_source': 'conceptnet', 'fact': ['apple', 'is a', 'healthy treat'], 'question_id': '4705'}, '2781': {'fact_surface': '[[remote]] belongs to the category of [[Human machine interaction]]', 'answer': 'remote', 'question': 'Which object in this image is for human-machine interaction?', 'img_file': 'COCO_val2014_000000102641.jpg', 'kb_source': 'dbpedia', 'fact': ['remote', 'belong to', 'Category:Human machine interaction'], 'question_id': '4704'}, '2782': {'fact_surface': '[[apples]] are [[a sweet, juicy fruit]]', 'answer': 'apple', 'question': 'What is the sweet, juicy object in this image?', 'img_file': 'COCO_val2014_000000102641.jpg', 'kb_source': 'conceptnet', 'fact': ['apple', 'is a', 'sweet juicy fruit'], 'question_id': '4703'}, '2783': {'fact_surface': '[[apple]] belongs to the category of [[Plant]]', 'answer': 'apple', 'question': 'Which of the objects in this image comes from a plant?', 'img_file': 'COCO_val2014_000000102641.jpg', 'kb_source': 'dbpedia', 'fact': ['apple', 'belong to', 'plant'], 'question_id': '4702'}, '2784': {'fact_surface': '[[monitor]] is used to [[show information]].', 'answer': 'monitor', 'question': 'Which object in this image is used to show information?', 'img_file': 'ILSVRC2012_test_00055362.JPEG', 'kb_source': 'conceptnet', 'fact': ['monitor', 'used for', 'show information'], 'question_id': '2325'}, '2785': {'fact_surface': '[[a remote]] is used for [[controlling a tv]].', 'answer': 'control tv', 'question': 'What is the object in the bottom left of this image used for?', 'img_file': 'COCO_val2014_000000102641.jpg', 'kb_source': 'conceptnet', 'fact': ['remote', 'used for', 'control tv'], 'question_id': '4700'}, '2786': {'fact_surface': '*Something you find at [[the end of a line]] is [[a kite]]', 'answer': 'kite', 'question': 'which object can we find at the end of the line in this image', 'img_file': 'COCO_val2014_000000114634.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'at location', 'end of line'], 'question_id': '4709'}, '2787': {'fact_surface': '[[a kite]] can [[fly]]', 'answer': 'kite', 'question': 'Which object in this image can fly?', 'img_file': 'COCO_val2014_000000114634.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'capable of', 'fly'], 'question_id': '4708'}, '2788': {'fact_surface': \"You are likely to find [[a banana]] in [[a monkey's hand]]\", 'answer': 'banana', 'question': \"Which object shown in this image can be found in a monkey's hand?\", 'img_file': 'COCO_val2014_000000003703.jpg', 'kb_source': 'conceptnet', 'fact': ['banana', 'at location', \"monkey's hand\"], 'question_id': '3761'}, '2789': {'fact_surface': '[[bananas]] are [[yellow with small brown spots when ripe]]', 'answer': 'banana', 'question': 'Which object in this image is yellow with small brown spots?', 'img_file': 'COCO_val2014_000000003703.jpg', 'kb_source': 'conceptnet', 'fact': ['banana', 'has property', 'yellow with small brown spot when ripe'], 'question_id': '3762'}, '2790': {'fact_surface': 'You can use [[a sofa]] to [[sleep on]]', 'answer': 'sofa', 'question': 'Which object in this image can be used for sleeping on?', 'img_file': 'COCO_val2014_000000153685.jpg', 'kb_source': 'conceptnet', 'fact': ['sofa', 'used for', 'sleep on'], 'question_id': '3763'}, '2791': {'fact_surface': 'You are likely to find [[a place to eat]] in [[a food court]]', 'answer': 'food', 'question': 'What can be found in this place?', 'img_file': 'COCO_val2014_000000154193.jpg', 'kb_source': 'conceptnet', 'fact': ['place to eat', 'at location', 'food'], 'question_id': '3764'}, '2792': {'fact_surface': '[[pizza]] is a subclass of [[finger food]]', 'answer': 'pizza', 'question': 'Which object in this image is a kind of finger food?', 'img_file': 'COCO_val2014_000000154193.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'is a', 'finger food'], 'question_id': '3765'}, '2793': {'fact_surface': '[[a dog]] can [[smell drugs]]', 'answer': 'dog', 'question': 'Which object in this image is capable of smell drug?', 'img_file': 'COCO_val2014_000000147259.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'capable of', 'smell drug'], 'question_id': '3767'}, '2794': {'fact_surface': '[[pillows]] belongs to the category of [[Bedding]]', 'answer': 'pillows', 'question': 'Which object in this image can be classified into Bedding?', 'img_file': 'COCO_val2014_000000005816.jpg', 'kb_source': 'dbpedia', 'fact': ['pillows', 'belong to', 'bedding'], 'question_id': '3769'}, '2795': {'fact_surface': '[[a fork]] can be used to [[eat a steak]]', 'answer': 'fork', 'question': 'Which object in this image is used for eat steak?', 'img_file': 'COCO_val2014_000000103496.jpg', 'kb_source': 'conceptnet', 'fact': ['fork', 'used for', 'eat steak'], 'question_id': '1292'}, '2796': {'fact_surface': '[[a dog]] can have [[a name]]', 'answer': 'dog', 'question': 'Which object in this image has a name', 'img_file': 'ILSVRC2012_test_00018599.JPEG', 'kb_source': 'conceptnet', 'fact': ['dog', 'has a', 'name'], 'question_id': '1792'}, '2797': {'fact_surface': '[[plates]] belongs to the category of [[Serving and dining]]', 'answer': 'plate', 'question': \"What's one thing in this image belonging to the category of Serving and dining?\", 'img_file': 'COCO_val2014_000000103496.jpg', 'kb_source': 'dbpedia', 'fact': ['plate', 'belong to', 'serving and dining'], 'question_id': '1293'}, '2798': {'fact_surface': '[[cake]] belongs to the category of [[Baked goods]]', 'answer': 'cake', 'question': 'Which object in this image belongs to the category Baked goods?', 'img_file': 'COCO_val2014_000000103496.jpg', 'kb_source': 'dbpedia', 'fact': ['cake', 'belong to', 'baked goods'], 'question_id': '1290'}, '2799': {'fact_surface': '[[computer]] are more accurate than [[human]]', 'answer': 'computer', 'question': 'which object in this image can give more accurate results than that from human', 'img_file': 'ILSVRC2012_test_00006421.JPEG', 'kb_source': 'webchild', 'fact': ['computer', 'accurate', 'human'], 'question_id': '4648'}, '2800': {'fact_surface': '[[pizza]] is a subclass of [[hot food or drink]]', 'answer': 'pizza', 'question': 'Which object in this image is a hot food or drink?', 'img_file': 'COCO_val2014_000000027493.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'is a', 'hot food or drink'], 'question_id': '1563'}, '2801': {'fact_surface': '[[frisbee]] belongs to the category of [[Sport]]', 'answer': 'frisbee', 'question': 'Which sporting item do you see in this image?', 'img_file': 'COCO_val2014_000000005728.jpg', 'kb_source': 'dbpedia', 'fact': ['frisbee', 'belong to', 'sport'], 'question_id': '4646'}, '2802': {'fact_surface': '[[hotdog]] belongs to the category of [[Fast food]]', 'answer': 'hotdog', 'question': 'Which fast food in this image contains meat?', 'img_file': 'COCO_val2014_000000134223.jpg', 'kb_source': 'dbpedia', 'fact': ['hotdog', 'belong to', 'fast food'], 'question_id': '4647'}, '2803': {'fact_surface': '[[a fork]] is for [[lifting food]].', 'answer': 'fork', 'question': 'Which object in this image is used for lift food?', 'img_file': 'COCO_val2014_000000115776.jpg', 'kb_source': 'conceptnet', 'fact': ['fork', 'used for', 'lift food'], 'question_id': '5159'}, '2804': {'fact_surface': 'You are likely to find [[coffee]] in [[a coffee shop]].', 'answer': 'coffee', 'question': 'What is likely to be found in this place?', 'img_file': 'COCO_val2014_000000115776.jpg', 'kb_source': 'conceptnet', 'fact': ['coffee', 'at location', 'coffee shop'], 'question_id': '5158'}, '2805': {'fact_surface': '[[kite]] is related to [[child]]', 'answer': 'child', 'question': 'Who likes to play this game?', 'img_file': 'COCO_val2014_000000012543.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'related to', 'child'], 'question_id': '117'}, '2806': {'fact_surface': '[[a kite]] can [[fly]]', 'answer': 'kite', 'question': 'Which object in this image can fly?', 'img_file': 'COCO_val2014_000000012543.jpg', 'kb_source': 'conceptnet', 'fact': ['kite', 'capable of', 'fly'], 'question_id': '116'}, '2807': {'fact_surface': '*Something you find in [[the kitchen]] is [[a can opener]]', 'answer': 'kitchen', 'question': 'Where can you find the object in this image?', 'img_file': 'ILSVRC2012_test_00057349.JPEG', 'kb_source': 'conceptnet', 'fact': ['can opener', 'at location', 'kitchen'], 'question_id': '111'}, '2808': {'fact_surface': 'You can use [[a can opener]] to [[open a can]].', 'answer': 'open can', 'question': 'What thing can the objects in this image do?', 'img_file': 'ILSVRC2012_test_00057349.JPEG', 'kb_source': 'conceptnet', 'fact': ['can opener', 'used for', 'open can'], 'question_id': '110'}, '2809': {'fact_surface': '[[Can openers]] can [[open cans]]', 'answer': 'open can', 'question': 'What can the object in this image do', 'img_file': 'ILSVRC2012_test_00057349.JPEG', 'kb_source': 'conceptnet', 'fact': ['can opener', 'capable of', 'open can'], 'question_id': '112'}, '2810': {'fact_surface': '[[A banjo]] is [[a stringed instrumetn]]', 'answer': 'banjo', 'question': 'Which object in this image is a stringed instrument?', 'img_file': 'ILSVRC2012_test_00028677.JPEG', 'kb_source': 'conceptnet', 'fact': ['banjo', 'is a', 'string instrumetn'], 'question_id': '3244'}, '2811': {'fact_surface': 'A [[bus]] is a [[form of mass transit]]', 'answer': 'bus', 'question': 'What object in this image can be used to transport a large number of people?', 'img_file': 'COCO_val2014_000000106508.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'is a', 'form of mass transit'], 'question_id': '1748'}, '2812': {'fact_surface': '[[A bus]] is [[good city transportation]]', 'answer': 'bus', 'question': 'Which object in this image is a good city transportation?', 'img_file': 'COCO_val2014_000000106508.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'is a', 'good city transportation'], 'question_id': '1749'}, '2813': {'fact_surface': '[[A boat]] can [[sail on a pond]]', 'answer': 'boat', 'question': 'Which object in this image might sail on a pond?', 'img_file': 'COCO_val2014_000000113294.jpg', 'kb_source': 'conceptnet', 'fact': ['boat', 'capable of', 'sail on pond'], 'question_id': '1744'}, '2814': {'fact_surface': 'A [[bus]] is a [[form of mass transit]]', 'answer': 'bus', 'question': 'What object in this image can be used to transport a large number of people?', 'img_file': 'COCO_val2014_000000106508.jpg', 'kb_source': 'conceptnet', 'fact': ['bus', 'is a', 'form of mass transit'], 'question_id': '1747'}, '2815': {'fact_surface': '[[dogs]] are [[hairy]]', 'answer': 'dog', 'question': 'What in this image is hairy?', 'img_file': 'COCO_val2014_000000100196.jpg', 'kb_source': 'conceptnet', 'fact': ['dog', 'has property', 'hairy'], 'question_id': '1486'}, '2816': {'fact_surface': '[[carrots]] are [[a vegetable]]', 'answer': 'carrot', 'question': 'Which object in this image is a vegetable?', 'img_file': 'COCO_val2014_000000107108.jpg', 'kb_source': 'conceptnet', 'fact': ['carrot', 'is a', 'vegetable'], 'question_id': '1560'}, '2817': {'fact_surface': '[[carrots]] are [[long, thin, and orage]]', 'answer': 'carrot', 'question': 'Which object in this image is long, thin and orange?', 'img_file': 'COCO_val2014_000000107108.jpg', 'kb_source': 'conceptnet', 'fact': ['carrot', 'is a', 'long thin and orage'], 'question_id': '1561'}, '2818': {'fact_surface': '[[pizza]] belongs to the category of [[Foods]]', 'answer': 'pizza', 'question': 'Which object in this image belongs to the category Foods?', 'img_file': 'COCO_val2014_000000027493.jpg', 'kb_source': 'dbpedia', 'fact': ['pizza', 'belong to', 'food'], 'question_id': '1562'}, '2819': {'fact_surface': '[[pizza]] is [[a good food]]', 'answer': 'pizza', 'question': 'Which object in this image is a good food?', 'img_file': 'COCO_val2014_000000027493.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'is a', 'good food'], 'question_id': '1564'}, '2820': {'fact_surface': '[[Pizza]] is usually [[cut into slices]]', 'answer': 'pizza', 'question': 'Which object in this image has the property of cut into slice?', 'img_file': 'COCO_val2014_000000027493.jpg', 'kb_source': 'conceptnet', 'fact': ['pizza', 'has property', 'cut into slice'], 'question_id': '1565'}, '2821': {'fact_surface': 'You are likely to find [[Turtles]] in [[an ocean]].', 'answer': 'turtle', 'question': 'What in the image is often encountered in the ocean?', 'img_file': 'ILSVRC2012_test_00002369.JPEG', 'kb_source': 'conceptnet', 'fact': ['turtle', 'at location', 'ocean'], 'question_id': '5630'}, '2822': {'fact_surface': '[[turtle]] has [[a shell]]', 'answer': 'turtle', 'question': 'Which object in the image has a hard shell?', 'img_file': 'ILSVRC2012_test_00002369.JPEG', 'kb_source': 'conceptnet', 'fact': ['turtle', 'part of', 'shell'], 'question_id': '5631'}}\n"
     ]
    }
   ],
   "source": [
    "import os,json\n",
    "\n",
    "with open('/ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/test_data/test3/all_qs_dict_release_test_500.json','r')as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "temp = {}\n",
    "    \n",
    "i = 0\n",
    "for key,value in data.items():\n",
    "    temp[str(i)] = value\n",
    "    i += 1\n",
    "    \n",
    "print(temp)\n",
    "\n",
    "with open('/ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/test_data/test3/all_qs_dict_release_test_500_order.json','w')as f:\n",
    "    json.dump(temp,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26060197",
   "metadata": {},
   "source": [
    "# AGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d470f591",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-28T03:02:29.083Z"
    }
   },
   "outputs": [],
   "source": [
    "# relation 训练 agcn  \n",
    "%cd code\n",
    "!python main_agcn.py --gpu_id 5 --exp_name fact_space --exp_id agcn --fusion_model AGCN --data_choice 5 --method_choice W2V  --save_model 0 --ZSL 0 --now_test 0 --fact_map 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98c97d5",
   "metadata": {},
   "source": [
    "# 分析实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a75bf432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-14T16:09:39.757573Z",
     "start_time": "2023-01-14T15:06:24.681909Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 01/14/23 23:06:27 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 01/14/23 23:06:27 - 0:00:00 - The experiment will be stored in dump/0114-MLP_knowledge_space/W2V\n",
      "                                     \n",
      "INFO - 01/14/23 23:06:27 - 0:00:00 - Running command: python main_relation.py --gpu_id 8 --exp_name MLP_knowledge_space --exp_id W2V --fusion_model MLPQ --data_choice 3 --method_choice W2V --ZSL 0 --save_model 1 --fact_map 1\n",
      "\n",
      "2023-01-14 23:06:29.558260: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-14 23:06:29.558328: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 16\n",
      "batch_size 16\n",
      "fusion_model:\n",
      "MLPQ(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      "  (w_emb): WordEmbedding(\n",
      "    (emb): Embedding(15422, 300, padding_idx=15421)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (text): Seq2SeqRNN(\n",
      "    (rnn): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  )\n",
      ")\n",
      "Answer Model:\n",
      "MLP(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "train E000: 100% 167/167 [00:34<00:00,  4.91it/s]\n",
      "INFO - 01/14/23 23:07:24 - 0:00:56 - Train Epoch 0: LOSS= 7.29813, lr= 0.000500, acc1= 20.64,acc3= 30.57,acc10= 36.64\n",
      "train E001: 100% 167/167 [00:33<00:00,  5.05it/s]\n",
      "INFO - 01/14/23 23:07:57 - 0:01:29 - Train Epoch 1: LOSS= 4.62714, lr= 0.000750, acc1= 52.30,acc3= 65.46,acc10= 70.66\n",
      "eval E001: 100% 177/177 [00:30<00:00,  5.86it/s]\n",
      "INFO - 01/14/23 23:08:27 - 0:02:00 - #################################################################################################################\n",
      "INFO - 01/14/23 23:08:27 - 0:02:00 - Test Epoch 1: LOSS= 4.13974, acc1= 61.32, acc3= 70.88, acc10= 74.67\n",
      "INFO - 01/14/23 23:08:27 - 0:02:00 - #################################################################################################################\n",
      "train E002: 100% 167/167 [00:33<00:00,  4.95it/s]\n",
      "INFO - 01/14/23 23:09:01 - 0:02:33 - Train Epoch 2: LOSS= 3.69660, lr= 0.001000, acc1= 65.87,acc3= 76.17,acc10= 80.33\n",
      "eval E002: 100% 177/177 [00:30<00:00,  5.80it/s]\n",
      "INFO - 01/14/23 23:09:31 - 0:03:04 - #################################################################################################################\n",
      "INFO - 01/14/23 23:09:31 - 0:03:04 - Test Epoch 2: LOSS= 3.80299, acc1= 66.45, acc3= 74.74, acc10= 78.36\n",
      "INFO - 01/14/23 23:09:31 - 0:03:04 - #################################################################################################################\n",
      "train E003: 100% 167/167 [00:33<00:00,  5.00it/s]\n",
      "INFO - 01/14/23 23:10:05 - 0:03:37 - Train Epoch 3: LOSS= 3.41347, lr= 0.001250, acc1= 69.35,acc3= 79.09,acc10= 82.09\n",
      "eval E003: 100% 177/177 [00:29<00:00,  6.05it/s]\n",
      "INFO - 01/14/23 23:10:34 - 0:04:07 - #################################################################################################################\n",
      "INFO - 01/14/23 23:10:34 - 0:04:07 - Test Epoch 3: LOSS= 4.04010, acc1= 63.12, acc3= 72.16, acc10= 75.70\n",
      "INFO - 01/14/23 23:10:34 - 0:04:07 - #################################################################################################################\n",
      "train E004: 100% 167/167 [00:34<00:00,  4.87it/s]\n",
      "INFO - 01/14/23 23:11:08 - 0:04:41 - Train Epoch 4: LOSS= 3.27621, lr= 0.001500, acc1= 70.93,acc3= 79.88,acc10= 83.21\n",
      "eval E004: 100% 177/177 [00:31<00:00,  5.70it/s]\n",
      "INFO - 01/14/23 23:11:39 - 0:05:12 - #################################################################################################################\n",
      "INFO - 01/14/23 23:11:39 - 0:05:12 - Test Epoch 4: LOSS= 4.11078, acc1= 65.43, acc3= 73.72, acc10= 77.19\n",
      "INFO - 01/14/23 23:11:39 - 0:05:12 - #################################################################################################################\n",
      "train E005: 100% 167/167 [00:34<00:00,  4.84it/s]\n",
      "INFO - 01/14/23 23:12:14 - 0:05:47 - Train Epoch 5: LOSS= 3.33711, lr= 0.001750, acc1= 71.19,acc3= 80.63,acc10= 83.74\n",
      "eval E005: 100% 177/177 [00:31<00:00,  5.64it/s]\n",
      "INFO - 01/14/23 23:12:45 - 0:06:18 - #################################################################################################################\n",
      "INFO - 01/14/23 23:12:45 - 0:06:18 - Test Epoch 5: LOSS= 4.08295, acc1= 66.49, acc3= 75.35, acc10= 78.43\n",
      "INFO - 01/14/23 23:12:45 - 0:06:18 - #################################################################################################################\n",
      "train E006: 100% 167/167 [00:32<00:00,  5.17it/s]\n",
      "INFO - 01/14/23 23:13:17 - 0:06:50 - Train Epoch 6: LOSS= 3.49944, lr= 0.002000, acc1= 70.21,acc3= 79.62,acc10= 83.81\n",
      "eval E006: 100% 177/177 [00:10<00:00, 17.02it/s]\n",
      "INFO - 01/14/23 23:13:28 - 0:07:01 - #################################################################################################################\n",
      "INFO - 01/14/23 23:13:28 - 0:07:01 - Test Epoch 6: LOSS= 4.18980, acc1= 65.85, acc3= 75.95, acc10= 78.29\n",
      "INFO - 01/14/23 23:13:28 - 0:07:01 - #################################################################################################################\n",
      "train E007: 100% 167/167 [00:16<00:00, 10.33it/s]\n",
      "INFO - 01/14/23 23:13:44 - 0:07:17 - Train Epoch 7: LOSS= 3.18691, lr= 0.002000, acc1= 73.85,acc3= 82.20,acc10= 85.50\n",
      "eval E007: 100% 177/177 [00:10<00:00, 17.43it/s]\n",
      "INFO - 01/14/23 23:13:54 - 0:07:27 - #################################################################################################################\n",
      "INFO - 01/14/23 23:13:54 - 0:07:27 - Test Epoch 7: LOSS= 3.97768, acc1= 68.26, acc3= 77.47, acc10= 80.77\n",
      "INFO - 01/14/23 23:13:54 - 0:07:27 - #################################################################################################################\n",
      "train E008: 100% 167/167 [00:16<00:00, 10.38it/s]\n",
      "INFO - 01/14/23 23:14:10 - 0:07:43 - Train Epoch 8: LOSS= 3.02140, lr= 0.002000, acc1= 76.10,acc3= 84.15,acc10= 87.79\n",
      "eval E008: 100% 177/177 [00:10<00:00, 16.46it/s]\n",
      "INFO - 01/14/23 23:14:21 - 0:07:54 - #################################################################################################################\n",
      "INFO - 01/14/23 23:14:21 - 0:07:54 - Test Epoch 8: LOSS= 4.11411, acc1= 66.99, acc3= 75.35, acc10= 78.85\n",
      "INFO - 01/14/23 23:14:21 - 0:07:54 - #################################################################################################################\n",
      "train E009: 100% 167/167 [00:15<00:00, 10.45it/s]\n",
      "INFO - 01/14/23 23:14:37 - 0:08:10 - Train Epoch 9: LOSS= 2.74915, lr= 0.002000, acc1= 78.83,acc3= 86.32,acc10= 88.98\n",
      "eval E009: 100% 177/177 [00:10<00:00, 17.06it/s]\n",
      "INFO - 01/14/23 23:14:47 - 0:08:20 - #################################################################################################################\n",
      "INFO - 01/14/23 23:14:47 - 0:08:20 - Test Epoch 9: LOSS= 4.20479, acc1= 68.33, acc3= 76.87, acc10= 80.13\n",
      "INFO - 01/14/23 23:14:47 - 0:08:20 - #################################################################################################################\n",
      "train E010: 100% 167/167 [00:15<00:00, 10.61it/s]\n",
      "INFO - 01/14/23 23:15:03 - 0:08:36 - Train Epoch 10: LOSS= 2.65365, lr= 0.002000, acc1= 79.88,acc3= 87.49,acc10= 89.92\n",
      "eval E010: 100% 177/177 [00:10<00:00, 17.02it/s]\n",
      "INFO - 01/14/23 23:15:14 - 0:08:46 - #################################################################################################################\n",
      "INFO - 01/14/23 23:15:14 - 0:08:46 - Test Epoch 10: LOSS= 4.15603, acc1= 69.18, acc3= 76.73, acc10= 79.63\n",
      "INFO - 01/14/23 23:15:14 - 0:08:46 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E011: 100% 167/167 [00:16<00:00, 10.22it/s]\n",
      "INFO - 01/14/23 23:15:30 - 0:09:03 - Train Epoch 11: LOSS= 2.54338, lr= 0.002000, acc1= 81.38,acc3= 87.94,acc10= 90.67\n",
      "eval E011: 100% 177/177 [00:10<00:00, 16.60it/s]\n",
      "INFO - 01/14/23 23:15:41 - 0:09:13 - #################################################################################################################\n",
      "INFO - 01/14/23 23:15:41 - 0:09:13 - Test Epoch 11: LOSS= 4.46066, acc1= 66.35, acc3= 76.20, acc10= 79.06\n",
      "INFO - 01/14/23 23:15:41 - 0:09:13 - #################################################################################################################\n",
      "train E012: 100% 167/167 [00:15<00:00, 10.69it/s]\n",
      "INFO - 01/14/23 23:15:56 - 0:09:29 - Train Epoch 12: LOSS= 2.36308, lr= 0.002000, acc1= 82.95,acc3= 89.58,acc10= 91.64\n",
      "eval E012: 100% 177/177 [00:10<00:00, 17.38it/s]\n",
      "INFO - 01/14/23 23:16:06 - 0:09:39 - #################################################################################################################\n",
      "INFO - 01/14/23 23:16:06 - 0:09:39 - Test Epoch 12: LOSS= 4.23443, acc1= 68.83, acc3= 77.47, acc10= 80.55\n",
      "INFO - 01/14/23 23:16:06 - 0:09:39 - #################################################################################################################\n",
      "train E013: 100% 167/167 [00:15<00:00, 10.46it/s]\n",
      "INFO - 01/14/23 23:16:22 - 0:09:55 - Train Epoch 13: LOSS= 2.27996, lr= 0.002000, acc1= 84.34,acc3= 89.62,acc10= 91.87\n",
      "eval E013: 100% 177/177 [00:10<00:00, 17.14it/s]\n",
      "INFO - 01/14/23 23:16:33 - 0:10:05 - #################################################################################################################\n",
      "INFO - 01/14/23 23:16:33 - 0:10:05 - Test Epoch 13: LOSS= 4.59271, acc1= 68.76, acc3= 76.41, acc10= 79.17\n",
      "INFO - 01/14/23 23:16:33 - 0:10:05 - #################################################################################################################\n",
      "train E014: 100% 167/167 [00:15<00:00, 10.70it/s]\n",
      "INFO - 01/14/23 23:16:48 - 0:10:21 - Train Epoch 14: LOSS= 1.90808, lr= 0.001400, acc1= 88.12,acc3= 92.58,acc10= 94.27\n",
      "eval E014: 100% 177/177 [00:10<00:00, 17.01it/s]\n",
      "INFO - 01/14/23 23:16:59 - 0:10:32 - #################################################################################################################\n",
      "INFO - 01/14/23 23:16:59 - 0:10:32 - Test Epoch 14: LOSS= 4.27307, acc1= 70.35, acc3= 78.25, acc10= 81.15\n",
      "INFO - 01/14/23 23:16:59 - 0:10:32 - #################################################################################################################\n",
      "train E015: 100% 167/167 [00:15<00:00, 10.52it/s]\n",
      "INFO - 01/14/23 23:17:15 - 0:10:47 - Train Epoch 15: LOSS= 1.55136, lr= 0.001400, acc1= 90.30,acc3= 94.45,acc10= 95.88\n",
      "eval E015: 100% 177/177 [00:10<00:00, 17.44it/s]\n",
      "INFO - 01/14/23 23:17:25 - 0:10:58 - #################################################################################################################\n",
      "INFO - 01/14/23 23:17:25 - 0:10:58 - Test Epoch 15: LOSS= 4.46068, acc1= 71.13, acc3= 78.71, acc10= 81.83\n",
      "INFO - 01/14/23 23:17:25 - 0:10:58 - #################################################################################################################\n",
      "train E016: 100% 167/167 [00:16<00:00, 10.26it/s]\n",
      "INFO - 01/14/23 23:17:41 - 0:11:14 - Train Epoch 16: LOSS= 1.35523, lr= 0.001400, acc1= 90.90,acc3= 95.05,acc10= 96.37\n",
      "eval E016: 100% 177/177 [00:10<00:00, 17.12it/s]\n",
      "INFO - 01/14/23 23:17:51 - 0:11:24 - #################################################################################################################\n",
      "INFO - 01/14/23 23:17:51 - 0:11:24 - Test Epoch 16: LOSS= 4.48418, acc1= 72.33, acc3= 79.81, acc10= 81.76\n",
      "INFO - 01/14/23 23:17:51 - 0:11:24 - #################################################################################################################\n",
      "train E017: 100% 167/167 [00:15<00:00, 10.57it/s]\n",
      "INFO - 01/14/23 23:18:07 - 0:11:40 - Train Epoch 17: LOSS= 1.08543, lr= 0.000980, acc1= 92.84,acc3= 96.14,acc10= 97.38\n",
      "eval E017: 100% 177/177 [00:10<00:00, 17.40it/s]\n",
      "INFO - 01/14/23 23:18:17 - 0:11:50 - #################################################################################################################\n",
      "INFO - 01/14/23 23:18:17 - 0:11:50 - Test Epoch 17: LOSS= 4.69409, acc1= 72.72, acc3= 80.13, acc10= 82.47\n",
      "INFO - 01/14/23 23:18:17 - 0:11:50 - #################################################################################################################\n",
      "train E018: 100% 167/167 [00:15<00:00, 10.78it/s]\n",
      "INFO - 01/14/23 23:18:33 - 0:12:06 - Train Epoch 18: LOSS= 1.02135, lr= 0.000980, acc1= 93.44,acc3= 96.55,acc10= 97.79\n",
      "eval E018: 100% 177/177 [00:10<00:00, 17.49it/s]\n",
      "INFO - 01/14/23 23:18:43 - 0:12:16 - #################################################################################################################\n",
      "INFO - 01/14/23 23:18:43 - 0:12:16 - Test Epoch 18: LOSS= 4.74821, acc1= 73.47, acc3= 79.53, acc10= 82.86\n",
      "INFO - 01/14/23 23:18:43 - 0:12:16 - #################################################################################################################\n",
      "train E019: 100% 167/167 [00:16<00:00, 10.39it/s]\n",
      "INFO - 01/14/23 23:18:59 - 0:12:32 - Train Epoch 19: LOSS= 0.93988, lr= 0.000980, acc1= 94.23,acc3= 97.08,acc10= 98.01\n",
      "eval E019: 100% 177/177 [00:11<00:00, 16.07it/s]\n",
      "INFO - 01/14/23 23:19:10 - 0:12:43 - #################################################################################################################\n",
      "INFO - 01/14/23 23:19:10 - 0:12:43 - Test Epoch 19: LOSS= 4.73452, acc1= 73.26, acc3= 80.20, acc10= 83.28\n",
      "INFO - 01/14/23 23:19:10 - 0:12:43 - #################################################################################################################\n",
      "train E020: 100% 167/167 [00:16<00:00, 10.33it/s]\n",
      "INFO - 01/14/23 23:19:26 - 0:12:59 - Train Epoch 20: LOSS= 0.77953, lr= 0.000686, acc1= 95.24,acc3= 98.39,acc10= 99.03\n",
      "eval E020: 100% 177/177 [00:10<00:00, 17.36it/s]\n",
      "INFO - 01/14/23 23:19:36 - 0:13:09 - #################################################################################################################\n",
      "INFO - 01/14/23 23:19:36 - 0:13:09 - Test Epoch 20: LOSS= 4.83651, acc1= 73.18, acc3= 80.34, acc10= 83.00\n",
      "INFO - 01/14/23 23:19:36 - 0:13:09 - #################################################################################################################\n",
      "train E021: 100% 167/167 [00:16<00:00, 10.33it/s]\n",
      "INFO - 01/14/23 23:19:53 - 0:13:25 - Train Epoch 21: LOSS= 0.72990, lr= 0.000686, acc1= 95.62,acc3= 98.58,acc10= 99.25\n",
      "eval E021: 100% 177/177 [00:10<00:00, 16.65it/s]\n",
      "INFO - 01/14/23 23:20:03 - 0:13:36 - #################################################################################################################\n",
      "INFO - 01/14/23 23:20:03 - 0:13:36 - Test Epoch 21: LOSS= 4.92149, acc1= 72.83, acc3= 80.20, acc10= 83.21\n",
      "INFO - 01/14/23 23:20:03 - 0:13:36 - #################################################################################################################\n",
      "train E022: 100% 167/167 [00:14<00:00, 11.63it/s]\n",
      "INFO - 01/14/23 23:20:18 - 0:13:50 - Train Epoch 22: LOSS= 0.71212, lr= 0.000686, acc1= 95.92,acc3= 98.13,acc10= 98.95\n",
      "eval E022: 100% 177/177 [00:10<00:00, 17.03it/s]\n",
      "INFO - 01/14/23 23:20:28 - 0:14:01 - #################################################################################################################\n",
      "INFO - 01/14/23 23:20:28 - 0:14:01 - Test Epoch 22: LOSS= 4.79214, acc1= 73.40, acc3= 80.09, acc10= 82.75\n",
      "INFO - 01/14/23 23:20:28 - 0:14:01 - #################################################################################################################\n",
      "train E023: 100% 167/167 [00:15<00:00, 10.51it/s]\n",
      "INFO - 01/14/23 23:20:44 - 0:14:17 - Train Epoch 23: LOSS= 0.63023, lr= 0.000480, acc1= 96.44,acc3= 98.43,acc10= 99.29\n",
      "eval E023: 100% 177/177 [00:10<00:00, 17.30it/s]\n",
      "INFO - 01/14/23 23:20:54 - 0:14:27 - #################################################################################################################\n",
      "INFO - 01/14/23 23:20:54 - 0:14:27 - Test Epoch 23: LOSS= 4.85587, acc1= 74.21, acc3= 80.48, acc10= 83.35\n",
      "INFO - 01/14/23 23:20:54 - 0:14:27 - #################################################################################################################\n",
      "train E024: 100% 167/167 [00:27<00:00,  6.08it/s]\n",
      "INFO - 01/14/23 23:21:22 - 0:14:54 - Train Epoch 24: LOSS= 0.56783, lr= 0.000480, acc1= 96.55,acc3= 98.76,acc10= 99.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E024: 100% 177/177 [00:30<00:00,  5.74it/s]\n",
      "INFO - 01/14/23 23:21:52 - 0:15:25 - #################################################################################################################\n",
      "INFO - 01/14/23 23:21:52 - 0:15:25 - Test Epoch 24: LOSS= 4.85646, acc1= 74.07, acc3= 80.59, acc10= 82.82\n",
      "INFO - 01/14/23 23:21:52 - 0:15:25 - #################################################################################################################\n",
      "train E025: 100% 167/167 [00:34<00:00,  4.82it/s]\n",
      "INFO - 01/14/23 23:22:27 - 0:16:00 - Train Epoch 25: LOSS= 0.53461, lr= 0.000480, acc1= 96.97,acc3= 99.03,acc10= 99.63\n",
      "eval E025: 100% 177/177 [00:31<00:00,  5.60it/s]\n",
      "INFO - 01/14/23 23:22:59 - 0:16:32 - #################################################################################################################\n",
      "INFO - 01/14/23 23:22:59 - 0:16:32 - Test Epoch 25: LOSS= 5.13040, acc1= 74.14, acc3= 80.66, acc10= 83.14\n",
      "INFO - 01/14/23 23:22:59 - 0:16:32 - #################################################################################################################\n",
      "train E026: 100% 167/167 [00:36<00:00,  4.61it/s]\n",
      "INFO - 01/14/23 23:23:35 - 0:17:08 - Train Epoch 26: LOSS= 0.49407, lr= 0.000336, acc1= 97.08,acc3= 99.14,acc10= 99.70\n",
      "eval E026: 100% 177/177 [00:31<00:00,  5.58it/s]\n",
      "INFO - 01/14/23 23:24:07 - 0:17:40 - #################################################################################################################\n",
      "INFO - 01/14/23 23:24:07 - 0:17:40 - Test Epoch 26: LOSS= 5.08447, acc1= 74.14, acc3= 80.69, acc10= 83.35\n",
      "INFO - 01/14/23 23:24:07 - 0:17:40 - #################################################################################################################\n",
      "train E027: 100% 167/167 [00:34<00:00,  4.90it/s]\n",
      "INFO - 01/14/23 23:24:41 - 0:18:14 - Train Epoch 27: LOSS= 0.49656, lr= 0.000336, acc1= 96.97,acc3= 99.10,acc10= 99.55\n",
      "eval E027: 100% 177/177 [00:30<00:00,  5.73it/s]\n",
      "INFO - 01/14/23 23:25:12 - 0:18:45 - #################################################################################################################\n",
      "INFO - 01/14/23 23:25:12 - 0:18:45 - Test Epoch 27: LOSS= 5.17338, acc1= 74.18, acc3= 80.38, acc10= 82.96\n",
      "INFO - 01/14/23 23:25:12 - 0:18:45 - #################################################################################################################\n",
      "train E028: 100% 167/167 [00:35<00:00,  4.75it/s]\n",
      "INFO - 01/14/23 23:25:47 - 0:19:20 - Train Epoch 28: LOSS= 0.47544, lr= 0.000336, acc1= 97.26,acc3= 99.21,acc10= 99.70\n",
      "eval E028: 100% 177/177 [00:31<00:00,  5.56it/s]\n",
      "INFO - 01/14/23 23:26:19 - 0:19:51 - #################################################################################################################\n",
      "INFO - 01/14/23 23:26:19 - 0:19:51 - Test Epoch 28: LOSS= 5.14708, acc1= 73.86, acc3= 80.80, acc10= 83.39\n",
      "INFO - 01/14/23 23:26:19 - 0:19:51 - #################################################################################################################\n",
      "train E029: 100% 167/167 [00:34<00:00,  4.83it/s]\n",
      "INFO - 01/14/23 23:26:53 - 0:20:26 - Train Epoch 29: LOSS= 0.43380, lr= 0.000235, acc1= 97.60,acc3= 99.25,acc10= 99.78\n",
      "eval E029: 100% 177/177 [00:30<00:00,  5.73it/s]\n",
      "INFO - 01/14/23 23:27:24 - 0:20:57 - #################################################################################################################\n",
      "INFO - 01/14/23 23:27:24 - 0:20:57 - Test Epoch 29: LOSS= 5.21732, acc1= 74.11, acc3= 80.98, acc10= 83.46\n",
      "INFO - 01/14/23 23:27:24 - 0:20:57 - #################################################################################################################\n",
      "train E030: 100% 167/167 [00:34<00:00,  4.89it/s]\n",
      "INFO - 01/14/23 23:27:58 - 0:21:31 - Train Epoch 30: LOSS= 0.40326, lr= 0.000235, acc1= 97.86,acc3= 99.44,acc10= 99.85\n",
      "eval E030: 100% 177/177 [00:30<00:00,  5.72it/s]\n",
      "INFO - 01/14/23 23:28:29 - 0:22:02 - #################################################################################################################\n",
      "INFO - 01/14/23 23:28:29 - 0:22:02 - Test Epoch 30: LOSS= 5.30588, acc1= 74.11, acc3= 80.91, acc10= 83.42\n",
      "INFO - 01/14/23 23:28:29 - 0:22:02 - #################################################################################################################\n",
      "train E031: 100% 167/167 [00:33<00:00,  4.92it/s]\n",
      "INFO - 01/14/23 23:29:03 - 0:22:36 - Train Epoch 31: LOSS= 0.42441, lr= 0.000235, acc1= 97.56,acc3= 99.21,acc10= 99.70\n",
      "eval E031: 100% 177/177 [00:31<00:00,  5.68it/s]\n",
      "INFO - 01/14/23 23:29:34 - 0:23:07 - #################################################################################################################\n",
      "INFO - 01/14/23 23:29:34 - 0:23:07 - Test Epoch 31: LOSS= 5.45477, acc1= 74.11, acc3= 80.62, acc10= 83.49\n",
      "INFO - 01/14/23 23:29:34 - 0:23:07 - #################################################################################################################\n",
      "train E032: 100% 167/167 [00:34<00:00,  4.84it/s]\n",
      "INFO - 01/14/23 23:30:09 - 0:23:42 - Train Epoch 32: LOSS= 0.38820, lr= 0.000165, acc1= 97.68,acc3= 99.29,acc10= 99.66\n",
      "eval E032: 100% 177/177 [00:30<00:00,  5.77it/s]\n",
      "INFO - 01/14/23 23:30:40 - 0:24:12 - #################################################################################################################\n",
      "INFO - 01/14/23 23:30:40 - 0:24:12 - Test Epoch 32: LOSS= 5.52393, acc1= 74.35, acc3= 80.77, acc10= 83.17\n",
      "INFO - 01/14/23 23:30:40 - 0:24:12 - #################################################################################################################\n",
      "train E033: 100% 167/167 [00:34<00:00,  4.87it/s]\n",
      "INFO - 01/14/23 23:31:14 - 0:24:47 - Train Epoch 33: LOSS= 0.38833, lr= 0.000165, acc1= 97.41,acc3= 99.59,acc10= 99.81\n",
      "eval E033: 100% 177/177 [00:31<00:00,  5.66it/s]\n",
      "INFO - 01/14/23 23:31:45 - 0:25:18 - #################################################################################################################\n",
      "INFO - 01/14/23 23:31:45 - 0:25:18 - Test Epoch 33: LOSS= 5.46668, acc1= 74.35, acc3= 80.62, acc10= 83.42\n",
      "INFO - 01/14/23 23:31:45 - 0:25:18 - #################################################################################################################\n",
      "train E034: 100% 167/167 [00:34<00:00,  4.83it/s]\n",
      "INFO - 01/14/23 23:32:20 - 0:25:53 - Train Epoch 34: LOSS= 0.35810, lr= 0.000165, acc1= 97.86,acc3= 99.55,acc10= 99.78\n",
      "eval E034: 100% 177/177 [00:31<00:00,  5.54it/s]\n",
      "INFO - 01/14/23 23:32:52 - 0:26:25 - #################################################################################################################\n",
      "INFO - 01/14/23 23:32:52 - 0:26:25 - Test Epoch 34: LOSS= 5.54554, acc1= 74.14, acc3= 80.73, acc10= 83.17\n",
      "INFO - 01/14/23 23:32:52 - 0:26:25 - #################################################################################################################\n",
      "train E035: 100% 167/167 [00:34<00:00,  4.85it/s]\n",
      "INFO - 01/14/23 23:33:26 - 0:26:59 - Train Epoch 35: LOSS= 0.37118, lr= 0.000115, acc1= 97.98,acc3= 99.78,acc10= 99.93\n",
      "eval E035: 100% 177/177 [00:31<00:00,  5.69it/s]\n",
      "INFO - 01/14/23 23:33:57 - 0:27:30 - #################################################################################################################\n",
      "INFO - 01/14/23 23:33:57 - 0:27:30 - Test Epoch 35: LOSS= 5.52588, acc1= 74.39, acc3= 80.94, acc10= 83.32\n",
      "INFO - 01/14/23 23:33:57 - 0:27:30 - #################################################################################################################\n",
      "train E036: 100% 167/167 [00:34<00:00,  4.80it/s]\n",
      "INFO - 01/14/23 23:34:32 - 0:28:05 - Train Epoch 36: LOSS= 0.36372, lr= 0.000115, acc1= 97.79,acc3= 99.59,acc10= 99.89\n",
      "eval E036: 100% 177/177 [00:31<00:00,  5.56it/s]\n",
      "INFO - 01/14/23 23:35:04 - 0:28:37 - #################################################################################################################\n",
      "INFO - 01/14/23 23:35:04 - 0:28:37 - Test Epoch 36: LOSS= 5.46225, acc1= 74.35, acc3= 80.84, acc10= 83.17\n",
      "INFO - 01/14/23 23:35:04 - 0:28:37 - #################################################################################################################\n",
      "train E037: 100% 167/167 [00:35<00:00,  4.72it/s]\n",
      "INFO - 01/14/23 23:35:39 - 0:29:12 - Train Epoch 37: LOSS= 0.34988, lr= 0.000115, acc1= 97.90,acc3= 99.70,acc10= 99.85\n",
      "eval E037: 100% 177/177 [00:30<00:00,  5.72it/s]\n",
      "INFO - 01/14/23 23:36:10 - 0:29:43 - #################################################################################################################\n",
      "INFO - 01/14/23 23:36:10 - 0:29:43 - Test Epoch 37: LOSS= 5.50067, acc1= 74.39, acc3= 80.69, acc10= 83.10\n",
      "INFO - 01/14/23 23:36:10 - 0:29:43 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E038: 100% 167/167 [00:33<00:00,  5.05it/s]\n",
      "INFO - 01/14/23 23:36:43 - 0:30:16 - Train Epoch 38: LOSS= 0.34164, lr= 0.000081, acc1= 97.68,acc3= 99.78,acc10= 99.93\n",
      "eval E038: 100% 177/177 [00:32<00:00,  5.52it/s]\n",
      "INFO - 01/14/23 23:37:16 - 0:30:48 - #################################################################################################################\n",
      "INFO - 01/14/23 23:37:16 - 0:30:48 - Test Epoch 38: LOSS= 5.49459, acc1= 74.39, acc3= 80.73, acc10= 83.21\n",
      "INFO - 01/14/23 23:37:16 - 0:30:48 - #################################################################################################################\n",
      "train E039: 100% 167/167 [00:34<00:00,  4.85it/s]\n",
      "INFO - 01/14/23 23:37:50 - 0:31:23 - Train Epoch 39: LOSS= 0.34127, lr= 0.000081, acc1= 97.68,acc3= 99.70,acc10= 99.93\n",
      "eval E039: 100% 177/177 [00:32<00:00,  5.47it/s]\n",
      "INFO - 01/14/23 23:38:22 - 0:31:55 - #################################################################################################################\n",
      "INFO - 01/14/23 23:38:22 - 0:31:55 - Test Epoch 39: LOSS= 5.52724, acc1= 74.39, acc3= 80.91, acc10= 83.32\n",
      "INFO - 01/14/23 23:38:22 - 0:31:55 - #################################################################################################################\n",
      "train E040: 100% 167/167 [00:34<00:00,  4.80it/s]\n",
      "INFO - 01/14/23 23:38:57 - 0:32:30 - Train Epoch 40: LOSS= 0.33520, lr= 0.000081, acc1= 97.83,acc3= 99.78,acc10= 99.96\n",
      "eval E040: 100% 177/177 [00:31<00:00,  5.63it/s]\n",
      "INFO - 01/14/23 23:39:29 - 0:33:01 - #################################################################################################################\n",
      "INFO - 01/14/23 23:39:29 - 0:33:01 - Test Epoch 40: LOSS= 5.55074, acc1= 74.57, acc3= 80.87, acc10= 83.17\n",
      "INFO - 01/14/23 23:39:29 - 0:33:01 - #################################################################################################################\n",
      "train E041: 100% 167/167 [00:34<00:00,  4.79it/s]\n",
      "INFO - 01/14/23 23:40:03 - 0:33:36 - Train Epoch 41: LOSS= 0.32879, lr= 0.000056, acc1= 97.90,acc3= 99.78,acc10= 100.00\n",
      "eval E041: 100% 177/177 [00:30<00:00,  5.73it/s]\n",
      "INFO - 01/14/23 23:40:34 - 0:34:07 - #################################################################################################################\n",
      "INFO - 01/14/23 23:40:34 - 0:34:07 - Test Epoch 41: LOSS= 5.55205, acc1= 74.67, acc3= 80.69, acc10= 83.17\n",
      "INFO - 01/14/23 23:40:34 - 0:34:07 - #################################################################################################################\n",
      "train E042: 100% 167/167 [00:33<00:00,  4.95it/s]\n",
      "INFO - 01/14/23 23:41:08 - 0:34:41 - Train Epoch 42: LOSS= 0.32370, lr= 0.000056, acc1= 98.16,acc3= 99.59,acc10= 99.85\n",
      "eval E042: 100% 177/177 [00:31<00:00,  5.59it/s]\n",
      "INFO - 01/14/23 23:41:40 - 0:35:13 - #################################################################################################################\n",
      "INFO - 01/14/23 23:41:40 - 0:35:13 - Test Epoch 42: LOSS= 5.62054, acc1= 74.67, acc3= 80.80, acc10= 83.14\n",
      "INFO - 01/14/23 23:41:40 - 0:35:13 - #################################################################################################################\n",
      "train E043: 100% 167/167 [00:25<00:00,  6.51it/s]\n",
      "INFO - 01/14/23 23:42:05 - 0:35:38 - Train Epoch 43: LOSS= 0.32615, lr= 0.000056, acc1= 98.05,acc3= 99.66,acc10= 99.96\n",
      "eval E043: 100% 177/177 [00:10<00:00, 17.12it/s]\n",
      "INFO - 01/14/23 23:42:16 - 0:35:49 - #################################################################################################################\n",
      "INFO - 01/14/23 23:42:16 - 0:35:49 - Test Epoch 43: LOSS= 5.63659, acc1= 74.78, acc3= 80.77, acc10= 83.07\n",
      "INFO - 01/14/23 23:42:16 - 0:35:49 - #################################################################################################################\n",
      "train E044: 100% 167/167 [00:15<00:00, 10.54it/s]\n",
      "INFO - 01/14/23 23:42:32 - 0:36:04 - Train Epoch 44: LOSS= 0.32003, lr= 0.000040, acc1= 97.90,acc3= 99.74,acc10= 99.96\n",
      "eval E044: 100% 177/177 [00:10<00:00, 17.42it/s]\n",
      "INFO - 01/14/23 23:42:42 - 0:36:15 - #################################################################################################################\n",
      "INFO - 01/14/23 23:42:42 - 0:36:15 - Test Epoch 44: LOSS= 5.65754, acc1= 74.74, acc3= 80.77, acc10= 83.17\n",
      "INFO - 01/14/23 23:42:42 - 0:36:15 - #################################################################################################################\n",
      "train E045: 100% 167/167 [00:15<00:00, 10.56it/s]\n",
      "INFO - 01/14/23 23:42:58 - 0:36:30 - Train Epoch 45: LOSS= 0.30460, lr= 0.000040, acc1= 98.13,acc3= 99.81,acc10= 99.96\n",
      "eval E045: 100% 177/177 [00:10<00:00, 16.64it/s]\n",
      "INFO - 01/14/23 23:43:08 - 0:36:41 - #################################################################################################################\n",
      "INFO - 01/14/23 23:43:08 - 0:36:41 - Test Epoch 45: LOSS= 5.68415, acc1= 74.39, acc3= 80.84, acc10= 83.14\n",
      "INFO - 01/14/23 23:43:08 - 0:36:41 - #################################################################################################################\n",
      "train E046: 100% 167/167 [00:15<00:00, 10.51it/s]\n",
      "INFO - 01/14/23 23:43:24 - 0:36:57 - Train Epoch 46: LOSS= 0.32610, lr= 0.000040, acc1= 98.09,acc3= 99.70,acc10= 99.93\n",
      "eval E046: 100% 177/177 [00:10<00:00, 16.79it/s]\n",
      "INFO - 01/14/23 23:43:35 - 0:37:07 - #################################################################################################################\n",
      "INFO - 01/14/23 23:43:35 - 0:37:07 - Test Epoch 46: LOSS= 5.68626, acc1= 74.32, acc3= 80.87, acc10= 83.24\n",
      "INFO - 01/14/23 23:43:35 - 0:37:07 - #################################################################################################################\n",
      "train E047: 100% 167/167 [00:15<00:00, 10.54it/s]\n",
      "INFO - 01/14/23 23:43:51 - 0:37:23 - Train Epoch 47: LOSS= 0.30571, lr= 0.000040, acc1= 98.28,acc3= 99.74,acc10= 99.93\n",
      "eval E047: 100% 177/177 [00:10<00:00, 17.21it/s]\n",
      "INFO - 01/14/23 23:44:01 - 0:37:34 - #################################################################################################################\n",
      "INFO - 01/14/23 23:44:01 - 0:37:34 - Test Epoch 47: LOSS= 5.69630, acc1= 74.50, acc3= 80.80, acc10= 83.35\n",
      "INFO - 01/14/23 23:44:01 - 0:37:34 - #################################################################################################################\n",
      "train E048: 100% 167/167 [00:16<00:00, 10.17it/s]\n",
      "INFO - 01/14/23 23:44:17 - 0:37:50 - Train Epoch 48: LOSS= 0.30448, lr= 0.000040, acc1= 98.05,acc3= 99.78,acc10= 99.96\n",
      "eval E048: 100% 177/177 [00:10<00:00, 17.33it/s]\n",
      "INFO - 01/14/23 23:44:27 - 0:38:00 - #################################################################################################################\n",
      "INFO - 01/14/23 23:44:27 - 0:38:00 - Test Epoch 48: LOSS= 5.68432, acc1= 74.57, acc3= 81.01, acc10= 83.24\n",
      "INFO - 01/14/23 23:44:27 - 0:38:00 - #################################################################################################################\n",
      "train E049: 100% 167/167 [00:16<00:00, 10.33it/s]\n",
      "INFO - 01/14/23 23:44:44 - 0:38:16 - Train Epoch 49: LOSS= 0.31634, lr= 0.000040, acc1= 98.16,acc3= 99.70,acc10= 99.96\n",
      "eval E049: 100% 177/177 [00:10<00:00, 16.81it/s]\n",
      "INFO - 01/14/23 23:44:54 - 0:38:27 - #################################################################################################################\n",
      "INFO - 01/14/23 23:44:54 - 0:38:27 - Test Epoch 49: LOSS= 5.69174, acc1= 74.60, acc3= 80.84, acc10= 83.32\n",
      "INFO - 01/14/23 23:44:54 - 0:38:27 - #################################################################################################################\n",
      "train E050: 100% 167/167 [00:16<00:00, 10.11it/s]\n",
      "INFO - 01/14/23 23:45:11 - 0:38:43 - Train Epoch 50: LOSS= 0.31303, lr= 0.000040, acc1= 97.98,acc3= 99.74,acc10= 100.00\n",
      "eval E050: 100% 177/177 [00:10<00:00, 17.59it/s]\n",
      "INFO - 01/14/23 23:45:21 - 0:38:54 - #################################################################################################################\n",
      "INFO - 01/14/23 23:45:21 - 0:38:54 - Test Epoch 50: LOSS= 5.74628, acc1= 74.50, acc3= 80.94, acc10= 83.35\n",
      "INFO - 01/14/23 23:45:21 - 0:38:54 - #################################################################################################################\n",
      "train E051: 100% 167/167 [00:15<00:00, 10.45it/s]\n",
      "INFO - 01/14/23 23:45:37 - 0:39:10 - Train Epoch 51: LOSS= 0.30196, lr= 0.000040, acc1= 97.86,acc3= 99.78,acc10= 99.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E051: 100% 177/177 [00:10<00:00, 17.34it/s]\n",
      "INFO - 01/14/23 23:45:47 - 0:39:20 - #################################################################################################################\n",
      "INFO - 01/14/23 23:45:47 - 0:39:20 - Test Epoch 51: LOSS= 5.72610, acc1= 74.60, acc3= 80.80, acc10= 83.24\n",
      "INFO - 01/14/23 23:45:47 - 0:39:20 - #################################################################################################################\n",
      "train E052: 100% 167/167 [00:16<00:00, 10.27it/s]\n",
      "INFO - 01/14/23 23:46:03 - 0:39:36 - Train Epoch 52: LOSS= 0.30301, lr= 0.000040, acc1= 97.94,acc3= 99.85,acc10= 99.96\n",
      "eval E052: 100% 177/177 [00:10<00:00, 16.73it/s]\n",
      "INFO - 01/14/23 23:46:14 - 0:39:47 - #################################################################################################################\n",
      "INFO - 01/14/23 23:46:14 - 0:39:47 - Test Epoch 52: LOSS= 5.77459, acc1= 74.60, acc3= 80.84, acc10= 83.10\n",
      "INFO - 01/14/23 23:46:14 - 0:39:47 - #################################################################################################################\n",
      "train E053: 100% 167/167 [00:16<00:00, 10.15it/s]\n",
      "INFO - 01/14/23 23:46:30 - 0:40:03 - Train Epoch 53: LOSS= 0.30359, lr= 0.000040, acc1= 98.24,acc3= 99.78,acc10= 99.93\n",
      "eval E053: 100% 177/177 [00:10<00:00, 17.33it/s]\n",
      "INFO - 01/14/23 23:46:40 - 0:40:13 - #################################################################################################################\n",
      "INFO - 01/14/23 23:46:40 - 0:40:13 - Test Epoch 53: LOSS= 5.77340, acc1= 74.32, acc3= 80.91, acc10= 83.21\n",
      "INFO - 01/14/23 23:46:40 - 0:40:13 - #################################################################################################################\n",
      "train E054: 100% 167/167 [00:16<00:00, 10.35it/s]\n",
      "INFO - 01/14/23 23:46:57 - 0:40:29 - Train Epoch 54: LOSS= 0.28210, lr= 0.000040, acc1= 98.13,acc3= 99.70,acc10= 99.85\n",
      "eval E054: 100% 177/177 [00:10<00:00, 17.32it/s]\n",
      "INFO - 01/14/23 23:47:07 - 0:40:40 - #################################################################################################################\n",
      "INFO - 01/14/23 23:47:07 - 0:40:40 - Test Epoch 54: LOSS= 5.82380, acc1= 74.39, acc3= 80.84, acc10= 83.21\n",
      "INFO - 01/14/23 23:47:07 - 0:40:40 - #################################################################################################################\n",
      "train E055: 100% 167/167 [00:15<00:00, 10.58it/s]\n",
      "INFO - 01/14/23 23:47:23 - 0:40:55 - Train Epoch 55: LOSS= 0.29926, lr= 0.000040, acc1= 98.13,acc3= 99.78,acc10= 99.96\n",
      "eval E055: 100% 177/177 [00:10<00:00, 17.51it/s]\n",
      "INFO - 01/14/23 23:47:33 - 0:41:06 - #################################################################################################################\n",
      "INFO - 01/14/23 23:47:33 - 0:41:06 - Test Epoch 55: LOSS= 5.77815, acc1= 74.39, acc3= 80.84, acc10= 83.14\n",
      "INFO - 01/14/23 23:47:33 - 0:41:06 - #################################################################################################################\n",
      "train E056: 100% 167/167 [00:16<00:00, 10.12it/s]\n",
      "INFO - 01/14/23 23:47:49 - 0:41:22 - Train Epoch 56: LOSS= 0.30601, lr= 0.000040, acc1= 97.90,acc3= 99.78,acc10= 99.93\n",
      "eval E056: 100% 177/177 [00:10<00:00, 17.23it/s]\n",
      "INFO - 01/14/23 23:48:00 - 0:41:32 - #################################################################################################################\n",
      "INFO - 01/14/23 23:48:00 - 0:41:32 - Test Epoch 56: LOSS= 5.79706, acc1= 74.39, acc3= 80.69, acc10= 83.14\n",
      "INFO - 01/14/23 23:48:00 - 0:41:32 - #################################################################################################################\n",
      "train E057: 100% 167/167 [00:15<00:00, 10.77it/s]\n",
      "INFO - 01/14/23 23:48:15 - 0:41:48 - Train Epoch 57: LOSS= 0.30191, lr= 0.000040, acc1= 97.98,acc3= 99.81,acc10= 100.00\n",
      "eval E057: 100% 177/177 [00:10<00:00, 17.44it/s]\n",
      "INFO - 01/14/23 23:48:25 - 0:41:58 - #################################################################################################################\n",
      "INFO - 01/14/23 23:48:25 - 0:41:58 - Test Epoch 57: LOSS= 5.78660, acc1= 74.42, acc3= 80.87, acc10= 83.17\n",
      "INFO - 01/14/23 23:48:25 - 0:41:58 - #################################################################################################################\n",
      "train E058: 100% 167/167 [00:16<00:00, 10.36it/s]\n",
      "INFO - 01/14/23 23:48:41 - 0:42:14 - Train Epoch 58: LOSS= 0.30990, lr= 0.000040, acc1= 98.01,acc3= 99.74,acc10= 99.96\n",
      "eval E058: 100% 177/177 [00:10<00:00, 16.18it/s]\n",
      "INFO - 01/14/23 23:48:52 - 0:42:25 - #################################################################################################################\n",
      "INFO - 01/14/23 23:48:52 - 0:42:25 - Test Epoch 58: LOSS= 5.82174, acc1= 74.50, acc3= 80.77, acc10= 83.35\n",
      "INFO - 01/14/23 23:48:52 - 0:42:25 - #################################################################################################################\n",
      "train E059: 100% 167/167 [00:16<00:00, 10.32it/s]\n",
      "INFO - 01/14/23 23:49:08 - 0:42:41 - Train Epoch 59: LOSS= 0.28283, lr= 0.000040, acc1= 98.09,acc3= 99.81,acc10= 100.00\n",
      "eval E059: 100% 177/177 [00:10<00:00, 17.19it/s]\n",
      "INFO - 01/14/23 23:49:19 - 0:42:52 - #################################################################################################################\n",
      "INFO - 01/14/23 23:49:19 - 0:42:52 - Test Epoch 59: LOSS= 5.82210, acc1= 74.81, acc3= 80.80, acc10= 83.28\n",
      "INFO - 01/14/23 23:49:19 - 0:42:52 - #################################################################################################################\n",
      "train E060: 100% 167/167 [00:15<00:00, 10.49it/s]\n",
      "INFO - 01/14/23 23:49:35 - 0:43:07 - Train Epoch 60: LOSS= 0.28455, lr= 0.000040, acc1= 98.09,acc3= 99.74,acc10= 99.93\n",
      "eval E060: 100% 177/177 [00:18<00:00,  9.38it/s]\n",
      "INFO - 01/14/23 23:49:54 - 0:43:26 - #################################################################################################################\n",
      "INFO - 01/14/23 23:49:54 - 0:43:26 - Test Epoch 60: LOSS= 5.84399, acc1= 74.53, acc3= 80.80, acc10= 83.24\n",
      "INFO - 01/14/23 23:49:54 - 0:43:26 - #################################################################################################################\n",
      "train E061: 100% 167/167 [00:34<00:00,  4.88it/s]\n",
      "INFO - 01/14/23 23:50:28 - 0:44:01 - Train Epoch 61: LOSS= 0.28744, lr= 0.000040, acc1= 97.98,acc3= 99.85,acc10= 100.00\n",
      "eval E061: 100% 177/177 [00:31<00:00,  5.68it/s]\n",
      "INFO - 01/14/23 23:50:59 - 0:44:32 - #################################################################################################################\n",
      "INFO - 01/14/23 23:50:59 - 0:44:32 - Test Epoch 61: LOSS= 5.81040, acc1= 74.46, acc3= 80.91, acc10= 83.21\n",
      "INFO - 01/14/23 23:50:59 - 0:44:32 - #################################################################################################################\n",
      "train E062: 100% 167/167 [00:34<00:00,  4.82it/s]\n",
      "INFO - 01/14/23 23:51:34 - 0:45:06 - Train Epoch 62: LOSS= 0.28168, lr= 0.000040, acc1= 97.94,acc3= 99.74,acc10= 99.96\n",
      "eval E062: 100% 177/177 [00:31<00:00,  5.69it/s]\n",
      "INFO - 01/14/23 23:52:05 - 0:45:38 - #################################################################################################################\n",
      "INFO - 01/14/23 23:52:05 - 0:45:38 - Test Epoch 62: LOSS= 5.83925, acc1= 74.32, acc3= 80.91, acc10= 83.10\n",
      "INFO - 01/14/23 23:52:05 - 0:45:38 - #################################################################################################################\n",
      "train E063: 100% 167/167 [00:34<00:00,  4.85it/s]\n",
      "INFO - 01/14/23 23:52:39 - 0:46:12 - Train Epoch 63: LOSS= 0.30443, lr= 0.000040, acc1= 98.28,acc3= 99.81,acc10= 99.96\n",
      "eval E063: 100% 177/177 [00:33<00:00,  5.35it/s]\n",
      "INFO - 01/14/23 23:53:12 - 0:46:45 - #################################################################################################################\n",
      "INFO - 01/14/23 23:53:12 - 0:46:45 - Test Epoch 63: LOSS= 5.82854, acc1= 74.57, acc3= 80.80, acc10= 83.28\n",
      "INFO - 01/14/23 23:53:12 - 0:46:45 - #################################################################################################################\n",
      "train E064: 100% 167/167 [00:33<00:00,  4.91it/s]\n",
      "INFO - 01/14/23 23:53:46 - 0:47:19 - Train Epoch 64: LOSS= 0.28813, lr= 0.000040, acc1= 97.94,acc3= 99.74,acc10= 99.96\n",
      "eval E064: 100% 177/177 [00:30<00:00,  5.84it/s]\n",
      "INFO - 01/14/23 23:54:17 - 0:47:49 - #################################################################################################################\n",
      "INFO - 01/14/23 23:54:17 - 0:47:49 - Test Epoch 64: LOSS= 5.84279, acc1= 74.42, acc3= 80.87, acc10= 83.17\n",
      "INFO - 01/14/23 23:54:17 - 0:47:49 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E065: 100% 167/167 [00:34<00:00,  4.91it/s]\n",
      "INFO - 01/14/23 23:54:51 - 0:48:23 - Train Epoch 65: LOSS= 0.28875, lr= 0.000040, acc1= 98.05,acc3= 99.85,acc10= 99.96\n",
      "eval E065: 100% 177/177 [00:32<00:00,  5.51it/s]\n",
      "INFO - 01/14/23 23:55:23 - 0:48:56 - #################################################################################################################\n",
      "INFO - 01/14/23 23:55:23 - 0:48:56 - Test Epoch 65: LOSS= 5.87278, acc1= 74.32, acc3= 80.77, acc10= 83.14\n",
      "INFO - 01/14/23 23:55:23 - 0:48:56 - #################################################################################################################\n",
      "train E066: 100% 167/167 [00:34<00:00,  4.87it/s]\n",
      "INFO - 01/14/23 23:55:57 - 0:49:30 - Train Epoch 66: LOSS= 0.30487, lr= 0.000040, acc1= 98.28,acc3= 99.78,acc10= 100.00\n",
      "eval E066: 100% 177/177 [00:31<00:00,  5.57it/s]\n",
      "INFO - 01/14/23 23:56:29 - 0:50:02 - #################################################################################################################\n",
      "INFO - 01/14/23 23:56:29 - 0:50:02 - Test Epoch 66: LOSS= 5.84840, acc1= 74.25, acc3= 80.84, acc10= 83.32\n",
      "INFO - 01/14/23 23:56:29 - 0:50:02 - #################################################################################################################\n",
      "train E067: 100% 167/167 [00:33<00:00,  4.95it/s]\n",
      "INFO - 01/14/23 23:57:03 - 0:50:35 - Train Epoch 67: LOSS= 0.27556, lr= 0.000040, acc1= 98.13,acc3= 99.85,acc10= 100.00\n",
      "eval E067: 100% 177/177 [00:31<00:00,  5.68it/s]\n",
      "INFO - 01/14/23 23:57:34 - 0:51:07 - #################################################################################################################\n",
      "INFO - 01/14/23 23:57:34 - 0:51:07 - Test Epoch 67: LOSS= 5.86645, acc1= 74.39, acc3= 80.80, acc10= 83.32\n",
      "INFO - 01/14/23 23:57:34 - 0:51:07 - #################################################################################################################\n",
      "train E068: 100% 167/167 [00:34<00:00,  4.86it/s]\n",
      "INFO - 01/14/23 23:58:08 - 0:51:41 - Train Epoch 68: LOSS= 0.30674, lr= 0.000040, acc1= 98.13,acc3= 99.78,acc10= 100.00\n",
      "eval E068: 100% 177/177 [00:30<00:00,  5.72it/s]\n",
      "INFO - 01/14/23 23:58:39 - 0:52:12 - #################################################################################################################\n",
      "INFO - 01/14/23 23:58:39 - 0:52:12 - Test Epoch 68: LOSS= 5.87453, acc1= 74.42, acc3= 80.87, acc10= 83.28\n",
      "INFO - 01/14/23 23:58:39 - 0:52:12 - #################################################################################################################\n",
      "train E069: 100% 167/167 [00:34<00:00,  4.87it/s]\n",
      "INFO - 01/14/23 23:59:13 - 0:52:46 - Train Epoch 69: LOSS= 0.28341, lr= 0.000040, acc1= 98.28,acc3= 99.81,acc10= 99.96\n",
      "eval E069: 100% 177/177 [00:30<00:00,  5.84it/s]\n",
      "INFO - 01/14/23 23:59:44 - 0:53:16 - #################################################################################################################\n",
      "INFO - 01/14/23 23:59:44 - 0:53:16 - Test Epoch 69: LOSS= 5.87443, acc1= 74.46, acc3= 80.91, acc10= 83.03\n",
      "INFO - 01/14/23 23:59:44 - 0:53:16 - #################################################################################################################\n",
      "train E070: 100% 167/167 [00:34<00:00,  4.79it/s]\n",
      "INFO - 01/15/23 00:00:19 - 0:53:51 - Train Epoch 70: LOSS= 0.28478, lr= 0.000040, acc1= 98.13,acc3= 99.70,acc10= 99.96\n",
      "eval E070: 100% 177/177 [00:31<00:00,  5.59it/s]\n",
      "INFO - 01/15/23 00:00:50 - 0:54:23 - #################################################################################################################\n",
      "INFO - 01/15/23 00:00:50 - 0:54:23 - Test Epoch 70: LOSS= 5.87954, acc1= 74.39, acc3= 80.84, acc10= 83.17\n",
      "INFO - 01/15/23 00:00:50 - 0:54:23 - #################################################################################################################\n",
      "train E071: 100% 167/167 [00:34<00:00,  4.84it/s]\n",
      "INFO - 01/15/23 00:01:25 - 0:54:58 - Train Epoch 71: LOSS= 0.28162, lr= 0.000040, acc1= 98.31,acc3= 99.78,acc10= 99.93\n",
      "eval E071: 100% 177/177 [00:30<00:00,  5.72it/s]\n",
      "INFO - 01/15/23 00:01:56 - 0:55:28 - #################################################################################################################\n",
      "INFO - 01/15/23 00:01:56 - 0:55:28 - Test Epoch 71: LOSS= 5.88343, acc1= 74.32, acc3= 80.84, acc10= 83.14\n",
      "INFO - 01/15/23 00:01:56 - 0:55:28 - #################################################################################################################\n",
      "train E072: 100% 167/167 [00:34<00:00,  4.89it/s]\n",
      "INFO - 01/15/23 00:02:30 - 0:56:03 - Train Epoch 72: LOSS= 0.28807, lr= 0.000040, acc1= 97.98,acc3= 99.81,acc10= 100.00\n",
      "eval E072: 100% 177/177 [00:31<00:00,  5.66it/s]\n",
      "INFO - 01/15/23 00:03:01 - 0:56:34 - #################################################################################################################\n",
      "INFO - 01/15/23 00:03:01 - 0:56:34 - Test Epoch 72: LOSS= 5.87238, acc1= 74.21, acc3= 80.77, acc10= 83.21\n",
      "INFO - 01/15/23 00:03:01 - 0:56:34 - #################################################################################################################\n",
      "train E073: 100% 167/167 [00:34<00:00,  4.87it/s]\n",
      "INFO - 01/15/23 00:03:35 - 0:57:08 - Train Epoch 73: LOSS= 0.26003, lr= 0.000040, acc1= 98.43,acc3= 99.78,acc10= 100.00\n",
      "eval E073: 100% 177/177 [00:31<00:00,  5.57it/s]\n",
      "INFO - 01/15/23 00:04:07 - 0:57:40 - #################################################################################################################\n",
      "INFO - 01/15/23 00:04:07 - 0:57:40 - Test Epoch 73: LOSS= 5.89594, acc1= 74.28, acc3= 80.84, acc10= 83.32\n",
      "INFO - 01/15/23 00:04:07 - 0:57:40 - #################################################################################################################\n",
      "train E074: 100% 167/167 [00:35<00:00,  4.73it/s]\n",
      "INFO - 01/15/23 00:04:43 - 0:58:15 - Train Epoch 74: LOSS= 0.27456, lr= 0.000040, acc1= 98.28,acc3= 99.74,acc10= 100.00\n",
      "eval E074: 100% 177/177 [00:31<00:00,  5.68it/s]\n",
      "INFO - 01/15/23 00:05:14 - 0:58:46 - #################################################################################################################\n",
      "INFO - 01/15/23 00:05:14 - 0:58:46 - Test Epoch 74: LOSS= 5.88165, acc1= 74.21, acc3= 80.87, acc10= 83.32\n",
      "INFO - 01/15/23 00:05:14 - 0:58:46 - #################################################################################################################\n",
      "train E075: 100% 167/167 [00:34<00:00,  4.85it/s]\n",
      "INFO - 01/15/23 00:05:48 - 0:59:21 - Train Epoch 75: LOSS= 0.28375, lr= 0.000040, acc1= 98.20,acc3= 99.81,acc10= 100.00\n",
      "eval E075: 100% 177/177 [00:31<00:00,  5.63it/s]\n",
      "INFO - 01/15/23 00:06:20 - 0:59:52 - #################################################################################################################\n",
      "INFO - 01/15/23 00:06:20 - 0:59:52 - Test Epoch 75: LOSS= 5.93459, acc1= 74.35, acc3= 80.80, acc10= 83.32\n",
      "INFO - 01/15/23 00:06:20 - 0:59:52 - #################################################################################################################\n",
      "train E076: 100% 167/167 [00:34<00:00,  4.81it/s]\n",
      "INFO - 01/15/23 00:06:54 - 1:00:27 - Train Epoch 76: LOSS= 0.27861, lr= 0.000040, acc1= 97.98,acc3= 99.81,acc10= 99.96\n",
      "eval E076: 100% 177/177 [00:31<00:00,  5.63it/s]\n",
      "INFO - 01/15/23 00:07:26 - 1:00:58 - #################################################################################################################\n",
      "INFO - 01/15/23 00:07:26 - 1:00:58 - Test Epoch 76: LOSS= 5.93332, acc1= 74.32, acc3= 80.84, acc10= 83.21\n",
      "INFO - 01/15/23 00:07:26 - 1:00:58 - #################################################################################################################\n",
      "train E077: 100% 167/167 [00:35<00:00,  4.74it/s]\n",
      "INFO - 01/15/23 00:08:01 - 1:01:34 - Train Epoch 77: LOSS= 0.26898, lr= 0.000040, acc1= 98.05,acc3= 99.81,acc10= 99.96\n",
      "eval E077: 100% 177/177 [00:31<00:00,  5.70it/s]\n",
      "INFO - 01/15/23 00:08:32 - 1:02:05 - #################################################################################################################\n",
      "INFO - 01/15/23 00:08:32 - 1:02:05 - Test Epoch 77: LOSS= 5.98123, acc1= 74.35, acc3= 80.91, acc10= 83.35\n",
      "INFO - 01/15/23 00:08:32 - 1:02:05 - #################################################################################################################\n",
      "train E078: 100% 167/167 [00:33<00:00,  4.99it/s]\n",
      "INFO - 01/15/23 00:09:05 - 1:02:38 - Train Epoch 78: LOSS= 0.28058, lr= 0.000040, acc1= 98.46,acc3= 99.81,acc10= 99.96\n",
      "eval E078: 100% 177/177 [00:31<00:00,  5.68it/s]\n",
      "INFO - 01/15/23 00:09:37 - 1:03:09 - #################################################################################################################\n",
      "INFO - 01/15/23 00:09:37 - 1:03:09 - Test Epoch 78: LOSS= 5.98154, acc1= 74.35, acc3= 80.80, acc10= 83.35\n",
      "INFO - 01/15/23 00:09:37 - 1:03:09 - #################################################################################################################\n",
      "INFO - 01/15/23 00:09:37 - 1:03:10 - best performance =  74.57, 81.01, 83.24. best epoch = 48, correspond_loss= 5.6843\n",
      "INFO - 01/15/23 00:09:37 - 1:03:10 -  fusion_model_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_fact_MLPQ_3.pkl\n",
      "INFO - 01/15/23 00:09:37 - 1:03:10 -  answer_net_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_fact_MLP_3.pkl\n"
     ]
    }
   ],
   "source": [
    "#!python main.py --gpu_id 8 --exp_name MLP_knowledge_space --exp_id W2V --fusion_model BAN --data_choice 3 --method_choice W2V --ZSL 0 --save_model 1 --fact_map 1\n",
    "# !python main.py --gpu_id 8 --exp_name MLP_knowledge_space --exp_id W2V --fusion_model UD --data_choice 3 --method_choice W2V --ZSL 0 --save_model 1 --relation_map 1\n",
    "\n",
    "\n",
    "# !python main_bert_cnn.py --gpu_id 8 --exp_name MLP_knowledge_space --exp_id W2V --fusion_model BERT --data_choice 3 --method_choice W2V --ZSL 0 --save_model 1 --fact_map 1\n",
    "\n",
    "!python main_relation.py --gpu_id 8 --exp_name MLP_knowledge_space --exp_id W2V --fusion_model MLPQ --data_choice 3 --method_choice W2V --ZSL 0 --save_model 1 --fact_map 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "606e5eef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-14T16:56:10.659241Z",
     "start_time": "2023-01-14T16:09:39.770422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 01/15/23 00:09:42 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 01/15/23 00:09:42 - 0:00:00 - The experiment will be stored in dump/0115-MLP_knowledge_space/W2V\n",
      "                                     \n",
      "INFO - 01/15/23 00:09:42 - 0:00:00 - Running command: python main_relation.py --gpu_id 8 --exp_name MLP_knowledge_space --exp_id W2V --fusion_model MLPQ --data_choice 3 --method_choice W2V --ZSL 0 --save_model 1 --relation_map 1\n",
      "\n",
      "2023-01-15 00:09:42.623122: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-15 00:09:42.623183: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 16\n",
      "batch_size 16\n",
      "fusion_model:\n",
      "MLPQ(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      "  (w_emb): WordEmbedding(\n",
      "    (emb): Embedding(15422, 300, padding_idx=15421)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (text): Seq2SeqRNN(\n",
      "    (rnn): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  )\n",
      ")\n",
      "Answer Model:\n",
      "MLP(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "train E000: 100% 167/167 [00:29<00:00,  5.68it/s]\n",
      "INFO - 01/15/23 00:10:29 - 0:00:47 - Train Epoch 0: LOSS= 3.17109, lr= 0.000500, acc1= 35.29,acc3= 60.02,acc10= 86.02\n",
      "train E001: 100% 167/167 [00:20<00:00,  8.24it/s]\n",
      "INFO - 01/15/23 00:10:49 - 0:01:07 - Train Epoch 1: LOSS= 2.29021, lr= 0.000750, acc1= 50.39,acc3= 70.96,acc10= 91.53\n",
      "eval E001: 100% 177/177 [00:10<00:00, 17.16it/s]\n",
      "INFO - 01/15/23 00:11:00 - 0:01:18 - #################################################################################################################\n",
      "INFO - 01/15/23 00:11:00 - 0:01:18 - Test Epoch 1: LOSS= 1.59917, acc1= 63.48, acc3= 80.20, acc10= 94.47\n",
      "INFO - 01/15/23 00:11:00 - 0:01:18 - #################################################################################################################\n",
      "train E002: 100% 167/167 [00:13<00:00, 12.11it/s]\n",
      "INFO - 01/15/23 00:11:14 - 0:01:32 - Train Epoch 2: LOSS= 1.73274, lr= 0.001000, acc1= 57.06,acc3= 77.89,acc10= 94.60\n",
      "eval E002: 100% 177/177 [00:10<00:00, 17.22it/s]\n",
      "INFO - 01/15/23 00:11:24 - 0:01:42 - #################################################################################################################\n",
      "INFO - 01/15/23 00:11:24 - 0:01:42 - Test Epoch 2: LOSS= 1.53140, acc1= 61.85, acc3= 80.62, acc10= 95.50\n",
      "INFO - 01/15/23 00:11:24 - 0:01:42 - #################################################################################################################\n",
      "train E003: 100% 167/167 [00:13<00:00, 12.10it/s]\n",
      "INFO - 01/15/23 00:11:38 - 0:01:56 - Train Epoch 3: LOSS= 1.54327, lr= 0.001250, acc1= 61.00,acc3= 81.23,acc10= 95.47\n",
      "eval E003: 100% 177/177 [00:10<00:00, 17.12it/s]\n",
      "INFO - 01/15/23 00:11:48 - 0:02:06 - #################################################################################################################\n",
      "INFO - 01/15/23 00:11:48 - 0:02:06 - Test Epoch 3: LOSS= 1.56033, acc1= 54.41, acc3= 79.63, acc10= 94.97\n",
      "INFO - 01/15/23 00:11:48 - 0:02:06 - #################################################################################################################\n",
      "train E004: 100% 167/167 [00:13<00:00, 12.14it/s]\n",
      "INFO - 01/15/23 00:12:02 - 0:02:20 - Train Epoch 4: LOSS= 1.36243, lr= 0.001500, acc1= 62.61,acc3= 82.24,acc10= 96.48\n",
      "eval E004: 100% 177/177 [00:10<00:00, 16.56it/s]\n",
      "INFO - 01/15/23 00:12:12 - 0:02:30 - #################################################################################################################\n",
      "INFO - 01/15/23 00:12:12 - 0:02:30 - Test Epoch 4: LOSS= 1.33254, acc1= 65.57, acc3= 83.46, acc10= 96.07\n",
      "INFO - 01/15/23 00:12:12 - 0:02:30 - #################################################################################################################\n",
      "train E005: 100% 167/167 [00:13<00:00, 12.24it/s]\n",
      "INFO - 01/15/23 00:12:26 - 0:02:44 - Train Epoch 5: LOSS= 1.34864, lr= 0.001750, acc1= 65.08,acc3= 83.51,acc10= 96.74\n",
      "eval E005: 100% 177/177 [00:10<00:00, 17.39it/s]\n",
      "INFO - 01/15/23 00:12:36 - 0:02:54 - #################################################################################################################\n",
      "INFO - 01/15/23 00:12:36 - 0:02:54 - Test Epoch 5: LOSS= 1.50962, acc1= 64.97, acc3= 80.09, acc10= 94.58\n",
      "INFO - 01/15/23 00:12:36 - 0:02:54 - #################################################################################################################\n",
      "train E006: 100% 167/167 [00:13<00:00, 12.23it/s]\n",
      "INFO - 01/15/23 00:12:50 - 0:03:08 - Train Epoch 6: LOSS= 1.30005, lr= 0.002000, acc1= 65.49,acc3= 85.35,acc10= 97.45\n",
      "eval E006: 100% 177/177 [00:09<00:00, 17.74it/s]\n",
      "INFO - 01/15/23 00:13:00 - 0:03:18 - #################################################################################################################\n",
      "INFO - 01/15/23 00:13:00 - 0:03:18 - Test Epoch 6: LOSS= 1.50481, acc1= 58.55, acc3= 81.44, acc10= 95.61\n",
      "INFO - 01/15/23 00:13:00 - 0:03:18 - #################################################################################################################\n",
      "train E007: 100% 167/167 [00:13<00:00, 11.98it/s]\n",
      "INFO - 01/15/23 00:13:14 - 0:03:32 - Train Epoch 7: LOSS= 1.25038, lr= 0.002000, acc1= 66.99,acc3= 85.95,acc10= 97.08\n",
      "eval E007: 100% 177/177 [00:10<00:00, 17.59it/s]\n",
      "INFO - 01/15/23 00:13:24 - 0:03:42 - #################################################################################################################\n",
      "INFO - 01/15/23 00:13:24 - 0:03:42 - Test Epoch 7: LOSS= 1.48560, acc1= 65.99, acc3= 82.15, acc10= 96.00\n",
      "INFO - 01/15/23 00:13:24 - 0:03:42 - #################################################################################################################\n",
      "train E008: 100% 167/167 [00:13<00:00, 12.39it/s]\n",
      "INFO - 01/15/23 00:13:37 - 0:03:55 - Train Epoch 8: LOSS= 1.17100, lr= 0.002000, acc1= 69.13,acc3= 87.04,acc10= 97.23\n",
      "eval E008: 100% 177/177 [00:10<00:00, 17.55it/s]\n",
      "INFO - 01/15/23 00:13:47 - 0:04:06 - #################################################################################################################\n",
      "INFO - 01/15/23 00:13:47 - 0:04:06 - Test Epoch 8: LOSS= 1.43885, acc1= 65.07, acc3= 84.38, acc10= 96.00\n",
      "INFO - 01/15/23 00:13:47 - 0:04:06 - #################################################################################################################\n",
      "train E009: 100% 167/167 [00:13<00:00, 12.18it/s]\n",
      "INFO - 01/15/23 00:14:01 - 0:04:19 - Train Epoch 9: LOSS= 0.96533, lr= 0.002000, acc1= 73.29,acc3= 89.73,acc10= 97.98\n",
      "eval E009: 100% 177/177 [00:10<00:00, 17.22it/s]\n",
      "INFO - 01/15/23 00:14:11 - 0:04:30 - #################################################################################################################\n",
      "INFO - 01/15/23 00:14:11 - 0:04:30 - Test Epoch 9: LOSS= 1.58183, acc1= 63.20, acc3= 82.93, acc10= 96.10\n",
      "INFO - 01/15/23 00:14:11 - 0:04:30 - #################################################################################################################\n",
      "train E010: 100% 167/167 [00:13<00:00, 12.47it/s]\n",
      "INFO - 01/15/23 00:14:25 - 0:04:43 - Train Epoch 10: LOSS= 0.98460, lr= 0.002000, acc1= 73.44,acc3= 90.56,acc10= 98.13\n",
      "eval E010: 100% 177/177 [00:10<00:00, 17.50it/s]\n",
      "INFO - 01/15/23 00:14:35 - 0:04:53 - #################################################################################################################\n",
      "INFO - 01/15/23 00:14:35 - 0:04:53 - Test Epoch 10: LOSS= 1.42583, acc1= 66.95, acc3= 85.65, acc10= 96.07\n",
      "INFO - 01/15/23 00:14:35 - 0:04:53 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E011: 100% 167/167 [00:13<00:00, 12.16it/s]\n",
      "INFO - 01/15/23 00:14:49 - 0:05:07 - Train Epoch 11: LOSS= 0.89722, lr= 0.002000, acc1= 76.28,acc3= 90.71,acc10= 98.61\n",
      "eval E011: 100% 177/177 [00:10<00:00, 17.22it/s]\n",
      "INFO - 01/15/23 00:14:59 - 0:05:17 - #################################################################################################################\n",
      "INFO - 01/15/23 00:14:59 - 0:05:17 - Test Epoch 11: LOSS= 1.42901, acc1= 65.32, acc3= 83.10, acc10= 96.28\n",
      "INFO - 01/15/23 00:14:59 - 0:05:17 - #################################################################################################################\n",
      "train E012: 100% 167/167 [00:14<00:00, 11.82it/s]\n",
      "INFO - 01/15/23 00:15:13 - 0:05:31 - Train Epoch 12: LOSS= 0.93362, lr= 0.002000, acc1= 75.23,acc3= 91.49,acc10= 98.54\n",
      "eval E012: 100% 177/177 [00:09<00:00, 17.83it/s]\n",
      "INFO - 01/15/23 00:15:23 - 0:05:41 - #################################################################################################################\n",
      "INFO - 01/15/23 00:15:23 - 0:05:41 - Test Epoch 12: LOSS= 1.60982, acc1= 65.50, acc3= 83.60, acc10= 96.35\n",
      "INFO - 01/15/23 00:15:23 - 0:05:41 - #################################################################################################################\n",
      "train E013: 100% 167/167 [00:13<00:00, 11.97it/s]\n",
      "INFO - 01/15/23 00:15:37 - 0:05:55 - Train Epoch 13: LOSS= 0.88077, lr= 0.002000, acc1= 77.59,acc3= 93.18,acc10= 98.95\n",
      "eval E013: 100% 177/177 [00:09<00:00, 18.09it/s]\n",
      "INFO - 01/15/23 00:15:47 - 0:06:05 - #################################################################################################################\n",
      "INFO - 01/15/23 00:15:47 - 0:06:05 - Test Epoch 13: LOSS= 1.56241, acc1= 65.11, acc3= 81.76, acc10= 96.10\n",
      "INFO - 01/15/23 00:15:47 - 0:06:05 - #################################################################################################################\n",
      "train E014: 100% 167/167 [00:14<00:00, 11.87it/s]\n",
      "INFO - 01/15/23 00:16:01 - 0:06:19 - Train Epoch 14: LOSS= 0.62563, lr= 0.001400, acc1= 81.60,acc3= 94.75,acc10= 99.48\n",
      "eval E014: 100% 177/177 [00:10<00:00, 17.63it/s]\n",
      "INFO - 01/15/23 00:16:11 - 0:06:29 - #################################################################################################################\n",
      "INFO - 01/15/23 00:16:11 - 0:06:29 - Test Epoch 14: LOSS= 1.61086, acc1= 67.52, acc3= 85.05, acc10= 96.88\n",
      "INFO - 01/15/23 00:16:11 - 0:06:29 - #################################################################################################################\n",
      "train E015: 100% 167/167 [00:14<00:00, 11.81it/s]\n",
      "INFO - 01/15/23 00:16:25 - 0:06:43 - Train Epoch 15: LOSS= 0.53038, lr= 0.001400, acc1= 83.40,acc3= 96.74,acc10= 99.70\n",
      "eval E015: 100% 177/177 [00:09<00:00, 17.91it/s]\n",
      "INFO - 01/15/23 00:16:35 - 0:06:53 - #################################################################################################################\n",
      "INFO - 01/15/23 00:16:35 - 0:06:53 - Test Epoch 15: LOSS= 1.64582, acc1= 67.34, acc3= 85.37, acc10= 95.96\n",
      "INFO - 01/15/23 00:16:35 - 0:06:53 - #################################################################################################################\n",
      "train E016: 100% 167/167 [00:13<00:00, 12.07it/s]\n",
      "INFO - 01/15/23 00:16:49 - 0:07:07 - Train Epoch 16: LOSS= 0.50516, lr= 0.001400, acc1= 83.63,acc3= 97.08,acc10= 99.78\n",
      "eval E016: 100% 177/177 [00:10<00:00, 16.72it/s]\n",
      "INFO - 01/15/23 00:16:59 - 0:07:18 - #################################################################################################################\n",
      "INFO - 01/15/23 00:16:59 - 0:07:18 - Test Epoch 16: LOSS= 1.71126, acc1= 68.05, acc3= 85.55, acc10= 96.71\n",
      "INFO - 01/15/23 00:16:59 - 0:07:18 - #################################################################################################################\n",
      "train E017: 100% 167/167 [00:13<00:00, 12.48it/s]\n",
      "INFO - 01/15/23 00:17:13 - 0:07:31 - Train Epoch 17: LOSS= 0.41499, lr= 0.000980, acc1= 86.47,acc3= 97.53,acc10= 99.85\n",
      "eval E017: 100% 177/177 [00:10<00:00, 16.72it/s]\n",
      "INFO - 01/15/23 00:17:23 - 0:07:41 - #################################################################################################################\n",
      "INFO - 01/15/23 00:17:23 - 0:07:41 - Test Epoch 17: LOSS= 1.91066, acc1= 68.58, acc3= 84.84, acc10= 96.67\n",
      "INFO - 01/15/23 00:17:23 - 0:07:41 - #################################################################################################################\n",
      "train E018: 100% 167/167 [00:13<00:00, 11.99it/s]\n",
      "INFO - 01/15/23 00:17:37 - 0:07:55 - Train Epoch 18: LOSS= 0.34278, lr= 0.000980, acc1= 88.35,acc3= 98.65,acc10= 99.93\n",
      "eval E018: 100% 177/177 [00:10<00:00, 16.81it/s]\n",
      "INFO - 01/15/23 00:17:48 - 0:08:06 - #################################################################################################################\n",
      "INFO - 01/15/23 00:17:48 - 0:08:06 - Test Epoch 18: LOSS= 1.90056, acc1= 68.19, acc3= 85.76, acc10= 97.02\n",
      "INFO - 01/15/23 00:17:48 - 0:08:06 - #################################################################################################################\n",
      "train E019: 100% 167/167 [00:14<00:00, 11.92it/s]\n",
      "INFO - 01/15/23 00:18:02 - 0:08:20 - Train Epoch 19: LOSS= 0.33422, lr= 0.000980, acc1= 89.25,acc3= 99.06,acc10= 99.85\n",
      "eval E019: 100% 177/177 [00:10<00:00, 17.30it/s]\n",
      "INFO - 01/15/23 00:18:12 - 0:08:30 - #################################################################################################################\n",
      "INFO - 01/15/23 00:18:12 - 0:08:30 - Test Epoch 19: LOSS= 1.92935, acc1= 67.06, acc3= 85.94, acc10= 97.06\n",
      "INFO - 01/15/23 00:18:12 - 0:08:30 - #################################################################################################################\n",
      "train E020: 100% 167/167 [00:13<00:00, 11.94it/s]\n",
      "INFO - 01/15/23 00:18:26 - 0:08:44 - Train Epoch 20: LOSS= 0.26889, lr= 0.000686, acc1= 91.31,acc3= 98.76,acc10= 99.89\n",
      "eval E020: 100% 177/177 [00:25<00:00,  6.84it/s]\n",
      "INFO - 01/15/23 00:18:52 - 0:09:10 - #################################################################################################################\n",
      "INFO - 01/15/23 00:18:52 - 0:09:10 - Test Epoch 20: LOSS= 2.03858, acc1= 67.66, acc3= 86.11, acc10= 97.13\n",
      "INFO - 01/15/23 00:18:52 - 0:09:10 - #################################################################################################################\n",
      "train E021: 100% 167/167 [00:29<00:00,  5.57it/s]\n",
      "INFO - 01/15/23 00:19:22 - 0:09:40 - Train Epoch 21: LOSS= 0.25852, lr= 0.000686, acc1= 91.98,acc3= 99.21,acc10= 99.96\n",
      "eval E021: 100% 177/177 [00:27<00:00,  6.45it/s]\n",
      "INFO - 01/15/23 00:19:49 - 0:10:07 - #################################################################################################################\n",
      "INFO - 01/15/23 00:19:49 - 0:10:07 - Test Epoch 21: LOSS= 2.01033, acc1= 67.55, acc3= 86.04, acc10= 96.85\n",
      "INFO - 01/15/23 00:19:49 - 0:10:07 - #################################################################################################################\n",
      "train E022: 100% 167/167 [00:28<00:00,  5.79it/s]\n",
      "INFO - 01/15/23 00:20:18 - 0:10:36 - Train Epoch 22: LOSS= 0.23391, lr= 0.000686, acc1= 92.92,acc3= 99.25,acc10= 100.00\n",
      "eval E022: 100% 177/177 [00:27<00:00,  6.36it/s]\n",
      "INFO - 01/15/23 00:20:46 - 0:11:04 - #################################################################################################################\n",
      "INFO - 01/15/23 00:20:46 - 0:11:04 - Test Epoch 22: LOSS= 2.01387, acc1= 67.98, acc3= 86.40, acc10= 96.78\n",
      "INFO - 01/15/23 00:20:46 - 0:11:04 - #################################################################################################################\n",
      "train E023: 100% 167/167 [00:29<00:00,  5.61it/s]\n",
      "INFO - 01/15/23 00:21:16 - 0:11:34 - Train Epoch 23: LOSS= 0.18725, lr= 0.000480, acc1= 94.23,acc3= 99.59,acc10= 99.96\n",
      "eval E023: 100% 177/177 [00:28<00:00,  6.20it/s]\n",
      "INFO - 01/15/23 00:21:44 - 0:12:02 - #################################################################################################################\n",
      "INFO - 01/15/23 00:21:44 - 0:12:02 - Test Epoch 23: LOSS= 2.03369, acc1= 67.55, acc3= 86.40, acc10= 96.95\n",
      "INFO - 01/15/23 00:21:44 - 0:12:02 - #################################################################################################################\n",
      "train E024: 100% 167/167 [00:29<00:00,  5.58it/s]\n",
      "INFO - 01/15/23 00:22:14 - 0:12:32 - Train Epoch 24: LOSS= 0.18275, lr= 0.000480, acc1= 93.33,acc3= 99.74,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E024: 100% 177/177 [00:28<00:00,  6.25it/s]\n",
      "INFO - 01/15/23 00:22:43 - 0:13:01 - #################################################################################################################\n",
      "INFO - 01/15/23 00:22:43 - 0:13:01 - Test Epoch 24: LOSS= 2.17556, acc1= 68.26, acc3= 86.54, acc10= 96.95\n",
      "INFO - 01/15/23 00:22:43 - 0:13:01 - #################################################################################################################\n",
      "train E025: 100% 167/167 [00:28<00:00,  5.83it/s]\n",
      "INFO - 01/15/23 00:23:11 - 0:13:29 - Train Epoch 25: LOSS= 0.18117, lr= 0.000480, acc1= 94.08,acc3= 99.78,acc10= 100.00\n",
      "eval E025: 100% 177/177 [00:27<00:00,  6.54it/s]\n",
      "INFO - 01/15/23 00:23:38 - 0:13:56 - #################################################################################################################\n",
      "INFO - 01/15/23 00:23:38 - 0:13:56 - Test Epoch 25: LOSS= 2.24735, acc1= 68.01, acc3= 85.83, acc10= 96.99\n",
      "INFO - 01/15/23 00:23:38 - 0:13:56 - #################################################################################################################\n",
      "train E026: 100% 167/167 [00:28<00:00,  5.86it/s]\n",
      "INFO - 01/15/23 00:24:07 - 0:14:25 - Train Epoch 26: LOSS= 0.15557, lr= 0.000336, acc1= 94.75,acc3= 99.81,acc10= 100.00\n",
      "eval E026: 100% 177/177 [00:27<00:00,  6.34it/s]\n",
      "INFO - 01/15/23 00:24:35 - 0:14:53 - #################################################################################################################\n",
      "INFO - 01/15/23 00:24:35 - 0:14:53 - Test Epoch 26: LOSS= 2.21979, acc1= 68.37, acc3= 86.43, acc10= 96.71\n",
      "INFO - 01/15/23 00:24:35 - 0:14:53 - #################################################################################################################\n",
      "train E027: 100% 167/167 [00:27<00:00,  6.01it/s]\n",
      "INFO - 01/15/23 00:25:03 - 0:15:21 - Train Epoch 27: LOSS= 0.14582, lr= 0.000336, acc1= 95.47,acc3= 99.78,acc10= 100.00\n",
      "eval E027: 100% 177/177 [00:27<00:00,  6.37it/s]\n",
      "INFO - 01/15/23 00:25:30 - 0:15:48 - #################################################################################################################\n",
      "INFO - 01/15/23 00:25:30 - 0:15:48 - Test Epoch 27: LOSS= 2.37098, acc1= 68.58, acc3= 86.40, acc10= 97.20\n",
      "INFO - 01/15/23 00:25:30 - 0:15:48 - #################################################################################################################\n",
      "train E028: 100% 167/167 [00:30<00:00,  5.56it/s]\n",
      "INFO - 01/15/23 00:26:00 - 0:16:18 - Train Epoch 28: LOSS= 0.15763, lr= 0.000336, acc1= 94.90,acc3= 99.85,acc10= 100.00\n",
      "eval E028: 100% 177/177 [00:27<00:00,  6.39it/s]\n",
      "INFO - 01/15/23 00:26:28 - 0:16:46 - #################################################################################################################\n",
      "INFO - 01/15/23 00:26:28 - 0:16:46 - Test Epoch 28: LOSS= 2.34731, acc1= 68.72, acc3= 86.26, acc10= 96.92\n",
      "INFO - 01/15/23 00:26:28 - 0:16:46 - #################################################################################################################\n",
      "train E029: 100% 167/167 [00:29<00:00,  5.64it/s]\n",
      "INFO - 01/15/23 00:26:58 - 0:17:16 - Train Epoch 29: LOSS= 0.12717, lr= 0.000235, acc1= 95.50,acc3= 99.93,acc10= 100.00\n",
      "eval E029: 100% 177/177 [00:26<00:00,  6.76it/s]\n",
      "INFO - 01/15/23 00:27:24 - 0:17:42 - #################################################################################################################\n",
      "INFO - 01/15/23 00:27:24 - 0:17:42 - Test Epoch 29: LOSS= 2.39879, acc1= 68.30, acc3= 86.01, acc10= 96.99\n",
      "INFO - 01/15/23 00:27:24 - 0:17:42 - #################################################################################################################\n",
      "train E030: 100% 167/167 [00:29<00:00,  5.62it/s]\n",
      "INFO - 01/15/23 00:27:54 - 0:18:12 - Train Epoch 30: LOSS= 0.11686, lr= 0.000235, acc1= 96.37,acc3= 99.74,acc10= 100.00\n",
      "eval E030: 100% 177/177 [00:26<00:00,  6.77it/s]\n",
      "INFO - 01/15/23 00:28:20 - 0:18:38 - #################################################################################################################\n",
      "INFO - 01/15/23 00:28:20 - 0:18:38 - Test Epoch 30: LOSS= 2.48467, acc1= 68.51, acc3= 86.26, acc10= 97.06\n",
      "INFO - 01/15/23 00:28:20 - 0:18:38 - #################################################################################################################\n",
      "train E031: 100% 167/167 [00:28<00:00,  5.76it/s]\n",
      "INFO - 01/15/23 00:28:49 - 0:19:07 - Train Epoch 31: LOSS= 0.12792, lr= 0.000235, acc1= 95.73,acc3= 99.70,acc10= 100.00\n",
      "eval E031: 100% 177/177 [00:27<00:00,  6.54it/s]\n",
      "INFO - 01/15/23 00:29:16 - 0:19:34 - #################################################################################################################\n",
      "INFO - 01/15/23 00:29:16 - 0:19:34 - Test Epoch 31: LOSS= 2.44406, acc1= 68.44, acc3= 86.22, acc10= 97.02\n",
      "INFO - 01/15/23 00:29:16 - 0:19:34 - #################################################################################################################\n",
      "train E032: 100% 167/167 [00:29<00:00,  5.64it/s]\n",
      "INFO - 01/15/23 00:29:45 - 0:20:04 - Train Epoch 32: LOSS= 0.11898, lr= 0.000165, acc1= 95.99,acc3= 99.89,acc10= 99.96\n",
      "eval E032: 100% 177/177 [00:27<00:00,  6.51it/s]\n",
      "INFO - 01/15/23 00:30:13 - 0:20:31 - #################################################################################################################\n",
      "INFO - 01/15/23 00:30:13 - 0:20:31 - Test Epoch 32: LOSS= 2.48109, acc1= 68.86, acc3= 86.22, acc10= 97.13\n",
      "INFO - 01/15/23 00:30:13 - 0:20:31 - #################################################################################################################\n",
      "train E033: 100% 167/167 [00:28<00:00,  5.83it/s]\n",
      "INFO - 01/15/23 00:30:41 - 0:20:59 - Train Epoch 33: LOSS= 0.11212, lr= 0.000165, acc1= 96.22,acc3= 99.81,acc10= 100.00\n",
      "eval E033: 100% 177/177 [00:27<00:00,  6.53it/s]\n",
      "INFO - 01/15/23 00:31:08 - 0:21:26 - #################################################################################################################\n",
      "INFO - 01/15/23 00:31:08 - 0:21:26 - Test Epoch 33: LOSS= 2.53409, acc1= 67.84, acc3= 85.97, acc10= 96.95\n",
      "INFO - 01/15/23 00:31:08 - 0:21:26 - #################################################################################################################\n",
      "train E034: 100% 167/167 [00:28<00:00,  5.93it/s]\n",
      "INFO - 01/15/23 00:31:37 - 0:21:55 - Train Epoch 34: LOSS= 0.10459, lr= 0.000165, acc1= 96.55,acc3= 99.89,acc10= 100.00\n",
      "eval E034: 100% 177/177 [00:26<00:00,  6.74it/s]\n",
      "INFO - 01/15/23 00:32:03 - 0:22:21 - #################################################################################################################\n",
      "INFO - 01/15/23 00:32:03 - 0:22:21 - Test Epoch 34: LOSS= 2.50744, acc1= 67.91, acc3= 86.47, acc10= 96.92\n",
      "INFO - 01/15/23 00:32:03 - 0:22:21 - #################################################################################################################\n",
      "train E035: 100% 167/167 [00:28<00:00,  5.90it/s]\n",
      "INFO - 01/15/23 00:32:31 - 0:22:49 - Train Epoch 35: LOSS= 0.09560, lr= 0.000115, acc1= 96.48,acc3= 99.81,acc10= 100.00\n",
      "eval E035: 100% 177/177 [00:25<00:00,  6.81it/s]\n",
      "INFO - 01/15/23 00:32:57 - 0:23:15 - #################################################################################################################\n",
      "INFO - 01/15/23 00:32:57 - 0:23:15 - Test Epoch 35: LOSS= 2.57573, acc1= 68.76, acc3= 86.29, acc10= 96.95\n",
      "INFO - 01/15/23 00:32:57 - 0:23:15 - #################################################################################################################\n",
      "train E036: 100% 167/167 [00:28<00:00,  5.77it/s]\n",
      "INFO - 01/15/23 00:33:26 - 0:23:44 - Train Epoch 36: LOSS= 0.09310, lr= 0.000115, acc1= 96.70,acc3= 99.89,acc10= 100.00\n",
      "eval E036: 100% 177/177 [00:26<00:00,  6.61it/s]\n",
      "INFO - 01/15/23 00:33:53 - 0:24:11 - #################################################################################################################\n",
      "INFO - 01/15/23 00:33:53 - 0:24:11 - Test Epoch 36: LOSS= 2.55770, acc1= 68.47, acc3= 86.43, acc10= 96.88\n",
      "INFO - 01/15/23 00:33:53 - 0:24:11 - #################################################################################################################\n",
      "train E037: 100% 167/167 [00:28<00:00,  5.79it/s]\n",
      "INFO - 01/15/23 00:34:22 - 0:24:40 - Train Epoch 37: LOSS= 0.10082, lr= 0.000115, acc1= 96.33,acc3= 99.89,acc10= 100.00\n",
      "eval E037: 100% 177/177 [00:26<00:00,  6.61it/s]\n",
      "INFO - 01/15/23 00:34:48 - 0:25:07 - #################################################################################################################\n",
      "INFO - 01/15/23 00:34:48 - 0:25:07 - Test Epoch 37: LOSS= 2.55234, acc1= 68.90, acc3= 86.29, acc10= 96.88\n",
      "INFO - 01/15/23 00:34:48 - 0:25:07 - #################################################################################################################\n",
      "train E038: 100% 167/167 [00:27<00:00,  5.98it/s]\n",
      "INFO - 01/15/23 00:35:16 - 0:25:35 - Train Epoch 38: LOSS= 0.09503, lr= 0.000081, acc1= 96.63,acc3= 99.89,acc10= 100.00\n",
      "eval E038: 100% 177/177 [00:25<00:00,  6.82it/s]\n",
      "INFO - 01/15/23 00:35:42 - 0:26:00 - #################################################################################################################\n",
      "INFO - 01/15/23 00:35:42 - 0:26:00 - Test Epoch 38: LOSS= 2.55026, acc1= 68.79, acc3= 86.43, acc10= 96.92\n",
      "INFO - 01/15/23 00:35:42 - 0:26:00 - #################################################################################################################\n",
      "train E039: 100% 167/167 [00:27<00:00,  6.02it/s]\n",
      "INFO - 01/15/23 00:36:10 - 0:26:28 - Train Epoch 39: LOSS= 0.09054, lr= 0.000081, acc1= 97.19,acc3= 99.89,acc10= 100.00\n",
      "eval E039: 100% 177/177 [00:26<00:00,  6.60it/s]\n",
      "INFO - 01/15/23 00:36:37 - 0:26:55 - #################################################################################################################\n",
      "INFO - 01/15/23 00:36:37 - 0:26:55 - Test Epoch 39: LOSS= 2.55483, acc1= 68.69, acc3= 86.29, acc10= 96.99\n",
      "INFO - 01/15/23 00:36:37 - 0:26:55 - #################################################################################################################\n",
      "train E040: 100% 167/167 [00:28<00:00,  5.92it/s]\n",
      "INFO - 01/15/23 00:37:05 - 0:27:23 - Train Epoch 40: LOSS= 0.09748, lr= 0.000081, acc1= 96.48,acc3= 99.81,acc10= 100.00\n",
      "eval E040: 100% 177/177 [00:27<00:00,  6.35it/s]\n",
      "INFO - 01/15/23 00:37:33 - 0:27:51 - #################################################################################################################\n",
      "INFO - 01/15/23 00:37:33 - 0:27:51 - Test Epoch 40: LOSS= 2.56682, acc1= 68.76, acc3= 86.33, acc10= 97.06\n",
      "INFO - 01/15/23 00:37:33 - 0:27:51 - #################################################################################################################\n",
      "train E041: 100% 167/167 [00:28<00:00,  5.89it/s]\n",
      "INFO - 01/15/23 00:38:01 - 0:28:20 - Train Epoch 41: LOSS= 0.09294, lr= 0.000056, acc1= 96.89,acc3= 99.93,acc10= 100.00\n",
      "eval E041: 100% 177/177 [00:26<00:00,  6.57it/s]\n",
      "INFO - 01/15/23 00:38:28 - 0:28:46 - #################################################################################################################\n",
      "INFO - 01/15/23 00:38:28 - 0:28:46 - Test Epoch 41: LOSS= 2.59249, acc1= 68.90, acc3= 86.43, acc10= 97.06\n",
      "INFO - 01/15/23 00:38:28 - 0:28:46 - #################################################################################################################\n",
      "train E042: 100% 167/167 [00:28<00:00,  5.77it/s]\n",
      "INFO - 01/15/23 00:38:57 - 0:29:15 - Train Epoch 42: LOSS= 0.08512, lr= 0.000056, acc1= 97.08,acc3= 99.93,acc10= 100.00\n",
      "eval E042: 100% 177/177 [00:25<00:00,  6.92it/s]\n",
      "INFO - 01/15/23 00:39:23 - 0:29:41 - #################################################################################################################\n",
      "INFO - 01/15/23 00:39:23 - 0:29:41 - Test Epoch 42: LOSS= 2.59528, acc1= 69.15, acc3= 86.40, acc10= 97.02\n",
      "INFO - 01/15/23 00:39:23 - 0:29:41 - #################################################################################################################\n",
      "train E043: 100% 167/167 [00:27<00:00,  6.05it/s]\n",
      "INFO - 01/15/23 00:39:50 - 0:30:09 - Train Epoch 43: LOSS= 0.07427, lr= 0.000056, acc1= 97.30,acc3= 99.96,acc10= 100.00\n",
      "eval E043: 100% 177/177 [00:10<00:00, 16.59it/s]\n",
      "INFO - 01/15/23 00:40:01 - 0:30:19 - #################################################################################################################\n",
      "INFO - 01/15/23 00:40:01 - 0:30:19 - Test Epoch 43: LOSS= 2.62995, acc1= 68.90, acc3= 86.36, acc10= 97.06\n",
      "INFO - 01/15/23 00:40:01 - 0:30:19 - #################################################################################################################\n",
      "train E044: 100% 167/167 [00:13<00:00, 11.94it/s]\n",
      "INFO - 01/15/23 00:40:15 - 0:30:33 - Train Epoch 44: LOSS= 0.08390, lr= 0.000040, acc1= 96.93,acc3= 99.96,acc10= 100.00\n",
      "eval E044: 100% 177/177 [00:10<00:00, 16.85it/s]\n",
      "INFO - 01/15/23 00:40:26 - 0:30:44 - #################################################################################################################\n",
      "INFO - 01/15/23 00:40:26 - 0:30:44 - Test Epoch 44: LOSS= 2.66689, acc1= 68.61, acc3= 86.47, acc10= 96.95\n",
      "INFO - 01/15/23 00:40:26 - 0:30:44 - #################################################################################################################\n",
      "train E045: 100% 167/167 [00:13<00:00, 12.24it/s]\n",
      "INFO - 01/15/23 00:40:39 - 0:30:57 - Train Epoch 45: LOSS= 0.08354, lr= 0.000040, acc1= 96.89,acc3= 99.93,acc10= 100.00\n",
      "eval E045: 100% 177/177 [00:10<00:00, 17.52it/s]\n",
      "INFO - 01/15/23 00:40:49 - 0:31:08 - #################################################################################################################\n",
      "INFO - 01/15/23 00:40:49 - 0:31:08 - Test Epoch 45: LOSS= 2.64740, acc1= 68.54, acc3= 86.29, acc10= 96.99\n",
      "INFO - 01/15/23 00:40:49 - 0:31:08 - #################################################################################################################\n",
      "train E046: 100% 167/167 [00:14<00:00, 11.77it/s]\n",
      "INFO - 01/15/23 00:41:04 - 0:31:22 - Train Epoch 46: LOSS= 0.08450, lr= 0.000040, acc1= 97.00,acc3= 100.00,acc10= 100.00\n",
      "eval E046: 100% 177/177 [00:10<00:00, 16.82it/s]\n",
      "INFO - 01/15/23 00:41:14 - 0:31:32 - #################################################################################################################\n",
      "INFO - 01/15/23 00:41:14 - 0:31:32 - Test Epoch 46: LOSS= 2.67268, acc1= 69.04, acc3= 86.47, acc10= 97.02\n",
      "INFO - 01/15/23 00:41:14 - 0:31:32 - #################################################################################################################\n",
      "train E047: 100% 167/167 [00:13<00:00, 12.82it/s]\n",
      "INFO - 01/15/23 00:41:27 - 0:31:45 - Train Epoch 47: LOSS= 0.08362, lr= 0.000040, acc1= 97.00,acc3= 99.96,acc10= 100.00\n",
      "eval E047: 100% 177/177 [00:10<00:00, 17.16it/s]\n",
      "INFO - 01/15/23 00:41:37 - 0:31:56 - #################################################################################################################\n",
      "INFO - 01/15/23 00:41:37 - 0:31:56 - Test Epoch 47: LOSS= 2.66161, acc1= 68.90, acc3= 86.47, acc10= 97.06\n",
      "INFO - 01/15/23 00:41:37 - 0:31:56 - #################################################################################################################\n",
      "train E048: 100% 167/167 [00:14<00:00, 11.81it/s]\n",
      "INFO - 01/15/23 00:41:52 - 0:32:10 - Train Epoch 48: LOSS= 0.07699, lr= 0.000040, acc1= 97.15,acc3= 99.96,acc10= 100.00\n",
      "eval E048: 100% 177/177 [00:10<00:00, 17.47it/s]\n",
      "INFO - 01/15/23 00:42:02 - 0:32:20 - #################################################################################################################\n",
      "INFO - 01/15/23 00:42:02 - 0:32:20 - Test Epoch 48: LOSS= 2.67092, acc1= 68.37, acc3= 86.33, acc10= 97.06\n",
      "INFO - 01/15/23 00:42:02 - 0:32:20 - #################################################################################################################\n",
      "train E049: 100% 167/167 [00:13<00:00, 12.12it/s]\n",
      "INFO - 01/15/23 00:42:16 - 0:32:34 - Train Epoch 49: LOSS= 0.07794, lr= 0.000040, acc1= 97.12,acc3= 99.89,acc10= 100.00\n",
      "eval E049: 100% 177/177 [00:10<00:00, 17.36it/s]\n",
      "INFO - 01/15/23 00:42:26 - 0:32:44 - #################################################################################################################\n",
      "INFO - 01/15/23 00:42:26 - 0:32:44 - Test Epoch 49: LOSS= 2.68209, acc1= 68.86, acc3= 86.33, acc10= 96.99\n",
      "INFO - 01/15/23 00:42:26 - 0:32:44 - #################################################################################################################\n",
      "train E050: 100% 167/167 [00:14<00:00, 11.76it/s]\n",
      "INFO - 01/15/23 00:42:40 - 0:32:58 - Train Epoch 50: LOSS= 0.07463, lr= 0.000040, acc1= 97.68,acc3= 99.96,acc10= 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E050: 100% 177/177 [00:10<00:00, 17.43it/s]\n",
      "INFO - 01/15/23 00:42:50 - 0:33:08 - #################################################################################################################\n",
      "INFO - 01/15/23 00:42:50 - 0:33:08 - Test Epoch 50: LOSS= 2.68920, acc1= 68.40, acc3= 86.26, acc10= 96.99\n",
      "INFO - 01/15/23 00:42:50 - 0:33:08 - #################################################################################################################\n",
      "train E051: 100% 167/167 [00:13<00:00, 12.26it/s]\n",
      "INFO - 01/15/23 00:43:04 - 0:33:22 - Train Epoch 51: LOSS= 0.08079, lr= 0.000040, acc1= 97.04,acc3= 99.89,acc10= 100.00\n",
      "eval E051: 100% 177/177 [00:11<00:00, 16.08it/s]\n",
      "INFO - 01/15/23 00:43:15 - 0:33:33 - #################################################################################################################\n",
      "INFO - 01/15/23 00:43:15 - 0:33:33 - Test Epoch 51: LOSS= 2.69025, acc1= 68.61, acc3= 86.43, acc10= 97.06\n",
      "INFO - 01/15/23 00:43:15 - 0:33:33 - #################################################################################################################\n",
      "train E052: 100% 167/167 [00:13<00:00, 12.45it/s]\n",
      "INFO - 01/15/23 00:43:28 - 0:33:46 - Train Epoch 52: LOSS= 0.07556, lr= 0.000040, acc1= 97.38,acc3= 99.89,acc10= 100.00\n",
      "eval E052: 100% 177/177 [00:10<00:00, 17.13it/s]\n",
      "INFO - 01/15/23 00:43:39 - 0:33:57 - #################################################################################################################\n",
      "INFO - 01/15/23 00:43:39 - 0:33:57 - Test Epoch 52: LOSS= 2.69356, acc1= 68.47, acc3= 86.29, acc10= 97.06\n",
      "INFO - 01/15/23 00:43:39 - 0:33:57 - #################################################################################################################\n",
      "train E053: 100% 167/167 [00:13<00:00, 11.95it/s]\n",
      "INFO - 01/15/23 00:43:52 - 0:34:11 - Train Epoch 53: LOSS= 0.08186, lr= 0.000040, acc1= 97.08,acc3= 99.89,acc10= 100.00\n",
      "eval E053: 100% 177/177 [00:10<00:00, 17.63it/s]\n",
      "INFO - 01/15/23 00:44:03 - 0:34:21 - #################################################################################################################\n",
      "INFO - 01/15/23 00:44:03 - 0:34:21 - Test Epoch 53: LOSS= 2.68753, acc1= 68.72, acc3= 86.43, acc10= 97.06\n",
      "INFO - 01/15/23 00:44:03 - 0:34:21 - #################################################################################################################\n",
      "train E054: 100% 167/167 [00:14<00:00, 11.90it/s]\n",
      "INFO - 01/15/23 00:44:17 - 0:34:35 - Train Epoch 54: LOSS= 0.08808, lr= 0.000040, acc1= 96.89,acc3= 99.89,acc10= 100.00\n",
      "eval E054: 100% 177/177 [00:09<00:00, 18.06it/s]\n",
      "INFO - 01/15/23 00:44:26 - 0:34:44 - #################################################################################################################\n",
      "INFO - 01/15/23 00:44:26 - 0:34:44 - Test Epoch 54: LOSS= 2.67302, acc1= 68.26, acc3= 86.15, acc10= 97.06\n",
      "INFO - 01/15/23 00:44:26 - 0:34:44 - #################################################################################################################\n",
      "train E055: 100% 167/167 [00:13<00:00, 12.23it/s]\n",
      "INFO - 01/15/23 00:44:40 - 0:34:58 - Train Epoch 55: LOSS= 0.08107, lr= 0.000040, acc1= 97.19,acc3= 99.96,acc10= 100.00\n",
      "eval E055: 100% 177/177 [00:09<00:00, 17.89it/s]\n",
      "INFO - 01/15/23 00:44:50 - 0:35:08 - #################################################################################################################\n",
      "INFO - 01/15/23 00:44:50 - 0:35:08 - Test Epoch 55: LOSS= 2.68171, acc1= 68.58, acc3= 86.18, acc10= 97.06\n",
      "INFO - 01/15/23 00:44:50 - 0:35:08 - #################################################################################################################\n",
      "train E056: 100% 167/167 [00:14<00:00, 11.69it/s]\n",
      "INFO - 01/15/23 00:45:04 - 0:35:22 - Train Epoch 56: LOSS= 0.07377, lr= 0.000040, acc1= 97.34,acc3= 99.89,acc10= 100.00\n",
      "eval E056: 100% 177/177 [00:09<00:00, 18.12it/s]\n",
      "INFO - 01/15/23 00:45:14 - 0:35:32 - #################################################################################################################\n",
      "INFO - 01/15/23 00:45:14 - 0:35:32 - Test Epoch 56: LOSS= 2.69869, acc1= 68.76, acc3= 86.22, acc10= 96.99\n",
      "INFO - 01/15/23 00:45:14 - 0:35:32 - #################################################################################################################\n",
      "train E057: 100% 167/167 [00:14<00:00, 11.83it/s]\n",
      "INFO - 01/15/23 00:45:28 - 0:35:46 - Train Epoch 57: LOSS= 0.07476, lr= 0.000040, acc1= 97.49,acc3= 99.96,acc10= 100.00\n",
      "eval E057: 100% 177/177 [00:10<00:00, 17.19it/s]\n",
      "INFO - 01/15/23 00:45:38 - 0:35:57 - #################################################################################################################\n",
      "INFO - 01/15/23 00:45:38 - 0:35:57 - Test Epoch 57: LOSS= 2.72386, acc1= 68.65, acc3= 86.36, acc10= 96.99\n",
      "INFO - 01/15/23 00:45:38 - 0:35:57 - #################################################################################################################\n",
      "train E058: 100% 167/167 [00:13<00:00, 12.22it/s]\n",
      "INFO - 01/15/23 00:45:52 - 0:36:10 - Train Epoch 58: LOSS= 0.06918, lr= 0.000040, acc1= 97.41,acc3= 99.96,acc10= 100.00\n",
      "eval E058: 100% 177/177 [00:10<00:00, 17.67it/s]\n",
      "INFO - 01/15/23 00:46:02 - 0:36:20 - #################################################################################################################\n",
      "INFO - 01/15/23 00:46:02 - 0:36:20 - Test Epoch 58: LOSS= 2.75439, acc1= 68.69, acc3= 86.22, acc10= 97.06\n",
      "INFO - 01/15/23 00:46:02 - 0:36:20 - #################################################################################################################\n",
      "train E059: 100% 167/167 [00:13<00:00, 12.02it/s]\n",
      "INFO - 01/15/23 00:46:16 - 0:36:34 - Train Epoch 59: LOSS= 0.07559, lr= 0.000040, acc1= 97.49,acc3= 99.93,acc10= 100.00\n",
      "eval E059: 100% 177/177 [00:09<00:00, 17.94it/s]\n",
      "INFO - 01/15/23 00:46:26 - 0:36:44 - #################################################################################################################\n",
      "INFO - 01/15/23 00:46:26 - 0:36:44 - Test Epoch 59: LOSS= 2.76326, acc1= 68.97, acc3= 86.36, acc10= 97.06\n",
      "INFO - 01/15/23 00:46:26 - 0:36:44 - #################################################################################################################\n",
      "train E060: 100% 167/167 [00:13<00:00, 12.19it/s]\n",
      "INFO - 01/15/23 00:46:40 - 0:36:58 - Train Epoch 60: LOSS= 0.07645, lr= 0.000040, acc1= 97.30,acc3= 99.96,acc10= 100.00\n",
      "eval E060: 100% 177/177 [00:10<00:00, 17.09it/s]\n",
      "INFO - 01/15/23 00:46:50 - 0:37:08 - #################################################################################################################\n",
      "INFO - 01/15/23 00:46:50 - 0:37:08 - Test Epoch 60: LOSS= 2.78720, acc1= 68.58, acc3= 86.40, acc10= 96.99\n",
      "INFO - 01/15/23 00:46:50 - 0:37:08 - #################################################################################################################\n",
      "train E061: 100% 167/167 [00:13<00:00, 11.99it/s]\n",
      "INFO - 01/15/23 00:47:04 - 0:37:22 - Train Epoch 61: LOSS= 0.07415, lr= 0.000040, acc1= 97.26,acc3= 100.00,acc10= 100.00\n",
      "eval E061: 100% 177/177 [00:10<00:00, 17.67it/s]\n",
      "INFO - 01/15/23 00:47:14 - 0:37:32 - #################################################################################################################\n",
      "INFO - 01/15/23 00:47:14 - 0:37:32 - Test Epoch 61: LOSS= 2.79606, acc1= 68.61, acc3= 86.26, acc10= 97.06\n",
      "INFO - 01/15/23 00:47:14 - 0:37:32 - #################################################################################################################\n",
      "train E062: 100% 167/167 [00:13<00:00, 12.27it/s]\n",
      "INFO - 01/15/23 00:47:28 - 0:37:46 - Train Epoch 62: LOSS= 0.08446, lr= 0.000040, acc1= 96.89,acc3= 99.85,acc10= 100.00\n",
      "eval E062: 100% 177/177 [00:13<00:00, 12.74it/s]\n",
      "INFO - 01/15/23 00:47:41 - 0:37:59 - #################################################################################################################\n",
      "INFO - 01/15/23 00:47:41 - 0:37:59 - Test Epoch 62: LOSS= 2.78850, acc1= 68.86, acc3= 86.47, acc10= 97.06\n",
      "INFO - 01/15/23 00:47:41 - 0:37:59 - #################################################################################################################\n",
      "train E063: 100% 167/167 [00:28<00:00,  5.93it/s]\n",
      "INFO - 01/15/23 00:48:10 - 0:38:28 - Train Epoch 63: LOSS= 0.07760, lr= 0.000040, acc1= 97.56,acc3= 99.93,acc10= 100.00\n",
      "eval E063: 100% 177/177 [00:25<00:00,  6.82it/s]\n",
      "INFO - 01/15/23 00:48:36 - 0:38:54 - #################################################################################################################\n",
      "INFO - 01/15/23 00:48:36 - 0:38:54 - Test Epoch 63: LOSS= 2.78097, acc1= 68.61, acc3= 86.36, acc10= 97.06\n",
      "INFO - 01/15/23 00:48:36 - 0:38:54 - #################################################################################################################\n",
      "train E064: 100% 167/167 [00:28<00:00,  5.79it/s]\n",
      "INFO - 01/15/23 00:49:04 - 0:39:22 - Train Epoch 64: LOSS= 0.06841, lr= 0.000040, acc1= 97.71,acc3= 99.96,acc10= 100.00\n",
      "eval E064: 100% 177/177 [00:28<00:00,  6.32it/s]\n",
      "INFO - 01/15/23 00:49:32 - 0:39:50 - #################################################################################################################\n",
      "INFO - 01/15/23 00:49:32 - 0:39:50 - Test Epoch 64: LOSS= 2.79952, acc1= 68.72, acc3= 86.36, acc10= 97.02\n",
      "INFO - 01/15/23 00:49:32 - 0:39:50 - #################################################################################################################\n",
      "train E065: 100% 167/167 [00:29<00:00,  5.74it/s]\n",
      "INFO - 01/15/23 00:50:01 - 0:40:20 - Train Epoch 65: LOSS= 0.07366, lr= 0.000040, acc1= 97.19,acc3= 99.85,acc10= 100.00\n",
      "eval E065: 100% 177/177 [00:27<00:00,  6.48it/s]\n",
      "INFO - 01/15/23 00:50:29 - 0:40:47 - #################################################################################################################\n",
      "INFO - 01/15/23 00:50:29 - 0:40:47 - Test Epoch 65: LOSS= 2.81125, acc1= 68.65, acc3= 86.33, acc10= 97.02\n",
      "INFO - 01/15/23 00:50:29 - 0:40:47 - #################################################################################################################\n",
      "train E066: 100% 167/167 [00:28<00:00,  5.85it/s]\n",
      "INFO - 01/15/23 00:50:57 - 0:41:15 - Train Epoch 66: LOSS= 0.07400, lr= 0.000040, acc1= 97.30,acc3= 100.00,acc10= 100.00\n",
      "eval E066: 100% 177/177 [00:27<00:00,  6.44it/s]\n",
      "INFO - 01/15/23 00:51:25 - 0:41:43 - #################################################################################################################\n",
      "INFO - 01/15/23 00:51:25 - 0:41:43 - Test Epoch 66: LOSS= 2.79645, acc1= 68.47, acc3= 86.33, acc10= 97.06\n",
      "INFO - 01/15/23 00:51:25 - 0:41:43 - #################################################################################################################\n",
      "train E067: 100% 167/167 [00:28<00:00,  5.88it/s]\n",
      "INFO - 01/15/23 00:51:53 - 0:42:11 - Train Epoch 67: LOSS= 0.07102, lr= 0.000040, acc1= 97.56,acc3= 99.96,acc10= 100.00\n",
      "eval E067: 100% 177/177 [00:27<00:00,  6.38it/s]\n",
      "INFO - 01/15/23 00:52:21 - 0:42:39 - #################################################################################################################\n",
      "INFO - 01/15/23 00:52:21 - 0:42:39 - Test Epoch 67: LOSS= 2.81023, acc1= 68.51, acc3= 86.33, acc10= 96.99\n",
      "INFO - 01/15/23 00:52:21 - 0:42:39 - #################################################################################################################\n",
      "train E068: 100% 167/167 [00:29<00:00,  5.75it/s]\n",
      "INFO - 01/15/23 00:52:50 - 0:43:08 - Train Epoch 68: LOSS= 0.07197, lr= 0.000040, acc1= 97.34,acc3= 99.96,acc10= 100.00\n",
      "eval E068: 100% 177/177 [00:27<00:00,  6.36it/s]\n",
      "INFO - 01/15/23 00:53:18 - 0:43:36 - #################################################################################################################\n",
      "INFO - 01/15/23 00:53:18 - 0:43:36 - Test Epoch 68: LOSS= 2.80976, acc1= 68.44, acc3= 86.50, acc10= 97.02\n",
      "INFO - 01/15/23 00:53:18 - 0:43:36 - #################################################################################################################\n",
      "train E069: 100% 167/167 [00:29<00:00,  5.72it/s]\n",
      "INFO - 01/15/23 00:53:47 - 0:44:05 - Train Epoch 69: LOSS= 0.07030, lr= 0.000040, acc1= 97.41,acc3= 99.89,acc10= 100.00\n",
      "eval E069: 100% 177/177 [00:27<00:00,  6.39it/s]\n",
      "INFO - 01/15/23 00:54:15 - 0:44:33 - #################################################################################################################\n",
      "INFO - 01/15/23 00:54:15 - 0:44:33 - Test Epoch 69: LOSS= 2.83967, acc1= 68.44, acc3= 86.47, acc10= 96.95\n",
      "INFO - 01/15/23 00:54:15 - 0:44:33 - #################################################################################################################\n",
      "train E070: 100% 167/167 [00:29<00:00,  5.66it/s]\n",
      "INFO - 01/15/23 00:54:44 - 0:45:02 - Train Epoch 70: LOSS= 0.06437, lr= 0.000040, acc1= 97.64,acc3= 99.96,acc10= 100.00\n",
      "eval E070: 100% 177/177 [00:27<00:00,  6.52it/s]\n",
      "INFO - 01/15/23 00:55:11 - 0:45:30 - #################################################################################################################\n",
      "INFO - 01/15/23 00:55:11 - 0:45:30 - Test Epoch 70: LOSS= 2.87876, acc1= 68.40, acc3= 86.40, acc10= 96.88\n",
      "INFO - 01/15/23 00:55:11 - 0:45:30 - #################################################################################################################\n",
      "train E071: 100% 167/167 [00:29<00:00,  5.72it/s]\n",
      "INFO - 01/15/23 00:55:41 - 0:45:59 - Train Epoch 71: LOSS= 0.06226, lr= 0.000040, acc1= 97.64,acc3= 99.96,acc10= 100.00\n",
      "eval E071: 100% 177/177 [00:27<00:00,  6.40it/s]\n",
      "INFO - 01/15/23 00:56:08 - 0:46:26 - #################################################################################################################\n",
      "INFO - 01/15/23 00:56:08 - 0:46:26 - Test Epoch 71: LOSS= 2.86163, acc1= 68.30, acc3= 86.40, acc10= 96.95\n",
      "INFO - 01/15/23 00:56:08 - 0:46:26 - #################################################################################################################\n",
      "INFO - 01/15/23 00:56:08 - 0:46:26 - best performance =  68.90, 86.43, 97.06. best epoch = 41, correspond_loss= 2.5925\n",
      "INFO - 01/15/23 00:56:08 - 0:46:26 -  fusion_model_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_relation_MLPQ_3.pkl\n",
      "INFO - 01/15/23 00:56:08 - 0:46:26 -  answer_net_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_relation_MLP_3.pkl\n"
     ]
    }
   ],
   "source": [
    "!python main_relation.py --gpu_id 8 --exp_name MLP_knowledge_space --exp_id W2V --fusion_model MLPQ --data_choice 3 --method_choice W2V --ZSL 0 --save_model 1 --relation_map 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b01d0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-01-31T16:52:17.907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 02/01/23 00:52:21 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 02/01/23 00:52:21 - 0:00:00 - The experiment will be stored in dump/0201-relation_space/bert\n",
      "                                     \n",
      "INFO - 02/01/23 00:52:21 - 0:00:00 - Running command: python main_bert_cnn.py --gpu_id 8 --exp_name relation_space --exp_id bert --fusion_model BERT --data_choice 3 --method_choice W2V --save_model 1 --ZSL 0 --relation_map 1\n",
      "\n",
      "2023-02-01 00:52:21.258830: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-01 00:52:21.258889: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 16\n",
      "batch_size 16\n",
      "INFO - 02/01/23 00:52:31 - 0:00:11 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO - 02/01/23 00:52:31 - 0:00:11 - extracting archive file /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmprb0phsmb\n",
      "embeddings.word_embeddings.weight:\tFalse\n",
      "embeddings.position_embeddings.weight:\tFalse\n",
      "embeddings.token_type_embeddings.weight:\tFalse\n",
      "embeddings.LayerNorm.weight:\tFalse\n",
      "embeddings.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.attention.self.query.weight:\tFalse\n",
      "encoder.layer.0.attention.self.query.bias:\tFalse\n",
      "encoder.layer.0.attention.self.key.weight:\tFalse\n",
      "encoder.layer.0.attention.self.key.bias:\tFalse\n",
      "encoder.layer.0.attention.self.value.weight:\tFalse\n",
      "encoder.layer.0.attention.self.value.bias:\tFalse\n",
      "encoder.layer.0.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.0.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.0.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.0.output.dense.weight:\tFalse\n",
      "encoder.layer.0.output.dense.bias:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.attention.self.query.weight:\tFalse\n",
      "encoder.layer.1.attention.self.query.bias:\tFalse\n",
      "encoder.layer.1.attention.self.key.weight:\tFalse\n",
      "encoder.layer.1.attention.self.key.bias:\tFalse\n",
      "encoder.layer.1.attention.self.value.weight:\tFalse\n",
      "encoder.layer.1.attention.self.value.bias:\tFalse\n",
      "encoder.layer.1.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.1.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.1.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.1.output.dense.weight:\tFalse\n",
      "encoder.layer.1.output.dense.bias:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.attention.self.query.weight:\tFalse\n",
      "encoder.layer.2.attention.self.query.bias:\tFalse\n",
      "encoder.layer.2.attention.self.key.weight:\tFalse\n",
      "encoder.layer.2.attention.self.key.bias:\tFalse\n",
      "encoder.layer.2.attention.self.value.weight:\tFalse\n",
      "encoder.layer.2.attention.self.value.bias:\tFalse\n",
      "encoder.layer.2.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.2.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.2.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.2.output.dense.weight:\tFalse\n",
      "encoder.layer.2.output.dense.bias:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.attention.self.query.weight:\tFalse\n",
      "encoder.layer.3.attention.self.query.bias:\tFalse\n",
      "encoder.layer.3.attention.self.key.weight:\tFalse\n",
      "encoder.layer.3.attention.self.key.bias:\tFalse\n",
      "encoder.layer.3.attention.self.value.weight:\tFalse\n",
      "encoder.layer.3.attention.self.value.bias:\tFalse\n",
      "encoder.layer.3.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.3.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.3.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.3.output.dense.weight:\tFalse\n",
      "encoder.layer.3.output.dense.bias:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.attention.self.query.weight:\tFalse\n",
      "encoder.layer.4.attention.self.query.bias:\tFalse\n",
      "encoder.layer.4.attention.self.key.weight:\tFalse\n",
      "encoder.layer.4.attention.self.key.bias:\tFalse\n",
      "encoder.layer.4.attention.self.value.weight:\tFalse\n",
      "encoder.layer.4.attention.self.value.bias:\tFalse\n",
      "encoder.layer.4.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.4.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.4.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.4.output.dense.weight:\tFalse\n",
      "encoder.layer.4.output.dense.bias:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.attention.self.query.weight:\tFalse\n",
      "encoder.layer.5.attention.self.query.bias:\tFalse\n",
      "encoder.layer.5.attention.self.key.weight:\tFalse\n",
      "encoder.layer.5.attention.self.key.bias:\tFalse\n",
      "encoder.layer.5.attention.self.value.weight:\tFalse\n",
      "encoder.layer.5.attention.self.value.bias:\tFalse\n",
      "encoder.layer.5.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.5.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.5.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.5.output.dense.weight:\tFalse\n",
      "encoder.layer.5.output.dense.bias:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.attention.self.query.weight:\tFalse\n",
      "encoder.layer.6.attention.self.query.bias:\tFalse\n",
      "encoder.layer.6.attention.self.key.weight:\tFalse\n",
      "encoder.layer.6.attention.self.key.bias:\tFalse\n",
      "encoder.layer.6.attention.self.value.weight:\tFalse\n",
      "encoder.layer.6.attention.self.value.bias:\tFalse\n",
      "encoder.layer.6.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.6.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.6.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.6.output.dense.weight:\tFalse\n",
      "encoder.layer.6.output.dense.bias:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.attention.self.query.weight:\tFalse\n",
      "encoder.layer.7.attention.self.query.bias:\tFalse\n",
      "encoder.layer.7.attention.self.key.weight:\tFalse\n",
      "encoder.layer.7.attention.self.key.bias:\tFalse\n",
      "encoder.layer.7.attention.self.value.weight:\tFalse\n",
      "encoder.layer.7.attention.self.value.bias:\tFalse\n",
      "encoder.layer.7.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.7.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.7.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.7.output.dense.weight:\tFalse\n",
      "encoder.layer.7.output.dense.bias:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.attention.self.query.weight:\tFalse\n",
      "encoder.layer.8.attention.self.query.bias:\tFalse\n",
      "encoder.layer.8.attention.self.key.weight:\tFalse\n",
      "encoder.layer.8.attention.self.key.bias:\tFalse\n",
      "encoder.layer.8.attention.self.value.weight:\tFalse\n",
      "encoder.layer.8.attention.self.value.bias:\tFalse\n",
      "encoder.layer.8.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.8.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.8.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.8.output.dense.weight:\tFalse\n",
      "encoder.layer.8.output.dense.bias:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.attention.self.query.weight:\tFalse\n",
      "encoder.layer.9.attention.self.query.bias:\tFalse\n",
      "encoder.layer.9.attention.self.key.weight:\tFalse\n",
      "encoder.layer.9.attention.self.key.bias:\tFalse\n",
      "encoder.layer.9.attention.self.value.weight:\tFalse\n",
      "encoder.layer.9.attention.self.value.bias:\tFalse\n",
      "encoder.layer.9.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.9.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.9.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.9.output.dense.weight:\tFalse\n",
      "encoder.layer.9.output.dense.bias:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.attention.self.query.weight:\tFalse\n",
      "encoder.layer.10.attention.self.query.bias:\tFalse\n",
      "encoder.layer.10.attention.self.key.weight:\tFalse\n",
      "encoder.layer.10.attention.self.key.bias:\tFalse\n",
      "encoder.layer.10.attention.self.value.weight:\tFalse\n",
      "encoder.layer.10.attention.self.value.bias:\tFalse\n",
      "encoder.layer.10.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.10.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.10.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.10.output.dense.weight:\tFalse\n",
      "encoder.layer.10.output.dense.bias:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.attention.self.query.weight:\tFalse\n",
      "encoder.layer.11.attention.self.query.bias:\tFalse\n",
      "encoder.layer.11.attention.self.key.weight:\tFalse\n",
      "encoder.layer.11.attention.self.key.bias:\tFalse\n",
      "encoder.layer.11.attention.self.value.weight:\tFalse\n",
      "encoder.layer.11.attention.self.value.bias:\tFalse\n",
      "encoder.layer.11.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.11.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.11.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.11.output.dense.weight:\tFalse\n",
      "encoder.layer.11.output.dense.bias:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.bias:\tFalse\n",
      "pooler.dense.weight:\tFalse\n",
      "pooler.dense.bias:\tFalse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight:\tFalse\r\n",
      "embeddings.position_embeddings.weight:\tFalse\r\n",
      "embeddings.token_type_embeddings.weight:\tFalse\r\n",
      "embeddings.LayerNorm.weight:\tFalse\r\n",
      "embeddings.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.0.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.0.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.0.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.0.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.0.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.0.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.0.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.0.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.0.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.0.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.0.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.0.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.0.output.dense.weight:\tFalse\r\n",
      "encoder.layer.0.output.dense.bias:\tFalse\r\n",
      "encoder.layer.0.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.0.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.1.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.1.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.1.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.1.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.1.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.1.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.1.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.1.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.1.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.1.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.1.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.1.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.1.output.dense.weight:\tFalse\r\n",
      "encoder.layer.1.output.dense.bias:\tFalse\r\n",
      "encoder.layer.1.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.1.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.2.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.2.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.2.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.2.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.2.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.2.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.2.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.2.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.2.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.2.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.2.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.2.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.2.output.dense.weight:\tFalse\r\n",
      "encoder.layer.2.output.dense.bias:\tFalse\r\n",
      "encoder.layer.2.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.2.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.3.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.3.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.3.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.3.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.3.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.3.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.3.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.3.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.3.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.3.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.3.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.3.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.3.output.dense.weight:\tFalse\r\n",
      "encoder.layer.3.output.dense.bias:\tFalse\r\n",
      "encoder.layer.3.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.3.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.4.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.4.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.4.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.4.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.4.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.4.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.4.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.4.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.4.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.4.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.4.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.4.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.4.output.dense.weight:\tFalse\r\n",
      "encoder.layer.4.output.dense.bias:\tFalse\r\n",
      "encoder.layer.4.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.4.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.5.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.5.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.5.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.5.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.5.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.5.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.5.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.5.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.5.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.5.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.5.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.5.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.5.output.dense.weight:\tFalse\r\n",
      "encoder.layer.5.output.dense.bias:\tFalse\r\n",
      "encoder.layer.5.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.5.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.6.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.6.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.6.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.6.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.6.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.6.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.6.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.6.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.6.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.6.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.6.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.6.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.6.output.dense.weight:\tFalse\r\n",
      "encoder.layer.6.output.dense.bias:\tFalse\r\n",
      "encoder.layer.6.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.6.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.7.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.7.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.7.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.7.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.7.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.7.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.7.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.7.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.7.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.7.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.7.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.7.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.7.output.dense.weight:\tFalse\r\n",
      "encoder.layer.7.output.dense.bias:\tFalse\r\n",
      "encoder.layer.7.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.7.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.8.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.8.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.8.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.8.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.8.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.8.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.8.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.8.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.8.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.8.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.8.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.8.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.8.output.dense.weight:\tFalse\r\n",
      "encoder.layer.8.output.dense.bias:\tFalse\r\n",
      "encoder.layer.8.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.8.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.9.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.9.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.9.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.9.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.9.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.9.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.9.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.9.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.9.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.9.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.9.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.9.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.9.output.dense.weight:\tFalse\r\n",
      "encoder.layer.9.output.dense.bias:\tFalse\r\n",
      "encoder.layer.9.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.9.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.10.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.10.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.10.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.10.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.10.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.10.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.10.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.10.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.10.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.10.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.10.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.10.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.10.output.dense.weight:\tFalse\r\n",
      "encoder.layer.10.output.dense.bias:\tFalse\r\n",
      "encoder.layer.10.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.10.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.11.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.11.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.11.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.11.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.11.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.11.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.11.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.11.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.11.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.11.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.11.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.11.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.11.output.dense.weight:\tFalse\r\n",
      "encoder.layer.11.output.dense.bias:\tFalse\r\n",
      "encoder.layer.11.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.11.output.LayerNorm.bias:\tFalse\r\n",
      "pooler.dense.weight:\tFalse\r\n",
      "pooler.dense.bias:\tFalse\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fusion_model:\r\n",
      "BERT(\r\n",
      "  (bert): BertModel(\r\n",
      "    (embeddings): BertEmbeddings(\r\n",
      "      (word_embeddings): Embedding(30522, 768)\r\n",
      "      (position_embeddings): Embedding(512, 768)\r\n",
      "      (token_type_embeddings): Embedding(2, 768)\r\n",
      "      (LayerNorm): BertLayerNorm()\r\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "    )\r\n",
      "    (encoder): BertEncoder(\r\n",
      "      (layer): ModuleList(\r\n",
      "        (0): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (1): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (2): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (3): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (4): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (5): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (6): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (7): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (8): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (lstm): LSTM(768, 768, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc_rnn): Linear(in_features=1536, out_features=1024, bias=True)\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(768, 8192, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(8192, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "Answer Model:\n",
      "MLP(\n",
      "  (mlp): GroupMLP(\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\n",
      "  )\n",
      ")\n",
      "train E000:   0% 0/167 [00:00<?, ?it/s]torch.Size([16, 1024]) torch.Size([103, 1024])\n",
      "train E000: 100% 167/167 [00:11<00:00, 14.79it/s]\n",
      "INFO - 02/01/23 00:52:55 - 0:00:35 - Train Epoch 0: LOSS= 2.58601, lr= 0.000500, acc1= 38.74,acc3= 62.38,acc10= 90.03\n",
      "train E001: 100% 167/167 [00:11<00:00, 14.88it/s]\n",
      "INFO - 02/01/23 00:53:07 - 0:00:46 - Train Epoch 1: LOSS= 1.81804, lr= 0.000750, acc1= 48.67,acc3= 72.87,acc10= 93.29\n",
      "eval E001: 100% 177/177 [00:06<00:00, 26.81it/s]\n",
      "INFO - 02/01/23 00:53:13 - 0:00:53 - #################################################################################################################\n",
      "INFO - 02/01/23 00:53:13 - 0:00:53 - Test Epoch 1: LOSS= 1.54143, acc1= 58.98, acc3= 78.82, acc10= 94.44\n",
      "INFO - 02/01/23 00:53:13 - 0:00:53 - #################################################################################################################\n",
      "train E002: 100% 167/167 [00:11<00:00, 14.09it/s]\n",
      "INFO - 02/01/23 00:53:25 - 0:01:05 - Train Epoch 2: LOSS= 1.77032, lr= 0.001000, acc1= 50.17,acc3= 73.55,acc10= 93.33\n",
      "eval E002: 100% 177/177 [00:06<00:00, 26.79it/s]\n",
      "INFO - 02/01/23 00:53:32 - 0:01:11 - #################################################################################################################\n",
      "INFO - 02/01/23 00:53:32 - 0:01:11 - Test Epoch 2: LOSS= 1.58632, acc1= 52.67, acc3= 75.81, acc10= 94.93\n",
      "INFO - 02/01/23 00:53:32 - 0:01:11 - #################################################################################################################\n",
      "train E003: 100% 167/167 [00:11<00:00, 14.62it/s]\n",
      "INFO - 02/01/23 00:53:43 - 0:01:23 - Train Epoch 3: LOSS= 1.72906, lr= 0.001250, acc1= 52.34,acc3= 73.59,acc10= 93.59\n",
      "eval E003: 100% 177/177 [00:06<00:00, 27.28it/s]\n",
      "INFO - 02/01/23 00:53:50 - 0:01:29 - #################################################################################################################\n",
      "INFO - 02/01/23 00:53:50 - 0:01:29 - Test Epoch 3: LOSS= 1.45063, acc1= 60.33, acc3= 77.19, acc10= 94.65\n",
      "INFO - 02/01/23 00:53:50 - 0:01:29 - #################################################################################################################\n",
      "train E004: 100% 167/167 [00:10<00:00, 16.26it/s]\n",
      "INFO - 02/01/23 00:54:00 - 0:01:39 - Train Epoch 4: LOSS= 1.61283, lr= 0.001500, acc1= 54.55,acc3= 75.80,acc10= 94.94\n",
      "eval E004: 100% 177/177 [00:06<00:00, 26.32it/s]\n",
      "INFO - 02/01/23 00:54:07 - 0:01:46 - #################################################################################################################\n",
      "INFO - 02/01/23 00:54:07 - 0:01:46 - Test Epoch 4: LOSS= 1.52490, acc1= 55.19, acc3= 76.87, acc10= 94.54\n",
      "INFO - 02/01/23 00:54:07 - 0:01:46 - #################################################################################################################\n",
      "train E005: 100% 167/167 [00:11<00:00, 14.52it/s]\n",
      "INFO - 02/01/23 00:54:18 - 0:01:58 - Train Epoch 5: LOSS= 1.56802, lr= 0.001750, acc1= 55.56,acc3= 77.07,acc10= 94.23\n",
      "eval E005: 100% 177/177 [00:06<00:00, 26.30it/s]\n",
      "INFO - 02/01/23 00:54:25 - 0:02:04 - #################################################################################################################\n",
      "INFO - 02/01/23 00:54:25 - 0:02:04 - Test Epoch 5: LOSS= 1.43713, acc1= 60.11, acc3= 79.77, acc10= 94.58\n",
      "INFO - 02/01/23 00:54:25 - 0:02:04 - #################################################################################################################\n",
      "train E006: 100% 167/167 [00:11<00:00, 14.76it/s]\n",
      "INFO - 02/01/23 00:54:36 - 0:02:16 - Train Epoch 6: LOSS= 1.50414, lr= 0.002000, acc1= 57.89,acc3= 77.29,acc10= 94.72\n",
      "eval E006: 100% 177/177 [00:07<00:00, 22.17it/s]\n",
      "INFO - 02/01/23 00:54:44 - 0:02:24 - #################################################################################################################\n",
      "INFO - 02/01/23 00:54:44 - 0:02:24 - Test Epoch 6: LOSS= 1.53120, acc1= 62.98, acc3= 78.89, acc10= 94.97\n",
      "INFO - 02/01/23 00:54:44 - 0:02:24 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E007: 100% 167/167 [00:11<00:00, 14.69it/s]\n",
      "INFO - 02/01/23 00:54:56 - 0:02:35 - Train Epoch 7: LOSS= 1.43139, lr= 0.002000, acc1= 59.12,acc3= 79.62,acc10= 95.05\n",
      "eval E007: 100% 177/177 [00:06<00:00, 26.98it/s]\n",
      "INFO - 02/01/23 00:55:02 - 0:02:42 - #################################################################################################################\n",
      "INFO - 02/01/23 00:55:02 - 0:02:42 - Test Epoch 7: LOSS= 1.51330, acc1= 58.48, acc3= 77.22, acc10= 94.23\n",
      "INFO - 02/01/23 00:55:02 - 0:02:42 - #################################################################################################################\n",
      "train E008: 100% 167/167 [00:11<00:00, 14.28it/s]\n",
      "INFO - 02/01/23 00:55:14 - 0:02:53 - Train Epoch 8: LOSS= 1.35972, lr= 0.002000, acc1= 59.69,acc3= 80.52,acc10= 96.22\n",
      "eval E008: 100% 177/177 [00:07<00:00, 22.36it/s]\n",
      "INFO - 02/01/23 00:55:22 - 0:03:01 - #################################################################################################################\n",
      "INFO - 02/01/23 00:55:22 - 0:03:01 - Test Epoch 8: LOSS= 1.31212, acc1= 64.65, acc3= 81.62, acc10= 94.76\n",
      "INFO - 02/01/23 00:55:22 - 0:03:01 - #################################################################################################################\n",
      "train E009: 100% 167/167 [00:11<00:00, 14.49it/s]\n",
      "INFO - 02/01/23 00:55:33 - 0:03:13 - Train Epoch 9: LOSS= 1.32568, lr= 0.002000, acc1= 62.01,acc3= 80.44,acc10= 95.88\n",
      "eval E009: 100% 177/177 [00:06<00:00, 26.71it/s]\n",
      "INFO - 02/01/23 00:55:40 - 0:03:20 - #################################################################################################################\n",
      "INFO - 02/01/23 00:55:40 - 0:03:20 - Test Epoch 9: LOSS= 1.37590, acc1= 61.99, acc3= 80.09, acc10= 94.51\n",
      "INFO - 02/01/23 00:55:40 - 0:03:20 - #################################################################################################################\n",
      "train E010: 100% 167/167 [00:11<00:00, 14.87it/s]\n",
      "INFO - 02/01/23 00:55:51 - 0:03:31 - Train Epoch 10: LOSS= 1.30457, lr= 0.002000, acc1= 62.35,acc3= 82.39,acc10= 96.10\n",
      "eval E010: 100% 177/177 [00:06<00:00, 26.82it/s]\n",
      "INFO - 02/01/23 00:55:58 - 0:03:37 - #################################################################################################################\n",
      "INFO - 02/01/23 00:55:58 - 0:03:37 - Test Epoch 10: LOSS= 1.41118, acc1= 59.58, acc3= 80.02, acc10= 95.18\n",
      "INFO - 02/01/23 00:55:58 - 0:03:37 - #################################################################################################################\n",
      "train E011: 100% 167/167 [00:11<00:00, 14.69it/s]\n",
      "INFO - 02/01/23 00:56:09 - 0:03:49 - Train Epoch 11: LOSS= 1.24712, lr= 0.002000, acc1= 62.38,acc3= 82.84,acc10= 95.99\n",
      "eval E011: 100% 177/177 [00:06<00:00, 26.78it/s]\n",
      "INFO - 02/01/23 00:56:16 - 0:03:55 - #################################################################################################################\n",
      "INFO - 02/01/23 00:56:16 - 0:03:55 - Test Epoch 11: LOSS= 1.48554, acc1= 64.22, acc3= 81.30, acc10= 95.01\n",
      "INFO - 02/01/23 00:56:16 - 0:03:55 - #################################################################################################################\n",
      "train E012: 100% 167/167 [00:10<00:00, 15.37it/s]\n",
      "INFO - 02/01/23 00:56:27 - 0:04:06 - Train Epoch 12: LOSS= 1.23574, lr= 0.002000, acc1= 63.92,acc3= 83.55,acc10= 96.52\n",
      "eval E012: 100% 177/177 [00:06<00:00, 26.71it/s]\n",
      "INFO - 02/01/23 00:56:33 - 0:04:13 - #################################################################################################################\n",
      "INFO - 02/01/23 00:56:33 - 0:04:13 - Test Epoch 12: LOSS= 1.50977, acc1= 60.64, acc3= 79.42, acc10= 95.08\n",
      "INFO - 02/01/23 00:56:33 - 0:04:13 - #################################################################################################################\n",
      "train E013: 100% 167/167 [00:11<00:00, 14.47it/s]\n",
      "INFO - 02/01/23 00:56:45 - 0:04:24 - Train Epoch 13: LOSS= 1.16368, lr= 0.002000, acc1= 64.74,acc3= 85.13,acc10= 96.82\n",
      "eval E013: 100% 177/177 [00:06<00:00, 26.51it/s]\n",
      "INFO - 02/01/23 00:56:52 - 0:04:31 - #################################################################################################################\n",
      "INFO - 02/01/23 00:56:52 - 0:04:31 - Test Epoch 13: LOSS= 1.27969, acc1= 64.72, acc3= 82.43, acc10= 96.32\n",
      "INFO - 02/01/23 00:56:52 - 0:04:31 - #################################################################################################################\n",
      "train E014: 100% 167/167 [00:11<00:00, 14.80it/s]\n",
      "INFO - 02/01/23 00:57:03 - 0:04:42 - Train Epoch 14: LOSS= 1.05248, lr= 0.001400, acc1= 67.82,acc3= 86.81,acc10= 97.79\n",
      "eval E014: 100% 177/177 [00:06<00:00, 27.28it/s]\n",
      "INFO - 02/01/23 00:57:09 - 0:04:49 - #################################################################################################################\n",
      "INFO - 02/01/23 00:57:09 - 0:04:49 - Test Epoch 14: LOSS= 1.32958, acc1= 66.42, acc3= 82.82, acc10= 95.71\n",
      "INFO - 02/01/23 00:57:09 - 0:04:49 - #################################################################################################################\n",
      "train E015: 100% 167/167 [00:11<00:00, 15.12it/s]\n",
      "INFO - 02/01/23 00:57:21 - 0:05:00 - Train Epoch 15: LOSS= 1.04525, lr= 0.001400, acc1= 68.68,acc3= 87.41,acc10= 97.41\n",
      "eval E015: 100% 177/177 [00:06<00:00, 26.75it/s]\n",
      "INFO - 02/01/23 00:57:27 - 0:05:07 - #################################################################################################################\n",
      "INFO - 02/01/23 00:57:27 - 0:05:07 - Test Epoch 15: LOSS= 1.30796, acc1= 67.66, acc3= 84.31, acc10= 96.17\n",
      "INFO - 02/01/23 00:57:27 - 0:05:07 - #################################################################################################################\n",
      "train E016: 100% 167/167 [00:12<00:00, 13.91it/s]\n",
      "INFO - 02/01/23 00:57:39 - 0:05:19 - Train Epoch 16: LOSS= 1.00662, lr= 0.001400, acc1= 69.84,acc3= 88.16,acc10= 98.01\n",
      "eval E016: 100% 177/177 [00:06<00:00, 26.58it/s]\n",
      "INFO - 02/01/23 00:57:46 - 0:05:25 - #################################################################################################################\n",
      "INFO - 02/01/23 00:57:46 - 0:05:25 - Test Epoch 16: LOSS= 1.27758, acc1= 66.35, acc3= 84.06, acc10= 96.46\n",
      "INFO - 02/01/23 00:57:46 - 0:05:25 - #################################################################################################################\n",
      "train E017: 100% 167/167 [00:10<00:00, 15.39it/s]\n",
      "INFO - 02/01/23 00:57:57 - 0:05:36 - Train Epoch 17: LOSS= 0.95728, lr= 0.000980, acc1= 70.06,acc3= 89.21,acc10= 98.13\n",
      "eval E017: 100% 177/177 [00:06<00:00, 26.59it/s]\n",
      "INFO - 02/01/23 00:58:03 - 0:05:43 - #################################################################################################################\n",
      "INFO - 02/01/23 00:58:03 - 0:05:43 - Test Epoch 17: LOSS= 1.21831, acc1= 68.65, acc3= 85.37, acc10= 96.56\n",
      "INFO - 02/01/23 00:58:03 - 0:05:43 - #################################################################################################################\n",
      "train E018: 100% 167/167 [00:11<00:00, 14.67it/s]\n",
      "INFO - 02/01/23 00:58:15 - 0:05:54 - Train Epoch 18: LOSS= 0.92335, lr= 0.000980, acc1= 70.66,acc3= 89.43,acc10= 98.24\n",
      "eval E018: 100% 177/177 [00:06<00:00, 26.50it/s]\n",
      "INFO - 02/01/23 00:58:21 - 0:06:01 - #################################################################################################################\n",
      "INFO - 02/01/23 00:58:21 - 0:06:01 - Test Epoch 18: LOSS= 1.21092, acc1= 68.37, acc3= 85.37, acc10= 96.71\n",
      "INFO - 02/01/23 00:58:21 - 0:06:01 - #################################################################################################################\n",
      "train E019: 100% 167/167 [00:11<00:00, 14.72it/s]\n",
      "INFO - 02/01/23 00:58:33 - 0:06:12 - Train Epoch 19: LOSS= 0.90664, lr= 0.000980, acc1= 71.64,acc3= 90.37,acc10= 98.50\n",
      "eval E019: 100% 177/177 [00:06<00:00, 26.98it/s]\n",
      "INFO - 02/01/23 00:58:39 - 0:06:19 - #################################################################################################################\n",
      "INFO - 02/01/23 00:58:39 - 0:06:19 - Test Epoch 19: LOSS= 1.27618, acc1= 67.55, acc3= 84.95, acc10= 96.67\n",
      "INFO - 02/01/23 00:58:39 - 0:06:19 - #################################################################################################################\n",
      "train E020: 100% 167/167 [00:11<00:00, 14.83it/s]\n",
      "INFO - 02/01/23 00:58:51 - 0:06:30 - Train Epoch 20: LOSS= 0.86182, lr= 0.000686, acc1= 72.91,acc3= 90.90,acc10= 98.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E020: 100% 177/177 [00:06<00:00, 26.66it/s]\n",
      "INFO - 02/01/23 00:58:57 - 0:06:37 - #################################################################################################################\n",
      "INFO - 02/01/23 00:58:57 - 0:06:37 - Test Epoch 20: LOSS= 1.23608, acc1= 68.44, acc3= 85.05, acc10= 97.13\n",
      "INFO - 02/01/23 00:58:57 - 0:06:37 - #################################################################################################################\n",
      "train E021: 100% 167/167 [00:11<00:00, 15.05it/s]\n",
      "INFO - 02/01/23 00:59:08 - 0:06:48 - Train Epoch 21: LOSS= 0.83894, lr= 0.000686, acc1= 74.33,acc3= 91.87,acc10= 98.50\n",
      "eval E021: 100% 177/177 [00:06<00:00, 26.85it/s]\n",
      "INFO - 02/01/23 00:59:15 - 0:06:54 - #################################################################################################################\n",
      "INFO - 02/01/23 00:59:15 - 0:06:54 - Test Epoch 21: LOSS= 1.30604, acc1= 68.54, acc3= 85.48, acc10= 96.28\n",
      "INFO - 02/01/23 00:59:15 - 0:06:54 - #################################################################################################################\n",
      "train E022: 100% 167/167 [00:11<00:00, 14.88it/s]\n",
      "INFO - 02/01/23 00:59:26 - 0:07:06 - Train Epoch 22: LOSS= 0.81825, lr= 0.000686, acc1= 73.89,acc3= 92.13,acc10= 99.29\n",
      "eval E022: 100% 177/177 [00:06<00:00, 26.90it/s]\n",
      "INFO - 02/01/23 00:59:33 - 0:07:12 - #################################################################################################################\n",
      "INFO - 02/01/23 00:59:33 - 0:07:12 - Test Epoch 22: LOSS= 1.36347, acc1= 66.06, acc3= 85.30, acc10= 96.17\n",
      "INFO - 02/01/23 00:59:33 - 0:07:12 - #################################################################################################################\n",
      "train E023: 100% 167/167 [00:10<00:00, 15.41it/s]\n",
      "INFO - 02/01/23 00:59:44 - 0:07:23 - Train Epoch 23: LOSS= 0.76052, lr= 0.000480, acc1= 76.02,acc3= 92.96,acc10= 99.25\n",
      "eval E023: 100% 177/177 [00:06<00:00, 26.92it/s]\n",
      "INFO - 02/01/23 00:59:50 - 0:07:30 - #################################################################################################################\n",
      "INFO - 02/01/23 00:59:50 - 0:07:30 - Test Epoch 23: LOSS= 1.24835, acc1= 68.65, acc3= 86.15, acc10= 97.10\n",
      "INFO - 02/01/23 00:59:50 - 0:07:30 - #################################################################################################################\n",
      "train E024: 100% 167/167 [00:11<00:00, 14.96it/s]\n",
      "INFO - 02/01/23 01:00:01 - 0:07:41 - Train Epoch 24: LOSS= 0.75227, lr= 0.000480, acc1= 75.61,acc3= 93.22,acc10= 99.06\n",
      "eval E024: 100% 177/177 [00:06<00:00, 26.92it/s]\n",
      "INFO - 02/01/23 01:00:08 - 0:07:47 - #################################################################################################################\n",
      "INFO - 02/01/23 01:00:08 - 0:07:47 - Test Epoch 24: LOSS= 1.35648, acc1= 68.79, acc3= 85.23, acc10= 96.49\n",
      "INFO - 02/01/23 01:00:08 - 0:07:47 - #################################################################################################################\n",
      "train E025: 100% 167/167 [00:11<00:00, 15.02it/s]\n",
      "INFO - 02/01/23 01:00:19 - 0:07:59 - Train Epoch 25: LOSS= 0.76559, lr= 0.000480, acc1= 75.35,acc3= 93.22,acc10= 99.10\n",
      "eval E025: 100% 177/177 [00:06<00:00, 26.65it/s]\n",
      "INFO - 02/01/23 01:00:26 - 0:08:05 - #################################################################################################################\n",
      "INFO - 02/01/23 01:00:26 - 0:08:05 - Test Epoch 25: LOSS= 1.25878, acc1= 69.64, acc3= 85.97, acc10= 96.92\n",
      "INFO - 02/01/23 01:00:26 - 0:08:05 - #################################################################################################################\n",
      "train E026: 100% 167/167 [00:11<00:00, 14.87it/s]\n",
      "INFO - 02/01/23 01:00:37 - 0:08:17 - Train Epoch 26: LOSS= 0.69114, lr= 0.000336, acc1= 77.29,acc3= 94.64,acc10= 99.51\n",
      "eval E026: 100% 177/177 [00:06<00:00, 26.88it/s]\n",
      "INFO - 02/01/23 01:00:44 - 0:08:23 - #################################################################################################################\n",
      "INFO - 02/01/23 01:00:44 - 0:08:23 - Test Epoch 26: LOSS= 1.31861, acc1= 69.11, acc3= 86.68, acc10= 97.27\n",
      "INFO - 02/01/23 01:00:44 - 0:08:23 - #################################################################################################################\n",
      "train E027: 100% 167/167 [00:11<00:00, 14.27it/s]\n",
      "INFO - 02/01/23 01:00:55 - 0:08:35 - Train Epoch 27: LOSS= 0.67046, lr= 0.000336, acc1= 77.52,acc3= 94.87,acc10= 99.48\n",
      "eval E027: 100% 177/177 [00:07<00:00, 22.45it/s]\n",
      "INFO - 02/01/23 01:01:03 - 0:08:43 - #################################################################################################################\n",
      "INFO - 02/01/23 01:01:03 - 0:08:43 - Test Epoch 27: LOSS= 1.31898, acc1= 69.04, acc3= 86.47, acc10= 96.95\n",
      "INFO - 02/01/23 01:01:03 - 0:08:43 - #################################################################################################################\n",
      "train E028: 100% 167/167 [00:11<00:00, 14.74it/s]\n",
      "INFO - 02/01/23 01:01:15 - 0:08:54 - Train Epoch 28: LOSS= 0.66652, lr= 0.000336, acc1= 78.08,acc3= 94.87,acc10= 99.59\n",
      "eval E028: 100% 177/177 [00:06<00:00, 27.07it/s]\n",
      "INFO - 02/01/23 01:01:21 - 0:09:01 - #################################################################################################################\n",
      "INFO - 02/01/23 01:01:21 - 0:09:01 - Test Epoch 28: LOSS= 1.38234, acc1= 68.90, acc3= 86.89, acc10= 96.99\n",
      "INFO - 02/01/23 01:01:21 - 0:09:01 - #################################################################################################################\n",
      "train E029: 100% 167/167 [00:11<00:00, 14.59it/s]\n",
      "INFO - 02/01/23 01:01:33 - 0:09:12 - Train Epoch 29: LOSS= 0.62354, lr= 0.000235, acc1= 78.72,acc3= 95.43,acc10= 99.70\n",
      "eval E029: 100% 177/177 [00:06<00:00, 26.42it/s]\n",
      "INFO - 02/01/23 01:01:39 - 0:09:19 - #################################################################################################################\n",
      "INFO - 02/01/23 01:01:39 - 0:09:19 - Test Epoch 29: LOSS= 1.36944, acc1= 68.44, acc3= 87.00, acc10= 97.31\n",
      "INFO - 02/01/23 01:01:39 - 0:09:19 - #################################################################################################################\n",
      "train E030: 100% 167/167 [00:11<00:00, 14.60it/s]\n",
      "INFO - 02/01/23 01:01:51 - 0:09:30 - Train Epoch 30: LOSS= 0.59699, lr= 0.000235, acc1= 79.69,acc3= 95.92,acc10= 99.59\n",
      "eval E030: 100% 177/177 [00:06<00:00, 26.80it/s]\n",
      "INFO - 02/01/23 01:01:57 - 0:09:37 - #################################################################################################################\n",
      "INFO - 02/01/23 01:01:57 - 0:09:37 - Test Epoch 30: LOSS= 1.41577, acc1= 69.04, acc3= 86.75, acc10= 97.02\n",
      "INFO - 02/01/23 01:01:57 - 0:09:37 - #################################################################################################################\n",
      "train E031: 100% 167/167 [00:11<00:00, 14.45it/s]\n",
      "INFO - 02/01/23 01:02:09 - 0:09:48 - Train Epoch 31: LOSS= 0.60774, lr= 0.000235, acc1= 79.21,acc3= 95.28,acc10= 99.70\n",
      "eval E031: 100% 177/177 [00:06<00:00, 26.62it/s]\n",
      "INFO - 02/01/23 01:02:16 - 0:09:55 - #################################################################################################################\n",
      "INFO - 02/01/23 01:02:16 - 0:09:55 - Test Epoch 31: LOSS= 1.41563, acc1= 68.97, acc3= 86.57, acc10= 96.88\n",
      "INFO - 02/01/23 01:02:16 - 0:09:55 - #################################################################################################################\n",
      "train E032: 100% 167/167 [00:11<00:00, 14.94it/s]\n",
      "INFO - 02/01/23 01:02:27 - 0:10:06 - Train Epoch 32: LOSS= 0.56767, lr= 0.000165, acc1= 80.67,acc3= 95.95,acc10= 99.74\n",
      "eval E032: 100% 177/177 [00:06<00:00, 26.66it/s]\n",
      "INFO - 02/01/23 01:02:33 - 0:10:13 - #################################################################################################################\n",
      "INFO - 02/01/23 01:02:33 - 0:10:13 - Test Epoch 32: LOSS= 1.41388, acc1= 69.47, acc3= 86.57, acc10= 97.17\n",
      "INFO - 02/01/23 01:02:33 - 0:10:13 - #################################################################################################################\n",
      "train E033: 100% 167/167 [00:11<00:00, 14.70it/s]\n",
      "INFO - 02/01/23 01:02:45 - 0:10:24 - Train Epoch 33: LOSS= 0.57818, lr= 0.000165, acc1= 80.10,acc3= 96.37,acc10= 99.81\n",
      "eval E033: 100% 177/177 [00:06<00:00, 27.02it/s]\n",
      "INFO - 02/01/23 01:02:51 - 0:10:31 - #################################################################################################################\n",
      "INFO - 02/01/23 01:02:51 - 0:10:31 - Test Epoch 33: LOSS= 1.45128, acc1= 68.37, acc3= 86.43, acc10= 97.34\n",
      "INFO - 02/01/23 01:02:51 - 0:10:31 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E034: 100% 167/167 [00:11<00:00, 14.34it/s]\n",
      "INFO - 02/01/23 01:03:03 - 0:10:42 - Train Epoch 34: LOSS= 0.54941, lr= 0.000165, acc1= 81.19,acc3= 96.74,acc10= 99.85\n",
      "eval E034: 100% 177/177 [00:06<00:00, 26.34it/s]\n",
      "INFO - 02/01/23 01:03:10 - 0:10:49 - #################################################################################################################\n",
      "INFO - 02/01/23 01:03:10 - 0:10:49 - Test Epoch 34: LOSS= 1.44588, acc1= 68.79, acc3= 87.04, acc10= 97.48\n",
      "INFO - 02/01/23 01:03:10 - 0:10:49 - #################################################################################################################\n",
      "train E035: 100% 167/167 [00:11<00:00, 14.56it/s]\n",
      "INFO - 02/01/23 01:03:21 - 0:11:01 - Train Epoch 35: LOSS= 0.55031, lr= 0.000115, acc1= 81.57,acc3= 96.85,acc10= 99.66\n",
      "eval E035: 100% 177/177 [00:06<00:00, 26.83it/s]\n",
      "INFO - 02/01/23 01:03:28 - 0:11:07 - #################################################################################################################\n",
      "INFO - 02/01/23 01:03:28 - 0:11:07 - Test Epoch 35: LOSS= 1.47680, acc1= 69.22, acc3= 86.47, acc10= 97.13\n",
      "INFO - 02/01/23 01:03:28 - 0:11:07 - #################################################################################################################\n",
      "train E036: 100% 167/167 [00:11<00:00, 15.12it/s]\n",
      "INFO - 02/01/23 01:03:39 - 0:11:18 - Train Epoch 36: LOSS= 0.55267, lr= 0.000115, acc1= 80.97,acc3= 96.67,acc10= 99.89\n",
      "eval E036: 100% 177/177 [00:06<00:00, 26.42it/s]\n",
      "INFO - 02/01/23 01:03:46 - 0:11:25 - #################################################################################################################\n",
      "INFO - 02/01/23 01:03:46 - 0:11:25 - Test Epoch 36: LOSS= 1.47611, acc1= 68.54, acc3= 86.47, acc10= 97.02\n",
      "INFO - 02/01/23 01:03:46 - 0:11:25 - #################################################################################################################\n",
      "train E037: 100% 167/167 [00:11<00:00, 14.23it/s]\n",
      "INFO - 02/01/23 01:03:57 - 0:11:37 - Train Epoch 37: LOSS= 0.53448, lr= 0.000115, acc1= 82.50,acc3= 96.52,acc10= 99.85\n",
      "eval E037: 100% 177/177 [00:07<00:00, 24.36it/s]\n",
      "INFO - 02/01/23 01:04:05 - 0:11:44 - #################################################################################################################\n",
      "INFO - 02/01/23 01:04:05 - 0:11:44 - Test Epoch 37: LOSS= 1.49307, acc1= 68.79, acc3= 86.40, acc10= 96.95\n",
      "INFO - 02/01/23 01:04:05 - 0:11:44 - #################################################################################################################\n",
      "train E038: 100% 167/167 [00:11<00:00, 14.68it/s]\n",
      "INFO - 02/01/23 01:04:16 - 0:11:55 - Train Epoch 38: LOSS= 0.52248, lr= 0.000081, acc1= 81.94,acc3= 97.23,acc10= 99.85\n",
      "eval E038: 100% 177/177 [00:06<00:00, 26.73it/s]\n",
      "INFO - 02/01/23 01:04:23 - 0:12:02 - #################################################################################################################\n",
      "INFO - 02/01/23 01:04:23 - 0:12:02 - Test Epoch 38: LOSS= 1.48614, acc1= 69.15, acc3= 86.65, acc10= 96.92\n",
      "INFO - 02/01/23 01:04:23 - 0:12:02 - #################################################################################################################\n",
      "train E039: 100% 167/167 [00:11<00:00, 14.69it/s]\n",
      "INFO - 02/01/23 01:04:34 - 0:12:13 - Train Epoch 39: LOSS= 0.50468, lr= 0.000081, acc1= 81.68,acc3= 97.26,acc10= 99.96\n",
      "eval E039: 100% 177/177 [00:06<00:00, 26.69it/s]\n",
      "INFO - 02/01/23 01:04:41 - 0:12:20 - #################################################################################################################\n",
      "INFO - 02/01/23 01:04:41 - 0:12:20 - Test Epoch 39: LOSS= 1.50946, acc1= 68.83, acc3= 87.32, acc10= 97.10\n",
      "INFO - 02/01/23 01:04:41 - 0:12:20 - #################################################################################################################\n",
      "train E040: 100% 167/167 [00:11<00:00, 15.16it/s]\n",
      "INFO - 02/01/23 01:04:52 - 0:12:31 - Train Epoch 40: LOSS= 0.50650, lr= 0.000081, acc1= 82.69,acc3= 97.19,acc10= 99.85\n",
      "eval E040: 100% 177/177 [00:06<00:00, 26.93it/s]\n",
      "INFO - 02/01/23 01:04:58 - 0:12:38 - #################################################################################################################\n",
      "INFO - 02/01/23 01:04:58 - 0:12:38 - Test Epoch 40: LOSS= 1.56285, acc1= 68.83, acc3= 87.04, acc10= 96.67\n",
      "INFO - 02/01/23 01:04:58 - 0:12:38 - #################################################################################################################\n",
      "train E041: 100% 167/167 [00:11<00:00, 15.18it/s]\n",
      "INFO - 02/01/23 01:05:09 - 0:12:49 - Train Epoch 41: LOSS= 0.49333, lr= 0.000056, acc1= 82.80,acc3= 97.64,acc10= 99.89\n",
      "eval E041: 100% 177/177 [00:06<00:00, 26.87it/s]\n",
      "INFO - 02/01/23 01:05:16 - 0:12:55 - #################################################################################################################\n",
      "INFO - 02/01/23 01:05:16 - 0:12:55 - Test Epoch 41: LOSS= 1.54953, acc1= 69.25, acc3= 86.96, acc10= 96.78\n",
      "INFO - 02/01/23 01:05:16 - 0:12:55 - #################################################################################################################\n",
      "train E042: 100% 167/167 [00:11<00:00, 14.04it/s]\n",
      "INFO - 02/01/23 01:05:28 - 0:13:07 - Train Epoch 42: LOSS= 0.49463, lr= 0.000056, acc1= 82.69,acc3= 97.90,acc10= 99.89\n",
      "eval E042: 100% 177/177 [00:07<00:00, 24.84it/s]\n",
      "INFO - 02/01/23 01:05:35 - 0:13:14 - #################################################################################################################\n",
      "INFO - 02/01/23 01:05:35 - 0:13:14 - Test Epoch 42: LOSS= 1.54100, acc1= 68.72, acc3= 86.89, acc10= 96.85\n",
      "INFO - 02/01/23 01:05:35 - 0:13:14 - #################################################################################################################\n",
      "train E043: 100% 167/167 [00:11<00:00, 14.93it/s]\n",
      "INFO - 02/01/23 01:05:46 - 0:13:26 - Train Epoch 43: LOSS= 0.49662, lr= 0.000056, acc1= 82.99,acc3= 97.38,acc10= 99.85\n",
      "eval E043: 100% 177/177 [00:06<00:00, 26.72it/s]\n",
      "INFO - 02/01/23 01:05:53 - 0:13:32 - #################################################################################################################\n",
      "INFO - 02/01/23 01:05:53 - 0:13:32 - Test Epoch 43: LOSS= 1.54462, acc1= 69.25, acc3= 87.11, acc10= 96.95\n",
      "INFO - 02/01/23 01:05:53 - 0:13:32 - #################################################################################################################\n",
      "train E044: 100% 167/167 [00:11<00:00, 14.94it/s]\n",
      "INFO - 02/01/23 01:06:04 - 0:13:43 - Train Epoch 44: LOSS= 0.46484, lr= 0.000040, acc1= 84.15,acc3= 97.41,acc10= 99.96\n",
      "eval E044: 100% 177/177 [00:06<00:00, 26.99it/s]\n",
      "INFO - 02/01/23 01:06:10 - 0:13:50 - #################################################################################################################\n",
      "INFO - 02/01/23 01:06:10 - 0:13:50 - Test Epoch 44: LOSS= 1.56469, acc1= 68.97, acc3= 86.65, acc10= 96.78\n",
      "INFO - 02/01/23 01:06:10 - 0:13:50 - #################################################################################################################\n",
      "train E045: 100% 167/167 [00:11<00:00, 15.05it/s]\n",
      "INFO - 02/01/23 01:06:22 - 0:14:01 - Train Epoch 45: LOSS= 0.48101, lr= 0.000040, acc1= 83.78,acc3= 97.30,acc10= 99.96\n",
      "eval E045: 100% 177/177 [00:06<00:00, 27.83it/s]\n",
      "INFO - 02/01/23 01:06:28 - 0:14:07 - #################################################################################################################\n",
      "INFO - 02/01/23 01:06:28 - 0:14:07 - Test Epoch 45: LOSS= 1.57872, acc1= 68.72, acc3= 86.75, acc10= 96.88\n",
      "INFO - 02/01/23 01:06:28 - 0:14:07 - #################################################################################################################\n",
      "train E046: 100% 167/167 [00:11<00:00, 14.56it/s]\n",
      "INFO - 02/01/23 01:06:39 - 0:14:19 - Train Epoch 46: LOSS= 0.44834, lr= 0.000040, acc1= 84.56,acc3= 97.98,acc10= 99.96\n",
      "eval E046: 100% 177/177 [00:06<00:00, 27.02it/s]\n",
      "INFO - 02/01/23 01:06:46 - 0:14:25 - #################################################################################################################\n",
      "INFO - 02/01/23 01:06:46 - 0:14:25 - Test Epoch 46: LOSS= 1.61491, acc1= 68.79, acc3= 86.72, acc10= 96.88\n",
      "INFO - 02/01/23 01:06:46 - 0:14:25 - #################################################################################################################\n",
      "train E047: 100% 167/167 [00:11<00:00, 14.72it/s]\n",
      "INFO - 02/01/23 01:06:57 - 0:14:37 - Train Epoch 47: LOSS= 0.45961, lr= 0.000040, acc1= 84.83,acc3= 97.75,acc10= 99.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E047: 100% 177/177 [00:07<00:00, 22.70it/s]\n",
      "INFO - 02/01/23 01:07:05 - 0:14:45 - #################################################################################################################\n",
      "INFO - 02/01/23 01:07:05 - 0:14:45 - Test Epoch 47: LOSS= 1.63897, acc1= 69.08, acc3= 86.68, acc10= 96.78\n",
      "INFO - 02/01/23 01:07:05 - 0:14:45 - #################################################################################################################\n",
      "train E048: 100% 167/167 [00:11<00:00, 14.64it/s]\n",
      "INFO - 02/01/23 01:07:17 - 0:14:56 - Train Epoch 48: LOSS= 0.48086, lr= 0.000040, acc1= 83.48,acc3= 97.19,acc10= 99.89\n",
      "eval E048: 100% 177/177 [00:06<00:00, 26.91it/s]\n",
      "INFO - 02/01/23 01:07:23 - 0:15:03 - #################################################################################################################\n",
      "INFO - 02/01/23 01:07:23 - 0:15:03 - Test Epoch 48: LOSS= 1.60847, acc1= 69.22, acc3= 86.86, acc10= 96.85\n",
      "INFO - 02/01/23 01:07:23 - 0:15:03 - #################################################################################################################\n",
      "train E049: 100% 167/167 [00:11<00:00, 14.71it/s]\n",
      "INFO - 02/01/23 01:07:34 - 0:15:14 - Train Epoch 49: LOSS= 0.47887, lr= 0.000040, acc1= 84.08,acc3= 97.41,acc10= 99.93\n",
      "eval E049: 100% 177/177 [00:06<00:00, 26.82it/s]\n",
      "INFO - 02/01/23 01:07:41 - 0:15:20 - #################################################################################################################\n",
      "INFO - 02/01/23 01:07:41 - 0:15:20 - Test Epoch 49: LOSS= 1.59285, acc1= 68.76, acc3= 87.00, acc10= 96.95\n",
      "INFO - 02/01/23 01:07:41 - 0:15:20 - #################################################################################################################\n",
      "train E050: 100% 167/167 [00:11<00:00, 14.17it/s]\n",
      "INFO - 02/01/23 01:07:53 - 0:15:32 - Train Epoch 50: LOSS= 0.46453, lr= 0.000040, acc1= 84.26,acc3= 97.38,acc10= 99.93\n",
      "eval E050: 100% 177/177 [00:06<00:00, 26.71it/s]\n",
      "INFO - 02/01/23 01:07:59 - 0:15:39 - #################################################################################################################\n",
      "INFO - 02/01/23 01:07:59 - 0:15:39 - Test Epoch 50: LOSS= 1.60215, acc1= 68.79, acc3= 86.93, acc10= 96.92\n",
      "INFO - 02/01/23 01:07:59 - 0:15:39 - #################################################################################################################\n",
      "train E051: 100% 167/167 [00:11<00:00, 15.02it/s]\n",
      "INFO - 02/01/23 01:08:11 - 0:15:50 - Train Epoch 51: LOSS= 0.44971, lr= 0.000040, acc1= 83.55,acc3= 98.09,acc10= 99.96\n",
      "eval E051: 100% 177/177 [00:06<00:00, 27.21it/s]\n",
      "INFO - 02/01/23 01:08:17 - 0:15:57 - #################################################################################################################\n",
      "INFO - 02/01/23 01:08:17 - 0:15:57 - Test Epoch 51: LOSS= 1.62834, acc1= 68.58, acc3= 86.65, acc10= 96.92\n",
      "INFO - 02/01/23 01:08:17 - 0:15:57 - #################################################################################################################\n",
      "train E052: 100% 167/167 [00:11<00:00, 14.82it/s]\n",
      "INFO - 02/01/23 01:08:28 - 0:16:08 - Train Epoch 52: LOSS= 0.45234, lr= 0.000040, acc1= 84.00,acc3= 97.79,acc10= 99.89\n",
      "eval E052: 100% 177/177 [00:06<00:00, 26.97it/s]\n",
      "INFO - 02/01/23 01:08:35 - 0:16:14 - #################################################################################################################\n",
      "INFO - 02/01/23 01:08:35 - 0:16:14 - Test Epoch 52: LOSS= 1.63004, acc1= 69.29, acc3= 86.89, acc10= 96.95\n",
      "INFO - 02/01/23 01:08:35 - 0:16:14 - #################################################################################################################\n",
      "train E053: 100% 167/167 [00:11<00:00, 14.64it/s]\n",
      "INFO - 02/01/23 01:08:46 - 0:16:26 - Train Epoch 53: LOSS= 0.46957, lr= 0.000040, acc1= 84.00,acc3= 97.79,acc10= 99.89\n",
      "eval E053: 100% 177/177 [00:07<00:00, 22.64it/s]\n",
      "INFO - 02/01/23 01:08:54 - 0:16:34 - #################################################################################################################\n",
      "INFO - 02/01/23 01:08:54 - 0:16:34 - Test Epoch 53: LOSS= 1.61320, acc1= 68.69, acc3= 86.89, acc10= 97.02\n",
      "INFO - 02/01/23 01:08:54 - 0:16:34 - #################################################################################################################\n",
      "train E054: 100% 167/167 [00:11<00:00, 14.73it/s]\n",
      "INFO - 02/01/23 01:09:06 - 0:16:45 - Train Epoch 54: LOSS= 0.44564, lr= 0.000040, acc1= 83.66,acc3= 97.75,acc10= 99.96\n",
      "eval E054: 100% 177/177 [00:06<00:00, 26.96it/s]\n",
      "INFO - 02/01/23 01:09:12 - 0:16:52 - #################################################################################################################\n",
      "INFO - 02/01/23 01:09:12 - 0:16:52 - Test Epoch 54: LOSS= 1.64852, acc1= 68.33, acc3= 87.28, acc10= 97.02\n",
      "INFO - 02/01/23 01:09:12 - 0:16:52 - #################################################################################################################\n",
      "train E055: 100% 167/167 [00:11<00:00, 14.91it/s]\n",
      "INFO - 02/01/23 01:09:23 - 0:17:03 - Train Epoch 55: LOSS= 0.44394, lr= 0.000040, acc1= 85.24,acc3= 98.13,acc10= 99.93\n",
      "eval E055: 100% 177/177 [00:06<00:00, 26.55it/s]\n",
      "INFO - 02/01/23 01:09:30 - 0:17:09 - #################################################################################################################\n",
      "INFO - 02/01/23 01:09:30 - 0:17:09 - Test Epoch 55: LOSS= 1.66343, acc1= 69.89, acc3= 87.35, acc10= 96.85\n",
      "INFO - 02/01/23 01:09:30 - 0:17:09 - #################################################################################################################\n",
      "train E056: 100% 167/167 [00:11<00:00, 14.36it/s]\n",
      "INFO - 02/01/23 01:09:42 - 0:17:21 - Train Epoch 56: LOSS= 0.43989, lr= 0.000040, acc1= 84.49,acc3= 97.94,acc10= 100.00\n",
      "eval E056: 100% 177/177 [00:06<00:00, 26.68it/s]\n",
      "INFO - 02/01/23 01:09:48 - 0:17:28 - #################################################################################################################\n",
      "INFO - 02/01/23 01:09:48 - 0:17:28 - Test Epoch 56: LOSS= 1.66056, acc1= 69.54, acc3= 87.25, acc10= 96.99\n",
      "INFO - 02/01/23 01:09:48 - 0:17:28 - #################################################################################################################\n",
      "train E057: 100% 167/167 [00:11<00:00, 14.57it/s]\n",
      "INFO - 02/01/23 01:10:00 - 0:17:39 - Train Epoch 57: LOSS= 0.41090, lr= 0.000040, acc1= 84.86,acc3= 98.09,acc10= 99.96\n",
      "eval E057: 100% 177/177 [00:06<00:00, 26.64it/s]\n",
      "INFO - 02/01/23 01:10:06 - 0:17:46 - #################################################################################################################\n",
      "INFO - 02/01/23 01:10:06 - 0:17:46 - Test Epoch 57: LOSS= 1.70716, acc1= 69.11, acc3= 86.86, acc10= 96.88\n",
      "INFO - 02/01/23 01:10:06 - 0:17:46 - #################################################################################################################\n",
      "train E058: 100% 167/167 [00:11<00:00, 15.02it/s]\n",
      "INFO - 02/01/23 01:10:18 - 0:17:57 - Train Epoch 58: LOSS= 0.44515, lr= 0.000040, acc1= 84.60,acc3= 97.94,acc10= 99.96\n",
      "eval E058: 100% 177/177 [00:06<00:00, 26.57it/s]\n",
      "INFO - 02/01/23 01:10:24 - 0:18:04 - #################################################################################################################\n",
      "INFO - 02/01/23 01:10:24 - 0:18:04 - Test Epoch 58: LOSS= 1.68544, acc1= 69.54, acc3= 87.14, acc10= 96.88\n",
      "INFO - 02/01/23 01:10:24 - 0:18:04 - #################################################################################################################\n",
      "train E059: 100% 167/167 [00:11<00:00, 14.57it/s]\n",
      "INFO - 02/01/23 01:10:36 - 0:18:15 - Train Epoch 59: LOSS= 0.46649, lr= 0.000040, acc1= 83.21,acc3= 97.71,acc10= 99.96\n",
      "eval E059: 100% 177/177 [00:06<00:00, 26.27it/s]\n",
      "INFO - 02/01/23 01:10:42 - 0:18:22 - #################################################################################################################\n",
      "INFO - 02/01/23 01:10:42 - 0:18:22 - Test Epoch 59: LOSS= 1.67236, acc1= 69.29, acc3= 87.04, acc10= 97.06\n",
      "INFO - 02/01/23 01:10:42 - 0:18:22 - #################################################################################################################\n",
      "train E060: 100% 167/167 [00:11<00:00, 14.93it/s]\n",
      "INFO - 02/01/23 01:10:54 - 0:18:33 - Train Epoch 60: LOSS= 0.43850, lr= 0.000040, acc1= 85.28,acc3= 97.94,acc10= 99.96\n",
      "eval E060: 100% 177/177 [00:06<00:00, 27.06it/s]\n",
      "INFO - 02/01/23 01:11:00 - 0:18:40 - #################################################################################################################\n",
      "INFO - 02/01/23 01:11:00 - 0:18:40 - Test Epoch 60: LOSS= 1.70563, acc1= 69.18, acc3= 86.93, acc10= 97.13\n",
      "INFO - 02/01/23 01:11:00 - 0:18:40 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E061: 100% 167/167 [00:11<00:00, 15.07it/s]\n",
      "INFO - 02/01/23 01:11:11 - 0:18:51 - Train Epoch 61: LOSS= 0.43872, lr= 0.000040, acc1= 84.64,acc3= 98.01,acc10= 99.89\n",
      "eval E061: 100% 177/177 [00:06<00:00, 26.69it/s]\n",
      "INFO - 02/01/23 01:11:18 - 0:18:57 - #################################################################################################################\n",
      "INFO - 02/01/23 01:11:18 - 0:18:57 - Test Epoch 61: LOSS= 1.66952, acc1= 68.86, acc3= 87.04, acc10= 97.13\n",
      "INFO - 02/01/23 01:11:18 - 0:18:57 - #################################################################################################################\n",
      "train E062: 100% 167/167 [00:11<00:00, 14.94it/s]\n",
      "INFO - 02/01/23 01:11:29 - 0:19:08 - Train Epoch 62: LOSS= 0.44389, lr= 0.000040, acc1= 84.83,acc3= 98.24,acc10= 99.85\n",
      "eval E062: 100% 177/177 [00:06<00:00, 26.99it/s]\n",
      "INFO - 02/01/23 01:11:36 - 0:19:15 - #################################################################################################################\n",
      "INFO - 02/01/23 01:11:36 - 0:19:15 - Test Epoch 62: LOSS= 1.66736, acc1= 69.32, acc3= 87.14, acc10= 97.10\n",
      "INFO - 02/01/23 01:11:36 - 0:19:15 - #################################################################################################################\n",
      "train E063:  55% 92/167 [00:05<00:05, 12.79it/s]"
     ]
    }
   ],
   "source": [
    "# relation间训练 BERT rnn  \n",
    "#待跑\n",
    "%cd code\n",
    "!python main_bert_cnn.py --gpu_id 8 --exp_name relation_space --exp_id bert --fusion_model BERT --data_choice 3 --method_choice W2V  --save_model 1 --ZSL 0  --relation_map 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "022bf624",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-31T16:50:06.439184Z",
     "start_time": "2023-01-31T16:30:19.797299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 02/01/23 00:30:22 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 02/01/23 00:30:22 - 0:00:00 - The experiment will be stored in dump/0201-fact_space/bert\n",
      "                                     \n",
      "INFO - 02/01/23 00:30:22 - 0:00:00 - Running command: python main_bert_cnn.py --gpu_id 8 --exp_name fact_space --exp_id bert --fusion_model BERT --data_choice 3 --method_choice W2V --save_model 1 --ZSL 0 --fact_map 1\n",
      "\n",
      "2023-02-01 00:30:22.377288: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-01 00:30:22.377340: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 16\n",
      "batch_size 16\n",
      "INFO - 02/01/23 00:30:32 - 0:00:11 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO - 02/01/23 00:30:32 - 0:00:11 - extracting archive file /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpc5c3ssvb\n",
      "embeddings.word_embeddings.weight:\tFalse\n",
      "embeddings.position_embeddings.weight:\tFalse\n",
      "embeddings.token_type_embeddings.weight:\tFalse\n",
      "embeddings.LayerNorm.weight:\tFalse\n",
      "embeddings.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.attention.self.query.weight:\tFalse\n",
      "encoder.layer.0.attention.self.query.bias:\tFalse\n",
      "encoder.layer.0.attention.self.key.weight:\tFalse\n",
      "encoder.layer.0.attention.self.key.bias:\tFalse\n",
      "encoder.layer.0.attention.self.value.weight:\tFalse\n",
      "encoder.layer.0.attention.self.value.bias:\tFalse\n",
      "encoder.layer.0.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.0.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.0.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.0.output.dense.weight:\tFalse\n",
      "encoder.layer.0.output.dense.bias:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.attention.self.query.weight:\tFalse\n",
      "encoder.layer.1.attention.self.query.bias:\tFalse\n",
      "encoder.layer.1.attention.self.key.weight:\tFalse\n",
      "encoder.layer.1.attention.self.key.bias:\tFalse\n",
      "encoder.layer.1.attention.self.value.weight:\tFalse\n",
      "encoder.layer.1.attention.self.value.bias:\tFalse\n",
      "encoder.layer.1.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.1.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.1.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.1.output.dense.weight:\tFalse\n",
      "encoder.layer.1.output.dense.bias:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.attention.self.query.weight:\tFalse\n",
      "encoder.layer.2.attention.self.query.bias:\tFalse\n",
      "encoder.layer.2.attention.self.key.weight:\tFalse\n",
      "encoder.layer.2.attention.self.key.bias:\tFalse\n",
      "encoder.layer.2.attention.self.value.weight:\tFalse\n",
      "encoder.layer.2.attention.self.value.bias:\tFalse\n",
      "encoder.layer.2.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.2.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.2.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.2.output.dense.weight:\tFalse\n",
      "encoder.layer.2.output.dense.bias:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.attention.self.query.weight:\tFalse\n",
      "encoder.layer.3.attention.self.query.bias:\tFalse\n",
      "encoder.layer.3.attention.self.key.weight:\tFalse\n",
      "encoder.layer.3.attention.self.key.bias:\tFalse\n",
      "encoder.layer.3.attention.self.value.weight:\tFalse\n",
      "encoder.layer.3.attention.self.value.bias:\tFalse\n",
      "encoder.layer.3.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.3.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.3.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.3.output.dense.weight:\tFalse\n",
      "encoder.layer.3.output.dense.bias:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.attention.self.query.weight:\tFalse\n",
      "encoder.layer.4.attention.self.query.bias:\tFalse\n",
      "encoder.layer.4.attention.self.key.weight:\tFalse\n",
      "encoder.layer.4.attention.self.key.bias:\tFalse\n",
      "encoder.layer.4.attention.self.value.weight:\tFalse\n",
      "encoder.layer.4.attention.self.value.bias:\tFalse\n",
      "encoder.layer.4.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.4.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.4.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.4.output.dense.weight:\tFalse\n",
      "encoder.layer.4.output.dense.bias:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.attention.self.query.weight:\tFalse\n",
      "encoder.layer.5.attention.self.query.bias:\tFalse\n",
      "encoder.layer.5.attention.self.key.weight:\tFalse\n",
      "encoder.layer.5.attention.self.key.bias:\tFalse\n",
      "encoder.layer.5.attention.self.value.weight:\tFalse\n",
      "encoder.layer.5.attention.self.value.bias:\tFalse\n",
      "encoder.layer.5.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.5.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.5.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.5.output.dense.weight:\tFalse\n",
      "encoder.layer.5.output.dense.bias:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.attention.self.query.weight:\tFalse\n",
      "encoder.layer.6.attention.self.query.bias:\tFalse\n",
      "encoder.layer.6.attention.self.key.weight:\tFalse\n",
      "encoder.layer.6.attention.self.key.bias:\tFalse\n",
      "encoder.layer.6.attention.self.value.weight:\tFalse\n",
      "encoder.layer.6.attention.self.value.bias:\tFalse\n",
      "encoder.layer.6.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.6.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.6.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.6.output.dense.weight:\tFalse\n",
      "encoder.layer.6.output.dense.bias:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.attention.self.query.weight:\tFalse\n",
      "encoder.layer.7.attention.self.query.bias:\tFalse\n",
      "encoder.layer.7.attention.self.key.weight:\tFalse\n",
      "encoder.layer.7.attention.self.key.bias:\tFalse\n",
      "encoder.layer.7.attention.self.value.weight:\tFalse\n",
      "encoder.layer.7.attention.self.value.bias:\tFalse\n",
      "encoder.layer.7.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.7.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.7.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.7.output.dense.weight:\tFalse\n",
      "encoder.layer.7.output.dense.bias:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.attention.self.query.weight:\tFalse\n",
      "encoder.layer.8.attention.self.query.bias:\tFalse\n",
      "encoder.layer.8.attention.self.key.weight:\tFalse\n",
      "encoder.layer.8.attention.self.key.bias:\tFalse\n",
      "encoder.layer.8.attention.self.value.weight:\tFalse\n",
      "encoder.layer.8.attention.self.value.bias:\tFalse\n",
      "encoder.layer.8.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.8.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.8.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.8.output.dense.weight:\tFalse\n",
      "encoder.layer.8.output.dense.bias:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.attention.self.query.weight:\tFalse\n",
      "encoder.layer.9.attention.self.query.bias:\tFalse\n",
      "encoder.layer.9.attention.self.key.weight:\tFalse\n",
      "encoder.layer.9.attention.self.key.bias:\tFalse\n",
      "encoder.layer.9.attention.self.value.weight:\tFalse\n",
      "encoder.layer.9.attention.self.value.bias:\tFalse\n",
      "encoder.layer.9.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.9.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.9.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.9.output.dense.weight:\tFalse\n",
      "encoder.layer.9.output.dense.bias:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.attention.self.query.weight:\tFalse\n",
      "encoder.layer.10.attention.self.query.bias:\tFalse\n",
      "encoder.layer.10.attention.self.key.weight:\tFalse\n",
      "encoder.layer.10.attention.self.key.bias:\tFalse\n",
      "encoder.layer.10.attention.self.value.weight:\tFalse\n",
      "encoder.layer.10.attention.self.value.bias:\tFalse\n",
      "encoder.layer.10.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.10.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.10.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.10.output.dense.weight:\tFalse\n",
      "encoder.layer.10.output.dense.bias:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.attention.self.query.weight:\tFalse\n",
      "encoder.layer.11.attention.self.query.bias:\tFalse\n",
      "encoder.layer.11.attention.self.key.weight:\tFalse\n",
      "encoder.layer.11.attention.self.key.bias:\tFalse\n",
      "encoder.layer.11.attention.self.value.weight:\tFalse\n",
      "encoder.layer.11.attention.self.value.bias:\tFalse\n",
      "encoder.layer.11.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.11.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.11.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.11.output.dense.weight:\tFalse\n",
      "encoder.layer.11.output.dense.bias:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.bias:\tFalse\n",
      "pooler.dense.weight:\tFalse\n",
      "pooler.dense.bias:\tFalse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight:\tFalse\r\n",
      "embeddings.position_embeddings.weight:\tFalse\r\n",
      "embeddings.token_type_embeddings.weight:\tFalse\r\n",
      "embeddings.LayerNorm.weight:\tFalse\r\n",
      "embeddings.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.0.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.0.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.0.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.0.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.0.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.0.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.0.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.0.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.0.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.0.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.0.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.0.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.0.output.dense.weight:\tFalse\r\n",
      "encoder.layer.0.output.dense.bias:\tFalse\r\n",
      "encoder.layer.0.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.0.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.1.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.1.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.1.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.1.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.1.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.1.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.1.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.1.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.1.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.1.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.1.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.1.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.1.output.dense.weight:\tFalse\r\n",
      "encoder.layer.1.output.dense.bias:\tFalse\r\n",
      "encoder.layer.1.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.1.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.2.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.2.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.2.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.2.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.2.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.2.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.2.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.2.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.2.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.2.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.2.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.2.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.2.output.dense.weight:\tFalse\r\n",
      "encoder.layer.2.output.dense.bias:\tFalse\r\n",
      "encoder.layer.2.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.2.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.3.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.3.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.3.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.3.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.3.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.3.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.3.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.3.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.3.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.3.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.3.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.3.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.3.output.dense.weight:\tFalse\r\n",
      "encoder.layer.3.output.dense.bias:\tFalse\r\n",
      "encoder.layer.3.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.3.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.4.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.4.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.4.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.4.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.4.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.4.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.4.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.4.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.4.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.4.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.4.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.4.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.4.output.dense.weight:\tFalse\r\n",
      "encoder.layer.4.output.dense.bias:\tFalse\r\n",
      "encoder.layer.4.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.4.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.5.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.5.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.5.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.5.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.5.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.5.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.5.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.5.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.5.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.5.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.5.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.5.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.5.output.dense.weight:\tFalse\r\n",
      "encoder.layer.5.output.dense.bias:\tFalse\r\n",
      "encoder.layer.5.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.5.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.6.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.6.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.6.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.6.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.6.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.6.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.6.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.6.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.6.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.6.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.6.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.6.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.6.output.dense.weight:\tFalse\r\n",
      "encoder.layer.6.output.dense.bias:\tFalse\r\n",
      "encoder.layer.6.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.6.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.7.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.7.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.7.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.7.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.7.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.7.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.7.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.7.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.7.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.7.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.7.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.7.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.7.output.dense.weight:\tFalse\r\n",
      "encoder.layer.7.output.dense.bias:\tFalse\r\n",
      "encoder.layer.7.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.7.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.8.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.8.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.8.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.8.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.8.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.8.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.8.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.8.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.8.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.8.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.8.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.8.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.8.output.dense.weight:\tFalse\r\n",
      "encoder.layer.8.output.dense.bias:\tFalse\r\n",
      "encoder.layer.8.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.8.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.9.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.9.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.9.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.9.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.9.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.9.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.9.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.9.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.9.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.9.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.9.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.9.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.9.output.dense.weight:\tFalse\r\n",
      "encoder.layer.9.output.dense.bias:\tFalse\r\n",
      "encoder.layer.9.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.9.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.10.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.10.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.10.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.10.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.10.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.10.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.10.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.10.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.10.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.10.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.10.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.10.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.10.output.dense.weight:\tFalse\r\n",
      "encoder.layer.10.output.dense.bias:\tFalse\r\n",
      "encoder.layer.10.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.10.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.11.attention.self.query.weight:\tFalse\r\n",
      "encoder.layer.11.attention.self.query.bias:\tFalse\r\n",
      "encoder.layer.11.attention.self.key.weight:\tFalse\r\n",
      "encoder.layer.11.attention.self.key.bias:\tFalse\r\n",
      "encoder.layer.11.attention.self.value.weight:\tFalse\r\n",
      "encoder.layer.11.attention.self.value.bias:\tFalse\r\n",
      "encoder.layer.11.attention.output.dense.weight:\tFalse\r\n",
      "encoder.layer.11.attention.output.dense.bias:\tFalse\r\n",
      "encoder.layer.11.attention.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.11.attention.output.LayerNorm.bias:\tFalse\r\n",
      "encoder.layer.11.intermediate.dense.weight:\tFalse\r\n",
      "encoder.layer.11.intermediate.dense.bias:\tFalse\r\n",
      "encoder.layer.11.output.dense.weight:\tFalse\r\n",
      "encoder.layer.11.output.dense.bias:\tFalse\r\n",
      "encoder.layer.11.output.LayerNorm.weight:\tFalse\r\n",
      "encoder.layer.11.output.LayerNorm.bias:\tFalse\r\n",
      "pooler.dense.weight:\tFalse\r\n",
      "pooler.dense.bias:\tFalse\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fusion_model:\r\n",
      "BERT(\r\n",
      "  (bert): BertModel(\r\n",
      "    (embeddings): BertEmbeddings(\r\n",
      "      (word_embeddings): Embedding(30522, 768)\r\n",
      "      (position_embeddings): Embedding(512, 768)\r\n",
      "      (token_type_embeddings): Embedding(2, 768)\r\n",
      "      (LayerNorm): BertLayerNorm()\r\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "    )\r\n",
      "    (encoder): BertEncoder(\r\n",
      "      (layer): ModuleList(\r\n",
      "        (0): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (1): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (2): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (3): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (4): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (5): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (6): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (7): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (8): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (9): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (10): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (11): BertLayer(\r\n",
      "          (attention): BertAttention(\r\n",
      "            (self): BertSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "              (softmax): Softmax(dim=-1)\r\n",
      "            )\r\n",
      "            (output): BertSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): BertLayerNorm()\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): BertIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "          )\r\n",
      "          (output): BertOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): BertLayerNorm()\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (pooler): BertPooler(\r\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "      (activation): Tanh()\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (lstm): LSTM(768, 768, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\r\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "  (fc_rnn): Linear(in_features=1536, out_features=1024, bias=True)\r\n",
      "  (mlp): GroupMLP(\r\n",
      "    (conv1): Conv1d(768, 8192, kernel_size=(1,), stride=(1,))\r\n",
      "    (drop): Dropout(p=0.5, inplace=False)\r\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\r\n",
      "    (conv2): Conv1d(8192, 1024, kernel_size=(1,), stride=(1,), groups=64)\r\n",
      "  )\r\n",
      ")\r\n",
      "Answer Model:\r\n",
      "MLP(\r\n",
      "  (mlp): GroupMLP(\r\n",
      "    (conv1): Conv1d(300, 2048, kernel_size=(1,), stride=(1,))\r\n",
      "    (drop): Dropout(p=0.0, inplace=False)\r\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\r\n",
      "    (conv2): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,), groups=64)\r\n",
      "  )\r\n",
      ")\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E000:   0% 0/167 [00:00<?, ?it/s]torch.Size([16, 1024]) torch.Size([2791, 1024])\n",
      "train E000: 100% 167/167 [00:13<00:00, 12.57it/s]\n",
      "INFO - 02/01/23 00:30:59 - 0:00:37 - Train Epoch 0: LOSS= 7.67075, lr= 0.000500, acc1= 7.94,acc3= 13.90,acc10= 17.50\n",
      "train E001: 100% 167/167 [00:12<00:00, 13.18it/s]\n",
      "INFO - 02/01/23 00:31:12 - 0:00:50 - Train Epoch 1: LOSS= 6.99248, lr= 0.000750, acc1= 11.58,acc3= 19.26,acc10= 25.25\n",
      "eval E001: 100% 177/177 [00:07<00:00, 22.19it/s]\n",
      "INFO - 02/01/23 00:31:20 - 0:00:58 - #################################################################################################################\n",
      "INFO - 02/01/23 00:31:20 - 0:00:58 - Test Epoch 1: LOSS= 6.91289, acc1= 11.48, acc3= 19.55, acc10= 25.43\n",
      "INFO - 02/01/23 00:31:20 - 0:00:58 - #################################################################################################################\n",
      "train E002: 100% 167/167 [00:13<00:00, 12.55it/s]\n",
      "INFO - 02/01/23 00:31:33 - 0:01:11 - Train Epoch 2: LOSS= 6.77536, lr= 0.001000, acc1= 13.86,acc3= 24.05,acc10= 30.12\n",
      "eval E002: 100% 177/177 [00:07<00:00, 23.40it/s]\n",
      "INFO - 02/01/23 00:31:41 - 0:01:19 - #################################################################################################################\n",
      "INFO - 02/01/23 00:31:41 - 0:01:19 - Test Epoch 2: LOSS= 6.85681, acc1= 12.86, acc3= 22.71, acc10= 27.74\n",
      "INFO - 02/01/23 00:31:41 - 0:01:19 - #################################################################################################################\n",
      "train E003: 100% 167/167 [00:13<00:00, 12.61it/s]\n",
      "INFO - 02/01/23 00:31:54 - 0:01:32 - Train Epoch 3: LOSS= 6.64272, lr= 0.001250, acc1= 15.21,acc3= 25.78,acc10= 32.26\n",
      "eval E003: 100% 177/177 [00:07<00:00, 23.19it/s]\n",
      "INFO - 02/01/23 00:32:01 - 0:01:40 - #################################################################################################################\n",
      "INFO - 02/01/23 00:32:01 - 0:01:40 - Test Epoch 3: LOSS= 6.94935, acc1= 13.28, acc3= 23.10, acc10= 29.05\n",
      "INFO - 02/01/23 00:32:01 - 0:01:40 - #################################################################################################################\n",
      "train E004: 100% 167/167 [00:13<00:00, 12.82it/s]\n",
      "INFO - 02/01/23 00:32:15 - 0:01:53 - Train Epoch 4: LOSS= 6.57865, lr= 0.001500, acc1= 15.55,acc3= 26.98,acc10= 33.31\n",
      "eval E004: 100% 177/177 [00:07<00:00, 23.43it/s]\n",
      "INFO - 02/01/23 00:32:22 - 0:02:00 - #################################################################################################################\n",
      "INFO - 02/01/23 00:32:22 - 0:02:00 - Test Epoch 4: LOSS= 6.79191, acc1= 12.68, acc3= 21.89, acc10= 28.41\n",
      "INFO - 02/01/23 00:32:22 - 0:02:00 - #################################################################################################################\n",
      "train E005: 100% 167/167 [00:13<00:00, 12.73it/s]\n",
      "INFO - 02/01/23 00:32:35 - 0:02:14 - Train Epoch 5: LOSS= 6.44584, lr= 0.001750, acc1= 16.79,acc3= 28.44,acc10= 35.56\n",
      "eval E005: 100% 177/177 [00:07<00:00, 23.61it/s]\n",
      "INFO - 02/01/23 00:32:43 - 0:02:21 - #################################################################################################################\n",
      "INFO - 02/01/23 00:32:43 - 0:02:21 - Test Epoch 5: LOSS= 7.01595, acc1= 11.44, acc3= 20.79, acc10= 26.39\n",
      "INFO - 02/01/23 00:32:43 - 0:02:21 - #################################################################################################################\n",
      "train E006: 100% 167/167 [00:12<00:00, 13.16it/s]\n",
      "INFO - 02/01/23 00:32:55 - 0:02:34 - Train Epoch 6: LOSS= 6.31222, lr= 0.002000, acc1= 17.72,acc3= 30.31,acc10= 38.29\n",
      "eval E006: 100% 177/177 [00:07<00:00, 23.74it/s]\n",
      "INFO - 02/01/23 00:33:03 - 0:02:41 - #################################################################################################################\n",
      "INFO - 02/01/23 00:33:03 - 0:02:41 - Test Epoch 6: LOSS= 6.67731, acc1= 15.30, acc3= 26.74, acc10= 32.45\n",
      "INFO - 02/01/23 00:33:03 - 0:02:41 - #################################################################################################################\n",
      "train E007: 100% 167/167 [00:12<00:00, 13.65it/s]\n",
      "INFO - 02/01/23 00:33:15 - 0:02:53 - Train Epoch 7: LOSS= 6.02086, lr= 0.002000, acc1= 20.72,acc3= 35.93,acc10= 44.55\n",
      "eval E007: 100% 177/177 [00:07<00:00, 23.35it/s]\n",
      "INFO - 02/01/23 00:33:23 - 0:03:01 - #################################################################################################################\n",
      "INFO - 02/01/23 00:33:23 - 0:03:01 - Test Epoch 7: LOSS= 6.48860, acc1= 18.99, acc3= 29.51, acc10= 37.30\n",
      "INFO - 02/01/23 00:33:23 - 0:03:01 - #################################################################################################################\n",
      "train E008: 100% 167/167 [00:13<00:00, 12.80it/s]\n",
      "INFO - 02/01/23 00:33:36 - 0:03:14 - Train Epoch 8: LOSS= 5.75371, lr= 0.002000, acc1= 26.41,acc3= 41.63,acc10= 49.57\n",
      "eval E008: 100% 177/177 [00:08<00:00, 21.33it/s]\n",
      "INFO - 02/01/23 00:33:44 - 0:03:22 - #################################################################################################################\n",
      "INFO - 02/01/23 00:33:44 - 0:03:22 - Test Epoch 8: LOSS= 6.39512, acc1= 18.99, acc3= 31.56, acc10= 38.54\n",
      "INFO - 02/01/23 00:33:44 - 0:03:22 - #################################################################################################################\n",
      "train E009: 100% 167/167 [00:13<00:00, 12.80it/s]\n",
      "INFO - 02/01/23 00:33:57 - 0:03:36 - Train Epoch 9: LOSS= 5.55996, lr= 0.002000, acc1= 27.31,acc3= 44.02,acc10= 53.62\n",
      "eval E009: 100% 177/177 [00:07<00:00, 23.35it/s]\n",
      "INFO - 02/01/23 00:34:05 - 0:03:43 - #################################################################################################################\n",
      "INFO - 02/01/23 00:34:05 - 0:03:43 - Test Epoch 9: LOSS= 6.24410, acc1= 21.68, acc3= 34.04, acc10= 42.08\n",
      "INFO - 02/01/23 00:34:05 - 0:03:43 - #################################################################################################################\n",
      "train E010: 100% 167/167 [00:12<00:00, 13.10it/s]\n",
      "INFO - 02/01/23 00:34:18 - 0:03:56 - Train Epoch 10: LOSS= 5.36390, lr= 0.002000, acc1= 31.62,acc3= 49.08,acc10= 58.60\n",
      "eval E010: 100% 177/177 [00:07<00:00, 23.70it/s]\n",
      "INFO - 02/01/23 00:34:25 - 0:04:03 - #################################################################################################################\n",
      "INFO - 02/01/23 00:34:25 - 0:04:03 - Test Epoch 10: LOSS= 6.38486, acc1= 20.05, acc3= 34.93, acc10= 43.71\n",
      "INFO - 02/01/23 00:34:25 - 0:04:03 - #################################################################################################################\n",
      "train E011: 100% 167/167 [00:13<00:00, 12.74it/s]\n",
      "INFO - 02/01/23 00:34:38 - 0:04:17 - Train Epoch 11: LOSS= 5.15553, lr= 0.002000, acc1= 34.06,acc3= 52.87,acc10= 62.53\n",
      "eval E011: 100% 177/177 [00:08<00:00, 20.20it/s]\n",
      "INFO - 02/01/23 00:34:47 - 0:04:25 - #################################################################################################################\n",
      "INFO - 02/01/23 00:34:47 - 0:04:25 - Test Epoch 11: LOSS= 5.82671, acc1= 26.82, acc3= 41.87, acc10= 50.87\n",
      "INFO - 02/01/23 00:34:47 - 0:04:25 - #################################################################################################################\n",
      "train E012: 100% 167/167 [00:13<00:00, 12.64it/s]\n",
      "INFO - 02/01/23 00:35:00 - 0:04:39 - Train Epoch 12: LOSS= 4.90336, lr= 0.002000, acc1= 37.73,acc3= 57.44,acc10= 67.03\n",
      "eval E012: 100% 177/177 [00:07<00:00, 23.60it/s]\n",
      "INFO - 02/01/23 00:35:08 - 0:04:46 - #################################################################################################################\n",
      "INFO - 02/01/23 00:35:08 - 0:04:46 - Test Epoch 12: LOSS= 5.75838, acc1= 30.32, acc3= 46.30, acc10= 54.69\n",
      "INFO - 02/01/23 00:35:08 - 0:04:46 - #################################################################################################################\n",
      "train E013: 100% 167/167 [00:13<00:00, 12.74it/s]\n",
      "INFO - 02/01/23 00:35:21 - 0:04:59 - Train Epoch 13: LOSS= 4.76929, lr= 0.002000, acc1= 40.76,acc3= 59.54,acc10= 69.05\n",
      "eval E013: 100% 177/177 [00:07<00:00, 23.79it/s]\n",
      "INFO - 02/01/23 00:35:28 - 0:05:07 - #################################################################################################################\n",
      "INFO - 02/01/23 00:35:28 - 0:05:07 - Test Epoch 13: LOSS= 5.93797, acc1= 28.13, acc3= 43.29, acc10= 51.65\n",
      "INFO - 02/01/23 00:35:28 - 0:05:07 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E014: 100% 167/167 [00:12<00:00, 13.16it/s]\n",
      "INFO - 02/01/23 00:35:41 - 0:05:19 - Train Epoch 14: LOSS= 4.25164, lr= 0.001400, acc1= 49.16,acc3= 69.73,acc10= 78.16\n",
      "eval E014: 100% 177/177 [00:07<00:00, 23.26it/s]\n",
      "INFO - 02/01/23 00:35:49 - 0:05:27 - #################################################################################################################\n",
      "INFO - 02/01/23 00:35:49 - 0:05:27 - Test Epoch 14: LOSS= 5.75141, acc1= 32.91, acc3= 49.31, acc10= 57.67\n",
      "INFO - 02/01/23 00:35:49 - 0:05:27 - #################################################################################################################\n",
      "train E015: 100% 167/167 [00:12<00:00, 13.31it/s]\n",
      "INFO - 02/01/23 00:36:01 - 0:05:40 - Train Epoch 15: LOSS= 3.99917, lr= 0.001400, acc1= 55.00,acc3= 73.62,acc10= 80.97\n",
      "eval E015: 100% 177/177 [00:07<00:00, 23.58it/s]\n",
      "INFO - 02/01/23 00:36:09 - 0:05:47 - #################################################################################################################\n",
      "INFO - 02/01/23 00:36:09 - 0:05:47 - Test Epoch 15: LOSS= 5.98403, acc1= 32.20, acc3= 47.93, acc10= 55.65\n",
      "INFO - 02/01/23 00:36:09 - 0:05:47 - #################################################################################################################\n",
      "train E016: 100% 167/167 [00:12<00:00, 13.03it/s]\n",
      "INFO - 02/01/23 00:36:22 - 0:06:00 - Train Epoch 16: LOSS= 3.93949, lr= 0.001400, acc1= 56.91,acc3= 75.87,acc10= 82.09\n",
      "eval E016: 100% 177/177 [00:07<00:00, 23.75it/s]\n",
      "INFO - 02/01/23 00:36:29 - 0:06:07 - #################################################################################################################\n",
      "INFO - 02/01/23 00:36:29 - 0:06:07 - Test Epoch 16: LOSS= 5.66405, acc1= 34.22, acc3= 50.30, acc10= 57.99\n",
      "INFO - 02/01/23 00:36:29 - 0:06:07 - #################################################################################################################\n",
      "train E017: 100% 167/167 [00:13<00:00, 12.73it/s]\n",
      "INFO - 02/01/23 00:36:42 - 0:06:21 - Train Epoch 17: LOSS= 3.41826, lr= 0.000980, acc1= 66.24,acc3= 83.55,acc10= 88.35\n",
      "eval E017: 100% 177/177 [00:08<00:00, 19.86it/s]\n",
      "INFO - 02/01/23 00:36:51 - 0:06:29 - #################################################################################################################\n",
      "INFO - 02/01/23 00:36:51 - 0:06:29 - Test Epoch 17: LOSS= 5.83281, acc1= 36.59, acc3= 51.26, acc10= 58.73\n",
      "INFO - 02/01/23 00:36:51 - 0:06:29 - #################################################################################################################\n",
      "train E018: 100% 167/167 [00:12<00:00, 12.92it/s]\n",
      "INFO - 02/01/23 00:37:04 - 0:06:42 - Train Epoch 18: LOSS= 3.18288, lr= 0.000980, acc1= 69.13,acc3= 85.69,acc10= 90.26\n",
      "eval E018: 100% 177/177 [00:07<00:00, 23.56it/s]\n",
      "INFO - 02/01/23 00:37:12 - 0:06:50 - #################################################################################################################\n",
      "INFO - 02/01/23 00:37:12 - 0:06:50 - Test Epoch 18: LOSS= 5.70036, acc1= 37.27, acc3= 53.17, acc10= 60.11\n",
      "INFO - 02/01/23 00:37:12 - 0:06:50 - #################################################################################################################\n",
      "train E019: 100% 167/167 [00:12<00:00, 12.99it/s]\n",
      "INFO - 02/01/23 00:37:25 - 0:07:03 - Train Epoch 19: LOSS= 3.07567, lr= 0.000980, acc1= 71.26,acc3= 86.96,acc10= 91.57\n",
      "eval E019: 100% 177/177 [00:07<00:00, 23.25it/s]\n",
      "INFO - 02/01/23 00:37:32 - 0:07:10 - #################################################################################################################\n",
      "INFO - 02/01/23 00:37:32 - 0:07:10 - Test Epoch 19: LOSS= 5.91331, acc1= 38.15, acc3= 53.88, acc10= 60.89\n",
      "INFO - 02/01/23 00:37:32 - 0:07:10 - #################################################################################################################\n",
      "train E020: 100% 167/167 [00:12<00:00, 13.05it/s]\n",
      "INFO - 02/01/23 00:37:45 - 0:07:23 - Train Epoch 20: LOSS= 2.72711, lr= 0.000686, acc1= 78.01,acc3= 90.41,acc10= 93.71\n",
      "eval E020: 100% 177/177 [00:07<00:00, 23.58it/s]\n",
      "INFO - 02/01/23 00:37:53 - 0:07:31 - #################################################################################################################\n",
      "INFO - 02/01/23 00:37:53 - 0:07:31 - Test Epoch 20: LOSS= 6.07518, acc1= 40.17, acc3= 54.20, acc10= 61.88\n",
      "INFO - 02/01/23 00:37:53 - 0:07:31 - #################################################################################################################\n",
      "train E021: 100% 167/167 [00:13<00:00, 12.80it/s]\n",
      "INFO - 02/01/23 00:38:06 - 0:07:44 - Train Epoch 21: LOSS= 2.55505, lr= 0.000686, acc1= 80.25,acc3= 92.36,acc10= 94.98\n",
      "eval E021: 100% 177/177 [00:07<00:00, 23.04it/s]\n",
      "INFO - 02/01/23 00:38:13 - 0:07:52 - #################################################################################################################\n",
      "INFO - 02/01/23 00:38:13 - 0:07:52 - Test Epoch 21: LOSS= 6.10738, acc1= 40.56, acc3= 54.23, acc10= 61.00\n",
      "INFO - 02/01/23 00:38:13 - 0:07:52 - #################################################################################################################\n",
      "train E022: 100% 167/167 [00:13<00:00, 12.31it/s]\n",
      "INFO - 02/01/23 00:38:27 - 0:08:05 - Train Epoch 22: LOSS= 2.43733, lr= 0.000686, acc1= 82.28,acc3= 93.33,acc10= 95.99\n",
      "eval E022: 100% 177/177 [00:09<00:00, 19.41it/s]\n",
      "INFO - 02/01/23 00:38:36 - 0:08:14 - #################################################################################################################\n",
      "INFO - 02/01/23 00:38:36 - 0:08:14 - Test Epoch 22: LOSS= 6.38689, acc1= 39.25, acc3= 54.84, acc10= 61.99\n",
      "INFO - 02/01/23 00:38:36 - 0:08:14 - #################################################################################################################\n",
      "train E023: 100% 167/167 [00:12<00:00, 13.56it/s]\n",
      "INFO - 02/01/23 00:38:48 - 0:08:27 - Train Epoch 23: LOSS= 2.12298, lr= 0.000480, acc1= 86.62,acc3= 94.94,acc10= 97.08\n",
      "eval E023: 100% 177/177 [00:07<00:00, 23.78it/s]\n",
      "INFO - 02/01/23 00:38:56 - 0:08:34 - #################################################################################################################\n",
      "INFO - 02/01/23 00:38:56 - 0:08:34 - Test Epoch 23: LOSS= 6.60087, acc1= 40.67, acc3= 54.98, acc10= 61.42\n",
      "INFO - 02/01/23 00:38:56 - 0:08:34 - #################################################################################################################\n",
      "train E024: 100% 167/167 [00:12<00:00, 12.93it/s]\n",
      "INFO - 02/01/23 00:39:09 - 0:08:47 - Train Epoch 24: LOSS= 2.03720, lr= 0.000480, acc1= 87.07,acc3= 95.58,acc10= 97.26\n",
      "eval E024: 100% 177/177 [00:07<00:00, 23.51it/s]\n",
      "INFO - 02/01/23 00:39:16 - 0:08:55 - #################################################################################################################\n",
      "INFO - 02/01/23 00:39:16 - 0:08:55 - Test Epoch 24: LOSS= 6.58595, acc1= 40.70, acc3= 55.37, acc10= 62.10\n",
      "INFO - 02/01/23 00:39:16 - 0:08:55 - #################################################################################################################\n",
      "train E025: 100% 167/167 [00:12<00:00, 13.00it/s]\n",
      "INFO - 02/01/23 00:39:29 - 0:09:07 - Train Epoch 25: LOSS= 1.92937, lr= 0.000480, acc1= 88.35,acc3= 96.48,acc10= 98.31\n",
      "eval E025: 100% 177/177 [00:07<00:00, 23.40it/s]\n",
      "INFO - 02/01/23 00:39:37 - 0:09:15 - #################################################################################################################\n",
      "INFO - 02/01/23 00:39:37 - 0:09:15 - Test Epoch 25: LOSS= 6.78285, acc1= 40.60, acc3= 55.79, acc10= 62.84\n",
      "INFO - 02/01/23 00:39:37 - 0:09:15 - #################################################################################################################\n",
      "train E026: 100% 167/167 [00:12<00:00, 12.98it/s]\n",
      "INFO - 02/01/23 00:39:50 - 0:09:28 - Train Epoch 26: LOSS= 1.73870, lr= 0.000336, acc1= 90.33,acc3= 97.04,acc10= 98.31\n",
      "eval E026: 100% 177/177 [00:07<00:00, 23.67it/s]\n",
      "INFO - 02/01/23 00:39:57 - 0:09:35 - #################################################################################################################\n",
      "INFO - 02/01/23 00:39:57 - 0:09:35 - Test Epoch 26: LOSS= 6.86099, acc1= 40.91, acc3= 55.33, acc10= 62.03\n",
      "INFO - 02/01/23 00:39:57 - 0:09:35 - #################################################################################################################\n",
      "train E027: 100% 167/167 [00:12<00:00, 13.08it/s]\n",
      "INFO - 02/01/23 00:40:10 - 0:09:48 - Train Epoch 27: LOSS= 1.65834, lr= 0.000336, acc1= 90.56,acc3= 96.93,acc10= 98.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E027: 100% 177/177 [00:07<00:00, 23.78it/s]\n",
      "INFO - 02/01/23 00:40:17 - 0:09:56 - #################################################################################################################\n",
      "INFO - 02/01/23 00:40:17 - 0:09:56 - Test Epoch 27: LOSS= 7.01741, acc1= 40.42, acc3= 54.73, acc10= 62.13\n",
      "INFO - 02/01/23 00:40:17 - 0:09:56 - #################################################################################################################\n",
      "train E028: 100% 167/167 [00:12<00:00, 13.03it/s]\n",
      "INFO - 02/01/23 00:40:30 - 0:10:08 - Train Epoch 28: LOSS= 1.63026, lr= 0.000336, acc1= 91.31,acc3= 97.60,acc10= 98.88\n",
      "eval E028: 100% 177/177 [00:07<00:00, 24.06it/s]\n",
      "INFO - 02/01/23 00:40:38 - 0:10:16 - #################################################################################################################\n",
      "INFO - 02/01/23 00:40:38 - 0:10:16 - Test Epoch 28: LOSS= 7.22501, acc1= 40.45, acc3= 55.44, acc10= 62.20\n",
      "INFO - 02/01/23 00:40:38 - 0:10:16 - #################################################################################################################\n",
      "train E029: 100% 167/167 [00:12<00:00, 13.03it/s]\n",
      "INFO - 02/01/23 00:40:50 - 0:10:29 - Train Epoch 29: LOSS= 1.45950, lr= 0.000235, acc1= 92.84,acc3= 98.28,acc10= 98.95\n",
      "eval E029: 100% 177/177 [00:07<00:00, 23.97it/s]\n",
      "INFO - 02/01/23 00:40:58 - 0:10:36 - #################################################################################################################\n",
      "INFO - 02/01/23 00:40:58 - 0:10:36 - Test Epoch 29: LOSS= 7.44887, acc1= 41.06, acc3= 55.69, acc10= 62.66\n",
      "INFO - 02/01/23 00:40:58 - 0:10:36 - #################################################################################################################\n",
      "train E030: 100% 167/167 [00:13<00:00, 12.29it/s]\n",
      "INFO - 02/01/23 00:41:11 - 0:10:50 - Train Epoch 30: LOSS= 1.37388, lr= 0.000235, acc1= 93.07,acc3= 97.90,acc10= 98.95\n",
      "eval E030: 100% 177/177 [00:07<00:00, 23.66it/s]\n",
      "INFO - 02/01/23 00:41:19 - 0:10:57 - #################################################################################################################\n",
      "INFO - 02/01/23 00:41:19 - 0:10:57 - Test Epoch 30: LOSS= 7.74321, acc1= 40.63, acc3= 55.19, acc10= 61.39\n",
      "INFO - 02/01/23 00:41:19 - 0:10:57 - #################################################################################################################\n",
      "train E031: 100% 167/167 [00:12<00:00, 12.93it/s]\n",
      "INFO - 02/01/23 00:41:32 - 0:11:10 - Train Epoch 31: LOSS= 1.32973, lr= 0.000235, acc1= 93.71,acc3= 98.31,acc10= 99.18\n",
      "eval E031: 100% 177/177 [00:07<00:00, 23.75it/s]\n",
      "INFO - 02/01/23 00:41:39 - 0:11:18 - #################################################################################################################\n",
      "INFO - 02/01/23 00:41:39 - 0:11:18 - Test Epoch 31: LOSS= 7.82129, acc1= 40.60, acc3= 55.30, acc10= 62.38\n",
      "INFO - 02/01/23 00:41:39 - 0:11:18 - #################################################################################################################\n",
      "train E032: 100% 167/167 [00:13<00:00, 12.74it/s]\n",
      "INFO - 02/01/23 00:41:52 - 0:11:31 - Train Epoch 32: LOSS= 1.20418, lr= 0.000165, acc1= 95.13,acc3= 98.50,acc10= 99.25\n",
      "eval E032: 100% 177/177 [00:08<00:00, 20.10it/s]\n",
      "INFO - 02/01/23 00:42:01 - 0:11:39 - #################################################################################################################\n",
      "INFO - 02/01/23 00:42:01 - 0:11:39 - Test Epoch 32: LOSS= 8.15850, acc1= 40.60, acc3= 55.30, acc10= 62.03\n",
      "INFO - 02/01/23 00:42:01 - 0:11:39 - #################################################################################################################\n",
      "train E033: 100% 167/167 [00:12<00:00, 12.85it/s]\n",
      "INFO - 02/01/23 00:42:14 - 0:11:52 - Train Epoch 33: LOSS= 1.19334, lr= 0.000165, acc1= 94.98,acc3= 98.73,acc10= 99.33\n",
      "eval E033: 100% 177/177 [00:07<00:00, 23.24it/s]\n",
      "INFO - 02/01/23 00:42:22 - 0:12:00 - #################################################################################################################\n",
      "INFO - 02/01/23 00:42:22 - 0:12:00 - Test Epoch 33: LOSS= 8.18708, acc1= 40.70, acc3= 54.59, acc10= 61.99\n",
      "INFO - 02/01/23 00:42:22 - 0:12:00 - #################################################################################################################\n",
      "train E034: 100% 167/167 [00:12<00:00, 12.93it/s]\n",
      "INFO - 02/01/23 00:42:35 - 0:12:13 - Train Epoch 34: LOSS= 1.14088, lr= 0.000165, acc1= 95.35,acc3= 98.43,acc10= 98.99\n",
      "eval E034: 100% 177/177 [00:07<00:00, 23.24it/s]\n",
      "INFO - 02/01/23 00:42:42 - 0:12:21 - #################################################################################################################\n",
      "INFO - 02/01/23 00:42:42 - 0:12:21 - Test Epoch 34: LOSS= 8.28790, acc1= 40.56, acc3= 54.16, acc10= 60.86\n",
      "INFO - 02/01/23 00:42:42 - 0:12:21 - #################################################################################################################\n",
      "train E035: 100% 167/167 [00:13<00:00, 12.69it/s]\n",
      "INFO - 02/01/23 00:42:55 - 0:12:34 - Train Epoch 35: LOSS= 1.07166, lr= 0.000115, acc1= 95.62,acc3= 99.29,acc10= 99.66\n",
      "eval E035: 100% 177/177 [00:07<00:00, 23.44it/s]\n",
      "INFO - 02/01/23 00:43:03 - 0:12:41 - #################################################################################################################\n",
      "INFO - 02/01/23 00:43:03 - 0:12:41 - Test Epoch 35: LOSS= 8.46411, acc1= 41.06, acc3= 54.80, acc10= 61.57\n",
      "INFO - 02/01/23 00:43:03 - 0:12:41 - #################################################################################################################\n",
      "train E036: 100% 167/167 [00:13<00:00, 12.66it/s]\n",
      "INFO - 02/01/23 00:43:16 - 0:12:55 - Train Epoch 36: LOSS= 1.04566, lr= 0.000115, acc1= 95.92,acc3= 99.14,acc10= 99.51\n",
      "eval E036: 100% 177/177 [00:07<00:00, 24.07it/s]\n",
      "INFO - 02/01/23 00:43:24 - 0:13:02 - #################################################################################################################\n",
      "INFO - 02/01/23 00:43:24 - 0:13:02 - Test Epoch 36: LOSS= 8.48749, acc1= 41.09, acc3= 55.08, acc10= 61.88\n",
      "INFO - 02/01/23 00:43:24 - 0:13:02 - #################################################################################################################\n",
      "train E037: 100% 167/167 [00:12<00:00, 12.85it/s]\n",
      "INFO - 02/01/23 00:43:37 - 0:13:15 - Train Epoch 37: LOSS= 0.99977, lr= 0.000115, acc1= 96.29,acc3= 99.21,acc10= 99.59\n",
      "eval E037: 100% 177/177 [00:08<00:00, 20.06it/s]\n",
      "INFO - 02/01/23 00:43:45 - 0:13:24 - #################################################################################################################\n",
      "INFO - 02/01/23 00:43:45 - 0:13:24 - Test Epoch 37: LOSS= 8.67029, acc1= 40.63, acc3= 54.87, acc10= 61.57\n",
      "INFO - 02/01/23 00:43:45 - 0:13:24 - #################################################################################################################\n",
      "train E038: 100% 167/167 [00:13<00:00, 12.49it/s]\n",
      "INFO - 02/01/23 00:43:59 - 0:13:37 - Train Epoch 38: LOSS= 1.00511, lr= 0.000081, acc1= 96.93,acc3= 98.91,acc10= 99.44\n",
      "eval E038: 100% 177/177 [00:08<00:00, 19.71it/s]\n",
      "INFO - 02/01/23 00:44:08 - 0:13:46 - #################################################################################################################\n",
      "INFO - 02/01/23 00:44:08 - 0:13:46 - Test Epoch 38: LOSS= 8.66803, acc1= 40.74, acc3= 54.66, acc10= 61.11\n",
      "INFO - 02/01/23 00:44:08 - 0:13:46 - #################################################################################################################\n",
      "train E039: 100% 167/167 [00:12<00:00, 12.85it/s]\n",
      "INFO - 02/01/23 00:44:21 - 0:13:59 - Train Epoch 39: LOSS= 0.93577, lr= 0.000081, acc1= 96.25,acc3= 99.44,acc10= 99.78\n",
      "eval E039: 100% 177/177 [00:08<00:00, 20.80it/s]\n",
      "INFO - 02/01/23 00:44:29 - 0:14:08 - #################################################################################################################\n",
      "INFO - 02/01/23 00:44:29 - 0:14:08 - Test Epoch 39: LOSS= 8.88744, acc1= 40.31, acc3= 54.87, acc10= 61.25\n",
      "INFO - 02/01/23 00:44:29 - 0:14:08 - #################################################################################################################\n",
      "train E040: 100% 167/167 [00:13<00:00, 12.78it/s]\n",
      "INFO - 02/01/23 00:44:42 - 0:14:21 - Train Epoch 40: LOSS= 0.91472, lr= 0.000081, acc1= 96.93,acc3= 99.36,acc10= 99.66\n",
      "eval E040: 100% 177/177 [00:07<00:00, 23.29it/s]\n",
      "INFO - 02/01/23 00:44:50 - 0:14:28 - #################################################################################################################\n",
      "INFO - 02/01/23 00:44:50 - 0:14:28 - Test Epoch 40: LOSS= 9.17335, acc1= 40.60, acc3= 55.12, acc10= 61.42\n",
      "INFO - 02/01/23 00:44:50 - 0:14:28 - #################################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train E041: 100% 167/167 [00:12<00:00, 13.24it/s]\n",
      "INFO - 02/01/23 00:45:03 - 0:14:41 - Train Epoch 41: LOSS= 0.89366, lr= 0.000056, acc1= 96.89,acc3= 99.55,acc10= 99.89\n",
      "eval E041: 100% 177/177 [00:07<00:00, 23.31it/s]\n",
      "INFO - 02/01/23 00:45:10 - 0:14:48 - #################################################################################################################\n",
      "INFO - 02/01/23 00:45:10 - 0:14:48 - Test Epoch 41: LOSS= 9.17479, acc1= 40.52, acc3= 54.73, acc10= 61.46\n",
      "INFO - 02/01/23 00:45:10 - 0:14:48 - #################################################################################################################\n",
      "train E042: 100% 167/167 [00:12<00:00, 12.94it/s]\n",
      "INFO - 02/01/23 00:45:23 - 0:15:01 - Train Epoch 42: LOSS= 0.89898, lr= 0.000056, acc1= 96.63,acc3= 99.36,acc10= 99.55\n",
      "eval E042: 100% 177/177 [00:07<00:00, 23.51it/s]\n",
      "INFO - 02/01/23 00:45:31 - 0:15:09 - #################################################################################################################\n",
      "INFO - 02/01/23 00:45:31 - 0:15:09 - Test Epoch 42: LOSS= 9.28169, acc1= 40.67, acc3= 54.30, acc10= 61.03\n",
      "INFO - 02/01/23 00:45:31 - 0:15:09 - #################################################################################################################\n",
      "train E043: 100% 167/167 [00:13<00:00, 12.84it/s]\n",
      "INFO - 02/01/23 00:45:44 - 0:15:22 - Train Epoch 43: LOSS= 0.88411, lr= 0.000056, acc1= 96.93,acc3= 99.48,acc10= 99.78\n",
      "eval E043: 100% 177/177 [00:08<00:00, 20.47it/s]\n",
      "INFO - 02/01/23 00:45:52 - 0:15:31 - #################################################################################################################\n",
      "INFO - 02/01/23 00:45:52 - 0:15:31 - Test Epoch 43: LOSS= 9.25723, acc1= 40.88, acc3= 54.27, acc10= 61.00\n",
      "INFO - 02/01/23 00:45:52 - 0:15:31 - #################################################################################################################\n",
      "train E044: 100% 167/167 [00:12<00:00, 12.99it/s]\n",
      "INFO - 02/01/23 00:46:05 - 0:15:43 - Train Epoch 44: LOSS= 0.85164, lr= 0.000040, acc1= 96.97,acc3= 99.33,acc10= 99.70\n",
      "eval E044: 100% 177/177 [00:07<00:00, 23.54it/s]\n",
      "INFO - 02/01/23 00:46:13 - 0:15:51 - #################################################################################################################\n",
      "INFO - 02/01/23 00:46:13 - 0:15:51 - Test Epoch 44: LOSS= 9.35694, acc1= 40.63, acc3= 54.16, acc10= 61.03\n",
      "INFO - 02/01/23 00:46:13 - 0:15:51 - #################################################################################################################\n",
      "train E045: 100% 167/167 [00:12<00:00, 12.86it/s]\n",
      "INFO - 02/01/23 00:46:26 - 0:16:04 - Train Epoch 45: LOSS= 0.88538, lr= 0.000040, acc1= 96.59,acc3= 99.21,acc10= 99.51\n",
      "eval E045: 100% 177/177 [00:07<00:00, 23.45it/s]\n",
      "INFO - 02/01/23 00:46:33 - 0:16:12 - #################################################################################################################\n",
      "INFO - 02/01/23 00:46:33 - 0:16:12 - Test Epoch 45: LOSS= 9.38836, acc1= 40.74, acc3= 54.27, acc10= 60.86\n",
      "INFO - 02/01/23 00:46:33 - 0:16:12 - #################################################################################################################\n",
      "train E046: 100% 167/167 [00:12<00:00, 13.11it/s]\n",
      "INFO - 02/01/23 00:46:46 - 0:16:24 - Train Epoch 46: LOSS= 0.85189, lr= 0.000040, acc1= 97.00,acc3= 99.44,acc10= 99.78\n",
      "eval E046: 100% 177/177 [00:07<00:00, 23.97it/s]\n",
      "INFO - 02/01/23 00:46:53 - 0:16:32 - #################################################################################################################\n",
      "INFO - 02/01/23 00:46:53 - 0:16:32 - Test Epoch 46: LOSS= 9.54727, acc1= 40.28, acc3= 54.27, acc10= 61.14\n",
      "INFO - 02/01/23 00:46:53 - 0:16:32 - #################################################################################################################\n",
      "train E047: 100% 167/167 [00:12<00:00, 12.96it/s]\n",
      "INFO - 02/01/23 00:47:06 - 0:16:45 - Train Epoch 47: LOSS= 0.83097, lr= 0.000040, acc1= 96.97,acc3= 99.55,acc10= 99.89\n",
      "eval E047: 100% 177/177 [00:07<00:00, 23.61it/s]\n",
      "INFO - 02/01/23 00:47:14 - 0:16:52 - #################################################################################################################\n",
      "INFO - 02/01/23 00:47:14 - 0:16:52 - Test Epoch 47: LOSS= 9.52486, acc1= 40.60, acc3= 54.34, acc10= 61.00\n",
      "INFO - 02/01/23 00:47:14 - 0:16:52 - #################################################################################################################\n",
      "train E048: 100% 167/167 [00:13<00:00, 12.68it/s]\n",
      "INFO - 02/01/23 00:47:27 - 0:17:05 - Train Epoch 48: LOSS= 0.87975, lr= 0.000040, acc1= 96.48,acc3= 99.33,acc10= 99.78\n",
      "eval E048: 100% 177/177 [00:07<00:00, 23.37it/s]\n",
      "INFO - 02/01/23 00:47:35 - 0:17:13 - #################################################################################################################\n",
      "INFO - 02/01/23 00:47:35 - 0:17:13 - Test Epoch 48: LOSS= 9.35175, acc1= 40.70, acc3= 54.62, acc10= 61.18\n",
      "INFO - 02/01/23 00:47:35 - 0:17:13 - #################################################################################################################\n",
      "train E049: 100% 167/167 [00:12<00:00, 13.81it/s]\n",
      "INFO - 02/01/23 00:47:47 - 0:17:25 - Train Epoch 49: LOSS= 0.82919, lr= 0.000040, acc1= 97.56,acc3= 99.78,acc10= 99.93\n",
      "eval E049: 100% 177/177 [00:07<00:00, 23.06it/s]\n",
      "INFO - 02/01/23 00:47:54 - 0:17:33 - #################################################################################################################\n",
      "INFO - 02/01/23 00:47:54 - 0:17:33 - Test Epoch 49: LOSS= 9.48944, acc1= 40.45, acc3= 54.66, acc10= 61.03\n",
      "INFO - 02/01/23 00:47:54 - 0:17:33 - #################################################################################################################\n",
      "train E050: 100% 167/167 [00:12<00:00, 13.16it/s]\n",
      "INFO - 02/01/23 00:48:07 - 0:17:45 - Train Epoch 50: LOSS= 0.85007, lr= 0.000040, acc1= 96.93,acc3= 99.48,acc10= 99.74\n",
      "eval E050: 100% 177/177 [00:07<00:00, 23.37it/s]\n",
      "INFO - 02/01/23 00:48:15 - 0:17:53 - #################################################################################################################\n",
      "INFO - 02/01/23 00:48:15 - 0:17:53 - Test Epoch 50: LOSS= 9.47848, acc1= 40.56, acc3= 54.66, acc10= 60.89\n",
      "INFO - 02/01/23 00:48:15 - 0:17:53 - #################################################################################################################\n",
      "train E051: 100% 167/167 [00:13<00:00, 12.74it/s]\n",
      "INFO - 02/01/23 00:48:28 - 0:18:06 - Train Epoch 51: LOSS= 0.80201, lr= 0.000040, acc1= 97.23,acc3= 99.59,acc10= 99.85\n",
      "eval E051: 100% 177/177 [00:08<00:00, 20.10it/s]\n",
      "INFO - 02/01/23 00:48:37 - 0:18:15 - #################################################################################################################\n",
      "INFO - 02/01/23 00:48:37 - 0:18:15 - Test Epoch 51: LOSS= 9.56912, acc1= 40.42, acc3= 54.62, acc10= 61.28\n",
      "INFO - 02/01/23 00:48:37 - 0:18:15 - #################################################################################################################\n",
      "train E052: 100% 167/167 [00:12<00:00, 12.95it/s]\n",
      "INFO - 02/01/23 00:48:49 - 0:18:28 - Train Epoch 52: LOSS= 0.80469, lr= 0.000040, acc1= 97.30,acc3= 99.44,acc10= 99.74\n",
      "eval E052: 100% 177/177 [00:08<00:00, 20.60it/s]\n",
      "INFO - 02/01/23 00:48:58 - 0:18:36 - #################################################################################################################\n",
      "INFO - 02/01/23 00:48:58 - 0:18:36 - Test Epoch 52: LOSS= 9.67600, acc1= 40.56, acc3= 54.73, acc10= 61.14\n",
      "INFO - 02/01/23 00:48:58 - 0:18:36 - #################################################################################################################\n",
      "train E053: 100% 167/167 [00:13<00:00, 12.75it/s]\n",
      "INFO - 02/01/23 00:49:11 - 0:18:49 - Train Epoch 53: LOSS= 0.76287, lr= 0.000040, acc1= 97.15,acc3= 99.59,acc10= 99.81\n",
      "eval E053: 100% 177/177 [00:07<00:00, 23.63it/s]\n",
      "INFO - 02/01/23 00:49:19 - 0:18:57 - #################################################################################################################\n",
      "INFO - 02/01/23 00:49:19 - 0:18:57 - Test Epoch 53: LOSS= 9.73362, acc1= 40.77, acc3= 54.84, acc10= 61.11\n",
      "INFO - 02/01/23 00:49:19 - 0:18:57 - #################################################################################################################\n",
      "train E054: 100% 167/167 [00:12<00:00, 12.96it/s]\n",
      "INFO - 02/01/23 00:49:32 - 0:19:10 - Train Epoch 54: LOSS= 0.80137, lr= 0.000040, acc1= 97.41,acc3= 99.66,acc10= 99.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval E054: 100% 177/177 [00:07<00:00, 23.74it/s]\n",
      "INFO - 02/01/23 00:49:39 - 0:19:17 - #################################################################################################################\n",
      "INFO - 02/01/23 00:49:39 - 0:19:17 - Test Epoch 54: LOSS= 9.71557, acc1= 40.60, acc3= 54.84, acc10= 60.96\n",
      "INFO - 02/01/23 00:49:39 - 0:19:17 - #################################################################################################################\n",
      "train E055: 100% 167/167 [00:13<00:00, 12.81it/s]\n",
      "INFO - 02/01/23 00:49:52 - 0:19:30 - Train Epoch 55: LOSS= 0.73953, lr= 0.000040, acc1= 97.45,acc3= 99.66,acc10= 99.78\n",
      "eval E055: 100% 177/177 [00:07<00:00, 23.49it/s]\n",
      "INFO - 02/01/23 00:50:00 - 0:19:38 - #################################################################################################################\n",
      "INFO - 02/01/23 00:50:00 - 0:19:38 - Test Epoch 55: LOSS= 9.97247, acc1= 40.38, acc3= 54.52, acc10= 61.11\n",
      "INFO - 02/01/23 00:50:00 - 0:19:38 - #################################################################################################################\n",
      "INFO - 02/01/23 00:50:04 - 0:19:42 - best performance =  40.60, 55.79, 62.84. best epoch = 25, correspond_loss= 6.7828\n",
      "INFO - 02/01/23 00:50:04 - 0:19:42 -  fusion_model_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_fact_BERT_3.pkl\n",
      "INFO - 02/01/23 00:50:04 - 0:19:42 -  answer_net_path = /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_fact_MLP_3.pkl\n"
     ]
    }
   ],
   "source": [
    "# relation间训练 BERT rnn  \n",
    "#待跑\n",
    "%cd code\n",
    "!python main_bert_cnn.py --gpu_id 8 --exp_name fact_space --exp_id bert --fusion_model BERT --data_choice 3 --method_choice W2V  --save_model 1 --ZSL 0  --fact_map 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c5793c92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:52:39.032835Z",
     "start_time": "2023-01-15T02:51:27.479668Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'code'\n",
      "/ws/code/ZS-F-VQA/code\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "INFO - 01/15/23 10:51:30 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 01/15/23 10:51:30 - 0:00:00 - The experiment will be stored in dump/0115-version_prediction/rel3_fact5data_3score_10\n",
      "                                     \n",
      "INFO - 01/15/23 10:51:30 - 0:00:00 - Running command: python joint_test_version.py --gpu_id 8 --exp_name version_prediction --ZSL 0 --exp_id rel3_fact5data_3score_10 --data_choice 3 --top_rel 3 --top_fact 1 --soft_score 10 --mrr 1\n",
      "\n",
      "* Loading vectors to /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/exp_data/common_data/glove.840B.300d.txt.pt\n",
      "use train data: 3\n",
      "batch_size 16\n",
      "batch_size 16\n",
      "INFO - 01/15/23 10:51:44 - 0:00:15 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO - 01/15/23 10:51:44 - 0:00:15 - extracting archive file /root/.cache/torch/pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp7ex9ulhe\n",
      "embeddings.word_embeddings.weight:\tFalse\n",
      "embeddings.position_embeddings.weight:\tFalse\n",
      "embeddings.token_type_embeddings.weight:\tFalse\n",
      "embeddings.LayerNorm.weight:\tFalse\n",
      "embeddings.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.attention.self.query.weight:\tFalse\n",
      "encoder.layer.0.attention.self.query.bias:\tFalse\n",
      "encoder.layer.0.attention.self.key.weight:\tFalse\n",
      "encoder.layer.0.attention.self.key.bias:\tFalse\n",
      "encoder.layer.0.attention.self.value.weight:\tFalse\n",
      "encoder.layer.0.attention.self.value.bias:\tFalse\n",
      "encoder.layer.0.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.0.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.0.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.0.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.0.output.dense.weight:\tFalse\n",
      "encoder.layer.0.output.dense.bias:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.0.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.attention.self.query.weight:\tFalse\n",
      "encoder.layer.1.attention.self.query.bias:\tFalse\n",
      "encoder.layer.1.attention.self.key.weight:\tFalse\n",
      "encoder.layer.1.attention.self.key.bias:\tFalse\n",
      "encoder.layer.1.attention.self.value.weight:\tFalse\n",
      "encoder.layer.1.attention.self.value.bias:\tFalse\n",
      "encoder.layer.1.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.1.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.1.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.1.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.1.output.dense.weight:\tFalse\n",
      "encoder.layer.1.output.dense.bias:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.1.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.attention.self.query.weight:\tFalse\n",
      "encoder.layer.2.attention.self.query.bias:\tFalse\n",
      "encoder.layer.2.attention.self.key.weight:\tFalse\n",
      "encoder.layer.2.attention.self.key.bias:\tFalse\n",
      "encoder.layer.2.attention.self.value.weight:\tFalse\n",
      "encoder.layer.2.attention.self.value.bias:\tFalse\n",
      "encoder.layer.2.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.2.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.2.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.2.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.2.output.dense.weight:\tFalse\n",
      "encoder.layer.2.output.dense.bias:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.2.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.attention.self.query.weight:\tFalse\n",
      "encoder.layer.3.attention.self.query.bias:\tFalse\n",
      "encoder.layer.3.attention.self.key.weight:\tFalse\n",
      "encoder.layer.3.attention.self.key.bias:\tFalse\n",
      "encoder.layer.3.attention.self.value.weight:\tFalse\n",
      "encoder.layer.3.attention.self.value.bias:\tFalse\n",
      "encoder.layer.3.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.3.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.3.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.3.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.3.output.dense.weight:\tFalse\n",
      "encoder.layer.3.output.dense.bias:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.3.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.attention.self.query.weight:\tFalse\n",
      "encoder.layer.4.attention.self.query.bias:\tFalse\n",
      "encoder.layer.4.attention.self.key.weight:\tFalse\n",
      "encoder.layer.4.attention.self.key.bias:\tFalse\n",
      "encoder.layer.4.attention.self.value.weight:\tFalse\n",
      "encoder.layer.4.attention.self.value.bias:\tFalse\n",
      "encoder.layer.4.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.4.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.4.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.4.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.4.output.dense.weight:\tFalse\n",
      "encoder.layer.4.output.dense.bias:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.4.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.attention.self.query.weight:\tFalse\n",
      "encoder.layer.5.attention.self.query.bias:\tFalse\n",
      "encoder.layer.5.attention.self.key.weight:\tFalse\n",
      "encoder.layer.5.attention.self.key.bias:\tFalse\n",
      "encoder.layer.5.attention.self.value.weight:\tFalse\n",
      "encoder.layer.5.attention.self.value.bias:\tFalse\n",
      "encoder.layer.5.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.5.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.5.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.5.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.5.output.dense.weight:\tFalse\n",
      "encoder.layer.5.output.dense.bias:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.5.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.attention.self.query.weight:\tFalse\n",
      "encoder.layer.6.attention.self.query.bias:\tFalse\n",
      "encoder.layer.6.attention.self.key.weight:\tFalse\n",
      "encoder.layer.6.attention.self.key.bias:\tFalse\n",
      "encoder.layer.6.attention.self.value.weight:\tFalse\n",
      "encoder.layer.6.attention.self.value.bias:\tFalse\n",
      "encoder.layer.6.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.6.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.6.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.6.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.6.output.dense.weight:\tFalse\n",
      "encoder.layer.6.output.dense.bias:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.6.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.attention.self.query.weight:\tFalse\n",
      "encoder.layer.7.attention.self.query.bias:\tFalse\n",
      "encoder.layer.7.attention.self.key.weight:\tFalse\n",
      "encoder.layer.7.attention.self.key.bias:\tFalse\n",
      "encoder.layer.7.attention.self.value.weight:\tFalse\n",
      "encoder.layer.7.attention.self.value.bias:\tFalse\n",
      "encoder.layer.7.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.7.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.7.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.7.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.7.output.dense.weight:\tFalse\n",
      "encoder.layer.7.output.dense.bias:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.7.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.attention.self.query.weight:\tFalse\n",
      "encoder.layer.8.attention.self.query.bias:\tFalse\n",
      "encoder.layer.8.attention.self.key.weight:\tFalse\n",
      "encoder.layer.8.attention.self.key.bias:\tFalse\n",
      "encoder.layer.8.attention.self.value.weight:\tFalse\n",
      "encoder.layer.8.attention.self.value.bias:\tFalse\n",
      "encoder.layer.8.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.8.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.8.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.8.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.8.output.dense.weight:\tFalse\n",
      "encoder.layer.8.output.dense.bias:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.8.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.attention.self.query.weight:\tFalse\n",
      "encoder.layer.9.attention.self.query.bias:\tFalse\n",
      "encoder.layer.9.attention.self.key.weight:\tFalse\n",
      "encoder.layer.9.attention.self.key.bias:\tFalse\n",
      "encoder.layer.9.attention.self.value.weight:\tFalse\n",
      "encoder.layer.9.attention.self.value.bias:\tFalse\n",
      "encoder.layer.9.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.9.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.9.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.9.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.9.output.dense.weight:\tFalse\n",
      "encoder.layer.9.output.dense.bias:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.9.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.attention.self.query.weight:\tFalse\n",
      "encoder.layer.10.attention.self.query.bias:\tFalse\n",
      "encoder.layer.10.attention.self.key.weight:\tFalse\n",
      "encoder.layer.10.attention.self.key.bias:\tFalse\n",
      "encoder.layer.10.attention.self.value.weight:\tFalse\n",
      "encoder.layer.10.attention.self.value.bias:\tFalse\n",
      "encoder.layer.10.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.10.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.10.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.10.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.10.output.dense.weight:\tFalse\n",
      "encoder.layer.10.output.dense.bias:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.10.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.attention.self.query.weight:\tFalse\n",
      "encoder.layer.11.attention.self.query.bias:\tFalse\n",
      "encoder.layer.11.attention.self.key.weight:\tFalse\n",
      "encoder.layer.11.attention.self.key.bias:\tFalse\n",
      "encoder.layer.11.attention.self.value.weight:\tFalse\n",
      "encoder.layer.11.attention.self.value.bias:\tFalse\n",
      "encoder.layer.11.attention.output.dense.weight:\tFalse\n",
      "encoder.layer.11.attention.output.dense.bias:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.attention.output.LayerNorm.bias:\tFalse\n",
      "encoder.layer.11.intermediate.dense.weight:\tFalse\n",
      "encoder.layer.11.intermediate.dense.bias:\tFalse\n",
      "encoder.layer.11.output.dense.weight:\tFalse\n",
      "encoder.layer.11.output.dense.bias:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.weight:\tFalse\n",
      "encoder.layer.11.output.LayerNorm.bias:\tFalse\n",
      "pooler.dense.weight:\tFalse\n",
      "pooler.dense.bias:\tFalse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin test! ...\n",
      "loading model  ...\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_answer_SAN_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_answer_MLP_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_relation_MLPQ_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_relation_MLP_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/fusion/general_fact_BERT_3.pkl model done!\n",
      "loading /ws/code/ZS-F-VQA/data/KG_VQA/fvqa/model_save/embedding/general_fact_MLP_3.pkl model done!\n",
      "use train data: 3\n",
      "batch_size 16\n",
      "use train data: 3\n",
      "batch_size 16\n",
      "  0%|                                                   | 0/177 [00:00<?, ?it/s]pre tensor([229.6721, 223.6250, 222.8338, 254.5532, 220.9849, 217.6131, 228.3917,\n",
      "        214.9400, 221.1468, 215.9988, 225.2060, 225.4382, 226.9471, 220.4655,\n",
      "        218.5087, 224.3367, 240.3174, 226.9881, 217.3538, 291.1552, 229.3745,\n",
      "        251.0191, 244.2145, 223.0420, 214.4972, 269.4458, 224.4652, 209.3833,\n",
      "        222.0690, 243.9139, 222.4798, 214.8600, 220.2093, 216.9550, 228.3423,\n",
      "        228.5414, 223.6777, 212.7744, 232.7888, 238.9922, 208.9712, 228.1116,\n",
      "        251.8602, 227.9680, 211.3993, 227.3545, 213.2326, 235.0718, 222.9418,\n",
      "        210.6904, 237.5021, 215.5456, 215.7923, 224.0381, 210.2934, 220.3437,\n",
      "        234.5627, 210.2961, 218.3480, 224.4177, 228.2213, 217.0259, 226.3947,\n",
      "        208.1052, 234.1749, 219.1592, 231.0496, 212.1626, 221.5326, 222.6427,\n",
      "        251.9922, 231.4914, 222.5705, 216.1669, 218.9808, 234.8072, 237.1153,\n",
      "        220.5069, 220.1081, 215.1031, 225.3333, 222.1614, 219.9029, 223.6837,\n",
      "        220.6748, 222.0671, 228.2143, 218.8951, 209.6225, 239.5814, 222.8885,\n",
      "        212.0076, 219.0967, 224.6213, 223.9810, 221.8376, 214.4867, 215.9058,\n",
      "        218.2608, 220.1209, 229.1306, 220.6173, 225.2998, 219.1090, 219.6269,\n",
      "        233.8429, 219.9650, 214.1104, 245.7070, 224.9119, 215.3208, 237.2041,\n",
      "        217.0556, 220.7280, 216.7931, 224.2312, 252.9799, 232.9585, 208.1805,\n",
      "        216.1615, 232.1932, 229.4303, 218.6491, 213.0824, 221.7840, 221.3147,\n",
      "        213.6889, 214.0198, 210.1541, 224.3821, 217.1310, 224.8226, 225.7075,\n",
      "        229.8081, 216.8625, 225.7933, 218.6524, 231.4081, 204.9634, 213.7328,\n",
      "        213.6145, 244.2097, 217.3150, 230.5303, 239.2488, 213.6112, 229.6802,\n",
      "        230.4551, 220.5627, 234.7850, 225.7651, 237.6203, 203.7893, 222.9595,\n",
      "        234.3902, 216.7574, 221.3124, 247.6062, 226.2660, 226.6039, 235.4905,\n",
      "        231.7517, 221.4438, 218.0477, 234.0589, 224.1603, 221.2526, 224.3170,\n",
      "        215.0525, 218.0705, 237.9614, 210.4003, 230.6191, 228.1528, 233.8136,\n",
      "        230.6464, 217.6969, 224.5509, 216.4749, 222.7018, 227.9404, 222.2215,\n",
      "        223.9315, 232.5285, 224.6154, 219.2290, 212.3516, 229.0401, 218.8885,\n",
      "        229.0577, 213.6802, 224.6955, 240.0555, 212.8097, 225.3777, 225.0763,\n",
      "        214.2549, 210.0255, 220.3520, 227.3435, 228.0132, 221.1659, 221.6894,\n",
      "        233.0339, 212.1740, 219.3654, 231.7971, 223.8393, 231.4206, 216.6298,\n",
      "        233.1760, 221.0538, 218.9901, 226.4086, 225.0237, 222.8246, 229.7673,\n",
      "        217.7275, 213.4260, 218.1592, 221.2577, 210.6621, 228.2162, 213.8888,\n",
      "        213.8473, 229.1014, 218.3959, 217.6826, 227.9881, 229.9205, 220.8578,\n",
      "        212.5100, 225.3060, 221.9811, 217.0429, 213.4884, 237.4404, 225.9823,\n",
      "        224.2942, 229.9565, 227.6153, 214.1528, 223.4685, 218.7862, 210.1342,\n",
      "        234.5132, 216.9969, 236.1680, 218.9879, 238.3599, 225.2020, 228.5322,\n",
      "        216.5900, 223.5555, 230.4001, 217.4101, 225.9344, 214.4684, 223.8157,\n",
      "        221.4055, 221.9169, 229.1066, 214.5691, 247.3145, 227.1068, 218.5598,\n",
      "        221.4178, 216.7995, 227.1029, 218.4499, 218.5001, 238.4486, 231.2753,\n",
      "        230.4780, 213.9068, 229.4515, 209.9234, 238.2785, 223.1645, 225.0128,\n",
      "        237.5781, 218.6016, 226.5800, 228.4460, 223.4670, 237.4423, 209.7827,\n",
      "        229.9064, 222.7679, 226.3838, 227.5717, 224.4070, 227.9373, 231.1149,\n",
      "        227.5384, 226.8652, 215.6043, 226.6619, 227.4443, 224.8804, 225.3231,\n",
      "        222.8291, 227.6008, 221.9257, 228.0626, 220.9162, 222.3086, 221.8230,\n",
      "        232.8077, 228.5051, 231.7312, 214.5777, 231.9484, 230.2674, 221.3342,\n",
      "        234.2070, 226.1369, 225.7462, 216.3214, 231.5609, 234.8777, 215.6987,\n",
      "        219.0589, 213.4875, 213.8479, 233.4620, 217.3061, 229.3802, 227.8244,\n",
      "        212.3722, 217.8676, 223.9709, 232.1686, 246.7562, 229.7786, 222.1909,\n",
      "        214.1677, 228.8818, 218.4823, 221.6013, 227.1988, 209.8529, 228.5871,\n",
      "        219.6665, 227.6992, 222.6158, 220.6133, 222.0421, 224.9974, 224.0170,\n",
      "        231.9663, 229.5334, 209.8105, 218.6772, 221.3348, 231.0537, 220.5485,\n",
      "        223.9020, 236.0332, 222.5901, 222.5901, 218.1791, 230.9742, 216.4777,\n",
      "        225.1406, 241.0892, 214.4595, 225.9429, 232.9017, 215.0480, 221.4145,\n",
      "        226.9651, 218.6184, 217.4118, 213.0056, 223.8704, 205.2058, 225.6399,\n",
      "        210.0289, 230.1759, 227.6844, 213.8871, 228.1684, 225.8356, 223.3666,\n",
      "        232.3197, 216.6448, 244.8460, 232.2131, 218.9181, 236.0399, 234.6049,\n",
      "        221.3729, 232.6783, 225.9034, 219.9825, 230.5070, 210.5252, 234.8589,\n",
      "        220.6863, 221.8977, 227.1743, 230.2695, 222.1833, 226.1017, 230.2229,\n",
      "        226.7936, 220.1214, 219.5107, 217.7159, 230.8858, 231.5994, 221.1747,\n",
      "        236.5152, 208.2706, 220.5615, 218.5632, 223.5108, 225.5785, 225.3813,\n",
      "        216.4232, 240.5293, 209.8132, 214.1717, 233.8535, 219.6977, 221.8926,\n",
      "        229.2462, 212.8040, 226.0717, 234.3210, 225.2751, 222.6750, 240.6607,\n",
      "        228.3520, 230.4279, 217.4417, 228.1066, 226.7142, 212.9531, 229.2754,\n",
      "        225.8879, 238.6370, 237.3246, 225.9704, 221.0312, 221.4646, 228.7373,\n",
      "        217.2935, 233.4447, 234.5487, 224.7554, 223.2602, 229.3299, 230.5361,\n",
      "        223.3551, 229.1320, 228.4615, 219.4050, 211.1304, 211.3787, 216.3739,\n",
      "        234.8248, 228.5674, 226.7981, 230.2984, 220.2472, 224.6838, 224.8976,\n",
      "        226.2517, 213.1588, 217.7996, 220.3354, 237.3858, 224.1740, 218.6805,\n",
      "        215.4673, 234.1400, 234.7916, 233.9750, 217.2812, 234.8107, 230.2608,\n",
      "        230.0330, 227.3233, 220.5476, 230.3010, 238.6743, 217.3237, 222.2975,\n",
      "        222.5901, 228.1382, 221.0744, 221.5127, 225.8611, 208.4346, 233.6782,\n",
      "        226.3094, 220.6610, 222.5901], device='cuda:8', dtype=torch.float64)\n",
      "100%|█████████████████████████████████████████| 177/177 [00:40<00:00,  4.41it/s]\n",
      "self.min: 75.06101989746094\n",
      "self.max: 360.2621765136719\n",
      "INFO - 01/15/23 10:52:37 - 0:01:07 - #################################################################################################################\n",
      "INFO - 01/15/23 10:52:37 - 0:01:07 - orig  acc1= 48.10, acc3= 66.24, acc10= 80.73\n",
      "INFO - 01/15/23 10:52:37 - 0:01:07 - ####  acc1= 64.82, acc3= 79.14, acc10= 88.59\n",
      "INFO - 01/15/23 10:52:37 - 0:01:07 - #################################################################################################################\n",
      "INFO - 01/15/23 10:52:37 - 0:01:07 - #################################################################################################################\n",
      "INFO - 01/15/23 10:52:37 - 0:01:07 - orig  mrr= 0.5937, mr = 15.61\n",
      "INFO - 01/15/23 10:52:37 - 0:01:07 - ####  mrr= 0.7331, mr = 9.74\n",
      "INFO - 01/15/23 10:52:37 - 0:01:07 - #################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "#  分析实验  联合测试2\n",
    "%cd code\n",
    "!python joint_test_version.py --gpu_id 8 --exp_name version_prediction --ZSL 0 --exp_id rel3_fact5data_3score_10 --data_choice 3  --top_rel 3 --top_fact 1 --soft_score 10  --mrr 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f93fbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T09:43:50.850084Z",
     "start_time": "2023-03-18T09:43:50.840592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.22\n",
      "79.27600000000001\n",
      "88.14200000000001\n",
      "0.7354\n",
      "10.138\n"
     ]
    }
   ],
   "source": [
    "a= [65.32, 79.31, 88.03, 0.736, 10.24]\n",
    "b= [64.82, 79.14, 88.59, 0.733, 9.73]\n",
    "for i in range(5):\n",
    "    print((a[i]*0.8+b[i]*0.2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
